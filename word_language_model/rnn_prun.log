<class 'torch.Tensor'> torch.Size([33278, 1500])
<class 'torch.Tensor'> torch.Size([6000, 1500])
<class 'torch.Tensor'> torch.Size([6000, 1500])
<class 'torch.Tensor'> torch.Size([6000])
<class 'torch.Tensor'> torch.Size([6000])
<class 'torch.Tensor'> torch.Size([6000, 1500])
<class 'torch.Tensor'> torch.Size([6000, 1500])
<class 'torch.Tensor'> torch.Size([6000])
<class 'torch.Tensor'> torch.Size([6000])
<class 'torch.Tensor'> torch.Size([33278])
RNNModel(
  (drop): Dropout(p=0.65)
  (encoder): Embedding(33278, 1500)
  (rnn): LSTM(1500, 1500, num_layers=2, dropout=0.65)
  (decoder): Linear(in_features=1500, out_features=33278, bias=True)
)
Dropout(p=0.65)
Embedding(33278, 1500)
LSTM(1500, 1500, num_layers=2, dropout=0.65)
Linear(in_features=1500, out_features=33278, bias=True)
| epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 57.57 | loss  7.94 | ppl  2819.11
| epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 57.23 | loss  6.84 | ppl   932.80
| epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 57.34 | loss  6.45 | ppl   631.39
| epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 57.45 | loss  6.30 | ppl   545.28
| epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.56 | loss  6.18 | ppl   484.46
| epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.66 | loss  6.12 | ppl   456.78
| epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.76 | loss  6.02 | ppl   411.93
| epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.82 | loss  6.03 | ppl   415.18
| epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.94 | loss  5.89 | ppl   359.80
| epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.07 | loss  5.86 | ppl   350.21
| epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.09 | loss  5.75 | ppl   313.41
| epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.19 | loss  5.76 | ppl   315.83
| epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.19 | loss  5.74 | ppl   311.87
| epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.36 | loss  5.64 | ppl   280.54
-----------------------------------------------------------------------------------------
| end of epoch   1 | time: 179.90s | valid loss  5.48 | valid ppl   239.88
-----------------------------------------------------------------------------------------
| epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch 58.20 | loss  5.63 | ppl   278.30
| epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch 58.02 | loss  5.61 | ppl   272.19
| epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch 58.09 | loss  5.44 | ppl   230.34
| epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch 58.46 | loss  5.46 | ppl   234.93
| epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.91 | loss  5.43 | ppl   228.03
| epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.90 | loss  5.43 | ppl   227.51
| epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 59.13 | loss  5.42 | ppl   225.48
| epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 59.42 | loss  5.47 | ppl   237.33
| epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch 59.18 | loss  5.34 | ppl   209.24
| epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.94 | loss  5.36 | ppl   213.39
| epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch 59.44 | loss  5.27 | ppl   193.91
| epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch 59.45 | loss  5.30 | ppl   200.47
| epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 59.50 | loss  5.31 | ppl   201.41
| epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 59.40 | loss  5.23 | ppl   186.55
-----------------------------------------------------------------------------------------
| end of epoch   2 | time: 184.46s | valid loss  5.15 | valid ppl   172.05
-----------------------------------------------------------------------------------------
| epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 59.28 | loss  5.27 | ppl   194.85
| epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch 58.66 | loss  5.28 | ppl   196.78
| epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 58.92 | loss  5.10 | ppl   164.81
| epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 59.53 | loss  5.15 | ppl   172.29
| epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 59.62 | loss  5.14 | ppl   169.88
| epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 59.52 | loss  5.13 | ppl   169.72
| epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 59.42 | loss  5.15 | ppl   172.79
| epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 59.58 | loss  5.22 | ppl   184.48
| epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 59.99 | loss  5.09 | ppl   162.91
| epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 59.49 | loss  5.13 | ppl   168.49
| epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 59.59 | loss  5.03 | ppl   153.33
| epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 59.64 | loss  5.06 | ppl   158.08
| epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch 59.90 | loss  5.08 | ppl   160.48
| epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 59.84 | loss  5.01 | ppl   149.50
-----------------------------------------------------------------------------------------
| end of epoch   3 | time: 186.15s | valid loss  5.00 | valid ppl   148.08
-----------------------------------------------------------------------------------------
| epoch   4 |   200/ 2983 batches | lr 20.00 | ms/batch 58.98 | loss  5.06 | ppl   157.43
| epoch   4 |   400/ 2983 batches | lr 20.00 | ms/batch 58.34 | loss  5.08 | ppl   160.41
| epoch   4 |   600/ 2983 batches | lr 20.00 | ms/batch 58.74 | loss  4.90 | ppl   134.39
| epoch   4 |   800/ 2983 batches | lr 20.00 | ms/batch 58.86 | loss  4.96 | ppl   142.06
| epoch   4 |  1000/ 2983 batches | lr 20.00 | ms/batch 59.33 | loss  4.95 | ppl   140.84
| epoch   4 |  1200/ 2983 batches | lr 20.00 | ms/batch 59.37 | loss  4.95 | ppl   141.43
| epoch   4 |  1400/ 2983 batches | lr 20.00 | ms/batch 59.75 | loss  4.98 | ppl   145.90
| epoch   4 |  1600/ 2983 batches | lr 20.00 | ms/batch 59.53 | loss  5.05 | ppl   155.91
| epoch   4 |  1800/ 2983 batches | lr 20.00 | ms/batch 59.74 | loss  4.92 | ppl   137.31
| epoch   4 |  2000/ 2983 batches | lr 20.00 | ms/batch 59.54 | loss  4.97 | ppl   143.83
| epoch   4 |  2200/ 2983 batches | lr 20.00 | ms/batch 59.47 | loss  4.86 | ppl   129.11
| epoch   4 |  2400/ 2983 batches | lr 20.00 | ms/batch 59.73 | loss  4.90 | ppl   134.12
| epoch   4 |  2600/ 2983 batches | lr 20.00 | ms/batch 59.42 | loss  4.92 | ppl   137.00
| epoch   4 |  2800/ 2983 batches | lr 20.00 | ms/batch 59.57 | loss  4.86 | ppl   128.44
-----------------------------------------------------------------------------------------
| end of epoch   4 | time: 185.81s | valid loss  4.90 | valid ppl   134.17
-----------------------------------------------------------------------------------------
| epoch   5 |   200/ 2983 batches | lr 20.00 | ms/batch 58.78 | loss  4.91 | ppl   135.21
| epoch   5 |   400/ 2983 batches | lr 20.00 | ms/batch 58.28 | loss  4.93 | ppl   138.26
| epoch   5 |   600/ 2983 batches | lr 20.00 | ms/batch 59.08 | loss  4.75 | ppl   115.60
| epoch   5 |   800/ 2983 batches | lr 20.00 | ms/batch 59.25 | loss  4.81 | ppl   123.24
| epoch   5 |  1000/ 2983 batches | lr 20.00 | ms/batch 59.08 | loss  4.81 | ppl   122.36
| epoch   5 |  1200/ 2983 batches | lr 20.00 | ms/batch 59.65 | loss  4.82 | ppl   124.10
| epoch   5 |  1400/ 2983 batches | lr 20.00 | ms/batch 59.32 | loss  4.85 | ppl   128.10
| epoch   5 |  1600/ 2983 batches | lr 20.00 | ms/batch 59.52 | loss  4.92 | ppl   136.80
| epoch   5 |  1800/ 2983 batches | lr 20.00 | ms/batch 59.43 | loss  4.80 | ppl   121.05
| epoch   5 |  2000/ 2983 batches | lr 20.00 | ms/batch 59.83 | loss  4.84 | ppl   126.95
| epoch   5 |  2200/ 2983 batches | lr 20.00 | ms/batch 59.03 | loss  4.73 | ppl   113.85
| epoch   5 |  2400/ 2983 batches | lr 20.00 | ms/batch 59.24 | loss  4.77 | ppl   118.28
| epoch   5 |  2600/ 2983 batches | lr 20.00 | ms/batch 59.57 | loss  4.80 | ppl   121.23
| epoch   5 |  2800/ 2983 batches | lr 20.00 | ms/batch 59.37 | loss  4.73 | ppl   113.85
-----------------------------------------------------------------------------------------
| end of epoch   5 | time: 185.37s | valid loss  4.83 | valid ppl   124.83
-----------------------------------------------------------------------------------------
| epoch   6 |   200/ 2983 batches | lr 20.00 | ms/batch 59.31 | loss  4.79 | ppl   120.22
| epoch   6 |   400/ 2983 batches | lr 20.00 | ms/batch 58.72 | loss  4.82 | ppl   123.36
| epoch   6 |   600/ 2983 batches | lr 20.00 | ms/batch 59.20 | loss  4.63 | ppl   102.79
| epoch   6 |   800/ 2983 batches | lr 20.00 | ms/batch 59.36 | loss  4.69 | ppl   109.12
| epoch   6 |  1000/ 2983 batches | lr 20.00 | ms/batch 59.46 | loss  4.70 | ppl   109.52
| epoch   6 |  1200/ 2983 batches | lr 20.00 | ms/batch 59.67 | loss  4.70 | ppl   110.40
| epoch   6 |  1400/ 2983 batches | lr 20.00 | ms/batch 59.47 | loss  4.75 | ppl   115.13
| epoch   6 |  1600/ 2983 batches | lr 20.00 | ms/batch 59.59 | loss  4.82 | ppl   123.53
| epoch   6 |  1800/ 2983 batches | lr 20.00 | ms/batch 59.61 | loss  4.70 | ppl   109.55
| epoch   6 |  2000/ 2983 batches | lr 20.00 | ms/batch 59.82 | loss  4.74 | ppl   114.40
| epoch   6 |  2200/ 2983 batches | lr 20.00 | ms/batch 59.69 | loss  4.63 | ppl   102.59
| epoch   6 |  2400/ 2983 batches | lr 20.00 | ms/batch 59.77 | loss  4.67 | ppl   106.96
| epoch   6 |  2600/ 2983 batches | lr 20.00 | ms/batch 59.46 | loss  4.70 | ppl   109.44
| epoch   6 |  2800/ 2983 batches | lr 20.00 | ms/batch 59.79 | loss  4.64 | ppl   103.44
-----------------------------------------------------------------------------------------
| end of epoch   6 | time: 186.06s | valid loss  4.77 | valid ppl   118.48
-----------------------------------------------------------------------------------------
| epoch   7 |   200/ 2983 batches | lr 20.00 | ms/batch 59.30 | loss  4.69 | ppl   109.02
| epoch   7 |   400/ 2983 batches | lr 20.00 | ms/batch 58.60 | loss  4.72 | ppl   112.02
| epoch   7 |   600/ 2983 batches | lr 20.00 | ms/batch 58.95 | loss  4.53 | ppl    93.17
| epoch   7 |   800/ 2983 batches | lr 20.00 | ms/batch 59.17 | loss  4.60 | ppl    99.25
| epoch   7 |  1000/ 2983 batches | lr 20.00 | ms/batch 59.82 | loss  4.60 | ppl    99.61
| epoch   7 |  1200/ 2983 batches | lr 20.00 | ms/batch 59.52 | loss  4.62 | ppl   101.09
| epoch   7 |  1400/ 2983 batches | lr 20.00 | ms/batch 59.47 | loss  4.66 | ppl   105.46
| epoch   7 |  1600/ 2983 batches | lr 20.00 | ms/batch 59.78 | loss  4.73 | ppl   113.13
| epoch   7 |  1800/ 2983 batches | lr 20.00 | ms/batch 59.53 | loss  4.61 | ppl   100.93
| epoch   7 |  2000/ 2983 batches | lr 20.00 | ms/batch 59.24 | loss  4.66 | ppl   105.46
| epoch   7 |  2200/ 2983 batches | lr 20.00 | ms/batch 59.56 | loss  4.54 | ppl    93.76
| epoch   7 |  2400/ 2983 batches | lr 20.00 | ms/batch 59.13 | loss  4.58 | ppl    97.64
| epoch   7 |  2600/ 2983 batches | lr 20.00 | ms/batch 59.64 | loss  4.61 | ppl   100.75
| epoch   7 |  2800/ 2983 batches | lr 20.00 | ms/batch 60.03 | loss  4.56 | ppl    95.22
-----------------------------------------------------------------------------------------
| end of epoch   7 | time: 185.93s | valid loss  4.74 | valid ppl   114.55
-----------------------------------------------------------------------------------------
| epoch   8 |   200/ 2983 batches | lr 20.00 | ms/batch 59.21 | loss  4.61 | ppl   100.50
| epoch   8 |   400/ 2983 batches | lr 20.00 | ms/batch 58.50 | loss  4.63 | ppl   103.02
| epoch   8 |   600/ 2983 batches | lr 20.00 | ms/batch 59.05 | loss  4.45 | ppl    85.57
| epoch   8 |   800/ 2983 batches | lr 20.00 | ms/batch 59.15 | loss  4.51 | ppl    91.28
| epoch   8 |  1000/ 2983 batches | lr 20.00 | ms/batch 59.53 | loss  4.53 | ppl    92.62
| epoch   8 |  1200/ 2983 batches | lr 20.00 | ms/batch 59.81 | loss  4.54 | ppl    93.30
| epoch   8 |  1400/ 2983 batches | lr 20.00 | ms/batch 59.50 | loss  4.58 | ppl    97.92
| epoch   8 |  1600/ 2983 batches | lr 20.00 | ms/batch 59.39 | loss  4.65 | ppl   105.00
| epoch   8 |  1800/ 2983 batches | lr 20.00 | ms/batch 59.76 | loss  4.55 | ppl    94.19
| epoch   8 |  2000/ 2983 batches | lr 20.00 | ms/batch 60.21 | loss  4.58 | ppl    97.38
| epoch   8 |  2200/ 2983 batches | lr 20.00 | ms/batch 59.60 | loss  4.47 | ppl    87.04
| epoch   8 |  2400/ 2983 batches | lr 20.00 | ms/batch 59.63 | loss  4.51 | ppl    90.86
| epoch   8 |  2600/ 2983 batches | lr 20.00 | ms/batch 59.83 | loss  4.54 | ppl    93.70
| epoch   8 |  2800/ 2983 batches | lr 20.00 | ms/batch 59.55 | loss  4.48 | ppl    88.17
-----------------------------------------------------------------------------------------
| end of epoch   8 | time: 186.28s | valid loss  4.73 | valid ppl   112.73
-----------------------------------------------------------------------------------------
| epoch   9 |   200/ 2983 batches | lr 20.00 | ms/batch 58.93 | loss  4.54 | ppl    93.53
| epoch   9 |   400/ 2983 batches | lr 20.00 | ms/batch 58.27 | loss  4.56 | ppl    95.57
| epoch   9 |   600/ 2983 batches | lr 20.00 | ms/batch 58.69 | loss  4.38 | ppl    79.91
| epoch   9 |   800/ 2983 batches | lr 20.00 | ms/batch 58.94 | loss  4.44 | ppl    84.43
| epoch   9 |  1000/ 2983 batches | lr 20.00 | ms/batch 59.35 | loss  4.46 | ppl    86.79
| epoch   9 |  1200/ 2983 batches | lr 20.00 | ms/batch 59.33 | loss  4.47 | ppl    87.59
| epoch   9 |  1400/ 2983 batches | lr 20.00 | ms/batch 59.40 | loss  4.51 | ppl    91.29
| epoch   9 |  1600/ 2983 batches | lr 20.00 | ms/batch 59.34 | loss  4.59 | ppl    98.53
| epoch   9 |  1800/ 2983 batches | lr 20.00 | ms/batch 59.00 | loss  4.48 | ppl    88.15
| epoch   9 |  2000/ 2983 batches | lr 20.00 | ms/batch 59.51 | loss  4.51 | ppl    91.25
| epoch   9 |  2200/ 2983 batches | lr 20.00 | ms/batch 59.41 | loss  4.40 | ppl    81.26
| epoch   9 |  2400/ 2983 batches | lr 20.00 | ms/batch 59.63 | loss  4.44 | ppl    85.16
| epoch   9 |  2600/ 2983 batches | lr 20.00 | ms/batch 59.41 | loss  4.48 | ppl    87.96
| epoch   9 |  2800/ 2983 batches | lr 20.00 | ms/batch 59.71 | loss  4.42 | ppl    83.38
-----------------------------------------------------------------------------------------
| end of epoch   9 | time: 185.28s | valid loss  4.69 | valid ppl   108.87
-----------------------------------------------------------------------------------------
| epoch  10 |   200/ 2983 batches | lr 20.00 | ms/batch 59.19 | loss  4.47 | ppl    87.60
| epoch  10 |   400/ 2983 batches | lr 20.00 | ms/batch 58.63 | loss  4.49 | ppl    89.52
| epoch  10 |   600/ 2983 batches | lr 20.00 | ms/batch 59.14 | loss  4.32 | ppl    74.99
| epoch  10 |   800/ 2983 batches | lr 20.00 | ms/batch 59.42 | loss  4.37 | ppl    79.30
| epoch  10 |  1000/ 2983 batches | lr 20.00 | ms/batch 59.44 | loss  4.40 | ppl    81.38
| epoch  10 |  1200/ 2983 batches | lr 20.00 | ms/batch 59.58 | loss  4.41 | ppl    82.56
| epoch  10 |  1400/ 2983 batches | lr 20.00 | ms/batch 59.89 | loss  4.45 | ppl    85.60
| epoch  10 |  1600/ 2983 batches | lr 20.00 | ms/batch 59.81 | loss  4.53 | ppl    92.63
| epoch  10 |  1800/ 2983 batches | lr 20.00 | ms/batch 59.63 | loss  4.42 | ppl    82.98
| epoch  10 |  2000/ 2983 batches | lr 20.00 | ms/batch 59.89 | loss  4.46 | ppl    86.47
| epoch  10 |  2200/ 2983 batches | lr 20.00 | ms/batch 59.43 | loss  4.34 | ppl    76.48
| epoch  10 |  2400/ 2983 batches | lr 20.00 | ms/batch 59.92 | loss  4.38 | ppl    79.67
| epoch  10 |  2600/ 2983 batches | lr 20.00 | ms/batch 59.89 | loss  4.42 | ppl    82.86
| epoch  10 |  2800/ 2983 batches | lr 20.00 | ms/batch 59.57 | loss  4.36 | ppl    78.64
-----------------------------------------------------------------------------------------
| end of epoch  10 | time: 186.19s | valid loss  4.68 | valid ppl   107.53
-----------------------------------------------------------------------------------------
| epoch  11 |   200/ 2983 batches | lr 20.00 | ms/batch 59.27 | loss  4.41 | ppl    82.50
| epoch  11 |   400/ 2983 batches | lr 20.00 | ms/batch 58.77 | loss  4.44 | ppl    84.97
| epoch  11 |   600/ 2983 batches | lr 20.00 | ms/batch 58.69 | loss  4.26 | ppl    70.97
| epoch  11 |   800/ 2983 batches | lr 20.00 | ms/batch 59.41 | loss  4.32 | ppl    75.17
| epoch  11 |  1000/ 2983 batches | lr 20.00 | ms/batch 60.03 | loss  4.35 | ppl    77.33
| epoch  11 |  1200/ 2983 batches | lr 20.00 | ms/batch 59.47 | loss  4.36 | ppl    78.28
| epoch  11 |  1400/ 2983 batches | lr 20.00 | ms/batch 59.60 | loss  4.39 | ppl    80.75
| epoch  11 |  1600/ 2983 batches | lr 20.00 | ms/batch 59.52 | loss  4.48 | ppl    88.12
| epoch  11 |  1800/ 2983 batches | lr 20.00 | ms/batch 59.73 | loss  4.37 | ppl    78.73
| epoch  11 |  2000/ 2983 batches | lr 20.00 | ms/batch 59.54 | loss  4.41 | ppl    82.13
| epoch  11 |  2200/ 2983 batches | lr 20.00 | ms/batch 59.70 | loss  4.29 | ppl    72.83
| epoch  11 |  2400/ 2983 batches | lr 20.00 | ms/batch 59.55 | loss  4.33 | ppl    76.05
| epoch  11 |  2600/ 2983 batches | lr 20.00 | ms/batch 59.38 | loss  4.36 | ppl    78.47
| epoch  11 |  2800/ 2983 batches | lr 20.00 | ms/batch 59.05 | loss  4.31 | ppl    74.61
-----------------------------------------------------------------------------------------
| end of epoch  11 | time: 186.01s | valid loss  4.65 | valid ppl   104.75
-----------------------------------------------------------------------------------------
| epoch  12 |   200/ 2983 batches | lr 20.00 | ms/batch 58.83 | loss  4.37 | ppl    78.72
| epoch  12 |   400/ 2983 batches | lr 20.00 | ms/batch 58.22 | loss  4.39 | ppl    80.28
| epoch  12 |   600/ 2983 batches | lr 20.00 | ms/batch 58.67 | loss  4.21 | ppl    67.09
| epoch  12 |   800/ 2983 batches | lr 20.00 | ms/batch 59.08 | loss  4.26 | ppl    71.09
| epoch  12 |  1000/ 2983 batches | lr 20.00 | ms/batch 59.20 | loss  4.30 | ppl    73.52
| epoch  12 |  1200/ 2983 batches | lr 20.00 | ms/batch 59.41 | loss  4.31 | ppl    74.47
| epoch  12 |  1400/ 2983 batches | lr 20.00 | ms/batch 59.20 | loss  4.35 | ppl    77.47
| epoch  12 |  1600/ 2983 batches | lr 20.00 | ms/batch 59.53 | loss  4.43 | ppl    83.84
| epoch  12 |  1800/ 2983 batches | lr 20.00 | ms/batch 59.07 | loss  4.32 | ppl    75.18
| epoch  12 |  2000/ 2983 batches | lr 20.00 | ms/batch 59.51 | loss  4.36 | ppl    78.16
| epoch  12 |  2200/ 2983 batches | lr 20.00 | ms/batch 59.24 | loss  4.24 | ppl    69.24
| epoch  12 |  2400/ 2983 batches | lr 20.00 | ms/batch 59.67 | loss  4.28 | ppl    71.93
| epoch  12 |  2600/ 2983 batches | lr 20.00 | ms/batch 59.30 | loss  4.32 | ppl    74.94
| epoch  12 |  2800/ 2983 batches | lr 20.00 | ms/batch 59.36 | loss  4.27 | ppl    71.37
-----------------------------------------------------------------------------------------
| end of epoch  12 | time: 185.35s | valid loss  4.65 | valid ppl   104.81
-----------------------------------------------------------------------------------------
| epoch  13 |   200/ 2983 batches | lr 5.00 | ms/batch 59.36 | loss  4.34 | ppl    76.34
| epoch  13 |   400/ 2983 batches | lr 5.00 | ms/batch 58.52 | loss  4.33 | ppl    75.86
| epoch  13 |   600/ 2983 batches | lr 5.00 | ms/batch 58.91 | loss  4.13 | ppl    62.29
| epoch  13 |   800/ 2983 batches | lr 5.00 | ms/batch 59.31 | loss  4.17 | ppl    64.76
| epoch  13 |  1000/ 2983 batches | lr 5.00 | ms/batch 59.73 | loss  4.20 | ppl    66.51
| epoch  13 |  1200/ 2983 batches | lr 5.00 | ms/batch 59.60 | loss  4.19 | ppl    65.93
| epoch  13 |  1400/ 2983 batches | lr 5.00 | ms/batch 59.58 | loss  4.20 | ppl    67.01
| epoch  13 |  1600/ 2983 batches | lr 5.00 | ms/batch 59.82 | loss  4.28 | ppl    72.15
| epoch  13 |  1800/ 2983 batches | lr 5.00 | ms/batch 59.62 | loss  4.16 | ppl    63.80
| epoch  13 |  2000/ 2983 batches | lr 5.00 | ms/batch 59.31 | loss  4.19 | ppl    65.75
| epoch  13 |  2200/ 2983 batches | lr 5.00 | ms/batch 60.01 | loss  4.04 | ppl    56.93
| epoch  13 |  2400/ 2983 batches | lr 5.00 | ms/batch 59.15 | loss  4.07 | ppl    58.49
| epoch  13 |  2600/ 2983 batches | lr 5.00 | ms/batch 59.35 | loss  4.09 | ppl    60.00
| epoch  13 |  2800/ 2983 batches | lr 5.00 | ms/batch 59.19 | loss  4.04 | ppl    56.61
-----------------------------------------------------------------------------------------
| end of epoch  13 | time: 186.10s | valid loss  4.57 | valid ppl    96.88
-----------------------------------------------------------------------------------------
begin prun train
| epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 61.67 | loss  4.23 | ppl    68.80
| epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 58.72 | loss  4.28 | ppl    72.35
| epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 58.73 | loss  4.10 | ppl    60.56
| epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 58.93 | loss  4.17 | ppl    64.66
| epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.91 | loss  4.20 | ppl    66.65
| epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 59.07 | loss  4.22 | ppl    68.16
| epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 59.83 | loss  4.25 | ppl    70.27
| epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 59.48 | loss  4.34 | ppl    76.47
| epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 59.64 | loss  4.23 | ppl    68.74
| epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 59.68 | loss  4.27 | ppl    71.70
| epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 59.47 | loss  4.14 | ppl    62.99
| epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 59.43 | loss  4.18 | ppl    65.52
| epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 59.46 | loss  4.22 | ppl    68.02
| epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 59.64 | loss  4.18 | ppl    65.64
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993332222222222
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993332222222222
-----------------------------------------------------------------------------------------
| end of epoch   1 | time: 185.72s | valid loss  4.62 | valid ppl   101.53
-----------------------------------------------------------------------------------------
begin prun train
| epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch 61.60 | loss  4.25 | ppl    69.79
| epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch 58.74 | loss  4.27 | ppl    71.46
| epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch 58.73 | loss  4.09 | ppl    59.71
| epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch 58.99 | loss  4.14 | ppl    62.71
| epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch 59.13 | loss  4.17 | ppl    64.95
| epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 59.21 | loss  4.19 | ppl    66.07
| epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 59.37 | loss  4.22 | ppl    68.19
| epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 59.57 | loss  4.30 | ppl    73.74
| epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch 59.46 | loss  4.20 | ppl    66.52
| epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch 59.56 | loss  4.23 | ppl    68.89
| epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch 59.26 | loss  4.11 | ppl    60.65
| epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch 59.19 | loss  4.14 | ppl    62.77
| epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 59.32 | loss  4.18 | ppl    65.33
| epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 59.59 | loss  4.14 | ppl    62.61
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.6  actual sp:  0.5993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.6  actual sp:  0.5993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.6  actual sp:  0.5993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.6  actual sp:  0.5993333333333333
-----------------------------------------------------------------------------------------
| end of epoch   2 | time: 185.11s | valid loss  4.62 | valid ppl   101.65
-----------------------------------------------------------------------------------------
begin prun train
| epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 61.21 | loss  4.23 | ppl    68.50
| epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch 58.38 | loss  4.25 | ppl    70.08
| epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 58.65 | loss  4.07 | ppl    58.44
| epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 58.67 | loss  4.11 | ppl    61.00
| epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 59.12 | loss  4.15 | ppl    63.51
| epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.59 | loss  4.16 | ppl    64.31
| epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.80 | loss  4.19 | ppl    66.17
| epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.95 | loss  4.27 | ppl    71.70
| epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.83 | loss  4.16 | ppl    63.97
| epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.97 | loss  4.21 | ppl    67.10
| epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.74 | loss  4.08 | ppl    59.41
| epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.88 | loss  4.11 | ppl    60.98
| epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch 59.28 | loss  4.14 | ppl    63.11
| epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.96 | loss  4.11 | ppl    60.71
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7  actual sp:  0.6993333333333334
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7  actual sp:  0.6993333333333334
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7  actual sp:  0.6993333333333334
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7  actual sp:  0.6993333333333334
-----------------------------------------------------------------------------------------
| end of epoch   3 | time: 183.90s | valid loss  4.62 | valid ppl   101.20
-----------------------------------------------------------------------------------------
begin prun train
| epoch   4 |   200/ 2983 batches | lr 20.00 | ms/batch 61.23 | loss  4.23 | ppl    68.97
| epoch   4 |   400/ 2983 batches | lr 20.00 | ms/batch 58.56 | loss  4.25 | ppl    70.24
| epoch   4 |   600/ 2983 batches | lr 20.00 | ms/batch 58.56 | loss  4.07 | ppl    58.32
| epoch   4 |   800/ 2983 batches | lr 20.00 | ms/batch 58.67 | loss  4.12 | ppl    61.60
| epoch   4 |  1000/ 2983 batches | lr 20.00 | ms/batch 59.01 | loss  4.15 | ppl    63.55
| epoch   4 |  1200/ 2983 batches | lr 20.00 | ms/batch 59.04 | loss  4.16 | ppl    64.38
| epoch   4 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.95 | loss  4.19 | ppl    65.99
| epoch   4 |  1600/ 2983 batches | lr 20.00 | ms/batch 59.21 | loss  4.27 | ppl    71.49
| epoch   4 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.83 | loss  4.16 | ppl    64.08
| epoch   4 |  2000/ 2983 batches | lr 20.00 | ms/batch 59.46 | loss  4.20 | ppl    66.39
| epoch   4 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.88 | loss  4.08 | ppl    59.07
| epoch   4 |  2400/ 2983 batches | lr 20.00 | ms/batch 59.57 | loss  4.11 | ppl    61.04
| epoch   4 |  2600/ 2983 batches | lr 20.00 | ms/batch 59.13 | loss  4.15 | ppl    63.32
| epoch   4 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.80 | loss  4.11 | ppl    60.79
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
-----------------------------------------------------------------------------------------
| end of epoch   4 | time: 183.98s | valid loss  4.61 | valid ppl   100.67
-----------------------------------------------------------------------------------------
begin prun train
| epoch   5 |   200/ 2983 batches | lr 20.00 | ms/batch 60.96 | loss  4.22 | ppl    67.91
| epoch   5 |   400/ 2983 batches | lr 20.00 | ms/batch 58.48 | loss  4.23 | ppl    68.93
| epoch   5 |   600/ 2983 batches | lr 20.00 | ms/batch 58.53 | loss  4.06 | ppl    58.26
| epoch   5 |   800/ 2983 batches | lr 20.00 | ms/batch 59.06 | loss  4.10 | ppl    60.45
| epoch   5 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.67 | loss  4.15 | ppl    63.15
| epoch   5 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.99 | loss  4.15 | ppl    63.40
| epoch   5 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.73 | loss  4.18 | ppl    65.43
| epoch   5 |  1600/ 2983 batches | lr 20.00 | ms/batch 59.10 | loss  4.26 | ppl    70.61
| epoch   5 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.83 | loss  4.16 | ppl    63.82
| epoch   5 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.83 | loss  4.20 | ppl    66.44
| epoch   5 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.50 | loss  4.06 | ppl    58.15
| epoch   5 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.96 | loss  4.09 | ppl    60.00
| epoch   5 |  2600/ 2983 batches | lr 20.00 | ms/batch 59.20 | loss  4.13 | ppl    62.33
| epoch   5 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.93 | loss  4.10 | ppl    60.17
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
-----------------------------------------------------------------------------------------
| end of epoch   5 | time: 183.26s | valid loss  4.63 | valid ppl   102.85
-----------------------------------------------------------------------------------------
begin prun train
| epoch   6 |   200/ 2983 batches | lr 20.00 | ms/batch 60.31 | loss  4.26 | ppl    70.46
| epoch   6 |   400/ 2983 batches | lr 20.00 | ms/batch 58.25 | loss  4.27 | ppl    71.36
| epoch   6 |   600/ 2983 batches | lr 20.00 | ms/batch 58.83 | loss  4.09 | ppl    59.60
| epoch   6 |   800/ 2983 batches | lr 20.00 | ms/batch 58.59 | loss  4.14 | ppl    62.97
| epoch   6 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.42 | loss  4.16 | ppl    64.33
| epoch   6 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.53 | loss  4.18 | ppl    65.32
| epoch   6 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.76 | loss  4.20 | ppl    67.01
| epoch   6 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.46 | loss  4.28 | ppl    72.46
| epoch   6 |  1800/ 2983 batches | lr 20.00 | ms/batch 59.08 | loss  4.18 | ppl    65.25
| epoch   6 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.63 | loss  4.22 | ppl    67.78
| epoch   6 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.66 | loss  4.09 | ppl    59.91
| epoch   6 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.47 | loss  4.12 | ppl    61.58
| epoch   6 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.38 | loss  4.15 | ppl    63.65
| epoch   6 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.76 | loss  4.12 | ppl    61.59
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993332222222222
-----------------------------------------------------------------------------------------
| end of epoch   6 | time: 182.37s | valid loss  4.64 | valid ppl   103.83
-----------------------------------------------------------------------------------------
begin prun train
| epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 60.45 | loss  4.17 | ppl    64.87
| epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 58.42 | loss  4.20 | ppl    66.60
| epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 58.54 | loss  4.02 | ppl    55.88
| epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 59.08 | loss  4.07 | ppl    58.44
| epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 59.14 | loss  4.12 | ppl    61.35
| epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.53 | loss  4.13 | ppl    61.96
| epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.54 | loss  4.16 | ppl    63.99
| epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.87 | loss  4.23 | ppl    68.54
| epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.91 | loss  4.13 | ppl    62.11
| epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.79 | loss  4.16 | ppl    64.35
| epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.52 | loss  4.04 | ppl    57.03
| epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.65 | loss  4.07 | ppl    58.56
| epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 59.12 | loss  4.11 | ppl    60.68
| epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.39 | loss  4.08 | ppl    59.06
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of epoch   1 | time: 182.68s | valid loss  4.64 | valid ppl   103.48
-----------------------------------------------------------------------------------------
begin prun train
| epoch   2 |   200/ 2983 batches | lr 5.00 | ms/batch 60.45 | loss  4.15 | ppl    63.51
| epoch   2 |   400/ 2983 batches | lr 5.00 | ms/batch 58.79 | loss  4.14 | ppl    63.09
| epoch   2 |   600/ 2983 batches | lr 5.00 | ms/batch 58.82 | loss  3.96 | ppl    52.46
| epoch   2 |   800/ 2983 batches | lr 5.00 | ms/batch 58.85 | loss  4.00 | ppl    54.64
| epoch   2 |  1000/ 2983 batches | lr 5.00 | ms/batch 58.62 | loss  4.04 | ppl    56.90
| epoch   2 |  1200/ 2983 batches | lr 5.00 | ms/batch 58.37 | loss  4.03 | ppl    56.53
| epoch   2 |  1400/ 2983 batches | lr 5.00 | ms/batch 58.68 | loss  4.05 | ppl    57.67
| epoch   2 |  1600/ 2983 batches | lr 5.00 | ms/batch 58.48 | loss  4.12 | ppl    61.67
| epoch   2 |  1800/ 2983 batches | lr 5.00 | ms/batch 59.21 | loss  4.02 | ppl    55.59
| epoch   2 |  2000/ 2983 batches | lr 5.00 | ms/batch 58.76 | loss  4.04 | ppl    56.93
| epoch   2 |  2200/ 2983 batches | lr 5.00 | ms/batch 58.54 | loss  3.91 | ppl    50.11
| epoch   2 |  2400/ 2983 batches | lr 5.00 | ms/batch 58.76 | loss  3.93 | ppl    50.82
| epoch   2 |  2600/ 2983 batches | lr 5.00 | ms/batch 58.86 | loss  3.97 | ppl    52.76
| epoch   2 |  2800/ 2983 batches | lr 5.00 | ms/batch 58.47 | loss  3.93 | ppl    50.70
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of epoch   2 | time: 182.69s | valid loss  4.59 | valid ppl    98.77
-----------------------------------------------------------------------------------------
begin prun train
| epoch   3 |   200/ 2983 batches | lr 1.25 | ms/batch 60.74 | loss  4.10 | ppl    60.29
| epoch   3 |   400/ 2983 batches | lr 1.25 | ms/batch 58.47 | loss  4.13 | ppl    61.95
| epoch   3 |   600/ 2983 batches | lr 1.25 | ms/batch 58.59 | loss  3.95 | ppl    51.95
| epoch   3 |   800/ 2983 batches | lr 1.25 | ms/batch 59.05 | loss  3.99 | ppl    54.20
| epoch   3 |  1000/ 2983 batches | lr 1.25 | ms/batch 58.53 | loss  4.03 | ppl    56.08
| epoch   3 |  1200/ 2983 batches | lr 1.25 | ms/batch 58.60 | loss  4.02 | ppl    55.61
| epoch   3 |  1400/ 2983 batches | lr 1.25 | ms/batch 58.73 | loss  4.04 | ppl    56.82
| epoch   3 |  1600/ 2983 batches | lr 1.25 | ms/batch 58.85 | loss  4.11 | ppl    60.80
| epoch   3 |  1800/ 2983 batches | lr 1.25 | ms/batch 58.95 | loss  4.01 | ppl    55.12
| epoch   3 |  2000/ 2983 batches | lr 1.25 | ms/batch 59.18 | loss  4.03 | ppl    56.11
| epoch   3 |  2200/ 2983 batches | lr 1.25 | ms/batch 58.63 | loss  3.90 | ppl    49.54
| epoch   3 |  2400/ 2983 batches | lr 1.25 | ms/batch 58.50 | loss  3.93 | ppl    50.93
| epoch   3 |  2600/ 2983 batches | lr 1.25 | ms/batch 58.56 | loss  3.95 | ppl    52.05
| epoch   3 |  2800/ 2983 batches | lr 1.25 | ms/batch 58.53 | loss  3.91 | ppl    49.93
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of epoch   3 | time: 182.67s | valid loss  4.56 | valid ppl    95.51
-----------------------------------------------------------------------------------------
begin prun train
| epoch   4 |   200/ 2983 batches | lr 1.25 | ms/batch 59.97 | loss  4.08 | ppl    58.86
| epoch   4 |   400/ 2983 batches | lr 1.25 | ms/batch 58.53 | loss  4.10 | ppl    60.19
| epoch   4 |   600/ 2983 batches | lr 1.25 | ms/batch 58.50 | loss  3.92 | ppl    50.27
| epoch   4 |   800/ 2983 batches | lr 1.25 | ms/batch 58.35 | loss  3.96 | ppl    52.65
| epoch   4 |  1000/ 2983 batches | lr 1.25 | ms/batch 58.24 | loss  4.01 | ppl    54.91
| epoch   4 |  1200/ 2983 batches | lr 1.25 | ms/batch 58.66 | loss  4.01 | ppl    54.87
| epoch   4 |  1400/ 2983 batches | lr 1.25 | ms/batch 58.43 | loss  4.02 | ppl    55.86
| epoch   4 |  1600/ 2983 batches | lr 1.25 | ms/batch 58.76 | loss  4.09 | ppl    59.94
| epoch   4 |  1800/ 2983 batches | lr 1.25 | ms/batch 58.63 | loss  4.00 | ppl    54.54
| epoch   4 |  2000/ 2983 batches | lr 1.25 | ms/batch 58.19 | loss  4.01 | ppl    55.25
| epoch   4 |  2200/ 2983 batches | lr 1.25 | ms/batch 58.47 | loss  3.89 | ppl    48.96
| epoch   4 |  2400/ 2983 batches | lr 1.25 | ms/batch 58.58 | loss  3.92 | ppl    50.22
| epoch   4 |  2600/ 2983 batches | lr 1.25 | ms/batch 58.59 | loss  3.94 | ppl    51.43
| epoch   4 |  2800/ 2983 batches | lr 1.25 | ms/batch 58.27 | loss  3.90 | ppl    49.58
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of epoch   4 | time: 181.95s | valid loss  4.55 | valid ppl    95.06
-----------------------------------------------------------------------------------------
begin prun train
| epoch   5 |   200/ 2983 batches | lr 1.25 | ms/batch 60.45 | loss  4.06 | ppl    57.78
| epoch   5 |   400/ 2983 batches | lr 1.25 | ms/batch 58.53 | loss  4.09 | ppl    59.51
| epoch   5 |   600/ 2983 batches | lr 1.25 | ms/batch 58.92 | loss  3.90 | ppl    49.51
| epoch   5 |   800/ 2983 batches | lr 1.25 | ms/batch 58.81 | loss  3.95 | ppl    52.09
| epoch   5 |  1000/ 2983 batches | lr 1.25 | ms/batch 58.61 | loss  4.00 | ppl    54.44
| epoch   5 |  1200/ 2983 batches | lr 1.25 | ms/batch 59.01 | loss  3.99 | ppl    53.91
| epoch   5 |  1400/ 2983 batches | lr 1.25 | ms/batch 58.81 | loss  4.01 | ppl    55.27
| epoch   5 |  1600/ 2983 batches | lr 1.25 | ms/batch 59.15 | loss  4.08 | ppl    59.08
| epoch   5 |  1800/ 2983 batches | lr 1.25 | ms/batch 59.07 | loss  3.99 | ppl    54.32
| epoch   5 |  2000/ 2983 batches | lr 1.25 | ms/batch 58.77 | loss  3.99 | ppl    54.32
| epoch   5 |  2200/ 2983 batches | lr 1.25 | ms/batch 58.75 | loss  3.88 | ppl    48.57
| epoch   5 |  2400/ 2983 batches | lr 1.25 | ms/batch 58.83 | loss  3.91 | ppl    49.67
| epoch   5 |  2600/ 2983 batches | lr 1.25 | ms/batch 58.98 | loss  3.93 | ppl    51.02
| epoch   5 |  2800/ 2983 batches | lr 1.25 | ms/batch 58.80 | loss  3.90 | ppl    49.31
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of epoch   5 | time: 183.15s | valid loss  4.55 | valid ppl    94.73
-----------------------------------------------------------------------------------------
begin prun train
| epoch   6 |   200/ 2983 batches | lr 1.25 | ms/batch 60.56 | loss  4.04 | ppl    56.90
| epoch   6 |   400/ 2983 batches | lr 1.25 | ms/batch 58.70 | loss  4.07 | ppl    58.72
| epoch   6 |   600/ 2983 batches | lr 1.25 | ms/batch 58.66 | loss  3.90 | ppl    49.19
| epoch   6 |   800/ 2983 batches | lr 1.25 | ms/batch 58.69 | loss  3.94 | ppl    51.35
| epoch   6 |  1000/ 2983 batches | lr 1.25 | ms/batch 58.85 | loss  3.99 | ppl    53.92
| epoch   6 |  1200/ 2983 batches | lr 1.25 | ms/batch 58.73 | loss  3.98 | ppl    53.72
| epoch   6 |  1400/ 2983 batches | lr 1.25 | ms/batch 59.04 | loss  4.00 | ppl    54.49
| epoch   6 |  1600/ 2983 batches | lr 1.25 | ms/batch 58.81 | loss  4.07 | ppl    58.75
| epoch   6 |  1800/ 2983 batches | lr 1.25 | ms/batch 58.75 | loss  3.98 | ppl    53.72
| epoch   6 |  2000/ 2983 batches | lr 1.25 | ms/batch 59.11 | loss  3.99 | ppl    54.04
| epoch   6 |  2200/ 2983 batches | lr 1.25 | ms/batch 58.62 | loss  3.88 | ppl    48.54
| epoch   6 |  2400/ 2983 batches | lr 1.25 | ms/batch 58.66 | loss  3.90 | ppl    49.42
| epoch   6 |  2600/ 2983 batches | lr 1.25 | ms/batch 58.59 | loss  3.92 | ppl    50.46
| epoch   6 |  2800/ 2983 batches | lr 1.25 | ms/batch 58.64 | loss  3.89 | ppl    49.05
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of epoch   6 | time: 182.95s | valid loss  4.55 | valid ppl    94.44
-----------------------------------------------------------------------------------------
begin prun train
| epoch   7 |   200/ 2983 batches | lr 1.25 | ms/batch 60.27 | loss  4.04 | ppl    56.80
| epoch   7 |   400/ 2983 batches | lr 1.25 | ms/batch 58.29 | loss  4.06 | ppl    57.91
| epoch   7 |   600/ 2983 batches | lr 1.25 | ms/batch 58.20 | loss  3.89 | ppl    48.67
| epoch   7 |   800/ 2983 batches | lr 1.25 | ms/batch 58.44 | loss  3.93 | ppl    50.85
| epoch   7 |  1000/ 2983 batches | lr 1.25 | ms/batch 58.60 | loss  3.98 | ppl    53.53
| epoch   7 |  1200/ 2983 batches | lr 1.25 | ms/batch 58.43 | loss  3.98 | ppl    53.54
| epoch   7 |  1400/ 2983 batches | lr 1.25 | ms/batch 58.97 | loss  3.99 | ppl    54.08
| epoch   7 |  1600/ 2983 batches | lr 1.25 | ms/batch 58.63 | loss  4.07 | ppl    58.31
| epoch   7 |  1800/ 2983 batches | lr 1.25 | ms/batch 58.64 | loss  3.97 | ppl    53.21
| epoch   7 |  2000/ 2983 batches | lr 1.25 | ms/batch 58.97 | loss  3.99 | ppl    53.83
| epoch   7 |  2200/ 2983 batches | lr 1.25 | ms/batch 58.44 | loss  3.87 | ppl    48.18
| epoch   7 |  2400/ 2983 batches | lr 1.25 | ms/batch 58.75 | loss  3.89 | ppl    48.94
| epoch   7 |  2600/ 2983 batches | lr 1.25 | ms/batch 58.53 | loss  3.92 | ppl    50.26
| epoch   7 |  2800/ 2983 batches | lr 1.25 | ms/batch 58.39 | loss  3.88 | ppl    48.48
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of epoch   7 | time: 182.26s | valid loss  4.55 | valid ppl    94.25
-----------------------------------------------------------------------------------------
begin prun train
| epoch   8 |   200/ 2983 batches | lr 1.25 | ms/batch 60.78 | loss  4.03 | ppl    56.04
| epoch   8 |   400/ 2983 batches | lr 1.25 | ms/batch 58.58 | loss  4.05 | ppl    57.36
| epoch   8 |   600/ 2983 batches | lr 1.25 | ms/batch 58.74 | loss  3.87 | ppl    47.81
| epoch   8 |   800/ 2983 batches | lr 1.25 | ms/batch 58.76 | loss  3.91 | ppl    50.12
| epoch   8 |  1000/ 2983 batches | lr 1.25 | ms/batch 58.74 | loss  3.97 | ppl    53.15
| epoch   8 |  1200/ 2983 batches | lr 1.25 | ms/batch 58.57 | loss  3.97 | ppl    53.02
| epoch   8 |  1400/ 2983 batches | lr 1.25 | ms/batch 58.76 | loss  3.99 | ppl    53.87
| epoch   8 |  1600/ 2983 batches | lr 1.25 | ms/batch 58.91 | loss  4.06 | ppl    57.79
| epoch   8 |  1800/ 2983 batches | lr 1.25 | ms/batch 58.75 | loss  3.96 | ppl    52.64
| epoch   8 |  2000/ 2983 batches | lr 1.25 | ms/batch 58.72 | loss  3.97 | ppl    53.19
| epoch   8 |  2200/ 2983 batches | lr 1.25 | ms/batch 58.83 | loss  3.87 | ppl    47.80
| epoch   8 |  2400/ 2983 batches | lr 1.25 | ms/batch 58.57 | loss  3.89 | ppl    48.85
| epoch   8 |  2600/ 2983 batches | lr 1.25 | ms/batch 58.96 | loss  3.91 | ppl    49.70
| epoch   8 |  2800/ 2983 batches | lr 1.25 | ms/batch 58.99 | loss  3.88 | ppl    48.57
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of epoch   8 | time: 182.82s | valid loss  4.55 | valid ppl    94.28
-----------------------------------------------------------------------------------------
begin prun train
| epoch   9 |   200/ 2983 batches | lr 0.31 | ms/batch 60.61 | loss  4.05 | ppl    57.28
| epoch   9 |   400/ 2983 batches | lr 0.31 | ms/batch 58.54 | loss  4.08 | ppl    59.42
| epoch   9 |   600/ 2983 batches | lr 0.31 | ms/batch 58.56 | loss  3.93 | ppl    50.86
| epoch   9 |   800/ 2983 batches | lr 0.31 | ms/batch 58.65 | loss  3.96 | ppl    52.64
| epoch   9 |  1000/ 2983 batches | lr 0.31 | ms/batch 59.01 | loss  3.99 | ppl    53.83
| epoch   9 |  1200/ 2983 batches | lr 0.31 | ms/batch 58.70 | loss  4.01 | ppl    55.20
| epoch   9 |  1400/ 2983 batches | lr 0.31 | ms/batch 58.66 | loss  4.03 | ppl    56.06
| epoch   9 |  1600/ 2983 batches | lr 0.31 | ms/batch 58.75 | loss  4.07 | ppl    58.63
| epoch   9 |  1800/ 2983 batches | lr 0.31 | ms/batch 58.61 | loss  4.00 | ppl    54.61
| epoch   9 |  2000/ 2983 batches | lr 0.31 | ms/batch 58.62 | loss  4.00 | ppl    54.46
| epoch   9 |  2200/ 2983 batches | lr 0.31 | ms/batch 58.68 | loss  3.89 | ppl    48.73
| epoch   9 |  2400/ 2983 batches | lr 0.31 | ms/batch 58.52 | loss  3.93 | ppl    50.78
| epoch   9 |  2600/ 2983 batches | lr 0.31 | ms/batch 58.75 | loss  3.93 | ppl    51.07
| epoch   9 |  2800/ 2983 batches | lr 0.31 | ms/batch 58.69 | loss  3.87 | ppl    48.15
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of epoch   9 | time: 182.73s | valid loss  4.52 | valid ppl    92.25
-----------------------------------------------------------------------------------------
begin prun train
| epoch  10 |   200/ 2983 batches | lr 0.31 | ms/batch 60.60 | loss  4.08 | ppl    59.13
| epoch  10 |   400/ 2983 batches | lr 0.31 | ms/batch 58.73 | loss  4.09 | ppl    59.63
| epoch  10 |   600/ 2983 batches | lr 0.31 | ms/batch 58.63 | loss  3.91 | ppl    49.85
| epoch  10 |   800/ 2983 batches | lr 0.31 | ms/batch 58.73 | loss  3.95 | ppl    51.70
| epoch  10 |  1000/ 2983 batches | lr 0.31 | ms/batch 58.66 | loss  3.98 | ppl    53.45
| epoch  10 |  1200/ 2983 batches | lr 0.31 | ms/batch 58.72 | loss  4.00 | ppl    54.73
| epoch  10 |  1400/ 2983 batches | lr 0.31 | ms/batch 59.20 | loss  4.02 | ppl    55.83
| epoch  10 |  1600/ 2983 batches | lr 0.31 | ms/batch 58.60 | loss  4.06 | ppl    58.19
| epoch  10 |  1800/ 2983 batches | lr 0.31 | ms/batch 58.70 | loss  4.00 | ppl    54.40
| epoch  10 |  2000/ 2983 batches | lr 0.31 | ms/batch 58.65 | loss  3.99 | ppl    54.12
| epoch  10 |  2200/ 2983 batches | lr 0.31 | ms/batch 58.65 | loss  3.88 | ppl    48.54
| epoch  10 |  2400/ 2983 batches | lr 0.31 | ms/batch 58.63 | loss  3.92 | ppl    50.46
| epoch  10 |  2600/ 2983 batches | lr 0.31 | ms/batch 58.64 | loss  3.94 | ppl    51.33
| epoch  10 |  2800/ 2983 batches | lr 0.31 | ms/batch 58.69 | loss  3.87 | ppl    48.05
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of epoch  10 | time: 182.64s | valid loss  4.52 | valid ppl    92.23
-----------------------------------------------------------------------------------------
begin prun train
| epoch  11 |   200/ 2983 batches | lr 0.31 | ms/batch 60.12 | loss  4.07 | ppl    58.80
| epoch  11 |   400/ 2983 batches | lr 0.31 | ms/batch 58.19 | loss  4.08 | ppl    58.97
| epoch  11 |   600/ 2983 batches | lr 0.31 | ms/batch 58.82 | loss  3.92 | ppl    50.19
| epoch  11 |   800/ 2983 batches | lr 0.31 | ms/batch 58.17 | loss  3.94 | ppl    51.63
| epoch  11 |  1000/ 2983 batches | lr 0.31 | ms/batch 58.24 | loss  3.97 | ppl    53.02
| epoch  11 |  1200/ 2983 batches | lr 0.31 | ms/batch 58.38 | loss  4.00 | ppl    54.36
| epoch  11 |  1400/ 2983 batches | lr 0.31 | ms/batch 58.73 | loss  4.02 | ppl    55.90
| epoch  11 |  1600/ 2983 batches | lr 0.31 | ms/batch 58.28 | loss  4.07 | ppl    58.31
| epoch  11 |  1800/ 2983 batches | lr 0.31 | ms/batch 58.53 | loss  3.99 | ppl    54.10
| epoch  11 |  2000/ 2983 batches | lr 0.31 | ms/batch 58.74 | loss  3.99 | ppl    54.26
| epoch  11 |  2200/ 2983 batches | lr 0.31 | ms/batch 58.31 | loss  3.88 | ppl    48.49
| epoch  11 |  2400/ 2983 batches | lr 0.31 | ms/batch 58.47 | loss  3.92 | ppl    50.43
| epoch  11 |  2600/ 2983 batches | lr 0.31 | ms/batch 58.22 | loss  3.93 | ppl    50.89
| epoch  11 |  2800/ 2983 batches | lr 0.31 | ms/batch 58.31 | loss  3.87 | ppl    48.10
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of epoch  11 | time: 181.87s | valid loss  4.52 | valid ppl    92.24
-----------------------------------------------------------------------------------------
begin prun train
| epoch  12 |   200/ 2983 batches | lr 0.08 | ms/batch 60.83 | loss  4.08 | ppl    59.40
| epoch  12 |   400/ 2983 batches | lr 0.08 | ms/batch 58.71 | loss  4.12 | ppl    61.59
| epoch  12 |   600/ 2983 batches | lr 0.08 | ms/batch 58.82 | loss  3.98 | ppl    53.39
| epoch  12 |   800/ 2983 batches | lr 0.08 | ms/batch 58.77 | loss  4.02 | ppl    55.77
| epoch  12 |  1000/ 2983 batches | lr 0.08 | ms/batch 58.61 | loss  4.03 | ppl    56.47
| epoch  12 |  1200/ 2983 batches | lr 0.08 | ms/batch 58.55 | loss  4.03 | ppl    56.41
| epoch  12 |  1400/ 2983 batches | lr 0.08 | ms/batch 58.47 | loss  4.06 | ppl    57.86
| epoch  12 |  1600/ 2983 batches | lr 0.08 | ms/batch 58.64 | loss  4.12 | ppl    61.37
| epoch  12 |  1800/ 2983 batches | lr 0.08 | ms/batch 59.07 | loss  4.04 | ppl    56.67
| epoch  12 |  2000/ 2983 batches | lr 0.08 | ms/batch 58.51 | loss  4.04 | ppl    56.80
| epoch  12 |  2200/ 2983 batches | lr 0.08 | ms/batch 58.63 | loss  3.90 | ppl    49.37
| epoch  12 |  2400/ 2983 batches | lr 0.08 | ms/batch 58.45 | loss  3.93 | ppl    50.87
| epoch  12 |  2600/ 2983 batches | lr 0.08 | ms/batch 58.49 | loss  3.95 | ppl    52.17
| epoch  12 |  2800/ 2983 batches | lr 0.08 | ms/batch 58.88 | loss  3.91 | ppl    50.11
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of epoch  12 | time: 182.63s | valid loss  4.52 | valid ppl    91.43
-----------------------------------------------------------------------------------------
begin prun train
| epoch  13 |   200/ 2983 batches | lr 0.08 | ms/batch 60.41 | loss  4.10 | ppl    60.26
| epoch  13 |   400/ 2983 batches | lr 0.08 | ms/batch 58.51 | loss  4.13 | ppl    62.23
| epoch  13 |   600/ 2983 batches | lr 0.08 | ms/batch 58.70 | loss  3.95 | ppl    52.16
| epoch  13 |   800/ 2983 batches | lr 0.08 | ms/batch 58.56 | loss  4.00 | ppl    54.41
| epoch  13 |  1000/ 2983 batches | lr 0.08 | ms/batch 58.65 | loss  4.03 | ppl    56.00
| epoch  13 |  1200/ 2983 batches | lr 0.08 | ms/batch 58.42 | loss  4.02 | ppl    55.72
| epoch  13 |  1400/ 2983 batches | lr 0.08 | ms/batch 58.47 | loss  4.05 | ppl    57.36
| epoch  13 |  1600/ 2983 batches | lr 0.08 | ms/batch 58.47 | loss  4.12 | ppl    61.26
| epoch  13 |  1800/ 2983 batches | lr 0.08 | ms/batch 58.98 | loss  4.02 | ppl    55.77
| epoch  13 |  2000/ 2983 batches | lr 0.08 | ms/batch 58.51 | loss  4.03 | ppl    56.13
| epoch  13 |  2200/ 2983 batches | lr 0.08 | ms/batch 58.69 | loss  3.90 | ppl    49.50
| epoch  13 |  2400/ 2983 batches | lr 0.08 | ms/batch 58.64 | loss  3.93 | ppl    50.97
| epoch  13 |  2600/ 2983 batches | lr 0.08 | ms/batch 58.51 | loss  3.97 | ppl    53.18
| epoch  13 |  2800/ 2983 batches | lr 0.08 | ms/batch 58.94 | loss  3.92 | ppl    50.54
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of epoch  13 | time: 182.32s | valid loss  4.51 | valid ppl    91.21
-----------------------------------------------------------------------------------------
begin prun train
| epoch  14 |   200/ 2983 batches | lr 0.08 | ms/batch 60.26 | loss  4.10 | ppl    60.15
| epoch  14 |   400/ 2983 batches | lr 0.08 | ms/batch 58.43 | loss  4.12 | ppl    61.45
| epoch  14 |   600/ 2983 batches | lr 0.08 | ms/batch 58.42 | loss  3.94 | ppl    51.53
| epoch  14 |   800/ 2983 batches | lr 0.08 | ms/batch 58.37 | loss  3.99 | ppl    54.03
| epoch  14 |  1000/ 2983 batches | lr 0.08 | ms/batch 58.74 | loss  4.02 | ppl    55.45
| epoch  14 |  1200/ 2983 batches | lr 0.08 | ms/batch 58.23 | loss  4.01 | ppl    55.20
| epoch  14 |  1400/ 2983 batches | lr 0.08 | ms/batch 58.21 | loss  4.05 | ppl    57.38
| epoch  14 |  1600/ 2983 batches | lr 0.08 | ms/batch 58.30 | loss  4.10 | ppl    60.52
| epoch  14 |  1800/ 2983 batches | lr 0.08 | ms/batch 58.31 | loss  4.02 | ppl    55.70
| epoch  14 |  2000/ 2983 batches | lr 0.08 | ms/batch 58.38 | loss  4.03 | ppl    56.44
| epoch  14 |  2200/ 2983 batches | lr 0.08 | ms/batch 58.40 | loss  3.91 | ppl    49.81
| epoch  14 |  2400/ 2983 batches | lr 0.08 | ms/batch 58.78 | loss  3.93 | ppl    51.01
| epoch  14 |  2600/ 2983 batches | lr 0.08 | ms/batch 58.52 | loss  3.97 | ppl    53.07
| epoch  14 |  2800/ 2983 batches | lr 0.08 | ms/batch 58.32 | loss  3.92 | ppl    50.21
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of epoch  14 | time: 181.82s | valid loss  4.51 | valid ppl    91.21
-----------------------------------------------------------------------------------------
begin prun train
| epoch  15 |   200/ 2983 batches | lr 0.02 | ms/batch 60.68 | loss  4.10 | ppl    60.05
| epoch  15 |   400/ 2983 batches | lr 0.02 | ms/batch 58.75 | loss  4.13 | ppl    61.90
| epoch  15 |   600/ 2983 batches | lr 0.02 | ms/batch 58.63 | loss  3.96 | ppl    52.41
| epoch  15 |   800/ 2983 batches | lr 0.02 | ms/batch 58.60 | loss  4.02 | ppl    55.78
| epoch  15 |  1000/ 2983 batches | lr 0.02 | ms/batch 58.50 | loss  4.03 | ppl    56.50
| epoch  15 |  1200/ 2983 batches | lr 0.02 | ms/batch 58.64 | loss  4.03 | ppl    56.42
| epoch  15 |  1400/ 2983 batches | lr 0.02 | ms/batch 58.61 | loss  4.06 | ppl    58.12
| epoch  15 |  1600/ 2983 batches | lr 0.02 | ms/batch 58.81 | loss  4.12 | ppl    61.61
| epoch  15 |  1800/ 2983 batches | lr 0.02 | ms/batch 58.62 | loss  4.04 | ppl    56.93
| epoch  15 |  2000/ 2983 batches | lr 0.02 | ms/batch 58.94 | loss  4.06 | ppl    58.06
| epoch  15 |  2200/ 2983 batches | lr 0.02 | ms/batch 58.61 | loss  3.93 | ppl    50.84
| epoch  15 |  2400/ 2983 batches | lr 0.02 | ms/batch 58.74 | loss  3.94 | ppl    51.21
| epoch  15 |  2600/ 2983 batches | lr 0.02 | ms/batch 58.59 | loss  3.98 | ppl    53.39
| epoch  15 |  2800/ 2983 batches | lr 0.02 | ms/batch 58.40 | loss  3.92 | ppl    50.39
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of epoch  15 | time: 182.53s | valid loss  4.51 | valid ppl    91.08
-----------------------------------------------------------------------------------------
begin prun train
| epoch  16 |   200/ 2983 batches | lr 0.02 | ms/batch 60.53 | loss  4.10 | ppl    60.14
| epoch  16 |   400/ 2983 batches | lr 0.02 | ms/batch 58.35 | loss  4.13 | ppl    61.93
| epoch  16 |   600/ 2983 batches | lr 0.02 | ms/batch 58.49 | loss  3.96 | ppl    52.48
| epoch  16 |   800/ 2983 batches | lr 0.02 | ms/batch 58.47 | loss  4.01 | ppl    55.42
| epoch  16 |  1000/ 2983 batches | lr 0.02 | ms/batch 58.51 | loss  4.04 | ppl    56.68
| epoch  16 |  1200/ 2983 batches | lr 0.02 | ms/batch 58.42 | loss  4.03 | ppl    56.17
| epoch  16 |  1400/ 2983 batches | lr 0.02 | ms/batch 58.42 | loss  4.06 | ppl    57.86
| epoch  16 |  1600/ 2983 batches | lr 0.02 | ms/batch 58.51 | loss  4.12 | ppl    61.60
| epoch  16 |  1800/ 2983 batches | lr 0.02 | ms/batch 58.59 | loss  4.04 | ppl    56.98
| epoch  16 |  2000/ 2983 batches | lr 0.02 | ms/batch 58.74 | loss  4.06 | ppl    57.99
| epoch  16 |  2200/ 2983 batches | lr 0.02 | ms/batch 58.69 | loss  3.92 | ppl    50.45
| epoch  16 |  2400/ 2983 batches | lr 0.02 | ms/batch 58.62 | loss  3.93 | ppl    50.71
| epoch  16 |  2600/ 2983 batches | lr 0.02 | ms/batch 58.42 | loss  3.97 | ppl    53.12
| epoch  16 |  2800/ 2983 batches | lr 0.02 | ms/batch 58.53 | loss  3.93 | ppl    50.75
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of epoch  16 | time: 182.10s | valid loss  4.51 | valid ppl    91.02
-----------------------------------------------------------------------------------------
begin prun train
| epoch  17 |   200/ 2983 batches | lr 0.02 | ms/batch 60.35 | loss  4.10 | ppl    60.63
| epoch  17 |   400/ 2983 batches | lr 0.02 | ms/batch 58.51 | loss  4.13 | ppl    62.37
| epoch  17 |   600/ 2983 batches | lr 0.02 | ms/batch 58.68 | loss  3.96 | ppl    52.66
| epoch  17 |   800/ 2983 batches | lr 0.02 | ms/batch 58.68 | loss  4.02 | ppl    55.58
| epoch  17 |  1000/ 2983 batches | lr 0.02 | ms/batch 58.70 | loss  4.03 | ppl    56.48
| epoch  17 |  1200/ 2983 batches | lr 0.02 | ms/batch 58.60 | loss  4.03 | ppl    56.02
| epoch  17 |  1400/ 2983 batches | lr 0.02 | ms/batch 58.50 | loss  4.06 | ppl    58.03
| epoch  17 |  1600/ 2983 batches | lr 0.02 | ms/batch 58.50 | loss  4.11 | ppl    61.10
| epoch  17 |  1800/ 2983 batches | lr 0.02 | ms/batch 58.51 | loss  4.04 | ppl    56.65
| epoch  17 |  2000/ 2983 batches | lr 0.02 | ms/batch 58.51 | loss  4.06 | ppl    57.87
| epoch  17 |  2200/ 2983 batches | lr 0.02 | ms/batch 58.65 | loss  3.92 | ppl    50.42
| epoch  17 |  2400/ 2983 batches | lr 0.02 | ms/batch 58.72 | loss  3.93 | ppl    50.85
| epoch  17 |  2600/ 2983 batches | lr 0.02 | ms/batch 58.58 | loss  3.98 | ppl    53.29
| epoch  17 |  2800/ 2983 batches | lr 0.02 | ms/batch 58.80 | loss  3.93 | ppl    50.73
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of epoch  17 | time: 182.29s | valid loss  4.51 | valid ppl    90.98
-----------------------------------------------------------------------------------------
begin prun train
| epoch  18 |   200/ 2983 batches | lr 0.02 | ms/batch 59.98 | loss  4.10 | ppl    60.41
| epoch  18 |   400/ 2983 batches | lr 0.02 | ms/batch 57.96 | loss  4.13 | ppl    62.11
| epoch  18 |   600/ 2983 batches | lr 0.02 | ms/batch 58.28 | loss  3.96 | ppl    52.52
| epoch  18 |   800/ 2983 batches | lr 0.02 | ms/batch 58.19 | loss  4.02 | ppl    55.60
| epoch  18 |  1000/ 2983 batches | lr 0.02 | ms/batch 58.20 | loss  4.03 | ppl    56.01
| epoch  18 |  1200/ 2983 batches | lr 0.02 | ms/batch 58.30 | loss  4.02 | ppl    55.89
| epoch  18 |  1400/ 2983 batches | lr 0.02 | ms/batch 58.19 | loss  4.06 | ppl    57.75
| epoch  18 |  1600/ 2983 batches | lr 0.02 | ms/batch 58.26 | loss  4.12 | ppl    61.61
| epoch  18 |  1800/ 2983 batches | lr 0.02 | ms/batch 58.25 | loss  4.04 | ppl    56.70
| epoch  18 |  2000/ 2983 batches | lr 0.02 | ms/batch 58.06 | loss  4.06 | ppl    57.89
| epoch  18 |  2200/ 2983 batches | lr 0.02 | ms/batch 58.24 | loss  3.91 | ppl    50.07
| epoch  18 |  2400/ 2983 batches | lr 0.02 | ms/batch 58.17 | loss  3.94 | ppl    51.36
| epoch  18 |  2600/ 2983 batches | lr 0.02 | ms/batch 58.17 | loss  3.97 | ppl    53.13
| epoch  18 |  2800/ 2983 batches | lr 0.02 | ms/batch 57.91 | loss  3.93 | ppl    50.77
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of epoch  18 | time: 181.06s | valid loss  4.51 | valid ppl    90.95
-----------------------------------------------------------------------------------------
begin prun train
| epoch  19 |   200/ 2983 batches | lr 0.02 | ms/batch 60.45 | loss  4.10 | ppl    60.26
| epoch  19 |   400/ 2983 batches | lr 0.02 | ms/batch 58.41 | loss  4.13 | ppl    62.19
| epoch  19 |   600/ 2983 batches | lr 0.02 | ms/batch 58.50 | loss  3.96 | ppl    52.42
| epoch  19 |   800/ 2983 batches | lr 0.02 | ms/batch 58.54 | loss  4.00 | ppl    54.80
| epoch  19 |  1000/ 2983 batches | lr 0.02 | ms/batch 58.52 | loss  4.02 | ppl    55.88
| epoch  19 |  1200/ 2983 batches | lr 0.02 | ms/batch 58.78 | loss  4.03 | ppl    56.06
| epoch  19 |  1400/ 2983 batches | lr 0.02 | ms/batch 59.02 | loss  4.06 | ppl    57.86
| epoch  19 |  1600/ 2983 batches | lr 0.02 | ms/batch 58.75 | loss  4.12 | ppl    61.60
| epoch  19 |  1800/ 2983 batches | lr 0.02 | ms/batch 58.59 | loss  4.03 | ppl    56.43
| epoch  19 |  2000/ 2983 batches | lr 0.02 | ms/batch 58.82 | loss  4.05 | ppl    57.26
| epoch  19 |  2200/ 2983 batches | lr 0.02 | ms/batch 58.62 | loss  3.92 | ppl    50.39
| epoch  19 |  2400/ 2983 batches | lr 0.02 | ms/batch 58.73 | loss  3.94 | ppl    51.23
| epoch  19 |  2600/ 2983 batches | lr 0.02 | ms/batch 58.72 | loss  3.97 | ppl    53.05
| epoch  19 |  2800/ 2983 batches | lr 0.02 | ms/batch 58.54 | loss  3.93 | ppl    51.14
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of epoch  19 | time: 182.45s | valid loss  4.51 | valid ppl    90.92
-----------------------------------------------------------------------------------------
begin prun train
| epoch  20 |   200/ 2983 batches | lr 0.02 | ms/batch 60.42 | loss  4.10 | ppl    60.28
| epoch  20 |   400/ 2983 batches | lr 0.02 | ms/batch 58.61 | loss  4.13 | ppl    62.40
| epoch  20 |   600/ 2983 batches | lr 0.02 | ms/batch 58.50 | loss  3.95 | ppl    52.14
| epoch  20 |   800/ 2983 batches | lr 0.02 | ms/batch 58.66 | loss  4.01 | ppl    54.97
| epoch  20 |  1000/ 2983 batches | lr 0.02 | ms/batch 58.48 | loss  4.03 | ppl    55.98
| epoch  20 |  1200/ 2983 batches | lr 0.02 | ms/batch 58.49 | loss  4.02 | ppl    55.56
| epoch  20 |  1400/ 2983 batches | lr 0.02 | ms/batch 58.52 | loss  4.05 | ppl    57.65
| epoch  20 |  1600/ 2983 batches | lr 0.02 | ms/batch 58.47 | loss  4.11 | ppl    60.90
| epoch  20 |  1800/ 2983 batches | lr 0.02 | ms/batch 58.51 | loss  4.03 | ppl    56.11
| epoch  20 |  2000/ 2983 batches | lr 0.02 | ms/batch 58.43 | loss  4.05 | ppl    57.46
| epoch  20 |  2200/ 2983 batches | lr 0.02 | ms/batch 58.98 | loss  3.92 | ppl    50.30
| epoch  20 |  2400/ 2983 batches | lr 0.02 | ms/batch 58.56 | loss  3.93 | ppl    51.05
| epoch  20 |  2600/ 2983 batches | lr 0.02 | ms/batch 58.56 | loss  3.98 | ppl    53.46
| epoch  20 |  2800/ 2983 batches | lr 0.02 | ms/batch 58.61 | loss  3.94 | ppl    51.31
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of epoch  20 | time: 182.20s | valid loss  4.51 | valid ppl    90.91
-----------------------------------------------------------------------------------------
begin prun train
| epoch  21 |   200/ 2983 batches | lr 0.02 | ms/batch 60.43 | loss  4.10 | ppl    60.37
| epoch  21 |   400/ 2983 batches | lr 0.02 | ms/batch 58.38 | loss  4.13 | ppl    62.05
| epoch  21 |   600/ 2983 batches | lr 0.02 | ms/batch 58.52 | loss  3.95 | ppl    51.84
| epoch  21 |   800/ 2983 batches | lr 0.02 | ms/batch 58.50 | loss  4.01 | ppl    55.26
| epoch  21 |  1000/ 2983 batches | lr 0.02 | ms/batch 58.47 | loss  4.02 | ppl    55.70
| epoch  21 |  1200/ 2983 batches | lr 0.02 | ms/batch 58.66 | loss  4.02 | ppl    55.71
| epoch  21 |  1400/ 2983 batches | lr 0.02 | ms/batch 58.33 | loss  4.06 | ppl    57.75
| epoch  21 |  1600/ 2983 batches | lr 0.02 | ms/batch 58.40 | loss  4.11 | ppl    61.12
| epoch  21 |  1800/ 2983 batches | lr 0.02 | ms/batch 58.47 | loss  4.03 | ppl    56.12
| epoch  21 |  2000/ 2983 batches | lr 0.02 | ms/batch 58.36 | loss  4.05 | ppl    57.32
| epoch  21 |  2200/ 2983 batches | lr 0.02 | ms/batch 58.52 | loss  3.92 | ppl    50.31
| epoch  21 |  2400/ 2983 batches | lr 0.02 | ms/batch 58.26 | loss  3.93 | ppl    50.96
| epoch  21 |  2600/ 2983 batches | lr 0.02 | ms/batch 58.38 | loss  3.97 | ppl    53.17
| epoch  21 |  2800/ 2983 batches | lr 0.02 | ms/batch 58.39 | loss  3.93 | ppl    50.85
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of epoch  21 | time: 181.89s | valid loss  4.51 | valid ppl    90.90
-----------------------------------------------------------------------------------------
=========================================================================================
| End of training | test loss  4.47 | test ppl    87.01
=========================================================================================
