python main.py --cuda --epochs 6 --save model/baseline/model.pt
<class 'torch.Tensor'> torch.Size([33278, 200])
<class 'torch.Tensor'> torch.Size([800, 200])
<class 'torch.Tensor'> torch.Size([800, 200])
<class 'torch.Tensor'> torch.Size([800])
<class 'torch.Tensor'> torch.Size([800])
<class 'torch.Tensor'> torch.Size([800, 200])
<class 'torch.Tensor'> torch.Size([800, 200])
<class 'torch.Tensor'> torch.Size([800])
<class 'torch.Tensor'> torch.Size([800])
<class 'torch.Tensor'> torch.Size([33278, 200])
<class 'torch.Tensor'> torch.Size([33278])
RNNModel(
  (drop): Dropout(p=0.2)
  (encoder): Embedding(33278, 200)
  (rnn): LSTM(200, 200, num_layers=2, dropout=0.2)
  (decoder): Linear(in_features=200, out_features=33278, bias=True)
)
Dropout(p=0.2)
Embedding(33278, 200)
LSTM(200, 200, num_layers=2, dropout=0.2)
Linear(in_features=200, out_features=33278, bias=True)
| train-epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 10.34 | loss  7.63 | ppl  2053.44
| train-epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 10.50 | loss  6.86 | ppl   951.17
| train-epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 10.96 | loss  6.48 | ppl   654.89
| train-epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 10.61 | loss  6.31 | ppl   548.52
| train-epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.70 | loss  6.15 | ppl   468.21
| train-epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.66 | loss  6.06 | ppl   426.35
| train-epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.75 | loss  5.94 | ppl   378.68
| train-epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.99 | loss  5.93 | ppl   377.77
| train-epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.67 | loss  5.80 | ppl   329.39
| train-epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.58 | loss  5.76 | ppl   318.46
| train-epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.66 | loss  5.66 | ppl   286.06
| train-epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.42 | loss  5.67 | ppl   290.76
| train-epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.68 | loss  5.65 | ppl   285.13
| train-epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.95 | loss  5.54 | ppl   254.12
-----------------------------------------------------------------------------------------
| end of train epoch   1 | time: 33.58s | valid loss  5.56 | valid ppl   259.89
-----------------------------------------------------------------------------------------
| train-epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch 10.18 | loss  5.55 | ppl   256.92
| train-epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch 10.82 | loss  5.54 | ppl   253.46
| train-epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch 10.61 | loss  5.37 | ppl   214.00
| train-epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch 10.58 | loss  5.38 | ppl   217.79
| train-epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.79 | loss  5.35 | ppl   211.20
| train-epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.25 | loss  5.33 | ppl   206.47
| train-epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.38 | loss  5.32 | ppl   205.17
| train-epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.44 | loss  5.39 | ppl   218.30
| train-epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch 11.16 | loss  5.27 | ppl   193.58
| train-epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch 11.21 | loss  5.27 | ppl   194.88
| train-epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch 11.18 | loss  5.18 | ppl   178.57
| train-epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch 11.00 | loss  5.22 | ppl   184.31
| train-epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.88 | loss  5.23 | ppl   186.13
| train-epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.69 | loss  5.14 | ppl   171.01
-----------------------------------------------------------------------------------------
| end of train epoch   2 | time: 33.57s | valid loss  5.29 | valid ppl   197.51
-----------------------------------------------------------------------------------------
| train-epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 10.23 | loss  5.20 | ppl   181.09
| train-epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch 10.11 | loss  5.21 | ppl   183.77
| train-epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 10.74 | loss  5.03 | ppl   153.49
| train-epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 10.78 | loss  5.08 | ppl   160.55
| train-epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.95 | loss  5.06 | ppl   157.97
| train-epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.72 | loss  5.06 | ppl   157.91
| train-epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 11.05 | loss  5.08 | ppl   160.61
| train-epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.63 | loss  5.15 | ppl   173.08
| train-epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 11.02 | loss  5.03 | ppl   152.47
| train-epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.59 | loss  5.05 | ppl   156.30
| train-epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.97 | loss  4.97 | ppl   143.58
| train-epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.70 | loss  5.00 | ppl   148.61
| train-epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.98 | loss  5.02 | ppl   150.96
| train-epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.64 | loss  4.94 | ppl   139.83
-----------------------------------------------------------------------------------------
| end of train epoch   3 | time: 33.86s | valid loss  5.19 | valid ppl   178.85
-----------------------------------------------------------------------------------------
| train-epoch   4 |   200/ 2983 batches | lr 20.00 | ms/batch 10.32 | loss  5.01 | ppl   149.42
| train-epoch   4 |   400/ 2983 batches | lr 20.00 | ms/batch 10.40 | loss  5.03 | ppl   153.09
| train-epoch   4 |   600/ 2983 batches | lr 20.00 | ms/batch 10.14 | loss  4.84 | ppl   126.98
| train-epoch   4 |   800/ 2983 batches | lr 20.00 | ms/batch 10.54 | loss  4.91 | ppl   135.31
| train-epoch   4 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.13 | loss  4.90 | ppl   133.67
| train-epoch   4 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.12 | loss  4.90 | ppl   133.81
| train-epoch   4 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.33 | loss  4.93 | ppl   137.74
| train-epoch   4 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.11 | loss  5.00 | ppl   149.11
| train-epoch   4 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.35 | loss  4.88 | ppl   131.80
| train-epoch   4 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.12 | loss  4.91 | ppl   135.18
| train-epoch   4 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.37 | loss  4.83 | ppl   124.73
| train-epoch   4 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.20 | loss  4.86 | ppl   129.38
| train-epoch   4 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.22 | loss  4.87 | ppl   130.84
| train-epoch   4 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.18 | loss  4.81 | ppl   122.31
-----------------------------------------------------------------------------------------
| end of train epoch   4 | time: 32.27s | valid loss  5.11 | valid ppl   165.20
-----------------------------------------------------------------------------------------
| train-epoch   5 |   200/ 2983 batches | lr 20.00 | ms/batch 10.67 | loss  4.88 | ppl   131.85
| train-epoch   5 |   400/ 2983 batches | lr 20.00 | ms/batch 10.94 | loss  4.90 | ppl   134.57
| train-epoch   5 |   600/ 2983 batches | lr 20.00 | ms/batch 10.78 | loss  4.72 | ppl   112.05
| train-epoch   5 |   800/ 2983 batches | lr 20.00 | ms/batch 11.08 | loss  4.78 | ppl   119.35
| train-epoch   5 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.72 | loss  4.78 | ppl   118.84
| train-epoch   5 |  1200/ 2983 batches | lr 20.00 | ms/batch 11.15 | loss  4.78 | ppl   119.55
| train-epoch   5 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.72 | loss  4.82 | ppl   123.69
| train-epoch   5 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.81 | loss  4.90 | ppl   133.92
| train-epoch   5 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.25 | loss  4.78 | ppl   118.87
| train-epoch   5 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.54 | loss  4.81 | ppl   122.54
| train-epoch   5 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.56 | loss  4.72 | ppl   112.08
| train-epoch   5 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.51 | loss  4.75 | ppl   116.02
| train-epoch   5 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.79 | loss  4.77 | ppl   118.48
| train-epoch   5 |  2800/ 2983 batches | lr 20.00 | ms/batch 11.08 | loss  4.71 | ppl   110.55
-----------------------------------------------------------------------------------------
| end of train epoch   5 | time: 33.84s | valid loss  5.06 | valid ppl   157.01
-----------------------------------------------------------------------------------------
| train-epoch   6 |   200/ 2983 batches | lr 20.00 | ms/batch 10.04 | loss  4.77 | ppl   118.27
| train-epoch   6 |   400/ 2983 batches | lr 20.00 | ms/batch  9.96 | loss  4.81 | ppl   122.31
| train-epoch   6 |   600/ 2983 batches | lr 20.00 | ms/batch 10.08 | loss  4.63 | ppl   102.21
| train-epoch   6 |   800/ 2983 batches | lr 20.00 | ms/batch 10.49 | loss  4.69 | ppl   108.39
| train-epoch   6 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.24 | loss  4.69 | ppl   109.15
| train-epoch   6 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.52 | loss  4.70 | ppl   109.48
| train-epoch   6 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.24 | loss  4.74 | ppl   113.87
| train-epoch   6 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.49 | loss  4.81 | ppl   122.86
| train-epoch   6 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.29 | loss  4.69 | ppl   108.94
| train-epoch   6 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.53 | loss  4.73 | ppl   113.38
| train-epoch   6 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.26 | loss  4.64 | ppl   103.48
| train-epoch   6 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.46 | loss  4.67 | ppl   107.10
| train-epoch   6 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.28 | loss  4.70 | ppl   109.83
| train-epoch   6 |  2800/ 2983 batches | lr 20.00 | ms/batch 11.17 | loss  4.63 | ppl   102.85
-----------------------------------------------------------------------------------------
| end of train epoch   6 | time: 32.91s | valid loss  5.00 | valid ppl   149.07
-----------------------------------------------------------------------------------------
required epochs   6 | actual epochs   9
pretrain epochs   6 | prune epochs   0 | retrain epochs   3
=========================================================================================
| End of training | test loss  4.93 | test ppl   138.43
=========================================================================================
python main.py --cuda --epochs 6 --tied --save model/baseline/model.pt
<class 'torch.Tensor'> torch.Size([33278, 200])
<class 'torch.Tensor'> torch.Size([800, 200])
<class 'torch.Tensor'> torch.Size([800, 200])
<class 'torch.Tensor'> torch.Size([800])
<class 'torch.Tensor'> torch.Size([800])
<class 'torch.Tensor'> torch.Size([800, 200])
<class 'torch.Tensor'> torch.Size([800, 200])
<class 'torch.Tensor'> torch.Size([800])
<class 'torch.Tensor'> torch.Size([800])
<class 'torch.Tensor'> torch.Size([33278])
RNNModel(
  (drop): Dropout(p=0.2)
  (encoder): Embedding(33278, 200)
  (rnn): LSTM(200, 200, num_layers=2, dropout=0.2)
  (decoder): Linear(in_features=200, out_features=33278, bias=True)
)
Dropout(p=0.2)
Embedding(33278, 200)
LSTM(200, 200, num_layers=2, dropout=0.2)
Linear(in_features=200, out_features=33278, bias=True)
| train-epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 10.91 | loss  7.60 | ppl  1996.57
| train-epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 11.04 | loss  6.79 | ppl   884.59
| train-epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 10.58 | loss  6.37 | ppl   583.03
| train-epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 10.97 | loss  6.20 | ppl   490.51
| train-epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.58 | loss  6.05 | ppl   426.17
| train-epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.96 | loss  5.96 | ppl   388.70
| train-epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.58 | loss  5.85 | ppl   348.41
| train-epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.58 | loss  5.86 | ppl   348.99
| train-epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.90 | loss  5.70 | ppl   298.04
| train-epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.52 | loss  5.67 | ppl   289.88
| train-epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.91 | loss  5.57 | ppl   261.86
| train-epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.67 | loss  5.58 | ppl   265.83
| train-epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.80 | loss  5.57 | ppl   261.30
| train-epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.57 | loss  5.46 | ppl   233.97
-----------------------------------------------------------------------------------------
| end of train epoch   1 | time: 33.71s | valid loss  5.44 | valid ppl   230.57
-----------------------------------------------------------------------------------------
| train-epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch 10.10 | loss  5.46 | ppl   236.21
| train-epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch 10.43 | loss  5.45 | ppl   233.23
| train-epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch 10.36 | loss  5.28 | ppl   196.31
| train-epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch 10.19 | loss  5.29 | ppl   198.16
| train-epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.82 | loss  5.26 | ppl   192.12
| train-epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.68 | loss  5.25 | ppl   190.83
| train-epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.40 | loss  5.26 | ppl   191.90
| train-epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.12 | loss  5.32 | ppl   203.63
| train-epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  5.19 | ppl   179.80
| train-epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch  9.80 | loss  5.20 | ppl   180.76
| train-epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch  9.93 | loss  5.12 | ppl   166.74
| train-epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch  9.79 | loss  5.14 | ppl   170.90
| train-epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch  9.80 | loss  5.16 | ppl   173.66
| train-epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.06 | loss  5.07 | ppl   159.91
-----------------------------------------------------------------------------------------
| end of train epoch   2 | time: 31.98s | valid loss  5.19 | valid ppl   179.37
-----------------------------------------------------------------------------------------
| train-epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  5.12 | ppl   168.12
| train-epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch 10.52 | loss  5.15 | ppl   172.10
| train-epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 10.07 | loss  4.97 | ppl   144.60
| train-epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 10.08 | loss  5.02 | ppl   151.10
| train-epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.35 | loss  5.01 | ppl   149.40
| train-epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.11 | loss  5.01 | ppl   149.72
| train-epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.09 | loss  5.03 | ppl   152.81
| train-epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.84 | loss  5.10 | ppl   164.52
| train-epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.57 | loss  4.98 | ppl   145.63
| train-epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.89 | loss  5.00 | ppl   148.96
| train-epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.53 | loss  4.92 | ppl   136.63
| train-epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.79 | loss  4.95 | ppl   141.38
| train-epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.62 | loss  4.97 | ppl   144.35
| train-epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.71 | loss  4.90 | ppl   134.54
-----------------------------------------------------------------------------------------
| end of train epoch   3 | time: 33.01s | valid loss  5.09 | valid ppl   161.86
-----------------------------------------------------------------------------------------
| train-epoch   4 |   200/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.96 | ppl   143.14
| train-epoch   4 |   400/ 2983 batches | lr 20.00 | ms/batch 10.05 | loss  4.99 | ppl   146.67
| train-epoch   4 |   600/ 2983 batches | lr 20.00 | ms/batch 10.04 | loss  4.81 | ppl   122.62
| train-epoch   4 |   800/ 2983 batches | lr 20.00 | ms/batch  9.92 | loss  4.87 | ppl   129.81
| train-epoch   4 |  1000/ 2983 batches | lr 20.00 | ms/batch  9.76 | loss  4.86 | ppl   129.64
| train-epoch   4 |  1200/ 2983 batches | lr 20.00 | ms/batch  9.81 | loss  4.87 | ppl   130.67
| train-epoch   4 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.91 | ppl   135.05
| train-epoch   4 |  1600/ 2983 batches | lr 20.00 | ms/batch  9.80 | loss  4.98 | ppl   145.14
| train-epoch   4 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.89 | loss  4.86 | ppl   128.85
| train-epoch   4 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.59 | loss  4.89 | ppl   132.30
| train-epoch   4 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.63 | loss  4.80 | ppl   121.25
| train-epoch   4 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.96 | loss  4.84 | ppl   125.98
| train-epoch   4 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.59 | loss  4.86 | ppl   129.40
| train-epoch   4 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.61 | loss  4.79 | ppl   120.84
-----------------------------------------------------------------------------------------
| end of train epoch   4 | time: 32.37s | valid loss  5.01 | valid ppl   150.26
-----------------------------------------------------------------------------------------
| train-epoch   5 |   200/ 2983 batches | lr 20.00 | ms/batch  9.75 | loss  4.85 | ppl   128.02
| train-epoch   5 |   400/ 2983 batches | lr 20.00 | ms/batch  9.80 | loss  4.88 | ppl   132.14
| train-epoch   5 |   600/ 2983 batches | lr 20.00 | ms/batch  9.77 | loss  4.70 | ppl   109.87
| train-epoch   5 |   800/ 2983 batches | lr 20.00 | ms/batch 10.26 | loss  4.77 | ppl   117.47
| train-epoch   5 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.12 | loss  4.77 | ppl   117.93
| train-epoch   5 |  1200/ 2983 batches | lr 20.00 | ms/batch  9.68 | loss  4.78 | ppl   118.83
| train-epoch   5 |  1400/ 2983 batches | lr 20.00 | ms/batch  9.49 | loss  4.81 | ppl   123.27
| train-epoch   5 |  1600/ 2983 batches | lr 20.00 | ms/batch  9.91 | loss  4.89 | ppl   132.36
| train-epoch   5 |  1800/ 2983 batches | lr 20.00 | ms/batch  9.74 | loss  4.78 | ppl   118.59
| train-epoch   5 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.05 | loss  4.80 | ppl   122.12
| train-epoch   5 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.04 | loss  4.71 | ppl   111.20
| train-epoch   5 |  2400/ 2983 batches | lr 20.00 | ms/batch  9.90 | loss  4.76 | ppl   116.44
| train-epoch   5 |  2600/ 2983 batches | lr 20.00 | ms/batch  9.91 | loss  4.78 | ppl   118.73
| train-epoch   5 |  2800/ 2983 batches | lr 20.00 | ms/batch  9.84 | loss  4.72 | ppl   111.89
-----------------------------------------------------------------------------------------
| end of train epoch   5 | time: 31.12s | valid loss  4.97 | valid ppl   143.87
-----------------------------------------------------------------------------------------
| train-epoch   6 |   200/ 2983 batches | lr 20.00 | ms/batch  9.95 | loss  4.78 | ppl   119.24
| train-epoch   6 |   400/ 2983 batches | lr 20.00 | ms/batch  9.74 | loss  4.80 | ppl   121.70
| train-epoch   6 |   600/ 2983 batches | lr 20.00 | ms/batch  9.85 | loss  4.63 | ppl   102.63
| train-epoch   6 |   800/ 2983 batches | lr 20.00 | ms/batch  9.89 | loss  4.69 | ppl   109.18
| train-epoch   6 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.04 | loss  4.70 | ppl   110.08
| train-epoch   6 |  1200/ 2983 batches | lr 20.00 | ms/batch  9.83 | loss  4.71 | ppl   110.65
| train-epoch   6 |  1400/ 2983 batches | lr 20.00 | ms/batch  9.84 | loss  4.75 | ppl   115.79
| train-epoch   6 |  1600/ 2983 batches | lr 20.00 | ms/batch  9.87 | loss  4.82 | ppl   123.79
| train-epoch   6 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.15 | loss  4.71 | ppl   111.31
| train-epoch   6 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.50 | loss  4.75 | ppl   115.17
| train-epoch   6 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.14 | loss  4.65 | ppl   104.55
| train-epoch   6 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.69 | loss  4.70 | ppl   109.61
| train-epoch   6 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.34 | loss  4.72 | ppl   112.26
| train-epoch   6 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.86 | loss  4.66 | ppl   105.56
-----------------------------------------------------------------------------------------
| end of train epoch   6 | time: 32.16s | valid loss  4.96 | valid ppl   142.89
-----------------------------------------------------------------------------------------
required epochs   6 | actual epochs   9
pretrain epochs   6 | prune epochs   0 | retrain epochs   3
=========================================================================================
| End of training | test loss  4.89 | test ppl   133.41
=========================================================================================
python main.py --cuda --tied --save model/baseline/model.pt
<class 'torch.Tensor'> torch.Size([33278, 200])
<class 'torch.Tensor'> torch.Size([800, 200])
<class 'torch.Tensor'> torch.Size([800, 200])
<class 'torch.Tensor'> torch.Size([800])
<class 'torch.Tensor'> torch.Size([800])
<class 'torch.Tensor'> torch.Size([800, 200])
<class 'torch.Tensor'> torch.Size([800, 200])
<class 'torch.Tensor'> torch.Size([800])
<class 'torch.Tensor'> torch.Size([800])
<class 'torch.Tensor'> torch.Size([33278])
RNNModel(
  (drop): Dropout(p=0.2)
  (encoder): Embedding(33278, 200)
  (rnn): LSTM(200, 200, num_layers=2, dropout=0.2)
  (decoder): Linear(in_features=200, out_features=33278, bias=True)
)
Dropout(p=0.2)
Embedding(33278, 200)
LSTM(200, 200, num_layers=2, dropout=0.2)
Linear(in_features=200, out_features=33278, bias=True)
| train-epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 10.62 | loss  7.60 | ppl  1996.57
| train-epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 10.93 | loss  6.79 | ppl   884.59
| train-epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 10.39 | loss  6.37 | ppl   583.03
| train-epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 10.49 | loss  6.20 | ppl   490.51
| train-epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.50 | loss  6.05 | ppl   426.17
| train-epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.62 | loss  5.96 | ppl   388.70
| train-epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch  9.98 | loss  5.85 | ppl   348.41
| train-epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.33 | loss  5.86 | ppl   348.99
| train-epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.04 | loss  5.70 | ppl   298.04
| train-epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.10 | loss  5.67 | ppl   289.88
| train-epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.37 | loss  5.57 | ppl   261.86
| train-epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch  9.95 | loss  5.58 | ppl   265.83
| train-epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.35 | loss  5.57 | ppl   261.30
| train-epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  5.46 | ppl   233.97
-----------------------------------------------------------------------------------------
| end of train epoch   1 | time: 32.44s | valid loss  5.44 | valid ppl   230.57
-----------------------------------------------------------------------------------------
| train-epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch  9.61 | loss  5.46 | ppl   236.21
| train-epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch  9.87 | loss  5.45 | ppl   233.23
| train-epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch  9.62 | loss  5.28 | ppl   196.31
| train-epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch  9.93 | loss  5.29 | ppl   198.16
| train-epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch  9.55 | loss  5.26 | ppl   192.12
| train-epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch  9.85 | loss  5.25 | ppl   190.83
| train-epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch  9.80 | loss  5.26 | ppl   191.90
| train-epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch  9.58 | loss  5.32 | ppl   203.63
| train-epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch  9.62 | loss  5.19 | ppl   179.80
| train-epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch  9.75 | loss  5.20 | ppl   180.76
| train-epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch  9.58 | loss  5.12 | ppl   166.74
| train-epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch  9.88 | loss  5.14 | ppl   170.90
| train-epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.27 | loss  5.16 | ppl   173.66
| train-epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  5.07 | ppl   159.91
-----------------------------------------------------------------------------------------
| end of train epoch   2 | time: 30.92s | valid loss  5.19 | valid ppl   179.37
-----------------------------------------------------------------------------------------
| train-epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch  9.97 | loss  5.12 | ppl   168.12
| train-epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch  9.63 | loss  5.15 | ppl   172.10
| train-epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch  9.91 | loss  4.97 | ppl   144.60
| train-epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 10.40 | loss  5.02 | ppl   151.10
| train-epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.03 | loss  5.01 | ppl   149.40
| train-epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.79 | loss  5.01 | ppl   149.72
| train-epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.41 | loss  5.03 | ppl   152.81
| train-epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.03 | loss  5.10 | ppl   164.52
| train-epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.40 | loss  4.98 | ppl   145.63
| train-epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.43 | loss  5.00 | ppl   148.96
| train-epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.09 | loss  4.92 | ppl   136.63
| train-epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.95 | ppl   141.38
| train-epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch  9.85 | loss  4.97 | ppl   144.35
| train-epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch  9.67 | loss  4.90 | ppl   134.54
-----------------------------------------------------------------------------------------
| end of train epoch   3 | time: 31.97s | valid loss  5.09 | valid ppl   161.86
-----------------------------------------------------------------------------------------
| train-epoch   4 |   200/ 2983 batches | lr 20.00 | ms/batch  9.70 | loss  4.96 | ppl   143.14
| train-epoch   4 |   400/ 2983 batches | lr 20.00 | ms/batch  9.64 | loss  4.99 | ppl   146.67
| train-epoch   4 |   600/ 2983 batches | lr 20.00 | ms/batch  9.95 | loss  4.81 | ppl   122.62
| train-epoch   4 |   800/ 2983 batches | lr 20.00 | ms/batch 10.03 | loss  4.87 | ppl   129.81
| train-epoch   4 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.46 | loss  4.86 | ppl   129.64
| train-epoch   4 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.43 | loss  4.87 | ppl   130.67
| train-epoch   4 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.91 | ppl   135.05
| train-epoch   4 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.44 | loss  4.98 | ppl   145.14
| train-epoch   4 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.03 | loss  4.86 | ppl   128.85
| train-epoch   4 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.44 | loss  4.89 | ppl   132.30
| train-epoch   4 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.08 | loss  4.80 | ppl   121.25
| train-epoch   4 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  4.84 | ppl   125.98
| train-epoch   4 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.43 | loss  4.86 | ppl   129.40
| train-epoch   4 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.03 | loss  4.79 | ppl   120.84
-----------------------------------------------------------------------------------------
| end of train epoch   4 | time: 32.07s | valid loss  5.01 | valid ppl   150.26
-----------------------------------------------------------------------------------------
| train-epoch   5 |   200/ 2983 batches | lr 20.00 | ms/batch  9.65 | loss  4.85 | ppl   128.02
| train-epoch   5 |   400/ 2983 batches | lr 20.00 | ms/batch 10.36 | loss  4.88 | ppl   132.14
| train-epoch   5 |   600/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.70 | ppl   109.87
| train-epoch   5 |   800/ 2983 batches | lr 20.00 | ms/batch 10.36 | loss  4.77 | ppl   117.47
| train-epoch   5 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.35 | loss  4.77 | ppl   117.93
| train-epoch   5 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.78 | ppl   118.83
| train-epoch   5 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.53 | loss  4.81 | ppl   123.27
| train-epoch   5 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.38 | loss  4.89 | ppl   132.36
| train-epoch   5 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.46 | loss  4.78 | ppl   118.59
| train-epoch   5 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.03 | loss  4.80 | ppl   122.12
| train-epoch   5 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.47 | loss  4.71 | ppl   111.20
| train-epoch   5 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.09 | loss  4.76 | ppl   116.44
| train-epoch   5 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.28 | loss  4.78 | ppl   118.73
| train-epoch   5 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.07 | loss  4.72 | ppl   111.89
-----------------------------------------------------------------------------------------
| end of train epoch   5 | time: 32.29s | valid loss  4.97 | valid ppl   143.87
-----------------------------------------------------------------------------------------
| train-epoch   6 |   200/ 2983 batches | lr 20.00 | ms/batch  9.68 | loss  4.78 | ppl   119.24
| train-epoch   6 |   400/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.80 | ppl   121.70
| train-epoch   6 |   600/ 2983 batches | lr 20.00 | ms/batch  9.92 | loss  4.63 | ppl   102.63
| train-epoch   6 |   800/ 2983 batches | lr 20.00 | ms/batch  9.76 | loss  4.69 | ppl   109.18
| train-epoch   6 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.23 | loss  4.70 | ppl   110.08
| train-epoch   6 |  1200/ 2983 batches | lr 20.00 | ms/batch  9.59 | loss  4.71 | ppl   110.65
| train-epoch   6 |  1400/ 2983 batches | lr 20.00 | ms/batch  9.65 | loss  4.75 | ppl   115.79
| train-epoch   6 |  1600/ 2983 batches | lr 20.00 | ms/batch  9.93 | loss  4.82 | ppl   123.79
| train-epoch   6 |  1800/ 2983 batches | lr 20.00 | ms/batch  9.62 | loss  4.71 | ppl   111.31
| train-epoch   6 |  2000/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.75 | ppl   115.17
| train-epoch   6 |  2200/ 2983 batches | lr 20.00 | ms/batch  9.66 | loss  4.65 | ppl   104.55
| train-epoch   6 |  2400/ 2983 batches | lr 20.00 | ms/batch  9.94 | loss  4.70 | ppl   109.61
| train-epoch   6 |  2600/ 2983 batches | lr 20.00 | ms/batch  9.72 | loss  4.72 | ppl   112.26
| train-epoch   6 |  2800/ 2983 batches | lr 20.00 | ms/batch  9.63 | loss  4.66 | ppl   105.56
-----------------------------------------------------------------------------------------
| end of train epoch   6 | time: 30.99s | valid loss  4.96 | valid ppl   142.89
-----------------------------------------------------------------------------------------
| train-epoch   7 |   200/ 2983 batches | lr 20.00 | ms/batch 10.16 | loss  4.72 | ppl   112.34
| train-epoch   7 |   400/ 2983 batches | lr 20.00 | ms/batch 10.52 | loss  4.75 | ppl   115.70
| train-epoch   7 |   600/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  4.57 | ppl    96.97
| train-epoch   7 |   800/ 2983 batches | lr 20.00 | ms/batch 10.35 | loss  4.63 | ppl   102.65
| train-epoch   7 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.18 | loss  4.65 | ppl   104.70
| train-epoch   7 |  1200/ 2983 batches | lr 20.00 | ms/batch 11.02 | loss  4.65 | ppl   105.09
| train-epoch   7 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.55 | loss  4.70 | ppl   109.41
| train-epoch   7 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.18 | loss  4.77 | ppl   117.65
| train-epoch   7 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.23 | loss  4.67 | ppl   106.17
| train-epoch   7 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.60 | loss  4.70 | ppl   109.88
| train-epoch   7 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.50 | loss  4.60 | ppl    99.24
| train-epoch   7 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.17 | loss  4.65 | ppl   104.42
| train-epoch   7 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.70 | loss  4.67 | ppl   107.11
| train-epoch   7 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.59 | loss  4.61 | ppl   100.77
-----------------------------------------------------------------------------------------
| end of train epoch   7 | time: 32.86s | valid loss  4.94 | valid ppl   139.39
-----------------------------------------------------------------------------------------
| train-epoch   8 |   200/ 2983 batches | lr 20.00 | ms/batch  9.97 | loss  4.67 | ppl   106.80
| train-epoch   8 |   400/ 2983 batches | lr 20.00 | ms/batch 10.34 | loss  4.70 | ppl   110.32
| train-epoch   8 |   600/ 2983 batches | lr 20.00 | ms/batch 10.85 | loss  4.52 | ppl    92.16
| train-epoch   8 |   800/ 2983 batches | lr 20.00 | ms/batch 10.15 | loss  4.59 | ppl    98.03
| train-epoch   8 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.51 | loss  4.61 | ppl   100.20
| train-epoch   8 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.50 | loss  4.61 | ppl   100.83
| train-epoch   8 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.49 | loss  4.66 | ppl   105.49
| train-epoch   8 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.47 | loss  4.73 | ppl   113.36
| train-epoch   8 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.32 | loss  4.62 | ppl   101.89
| train-epoch   8 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.19 | loss  4.66 | ppl   105.61
| train-epoch   8 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.43 | loss  4.56 | ppl    95.65
| train-epoch   8 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.56 | loss  4.61 | ppl   100.33
| train-epoch   8 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.76 | loss  4.63 | ppl   102.81
| train-epoch   8 |  2800/ 2983 batches | lr 20.00 | ms/batch 11.05 | loss  4.57 | ppl    96.83
-----------------------------------------------------------------------------------------
| end of train epoch   8 | time: 33.23s | valid loss  4.93 | valid ppl   138.01
-----------------------------------------------------------------------------------------
| train-epoch   9 |   200/ 2983 batches | lr 20.00 | ms/batch 11.11 | loss  4.64 | ppl   103.24
| train-epoch   9 |   400/ 2983 batches | lr 20.00 | ms/batch 11.04 | loss  4.67 | ppl   106.54
| train-epoch   9 |   600/ 2983 batches | lr 20.00 | ms/batch 10.84 | loss  4.49 | ppl    88.91
| train-epoch   9 |   800/ 2983 batches | lr 20.00 | ms/batch 10.26 | loss  4.55 | ppl    94.61
| train-epoch   9 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.20 | loss  4.57 | ppl    96.82
| train-epoch   9 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.11 | loss  4.58 | ppl    97.54
| train-epoch   9 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.18 | loss  4.62 | ppl   101.79
| train-epoch   9 |  1600/ 2983 batches | lr 20.00 | ms/batch  9.94 | loss  4.70 | ppl   109.46
| train-epoch   9 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.21 | loss  4.59 | ppl    98.85
| train-epoch   9 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.19 | loss  4.63 | ppl   102.15
| train-epoch   9 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.04 | loss  4.52 | ppl    92.07
| train-epoch   9 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.21 | loss  4.58 | ppl    97.07
| train-epoch   9 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.17 | loss  4.60 | ppl    99.77
| train-epoch   9 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.09 | loss  4.54 | ppl    93.77
-----------------------------------------------------------------------------------------
| end of train epoch   9 | time: 32.47s | valid loss  4.91 | valid ppl   135.54
-----------------------------------------------------------------------------------------
| train-epoch  10 |   200/ 2983 batches | lr 20.00 | ms/batch 10.08 | loss  4.60 | ppl    99.97
| train-epoch  10 |   400/ 2983 batches | lr 20.00 | ms/batch 10.29 | loss  4.63 | ppl   102.65
| train-epoch  10 |   600/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.46 | ppl    86.11
| train-epoch  10 |   800/ 2983 batches | lr 20.00 | ms/batch 10.20 | loss  4.51 | ppl    91.25
| train-epoch  10 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.20 | loss  4.54 | ppl    93.84
| train-epoch  10 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.43 | loss  4.55 | ppl    95.00
| train-epoch  10 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.21 | loss  4.59 | ppl    98.88
| train-epoch  10 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.34 | loss  4.66 | ppl   106.07
| train-epoch  10 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.58 | loss  4.56 | ppl    95.86
| train-epoch  10 |  2000/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.60 | ppl    99.77
| train-epoch  10 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.27 | loss  4.49 | ppl    89.32
| train-epoch  10 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.55 | ppl    94.44
| train-epoch  10 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.35 | loss  4.57 | ppl    96.82
| train-epoch  10 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.52 | ppl    92.12
-----------------------------------------------------------------------------------------
| end of train epoch  10 | time: 32.16s | valid loss  4.91 | valid ppl   135.93
-----------------------------------------------------------------------------------------
| train-epoch  11 |   200/ 2983 batches | lr 5.00 | ms/batch  9.96 | loss  4.61 | ppl   100.51
| train-epoch  11 |   400/ 2983 batches | lr 5.00 | ms/batch 10.27 | loss  4.61 | ppl   100.64
| train-epoch  11 |   600/ 2983 batches | lr 5.00 | ms/batch  9.61 | loss  4.42 | ppl    83.48
| train-epoch  11 |   800/ 2983 batches | lr 5.00 | ms/batch 10.33 | loss  4.48 | ppl    87.98
| train-epoch  11 |  1000/ 2983 batches | lr 5.00 | ms/batch 10.53 | loss  4.47 | ppl    87.69
| train-epoch  11 |  1200/ 2983 batches | lr 5.00 | ms/batch 10.70 | loss  4.47 | ppl    87.21
| train-epoch  11 |  1400/ 2983 batches | lr 5.00 | ms/batch 10.64 | loss  4.48 | ppl    88.58
| train-epoch  11 |  1600/ 2983 batches | lr 5.00 | ms/batch 10.42 | loss  4.54 | ppl    93.83
| train-epoch  11 |  1800/ 2983 batches | lr 5.00 | ms/batch 10.41 | loss  4.43 | ppl    83.73
| train-epoch  11 |  2000/ 2983 batches | lr 5.00 | ms/batch 10.30 | loss  4.45 | ppl    85.45
| train-epoch  11 |  2200/ 2983 batches | lr 5.00 | ms/batch 10.57 | loss  4.32 | ppl    75.55
| train-epoch  11 |  2400/ 2983 batches | lr 5.00 | ms/batch 10.76 | loss  4.36 | ppl    78.05
| train-epoch  11 |  2600/ 2983 batches | lr 5.00 | ms/batch 10.15 | loss  4.37 | ppl    79.29
| train-epoch  11 |  2800/ 2983 batches | lr 5.00 | ms/batch 10.73 | loss  4.30 | ppl    73.82
-----------------------------------------------------------------------------------------
| end of train epoch  11 | time: 32.85s | valid loss  4.77 | valid ppl   118.27
-----------------------------------------------------------------------------------------
| train-epoch  12 |   200/ 2983 batches | lr 5.00 | ms/batch 10.01 | loss  4.47 | ppl    87.72
| train-epoch  12 |   400/ 2983 batches | lr 5.00 | ms/batch 10.14 | loss  4.50 | ppl    89.72
| train-epoch  12 |   600/ 2983 batches | lr 5.00 | ms/batch  9.95 | loss  4.31 | ppl    74.60
| train-epoch  12 |   800/ 2983 batches | lr 5.00 | ms/batch 10.11 | loss  4.37 | ppl    78.76
| train-epoch  12 |  1000/ 2983 batches | lr 5.00 | ms/batch 10.01 | loss  4.39 | ppl    80.49
| train-epoch  12 |  1200/ 2983 batches | lr 5.00 | ms/batch 10.14 | loss  4.39 | ppl    80.60
| train-epoch  12 |  1400/ 2983 batches | lr 5.00 | ms/batch 10.06 | loss  4.42 | ppl    82.88
| train-epoch  12 |  1600/ 2983 batches | lr 5.00 | ms/batch 10.22 | loss  4.48 | ppl    88.38
| train-epoch  12 |  1800/ 2983 batches | lr 5.00 | ms/batch  9.91 | loss  4.37 | ppl    79.35
| train-epoch  12 |  2000/ 2983 batches | lr 5.00 | ms/batch 10.06 | loss  4.40 | ppl    81.52
| train-epoch  12 |  2200/ 2983 batches | lr 5.00 | ms/batch 10.04 | loss  4.28 | ppl    72.40
| train-epoch  12 |  2400/ 2983 batches | lr 5.00 | ms/batch 10.12 | loss  4.32 | ppl    75.31
| train-epoch  12 |  2600/ 2983 batches | lr 5.00 | ms/batch 10.08 | loss  4.35 | ppl    77.28
| train-epoch  12 |  2800/ 2983 batches | lr 5.00 | ms/batch 10.14 | loss  4.28 | ppl    72.49
-----------------------------------------------------------------------------------------
| end of train epoch  12 | time: 31.73s | valid loss  4.75 | valid ppl   116.02
-----------------------------------------------------------------------------------------
| train-epoch  13 |   200/ 2983 batches | lr 5.00 | ms/batch 10.27 | loss  4.42 | ppl    83.21
| train-epoch  13 |   400/ 2983 batches | lr 5.00 | ms/batch  9.96 | loss  4.45 | ppl    85.29
| train-epoch  13 |   600/ 2983 batches | lr 5.00 | ms/batch 10.19 | loss  4.26 | ppl    71.10
| train-epoch  13 |   800/ 2983 batches | lr 5.00 | ms/batch 10.17 | loss  4.33 | ppl    75.89
| train-epoch  13 |  1000/ 2983 batches | lr 5.00 | ms/batch 10.10 | loss  4.35 | ppl    77.71
| train-epoch  13 |  1200/ 2983 batches | lr 5.00 | ms/batch 10.01 | loss  4.35 | ppl    77.61
| train-epoch  13 |  1400/ 2983 batches | lr 5.00 | ms/batch 10.01 | loss  4.38 | ppl    80.15
| train-epoch  13 |  1600/ 2983 batches | lr 5.00 | ms/batch 10.32 | loss  4.45 | ppl    85.48
| train-epoch  13 |  1800/ 2983 batches | lr 5.00 | ms/batch  9.86 | loss  4.34 | ppl    76.77
| train-epoch  13 |  2000/ 2983 batches | lr 5.00 | ms/batch  9.67 | loss  4.37 | ppl    79.44
| train-epoch  13 |  2200/ 2983 batches | lr 5.00 | ms/batch 10.14 | loss  4.26 | ppl    70.66
| train-epoch  13 |  2400/ 2983 batches | lr 5.00 | ms/batch 10.33 | loss  4.30 | ppl    73.52
| train-epoch  13 |  2600/ 2983 batches | lr 5.00 | ms/batch 10.77 | loss  4.33 | ppl    75.62
| train-epoch  13 |  2800/ 2983 batches | lr 5.00 | ms/batch 10.64 | loss  4.27 | ppl    71.17
-----------------------------------------------------------------------------------------
| end of train epoch  13 | time: 32.09s | valid loss  4.75 | valid ppl   115.23
-----------------------------------------------------------------------------------------
| train-epoch  14 |   200/ 2983 batches | lr 5.00 | ms/batch 10.48 | loss  4.39 | ppl    80.43
| train-epoch  14 |   400/ 2983 batches | lr 5.00 | ms/batch 10.20 | loss  4.41 | ppl    82.34
| train-epoch  14 |   600/ 2983 batches | lr 5.00 | ms/batch 10.04 | loss  4.23 | ppl    68.84
| train-epoch  14 |   800/ 2983 batches | lr 5.00 | ms/batch  9.97 | loss  4.29 | ppl    73.22
| train-epoch  14 |  1000/ 2983 batches | lr 5.00 | ms/batch 10.36 | loss  4.32 | ppl    75.20
| train-epoch  14 |  1200/ 2983 batches | lr 5.00 | ms/batch  9.96 | loss  4.33 | ppl    75.79
| train-epoch  14 |  1400/ 2983 batches | lr 5.00 | ms/batch 10.27 | loss  4.36 | ppl    78.13
| train-epoch  14 |  1600/ 2983 batches | lr 5.00 | ms/batch 10.18 | loss  4.42 | ppl    83.05
| train-epoch  14 |  1800/ 2983 batches | lr 5.00 | ms/batch 10.05 | loss  4.32 | ppl    75.29
| train-epoch  14 |  2000/ 2983 batches | lr 5.00 | ms/batch 10.22 | loss  4.35 | ppl    77.69
| train-epoch  14 |  2200/ 2983 batches | lr 5.00 | ms/batch  9.93 | loss  4.23 | ppl    68.99
| train-epoch  14 |  2400/ 2983 batches | lr 5.00 | ms/batch 10.71 | loss  4.28 | ppl    72.41
| train-epoch  14 |  2600/ 2983 batches | lr 5.00 | ms/batch 10.43 | loss  4.31 | ppl    74.37
| train-epoch  14 |  2800/ 2983 batches | lr 5.00 | ms/batch 10.77 | loss  4.25 | ppl    70.04
-----------------------------------------------------------------------------------------
| end of train epoch  14 | time: 32.47s | valid loss  4.74 | valid ppl   114.65
-----------------------------------------------------------------------------------------
| train-epoch  15 |   200/ 2983 batches | lr 5.00 | ms/batch 10.04 | loss  4.37 | ppl    78.70
| train-epoch  15 |   400/ 2983 batches | lr 5.00 | ms/batch 10.16 | loss  4.39 | ppl    80.61
| train-epoch  15 |   600/ 2983 batches | lr 5.00 | ms/batch  9.89 | loss  4.21 | ppl    67.52
| train-epoch  15 |   800/ 2983 batches | lr 5.00 | ms/batch 10.18 | loss  4.27 | ppl    71.77
| train-epoch  15 |  1000/ 2983 batches | lr 5.00 | ms/batch 10.03 | loss  4.29 | ppl    73.13
| train-epoch  15 |  1200/ 2983 batches | lr 5.00 | ms/batch 10.03 | loss  4.31 | ppl    74.35
| train-epoch  15 |  1400/ 2983 batches | lr 5.00 | ms/batch 10.23 | loss  4.34 | ppl    76.36
| train-epoch  15 |  1600/ 2983 batches | lr 5.00 | ms/batch  9.95 | loss  4.40 | ppl    81.26
| train-epoch  15 |  1800/ 2983 batches | lr 5.00 | ms/batch 10.36 | loss  4.30 | ppl    73.87
| train-epoch  15 |  2000/ 2983 batches | lr 5.00 | ms/batch  9.92 | loss  4.34 | ppl    76.39
| train-epoch  15 |  2200/ 2983 batches | lr 5.00 | ms/batch 10.21 | loss  4.22 | ppl    68.09
| train-epoch  15 |  2400/ 2983 batches | lr 5.00 | ms/batch  9.97 | loss  4.26 | ppl    70.97
| train-epoch  15 |  2600/ 2983 batches | lr 5.00 | ms/batch 10.16 | loss  4.29 | ppl    73.31
| train-epoch  15 |  2800/ 2983 batches | lr 5.00 | ms/batch  9.99 | loss  4.24 | ppl    69.08
-----------------------------------------------------------------------------------------
| end of train epoch  15 | time: 31.77s | valid loss  4.74 | valid ppl   114.51
-----------------------------------------------------------------------------------------
| train-epoch  16 |   200/ 2983 batches | lr 5.00 | ms/batch 10.06 | loss  4.34 | ppl    77.04
| train-epoch  16 |   400/ 2983 batches | lr 5.00 | ms/batch 10.15 | loss  4.36 | ppl    78.59
| train-epoch  16 |   600/ 2983 batches | lr 5.00 | ms/batch 10.03 | loss  4.19 | ppl    65.89
| train-epoch  16 |   800/ 2983 batches | lr 5.00 | ms/batch 10.10 | loss  4.25 | ppl    70.28
| train-epoch  16 |  1000/ 2983 batches | lr 5.00 | ms/batch  9.90 | loss  4.28 | ppl    72.31
| train-epoch  16 |  1200/ 2983 batches | lr 5.00 | ms/batch 10.18 | loss  4.29 | ppl    73.00
| train-epoch  16 |  1400/ 2983 batches | lr 5.00 | ms/batch  9.92 | loss  4.32 | ppl    75.14
| train-epoch  16 |  1600/ 2983 batches | lr 5.00 | ms/batch 10.30 | loss  4.38 | ppl    80.10
| train-epoch  16 |  1800/ 2983 batches | lr 5.00 | ms/batch  9.90 | loss  4.28 | ppl    72.59
| train-epoch  16 |  2000/ 2983 batches | lr 5.00 | ms/batch 10.18 | loss  4.32 | ppl    75.33
| train-epoch  16 |  2200/ 2983 batches | lr 5.00 | ms/batch 10.22 | loss  4.21 | ppl    67.19
| train-epoch  16 |  2400/ 2983 batches | lr 5.00 | ms/batch  9.99 | loss  4.25 | ppl    70.01
| train-epoch  16 |  2600/ 2983 batches | lr 5.00 | ms/batch 10.10 | loss  4.28 | ppl    72.18
| train-epoch  16 |  2800/ 2983 batches | lr 5.00 | ms/batch 10.32 | loss  4.22 | ppl    68.19
-----------------------------------------------------------------------------------------
| end of train epoch  16 | time: 31.86s | valid loss  4.74 | valid ppl   114.04
-----------------------------------------------------------------------------------------
| train-epoch  17 |   200/ 2983 batches | lr 5.00 | ms/batch 10.69 | loss  4.32 | ppl    75.40
| train-epoch  17 |   400/ 2983 batches | lr 5.00 | ms/batch 10.75 | loss  4.35 | ppl    77.41
| train-epoch  17 |   600/ 2983 batches | lr 5.00 | ms/batch 10.25 | loss  4.17 | ppl    64.97
| train-epoch  17 |   800/ 2983 batches | lr 5.00 | ms/batch 10.03 | loss  4.24 | ppl    69.16
| train-epoch  17 |  1000/ 2983 batches | lr 5.00 | ms/batch  9.91 | loss  4.27 | ppl    71.23
| train-epoch  17 |  1200/ 2983 batches | lr 5.00 | ms/batch 10.21 | loss  4.27 | ppl    71.76
| train-epoch  17 |  1400/ 2983 batches | lr 5.00 | ms/batch  9.97 | loss  4.30 | ppl    74.05
| train-epoch  17 |  1600/ 2983 batches | lr 5.00 | ms/batch 10.18 | loss  4.37 | ppl    79.07
| train-epoch  17 |  1800/ 2983 batches | lr 5.00 | ms/batch  9.95 | loss  4.27 | ppl    71.52
| train-epoch  17 |  2000/ 2983 batches | lr 5.00 | ms/batch 10.11 | loss  4.31 | ppl    74.39
| train-epoch  17 |  2200/ 2983 batches | lr 5.00 | ms/batch 10.00 | loss  4.19 | ppl    65.83
| train-epoch  17 |  2400/ 2983 batches | lr 5.00 | ms/batch 10.25 | loss  4.24 | ppl    69.18
| train-epoch  17 |  2600/ 2983 batches | lr 5.00 | ms/batch  9.99 | loss  4.27 | ppl    71.19
| train-epoch  17 |  2800/ 2983 batches | lr 5.00 | ms/batch  9.89 | loss  4.21 | ppl    67.63
-----------------------------------------------------------------------------------------
| end of train epoch  17 | time: 32.00s | valid loss  4.73 | valid ppl   113.51
-----------------------------------------------------------------------------------------
| train-epoch  18 |   200/ 2983 batches | lr 5.00 | ms/batch 10.00 | loss  4.31 | ppl    74.51
| train-epoch  18 |   400/ 2983 batches | lr 5.00 | ms/batch 10.24 | loss  4.33 | ppl    76.03
| train-epoch  18 |   600/ 2983 batches | lr 5.00 | ms/batch  9.90 | loss  4.16 | ppl    63.88
| train-epoch  18 |   800/ 2983 batches | lr 5.00 | ms/batch 10.03 | loss  4.22 | ppl    68.06
| train-epoch  18 |  1000/ 2983 batches | lr 5.00 | ms/batch 10.24 | loss  4.25 | ppl    69.90
| train-epoch  18 |  1200/ 2983 batches | lr 5.00 | ms/batch  9.99 | loss  4.26 | ppl    70.88
| train-epoch  18 |  1400/ 2983 batches | lr 5.00 | ms/batch 10.39 | loss  4.29 | ppl    72.98
| train-epoch  18 |  1600/ 2983 batches | lr 5.00 | ms/batch 10.40 | loss  4.35 | ppl    77.73
| train-epoch  18 |  1800/ 2983 batches | lr 5.00 | ms/batch 10.67 | loss  4.26 | ppl    70.72
| train-epoch  18 |  2000/ 2983 batches | lr 5.00 | ms/batch 10.37 | loss  4.30 | ppl    73.44
| train-epoch  18 |  2200/ 2983 batches | lr 5.00 | ms/batch 10.60 | loss  4.18 | ppl    65.19
| train-epoch  18 |  2400/ 2983 batches | lr 5.00 | ms/batch 10.41 | loss  4.22 | ppl    68.34
| train-epoch  18 |  2600/ 2983 batches | lr 5.00 | ms/batch 10.56 | loss  4.25 | ppl    70.39
| train-epoch  18 |  2800/ 2983 batches | lr 5.00 | ms/batch 10.60 | loss  4.20 | ppl    66.81
-----------------------------------------------------------------------------------------
| end of train epoch  18 | time: 32.61s | valid loss  4.73 | valid ppl   113.24
-----------------------------------------------------------------------------------------
| train-epoch  19 |   200/ 2983 batches | lr 5.00 | ms/batch  9.95 | loss  4.29 | ppl    72.72
| train-epoch  19 |   400/ 2983 batches | lr 5.00 | ms/batch 10.22 | loss  4.32 | ppl    75.05
| train-epoch  19 |   600/ 2983 batches | lr 5.00 | ms/batch  9.91 | loss  4.14 | ppl    62.88
| train-epoch  19 |   800/ 2983 batches | lr 5.00 | ms/batch 10.64 | loss  4.20 | ppl    66.82
| train-epoch  19 |  1000/ 2983 batches | lr 5.00 | ms/batch 10.44 | loss  4.24 | ppl    69.50
| train-epoch  19 |  1200/ 2983 batches | lr 5.00 | ms/batch 10.69 | loss  4.24 | ppl    69.63
| train-epoch  19 |  1400/ 2983 batches | lr 5.00 | ms/batch 10.41 | loss  4.28 | ppl    72.01
| train-epoch  19 |  1600/ 2983 batches | lr 5.00 | ms/batch 10.82 | loss  4.34 | ppl    76.96
| train-epoch  19 |  1800/ 2983 batches | lr 5.00 | ms/batch 10.39 | loss  4.24 | ppl    69.68
| train-epoch  19 |  2000/ 2983 batches | lr 5.00 | ms/batch 10.39 | loss  4.28 | ppl    72.47
| train-epoch  19 |  2200/ 2983 batches | lr 5.00 | ms/batch 10.64 | loss  4.16 | ppl    64.33
| train-epoch  19 |  2400/ 2983 batches | lr 5.00 | ms/batch 10.56 | loss  4.21 | ppl    67.56
| train-epoch  19 |  2600/ 2983 batches | lr 5.00 | ms/batch 10.23 | loss  4.24 | ppl    69.47
| train-epoch  19 |  2800/ 2983 batches | lr 5.00 | ms/batch 10.18 | loss  4.19 | ppl    65.89
-----------------------------------------------------------------------------------------
| end of train epoch  19 | time: 32.83s | valid loss  4.73 | valid ppl   113.18
-----------------------------------------------------------------------------------------
| train-epoch  20 |   200/ 2983 batches | lr 5.00 | ms/batch 10.38 | loss  4.27 | ppl    71.87
| train-epoch  20 |   400/ 2983 batches | lr 5.00 | ms/batch 10.26 | loss  4.31 | ppl    74.08
| train-epoch  20 |   600/ 2983 batches | lr 5.00 | ms/batch 10.38 | loss  4.13 | ppl    62.30
| train-epoch  20 |   800/ 2983 batches | lr 5.00 | ms/batch 10.33 | loss  4.19 | ppl    65.92
| train-epoch  20 |  1000/ 2983 batches | lr 5.00 | ms/batch 10.29 | loss  4.22 | ppl    68.13
| train-epoch  20 |  1200/ 2983 batches | lr 5.00 | ms/batch 10.34 | loss  4.23 | ppl    69.02
| train-epoch  20 |  1400/ 2983 batches | lr 5.00 | ms/batch 10.19 | loss  4.26 | ppl    71.12
| train-epoch  20 |  1600/ 2983 batches | lr 5.00 | ms/batch 10.76 | loss  4.33 | ppl    75.82
| train-epoch  20 |  1800/ 2983 batches | lr 5.00 | ms/batch 10.51 | loss  4.23 | ppl    68.84
| train-epoch  20 |  2000/ 2983 batches | lr 5.00 | ms/batch 10.81 | loss  4.27 | ppl    71.59
| train-epoch  20 |  2200/ 2983 batches | lr 5.00 | ms/batch 10.80 | loss  4.16 | ppl    63.82
| train-epoch  20 |  2400/ 2983 batches | lr 5.00 | ms/batch 10.62 | loss  4.20 | ppl    66.90
| train-epoch  20 |  2600/ 2983 batches | lr 5.00 | ms/batch 10.77 | loss  4.23 | ppl    68.88
| train-epoch  20 |  2800/ 2983 batches | lr 5.00 | ms/batch 10.47 | loss  4.18 | ppl    65.26
-----------------------------------------------------------------------------------------
| end of train epoch  20 | time: 33.15s | valid loss  4.73 | valid ppl   113.24
-----------------------------------------------------------------------------------------
| train-epoch  21 |   200/ 2983 batches | lr 1.25 | ms/batch 10.42 | loss  4.30 | ppl    73.50
| train-epoch  21 |   400/ 2983 batches | lr 1.25 | ms/batch 10.15 | loss  4.33 | ppl    75.74
| train-epoch  21 |   600/ 2983 batches | lr 1.25 | ms/batch 10.69 | loss  4.15 | ppl    63.56
| train-epoch  21 |   800/ 2983 batches | lr 1.25 | ms/batch 10.75 | loss  4.21 | ppl    67.53
| train-epoch  21 |  1000/ 2983 batches | lr 1.25 | ms/batch 10.88 | loss  4.23 | ppl    68.99
| train-epoch  21 |  1200/ 2983 batches | lr 1.25 | ms/batch 10.55 | loss  4.24 | ppl    69.44
| train-epoch  21 |  1400/ 2983 batches | lr 1.25 | ms/batch 10.50 | loss  4.25 | ppl    70.45
| train-epoch  21 |  1600/ 2983 batches | lr 1.25 | ms/batch 10.78 | loss  4.31 | ppl    74.18
| train-epoch  21 |  1800/ 2983 batches | lr 1.25 | ms/batch 10.62 | loss  4.22 | ppl    68.03
| train-epoch  21 |  2000/ 2983 batches | lr 1.25 | ms/batch 10.66 | loss  4.25 | ppl    70.10
| train-epoch  21 |  2200/ 2983 batches | lr 1.25 | ms/batch 10.80 | loss  4.12 | ppl    61.55
| train-epoch  21 |  2400/ 2983 batches | lr 1.25 | ms/batch 10.61 | loss  4.16 | ppl    63.90
| train-epoch  21 |  2600/ 2983 batches | lr 1.25 | ms/batch 10.82 | loss  4.19 | ppl    66.12
| train-epoch  21 |  2800/ 2983 batches | lr 1.25 | ms/batch 10.69 | loss  4.13 | ppl    62.09
-----------------------------------------------------------------------------------------
| end of train epoch  21 | time: 33.52s | valid loss  4.69 | valid ppl   109.04
-----------------------------------------------------------------------------------------
| train-epoch  22 |   200/ 2983 batches | lr 1.25 | ms/batch 10.14 | loss  4.27 | ppl    71.49
| train-epoch  22 |   400/ 2983 batches | lr 1.25 | ms/batch 10.33 | loss  4.30 | ppl    73.43
| train-epoch  22 |   600/ 2983 batches | lr 1.25 | ms/batch 10.08 | loss  4.12 | ppl    61.84
| train-epoch  22 |   800/ 2983 batches | lr 1.25 | ms/batch  9.96 | loss  4.18 | ppl    65.60
| train-epoch  22 |  1000/ 2983 batches | lr 1.25 | ms/batch 10.27 | loss  4.21 | ppl    67.11
| train-epoch  22 |  1200/ 2983 batches | lr 1.25 | ms/batch 10.08 | loss  4.22 | ppl    67.83
| train-epoch  22 |  1400/ 2983 batches | lr 1.25 | ms/batch 10.40 | loss  4.24 | ppl    69.36
| train-epoch  22 |  1600/ 2983 batches | lr 1.25 | ms/batch 10.86 | loss  4.29 | ppl    72.92
| train-epoch  22 |  1800/ 2983 batches | lr 1.25 | ms/batch 10.52 | loss  4.20 | ppl    66.82
| train-epoch  22 |  2000/ 2983 batches | lr 1.25 | ms/batch 10.88 | loss  4.24 | ppl    69.16
| train-epoch  22 |  2200/ 2983 batches | lr 1.25 | ms/batch 10.51 | loss  4.11 | ppl    61.02
| train-epoch  22 |  2400/ 2983 batches | lr 1.25 | ms/batch 10.87 | loss  4.15 | ppl    63.64
| train-epoch  22 |  2600/ 2983 batches | lr 1.25 | ms/batch 10.50 | loss  4.19 | ppl    65.71
| train-epoch  22 |  2800/ 2983 batches | lr 1.25 | ms/batch 10.56 | loss  4.13 | ppl    62.00
-----------------------------------------------------------------------------------------
| end of train epoch  22 | time: 32.77s | valid loss  4.69 | valid ppl   108.88
-----------------------------------------------------------------------------------------
| train-epoch  23 |   200/ 2983 batches | lr 1.25 | ms/batch 10.09 | loss  4.26 | ppl    70.69
| train-epoch  23 |   400/ 2983 batches | lr 1.25 | ms/batch 10.22 | loss  4.28 | ppl    72.35
| train-epoch  23 |   600/ 2983 batches | lr 1.25 | ms/batch 10.17 | loss  4.11 | ppl    60.87
| train-epoch  23 |   800/ 2983 batches | lr 1.25 | ms/batch 10.26 | loss  4.17 | ppl    64.66
| train-epoch  23 |  1000/ 2983 batches | lr 1.25 | ms/batch 10.24 | loss  4.19 | ppl    66.23
| train-epoch  23 |  1200/ 2983 batches | lr 1.25 | ms/batch 10.13 | loss  4.21 | ppl    67.22
| train-epoch  23 |  1400/ 2983 batches | lr 1.25 | ms/batch 10.61 | loss  4.23 | ppl    68.86
| train-epoch  23 |  1600/ 2983 batches | lr 1.25 | ms/batch 10.53 | loss  4.29 | ppl    72.71
| train-epoch  23 |  1800/ 2983 batches | lr 1.25 | ms/batch 10.33 | loss  4.19 | ppl    66.05
| train-epoch  23 |  2000/ 2983 batches | lr 1.25 | ms/batch 10.08 | loss  4.23 | ppl    68.56
| train-epoch  23 |  2200/ 2983 batches | lr 1.25 | ms/batch 10.23 | loss  4.10 | ppl    60.59
| train-epoch  23 |  2400/ 2983 batches | lr 1.25 | ms/batch 10.47 | loss  4.14 | ppl    62.73
| train-epoch  23 |  2600/ 2983 batches | lr 1.25 | ms/batch 10.76 | loss  4.18 | ppl    65.57
| train-epoch  23 |  2800/ 2983 batches | lr 1.25 | ms/batch 10.43 | loss  4.12 | ppl    61.67
-----------------------------------------------------------------------------------------
| end of train epoch  23 | time: 32.61s | valid loss  4.69 | valid ppl   108.60
-----------------------------------------------------------------------------------------
| train-epoch  24 |   200/ 2983 batches | lr 1.25 | ms/batch 10.32 | loss  4.25 | ppl    69.78
| train-epoch  24 |   400/ 2983 batches | lr 1.25 | ms/batch 10.00 | loss  4.27 | ppl    71.38
| train-epoch  24 |   600/ 2983 batches | lr 1.25 | ms/batch 10.27 | loss  4.10 | ppl    60.29
| train-epoch  24 |   800/ 2983 batches | lr 1.25 | ms/batch  9.99 | loss  4.16 | ppl    64.26
| train-epoch  24 |  1000/ 2983 batches | lr 1.25 | ms/batch 10.29 | loss  4.19 | ppl    66.06
| train-epoch  24 |  1200/ 2983 batches | lr 1.25 | ms/batch  9.97 | loss  4.20 | ppl    66.56
| train-epoch  24 |  1400/ 2983 batches | lr 1.25 | ms/batch 10.20 | loss  4.23 | ppl    68.48
| train-epoch  24 |  1600/ 2983 batches | lr 1.25 | ms/batch  9.97 | loss  4.28 | ppl    72.33
| train-epoch  24 |  1800/ 2983 batches | lr 1.25 | ms/batch 10.06 | loss  4.19 | ppl    66.03
| train-epoch  24 |  2000/ 2983 batches | lr 1.25 | ms/batch 10.29 | loss  4.23 | ppl    68.40
| train-epoch  24 |  2200/ 2983 batches | lr 1.25 | ms/batch 10.89 | loss  4.10 | ppl    60.46
| train-epoch  24 |  2400/ 2983 batches | lr 1.25 | ms/batch 10.80 | loss  4.14 | ppl    62.90
| train-epoch  24 |  2600/ 2983 batches | lr 1.25 | ms/batch 10.60 | loss  4.18 | ppl    65.31
| train-epoch  24 |  2800/ 2983 batches | lr 1.25 | ms/batch 10.83 | loss  4.12 | ppl    61.74
-----------------------------------------------------------------------------------------
| end of train epoch  24 | time: 32.55s | valid loss  4.69 | valid ppl   108.53
-----------------------------------------------------------------------------------------
| train-epoch  25 |   200/ 2983 batches | lr 1.25 | ms/batch 10.26 | loss  4.24 | ppl    69.14
| train-epoch  25 |   400/ 2983 batches | lr 1.25 | ms/batch 10.00 | loss  4.26 | ppl    70.94
| train-epoch  25 |   600/ 2983 batches | lr 1.25 | ms/batch 10.24 | loss  4.09 | ppl    59.66
| train-epoch  25 |   800/ 2983 batches | lr 1.25 | ms/batch  9.91 | loss  4.15 | ppl    63.55
| train-epoch  25 |  1000/ 2983 batches | lr 1.25 | ms/batch 10.13 | loss  4.18 | ppl    65.28
| train-epoch  25 |  1200/ 2983 batches | lr 1.25 | ms/batch 10.06 | loss  4.19 | ppl    66.08
| train-epoch  25 |  1400/ 2983 batches | lr 1.25 | ms/batch  9.94 | loss  4.22 | ppl    68.05
| train-epoch  25 |  1600/ 2983 batches | lr 1.25 | ms/batch 10.25 | loss  4.27 | ppl    71.46
| train-epoch  25 |  1800/ 2983 batches | lr 1.25 | ms/batch 10.00 | loss  4.18 | ppl    65.36
| train-epoch  25 |  2000/ 2983 batches | lr 1.25 | ms/batch 10.40 | loss  4.22 | ppl    68.18
| train-epoch  25 |  2200/ 2983 batches | lr 1.25 | ms/batch 10.01 | loss  4.10 | ppl    60.34
| train-epoch  25 |  2400/ 2983 batches | lr 1.25 | ms/batch 10.28 | loss  4.14 | ppl    62.61
| train-epoch  25 |  2600/ 2983 batches | lr 1.25 | ms/batch 10.03 | loss  4.18 | ppl    65.31
| train-epoch  25 |  2800/ 2983 batches | lr 1.25 | ms/batch 10.10 | loss  4.12 | ppl    61.63
-----------------------------------------------------------------------------------------
| end of train epoch  25 | time: 31.87s | valid loss  4.69 | valid ppl   108.47
-----------------------------------------------------------------------------------------
| train-epoch  26 |   200/ 2983 batches | lr 1.25 | ms/batch  9.99 | loss  4.23 | ppl    68.85
| train-epoch  26 |   400/ 2983 batches | lr 1.25 | ms/batch 10.32 | loss  4.26 | ppl    70.49
| train-epoch  26 |   600/ 2983 batches | lr 1.25 | ms/batch 10.10 | loss  4.08 | ppl    59.39
| train-epoch  26 |   800/ 2983 batches | lr 1.25 | ms/batch 10.27 | loss  4.15 | ppl    63.21
| train-epoch  26 |  1000/ 2983 batches | lr 1.25 | ms/batch 10.18 | loss  4.17 | ppl    64.72
| train-epoch  26 |  1200/ 2983 batches | lr 1.25 | ms/batch  9.80 | loss  4.19 | ppl    65.75
| train-epoch  26 |  1400/ 2983 batches | lr 1.25 | ms/batch 10.20 | loss  4.21 | ppl    67.54
| train-epoch  26 |  1600/ 2983 batches | lr 1.25 | ms/batch 10.38 | loss  4.27 | ppl    71.53
| train-epoch  26 |  1800/ 2983 batches | lr 1.25 | ms/batch 10.49 | loss  4.17 | ppl    64.91
| train-epoch  26 |  2000/ 2983 batches | lr 1.25 | ms/batch 10.42 | loss  4.21 | ppl    67.56
| train-epoch  26 |  2200/ 2983 batches | lr 1.25 | ms/batch 10.43 | loss  4.09 | ppl    59.95
| train-epoch  26 |  2400/ 2983 batches | lr 1.25 | ms/batch 10.63 | loss  4.14 | ppl    62.51
| train-epoch  26 |  2600/ 2983 batches | lr 1.25 | ms/batch 10.16 | loss  4.17 | ppl    64.91
| train-epoch  26 |  2800/ 2983 batches | lr 1.25 | ms/batch 10.69 | loss  4.12 | ppl    61.37
-----------------------------------------------------------------------------------------
| end of train epoch  26 | time: 32.49s | valid loss  4.69 | valid ppl   108.40
-----------------------------------------------------------------------------------------
| train-epoch  27 |   200/ 2983 batches | lr 1.25 | ms/batch 10.32 | loss  4.22 | ppl    68.25
| train-epoch  27 |   400/ 2983 batches | lr 1.25 | ms/batch 10.13 | loss  4.26 | ppl    70.52
| train-epoch  27 |   600/ 2983 batches | lr 1.25 | ms/batch 10.16 | loss  4.08 | ppl    59.19
| train-epoch  27 |   800/ 2983 batches | lr 1.25 | ms/batch 10.10 | loss  4.14 | ppl    62.69
| train-epoch  27 |  1000/ 2983 batches | lr 1.25 | ms/batch 10.30 | loss  4.16 | ppl    64.38
| train-epoch  27 |  1200/ 2983 batches | lr 1.25 | ms/batch 10.13 | loss  4.18 | ppl    65.48
| train-epoch  27 |  1400/ 2983 batches | lr 1.25 | ms/batch 10.28 | loss  4.21 | ppl    67.53
| train-epoch  27 |  1600/ 2983 batches | lr 1.25 | ms/batch 10.05 | loss  4.27 | ppl    71.17
| train-epoch  27 |  1800/ 2983 batches | lr 1.25 | ms/batch  9.93 | loss  4.18 | ppl    65.07
| train-epoch  27 |  2000/ 2983 batches | lr 1.25 | ms/batch 10.49 | loss  4.21 | ppl    67.59
| train-epoch  27 |  2200/ 2983 batches | lr 1.25 | ms/batch 10.44 | loss  4.09 | ppl    59.74
| train-epoch  27 |  2400/ 2983 batches | lr 1.25 | ms/batch 10.77 | loss  4.13 | ppl    62.31
| train-epoch  27 |  2600/ 2983 batches | lr 1.25 | ms/batch 10.41 | loss  4.17 | ppl    64.91
| train-epoch  27 |  2800/ 2983 batches | lr 1.25 | ms/batch 10.69 | loss  4.12 | ppl    61.28
-----------------------------------------------------------------------------------------
| end of train epoch  27 | time: 32.49s | valid loss  4.68 | valid ppl   108.25
-----------------------------------------------------------------------------------------
| train-epoch  28 |   200/ 2983 batches | lr 1.25 | ms/batch 10.24 | loss  4.22 | ppl    68.10
| train-epoch  28 |   400/ 2983 batches | lr 1.25 | ms/batch  9.94 | loss  4.25 | ppl    69.90
| train-epoch  28 |   600/ 2983 batches | lr 1.25 | ms/batch 10.28 | loss  4.07 | ppl    58.70
| train-epoch  28 |   800/ 2983 batches | lr 1.25 | ms/batch 10.12 | loss  4.14 | ppl    62.55
| train-epoch  28 |  1000/ 2983 batches | lr 1.25 | ms/batch 10.33 | loss  4.16 | ppl    64.36
| train-epoch  28 |  1200/ 2983 batches | lr 1.25 | ms/batch 10.21 | loss  4.17 | ppl    64.91
| train-epoch  28 |  1400/ 2983 batches | lr 1.25 | ms/batch 10.17 | loss  4.21 | ppl    67.15
| train-epoch  28 |  1600/ 2983 batches | lr 1.25 | ms/batch 10.11 | loss  4.26 | ppl    70.48
| train-epoch  28 |  1800/ 2983 batches | lr 1.25 | ms/batch 10.40 | loss  4.17 | ppl    64.74
| train-epoch  28 |  2000/ 2983 batches | lr 1.25 | ms/batch 10.20 | loss  4.21 | ppl    67.34
| train-epoch  28 |  2200/ 2983 batches | lr 1.25 | ms/batch 10.17 | loss  4.09 | ppl    59.47
| train-epoch  28 |  2400/ 2983 batches | lr 1.25 | ms/batch 10.36 | loss  4.13 | ppl    61.91
| train-epoch  28 |  2600/ 2983 batches | lr 1.25 | ms/batch 10.08 | loss  4.17 | ppl    64.43
| train-epoch  28 |  2800/ 2983 batches | lr 1.25 | ms/batch 10.36 | loss  4.11 | ppl    60.78
-----------------------------------------------------------------------------------------
| end of train epoch  28 | time: 32.15s | valid loss  4.68 | valid ppl   108.05
-----------------------------------------------------------------------------------------
| train-epoch  29 |   200/ 2983 batches | lr 1.25 | ms/batch 10.45 | loss  4.21 | ppl    67.53
| train-epoch  29 |   400/ 2983 batches | lr 1.25 | ms/batch 10.08 | loss  4.24 | ppl    69.33
| train-epoch  29 |   600/ 2983 batches | lr 1.25 | ms/batch 10.20 | loss  4.07 | ppl    58.38
| train-epoch  29 |   800/ 2983 batches | lr 1.25 | ms/batch 10.25 | loss  4.13 | ppl    61.94
| train-epoch  29 |  1000/ 2983 batches | lr 1.25 | ms/batch 10.08 | loss  4.17 | ppl    64.41
| train-epoch  29 |  1200/ 2983 batches | lr 1.25 | ms/batch 10.22 | loss  4.17 | ppl    64.61
| train-epoch  29 |  1400/ 2983 batches | lr 1.25 | ms/batch 10.24 | loss  4.20 | ppl    66.52
| train-epoch  29 |  1600/ 2983 batches | lr 1.25 | ms/batch 10.31 | loss  4.25 | ppl    70.28
| train-epoch  29 |  1800/ 2983 batches | lr 1.25 | ms/batch 10.36 | loss  4.17 | ppl    64.46
| train-epoch  29 |  2000/ 2983 batches | lr 1.25 | ms/batch 10.44 | loss  4.21 | ppl    67.06
| train-epoch  29 |  2200/ 2983 batches | lr 1.25 | ms/batch 10.39 | loss  4.08 | ppl    59.09
| train-epoch  29 |  2400/ 2983 batches | lr 1.25 | ms/batch 10.57 | loss  4.12 | ppl    61.69
| train-epoch  29 |  2600/ 2983 batches | lr 1.25 | ms/batch  9.95 | loss  4.16 | ppl    64.31
| train-epoch  29 |  2800/ 2983 batches | lr 1.25 | ms/batch 10.58 | loss  4.11 | ppl    60.66
-----------------------------------------------------------------------------------------
| end of train epoch  29 | time: 32.44s | valid loss  4.68 | valid ppl   108.26
-----------------------------------------------------------------------------------------
| train-epoch  30 |   200/ 2983 batches | lr 0.31 | ms/batch 10.00 | loss  4.23 | ppl    68.66
| train-epoch  30 |   400/ 2983 batches | lr 0.31 | ms/batch 10.39 | loss  4.26 | ppl    70.79
| train-epoch  30 |   600/ 2983 batches | lr 0.31 | ms/batch 10.11 | loss  4.10 | ppl    60.05
| train-epoch  30 |   800/ 2983 batches | lr 0.31 | ms/batch 10.14 | loss  4.16 | ppl    64.07
| train-epoch  30 |  1000/ 2983 batches | lr 0.31 | ms/batch 10.44 | loss  4.18 | ppl    65.17
| train-epoch  30 |  1200/ 2983 batches | lr 0.31 | ms/batch 10.12 | loss  4.18 | ppl    65.46
| train-epoch  30 |  1400/ 2983 batches | lr 0.31 | ms/batch 10.29 | loss  4.21 | ppl    67.62
| train-epoch  30 |  1600/ 2983 batches | lr 0.31 | ms/batch 10.41 | loss  4.26 | ppl    70.86
| train-epoch  30 |  1800/ 2983 batches | lr 0.31 | ms/batch 10.44 | loss  4.17 | ppl    64.64
| train-epoch  30 |  2000/ 2983 batches | lr 0.31 | ms/batch 10.47 | loss  4.20 | ppl    66.59
| train-epoch  30 |  2200/ 2983 batches | lr 0.31 | ms/batch 10.82 | loss  4.08 | ppl    59.04
| train-epoch  30 |  2400/ 2983 batches | lr 0.31 | ms/batch 10.46 | loss  4.11 | ppl    61.02
| train-epoch  30 |  2600/ 2983 batches | lr 0.31 | ms/batch 10.82 | loss  4.15 | ppl    63.49
| train-epoch  30 |  2800/ 2983 batches | lr 0.31 | ms/batch 10.48 | loss  4.09 | ppl    59.87
-----------------------------------------------------------------------------------------
| end of train epoch  30 | time: 32.77s | valid loss  4.67 | valid ppl   106.59
-----------------------------------------------------------------------------------------
| train-epoch  31 |   200/ 2983 batches | lr 0.31 | ms/batch 10.05 | loss  4.22 | ppl    68.20
| train-epoch  31 |   400/ 2983 batches | lr 0.31 | ms/batch  9.96 | loss  4.25 | ppl    69.94
| train-epoch  31 |   600/ 2983 batches | lr 0.31 | ms/batch 10.21 | loss  4.08 | ppl    59.36
| train-epoch  31 |   800/ 2983 batches | lr 0.31 | ms/batch  9.93 | loss  4.14 | ppl    62.94
| train-epoch  31 |  1000/ 2983 batches | lr 0.31 | ms/batch  9.94 | loss  4.17 | ppl    64.65
| train-epoch  31 |  1200/ 2983 batches | lr 0.31 | ms/batch 10.15 | loss  4.17 | ppl    64.91
| train-epoch  31 |  1400/ 2983 batches | lr 0.31 | ms/batch 10.11 | loss  4.21 | ppl    67.19
| train-epoch  31 |  1600/ 2983 batches | lr 0.31 | ms/batch 10.45 | loss  4.26 | ppl    70.68
| train-epoch  31 |  1800/ 2983 batches | lr 0.31 | ms/batch 10.76 | loss  4.16 | ppl    64.33
| train-epoch  31 |  2000/ 2983 batches | lr 0.31 | ms/batch 10.43 | loss  4.20 | ppl    66.70
| train-epoch  31 |  2200/ 2983 batches | lr 0.31 | ms/batch 10.74 | loss  4.08 | ppl    58.96
| train-epoch  31 |  2400/ 2983 batches | lr 0.31 | ms/batch 10.13 | loss  4.11 | ppl    61.02
| train-epoch  31 |  2600/ 2983 batches | lr 0.31 | ms/batch 10.45 | loss  4.15 | ppl    63.67
| train-epoch  31 |  2800/ 2983 batches | lr 0.31 | ms/batch 10.43 | loss  4.10 | ppl    60.04
-----------------------------------------------------------------------------------------
| end of train epoch  31 | time: 32.53s | valid loss  4.67 | valid ppl   106.50
-----------------------------------------------------------------------------------------
| train-epoch  32 |   200/ 2983 batches | lr 0.31 | ms/batch 10.00 | loss  4.22 | ppl    67.77
| train-epoch  32 |   400/ 2983 batches | lr 0.31 | ms/batch 10.16 | loss  4.24 | ppl    69.47
| train-epoch  32 |   600/ 2983 batches | lr 0.31 | ms/batch 10.03 | loss  4.08 | ppl    59.06
| train-epoch  32 |   800/ 2983 batches | lr 0.31 | ms/batch  9.94 | loss  4.14 | ppl    62.76
| train-epoch  32 |  1000/ 2983 batches | lr 0.31 | ms/batch 10.46 | loss  4.16 | ppl    64.12
| train-epoch  32 |  1200/ 2983 batches | lr 0.31 | ms/batch  9.68 | loss  4.17 | ppl    64.45
| train-epoch  32 |  1400/ 2983 batches | lr 0.31 | ms/batch  9.95 | loss  4.20 | ppl    66.60
| train-epoch  32 |  1600/ 2983 batches | lr 0.31 | ms/batch 10.09 | loss  4.25 | ppl    70.34
| train-epoch  32 |  1800/ 2983 batches | lr 0.31 | ms/batch 10.12 | loss  4.17 | ppl    64.48
| train-epoch  32 |  2000/ 2983 batches | lr 0.31 | ms/batch 10.13 | loss  4.20 | ppl    66.45
| train-epoch  32 |  2200/ 2983 batches | lr 0.31 | ms/batch 10.12 | loss  4.07 | ppl    58.79
| train-epoch  32 |  2400/ 2983 batches | lr 0.31 | ms/batch 10.10 | loss  4.11 | ppl    60.87
| train-epoch  32 |  2600/ 2983 batches | lr 0.31 | ms/batch 10.11 | loss  4.16 | ppl    63.82
| train-epoch  32 |  2800/ 2983 batches | lr 0.31 | ms/batch 10.10 | loss  4.10 | ppl    60.26
-----------------------------------------------------------------------------------------
| end of train epoch  32 | time: 31.66s | valid loss  4.67 | valid ppl   106.39
-----------------------------------------------------------------------------------------
| train-epoch  33 |   200/ 2983 batches | lr 0.31 | ms/batch  9.79 | loss  4.21 | ppl    67.57
| train-epoch  33 |   400/ 2983 batches | lr 0.31 | ms/batch  9.68 | loss  4.24 | ppl    69.68
| train-epoch  33 |   600/ 2983 batches | lr 0.31 | ms/batch  9.63 | loss  4.07 | ppl    58.76
| train-epoch  33 |   800/ 2983 batches | lr 0.31 | ms/batch  9.67 | loss  4.13 | ppl    62.20
| train-epoch  33 |  1000/ 2983 batches | lr 0.31 | ms/batch  9.72 | loss  4.16 | ppl    63.85
| train-epoch  33 |  1200/ 2983 batches | lr 0.31 | ms/batch  9.67 | loss  4.16 | ppl    64.32
| train-epoch  33 |  1400/ 2983 batches | lr 0.31 | ms/batch  9.66 | loss  4.20 | ppl    66.63
| train-epoch  33 |  1600/ 2983 batches | lr 0.31 | ms/batch  9.64 | loss  4.25 | ppl    70.25
| train-epoch  33 |  1800/ 2983 batches | lr 0.31 | ms/batch  9.64 | loss  4.16 | ppl    64.04
| train-epoch  33 |  2000/ 2983 batches | lr 0.31 | ms/batch  9.64 | loss  4.19 | ppl    66.32
| train-epoch  33 |  2200/ 2983 batches | lr 0.31 | ms/batch  9.64 | loss  4.07 | ppl    58.82
| train-epoch  33 |  2400/ 2983 batches | lr 0.31 | ms/batch  9.64 | loss  4.11 | ppl    60.73
| train-epoch  33 |  2600/ 2983 batches | lr 0.31 | ms/batch  9.62 | loss  4.15 | ppl    63.51
| train-epoch  33 |  2800/ 2983 batches | lr 0.31 | ms/batch  9.61 | loss  4.10 | ppl    60.24
-----------------------------------------------------------------------------------------
| end of train epoch  33 | time: 30.41s | valid loss  4.67 | valid ppl   106.31
-----------------------------------------------------------------------------------------
| train-epoch  34 |   200/ 2983 batches | lr 0.31 | ms/batch  9.81 | loss  4.21 | ppl    67.61
| train-epoch  34 |   400/ 2983 batches | lr 0.31 | ms/batch  9.73 | loss  4.24 | ppl    69.44
| train-epoch  34 |   600/ 2983 batches | lr 0.31 | ms/batch  9.64 | loss  4.07 | ppl    58.71
| train-epoch  34 |   800/ 2983 batches | lr 0.31 | ms/batch  9.72 | loss  4.13 | ppl    62.22
| train-epoch  34 |  1000/ 2983 batches | lr 0.31 | ms/batch  9.65 | loss  4.16 | ppl    63.81
| train-epoch  34 |  1200/ 2983 batches | lr 0.31 | ms/batch  9.65 | loss  4.17 | ppl    64.50
| train-epoch  34 |  1400/ 2983 batches | lr 0.31 | ms/batch  9.67 | loss  4.19 | ppl    66.31
| train-epoch  34 |  1600/ 2983 batches | lr 0.31 | ms/batch  9.66 | loss  4.25 | ppl    69.90
| train-epoch  34 |  1800/ 2983 batches | lr 0.31 | ms/batch  9.68 | loss  4.16 | ppl    63.98
| train-epoch  34 |  2000/ 2983 batches | lr 0.31 | ms/batch  9.76 | loss  4.20 | ppl    66.54
| train-epoch  34 |  2200/ 2983 batches | lr 0.31 | ms/batch  9.66 | loss  4.07 | ppl    58.82
| train-epoch  34 |  2400/ 2983 batches | lr 0.31 | ms/batch  9.65 | loss  4.11 | ppl    60.84
| train-epoch  34 |  2600/ 2983 batches | lr 0.31 | ms/batch  9.65 | loss  4.15 | ppl    63.47
| train-epoch  34 |  2800/ 2983 batches | lr 0.31 | ms/batch  9.65 | loss  4.10 | ppl    60.29
-----------------------------------------------------------------------------------------
| end of train epoch  34 | time: 30.45s | valid loss  4.67 | valid ppl   106.30
-----------------------------------------------------------------------------------------
| train-epoch  35 |   200/ 2983 batches | lr 0.31 | ms/batch  9.81 | loss  4.21 | ppl    67.29
| train-epoch  35 |   400/ 2983 batches | lr 0.31 | ms/batch  9.81 | loss  4.24 | ppl    69.33
| train-epoch  35 |   600/ 2983 batches | lr 0.31 | ms/batch  9.75 | loss  4.07 | ppl    58.40
| train-epoch  35 |   800/ 2983 batches | lr 0.31 | ms/batch  9.73 | loss  4.13 | ppl    62.39
| train-epoch  35 |  1000/ 2983 batches | lr 0.31 | ms/batch  9.79 | loss  4.15 | ppl    63.58
| train-epoch  35 |  1200/ 2983 batches | lr 0.31 | ms/batch  9.80 | loss  4.17 | ppl    64.43
| train-epoch  35 |  1400/ 2983 batches | lr 0.31 | ms/batch  9.75 | loss  4.20 | ppl    66.62
| train-epoch  35 |  1600/ 2983 batches | lr 0.31 | ms/batch  9.68 | loss  4.25 | ppl    70.11
| train-epoch  35 |  1800/ 2983 batches | lr 0.31 | ms/batch  9.69 | loss  4.16 | ppl    63.88
| train-epoch  35 |  2000/ 2983 batches | lr 0.31 | ms/batch  9.66 | loss  4.19 | ppl    66.33
| train-epoch  35 |  2200/ 2983 batches | lr 0.31 | ms/batch  9.68 | loss  4.07 | ppl    58.49
| train-epoch  35 |  2400/ 2983 batches | lr 0.31 | ms/batch  9.68 | loss  4.11 | ppl    60.81
| train-epoch  35 |  2600/ 2983 batches | lr 0.31 | ms/batch  9.68 | loss  4.15 | ppl    63.54
| train-epoch  35 |  2800/ 2983 batches | lr 0.31 | ms/batch  9.74 | loss  4.10 | ppl    60.08
-----------------------------------------------------------------------------------------
| end of train epoch  35 | time: 30.75s | valid loss  4.67 | valid ppl   106.35
-----------------------------------------------------------------------------------------
| train-epoch  36 |   200/ 2983 batches | lr 0.08 | ms/batch  9.80 | loss  4.22 | ppl    67.77
| train-epoch  36 |   400/ 2983 batches | lr 0.08 | ms/batch  9.68 | loss  4.25 | ppl    70.14
| train-epoch  36 |   600/ 2983 batches | lr 0.08 | ms/batch  9.65 | loss  4.09 | ppl    59.46
| train-epoch  36 |   800/ 2983 batches | lr 0.08 | ms/batch  9.80 | loss  4.15 | ppl    63.25
| train-epoch  36 |  1000/ 2983 batches | lr 0.08 | ms/batch  9.75 | loss  4.16 | ppl    63.84
| train-epoch  36 |  1200/ 2983 batches | lr 0.08 | ms/batch  9.69 | loss  4.17 | ppl    64.67
| train-epoch  36 |  1400/ 2983 batches | lr 0.08 | ms/batch  9.68 | loss  4.20 | ppl    66.78
| train-epoch  36 |  1600/ 2983 batches | lr 0.08 | ms/batch  9.68 | loss  4.25 | ppl    70.22
| train-epoch  36 |  1800/ 2983 batches | lr 0.08 | ms/batch  9.78 | loss  4.16 | ppl    63.98
| train-epoch  36 |  2000/ 2983 batches | lr 0.08 | ms/batch  9.93 | loss  4.19 | ppl    66.21
| train-epoch  36 |  2200/ 2983 batches | lr 0.08 | ms/batch 10.11 | loss  4.07 | ppl    58.63
| train-epoch  36 |  2400/ 2983 batches | lr 0.08 | ms/batch 10.11 | loss  4.11 | ppl    60.84
| train-epoch  36 |  2600/ 2983 batches | lr 0.08 | ms/batch 10.12 | loss  4.14 | ppl    62.95
| train-epoch  36 |  2800/ 2983 batches | lr 0.08 | ms/batch 10.13 | loss  4.09 | ppl    59.48
-----------------------------------------------------------------------------------------
| end of train epoch  36 | time: 31.05s | valid loss  4.66 | valid ppl   105.96
-----------------------------------------------------------------------------------------
| train-epoch  37 |   200/ 2983 batches | lr 0.08 | ms/batch 10.06 | loss  4.21 | ppl    67.62
| train-epoch  37 |   400/ 2983 batches | lr 0.08 | ms/batch 10.10 | loss  4.24 | ppl    69.69
| train-epoch  37 |   600/ 2983 batches | lr 0.08 | ms/batch 10.09 | loss  4.08 | ppl    58.96
| train-epoch  37 |   800/ 2983 batches | lr 0.08 | ms/batch 10.11 | loss  4.14 | ppl    63.03
| train-epoch  37 |  1000/ 2983 batches | lr 0.08 | ms/batch 10.11 | loss  4.16 | ppl    64.16
| train-epoch  37 |  1200/ 2983 batches | lr 0.08 | ms/batch 10.09 | loss  4.17 | ppl    64.46
| train-epoch  37 |  1400/ 2983 batches | lr 0.08 | ms/batch 10.10 | loss  4.20 | ppl    66.42
| train-epoch  37 |  1600/ 2983 batches | lr 0.08 | ms/batch 10.09 | loss  4.25 | ppl    70.15
| train-epoch  37 |  1800/ 2983 batches | lr 0.08 | ms/batch 10.09 | loss  4.15 | ppl    63.65
| train-epoch  37 |  2000/ 2983 batches | lr 0.08 | ms/batch 10.09 | loss  4.19 | ppl    66.16
| train-epoch  37 |  2200/ 2983 batches | lr 0.08 | ms/batch 10.11 | loss  4.07 | ppl    58.76
| train-epoch  37 |  2400/ 2983 batches | lr 0.08 | ms/batch 10.10 | loss  4.10 | ppl    60.64
| train-epoch  37 |  2600/ 2983 batches | lr 0.08 | ms/batch 10.10 | loss  4.15 | ppl    63.24
| train-epoch  37 |  2800/ 2983 batches | lr 0.08 | ms/batch 10.09 | loss  4.09 | ppl    59.60
-----------------------------------------------------------------------------------------
| end of train epoch  37 | time: 31.72s | valid loss  4.66 | valid ppl   105.91
-----------------------------------------------------------------------------------------
| train-epoch  38 |   200/ 2983 batches | lr 0.08 | ms/batch  9.65 | loss  4.22 | ppl    67.84
| train-epoch  38 |   400/ 2983 batches | lr 0.08 | ms/batch  9.65 | loss  4.24 | ppl    69.45
| train-epoch  38 |   600/ 2983 batches | lr 0.08 | ms/batch  9.72 | loss  4.08 | ppl    58.89
| train-epoch  38 |   800/ 2983 batches | lr 0.08 | ms/batch  9.72 | loss  4.14 | ppl    62.83
| train-epoch  38 |  1000/ 2983 batches | lr 0.08 | ms/batch  9.65 | loss  4.16 | ppl    64.09
| train-epoch  38 |  1200/ 2983 batches | lr 0.08 | ms/batch  9.63 | loss  4.16 | ppl    63.99
| train-epoch  38 |  1400/ 2983 batches | lr 0.08 | ms/batch  9.67 | loss  4.20 | ppl    66.54
| train-epoch  38 |  1600/ 2983 batches | lr 0.08 | ms/batch  9.73 | loss  4.25 | ppl    69.98
| train-epoch  38 |  1800/ 2983 batches | lr 0.08 | ms/batch  9.74 | loss  4.16 | ppl    64.02
| train-epoch  38 |  2000/ 2983 batches | lr 0.08 | ms/batch  9.79 | loss  4.19 | ppl    66.22
| train-epoch  38 |  2200/ 2983 batches | lr 0.08 | ms/batch  9.67 | loss  4.07 | ppl    58.70
| train-epoch  38 |  2400/ 2983 batches | lr 0.08 | ms/batch  9.67 | loss  4.11 | ppl    60.65
| train-epoch  38 |  2600/ 2983 batches | lr 0.08 | ms/batch  9.81 | loss  4.14 | ppl    62.74
| train-epoch  38 |  2800/ 2983 batches | lr 0.08 | ms/batch  9.76 | loss  4.09 | ppl    59.66
-----------------------------------------------------------------------------------------
| end of train epoch  38 | time: 30.52s | valid loss  4.66 | valid ppl   105.91
-----------------------------------------------------------------------------------------
| train-epoch  39 |   200/ 2983 batches | lr 0.02 | ms/batch  9.80 | loss  4.22 | ppl    67.98
| train-epoch  39 |   400/ 2983 batches | lr 0.02 | ms/batch  9.83 | loss  4.25 | ppl    69.83
| train-epoch  39 |   600/ 2983 batches | lr 0.02 | ms/batch  9.80 | loss  4.08 | ppl    59.03
| train-epoch  39 |   800/ 2983 batches | lr 0.02 | ms/batch  9.87 | loss  4.14 | ppl    62.91
| train-epoch  39 |  1000/ 2983 batches | lr 0.02 | ms/batch  9.94 | loss  4.16 | ppl    63.96
| train-epoch  39 |  1200/ 2983 batches | lr 0.02 | ms/batch 10.20 | loss  4.17 | ppl    64.58
| train-epoch  39 |  1400/ 2983 batches | lr 0.02 | ms/batch 10.23 | loss  4.20 | ppl    66.52
| train-epoch  39 |  1600/ 2983 batches | lr 0.02 | ms/batch 10.23 | loss  4.25 | ppl    69.89
| train-epoch  39 |  1800/ 2983 batches | lr 0.02 | ms/batch 10.24 | loss  4.16 | ppl    63.88
| train-epoch  39 |  2000/ 2983 batches | lr 0.02 | ms/batch 10.23 | loss  4.19 | ppl    66.19
| train-epoch  39 |  2200/ 2983 batches | lr 0.02 | ms/batch 10.25 | loss  4.07 | ppl    58.66
| train-epoch  39 |  2400/ 2983 batches | lr 0.02 | ms/batch 10.21 | loss  4.11 | ppl    60.71
| train-epoch  39 |  2600/ 2983 batches | lr 0.02 | ms/batch 10.24 | loss  4.15 | ppl    63.12
| train-epoch  39 |  2800/ 2983 batches | lr 0.02 | ms/batch 10.23 | loss  4.09 | ppl    59.47
-----------------------------------------------------------------------------------------
| end of train epoch  39 | time: 31.77s | valid loss  4.66 | valid ppl   105.83
-----------------------------------------------------------------------------------------
| train-epoch  40 |   200/ 2983 batches | lr 0.02 | ms/batch  9.79 | loss  4.22 | ppl    67.82
| train-epoch  40 |   400/ 2983 batches | lr 0.02 | ms/batch  9.74 | loss  4.24 | ppl    69.68
| train-epoch  40 |   600/ 2983 batches | lr 0.02 | ms/batch  9.81 | loss  4.08 | ppl    59.13
| train-epoch  40 |   800/ 2983 batches | lr 0.02 | ms/batch  9.72 | loss  4.14 | ppl    62.56
| train-epoch  40 |  1000/ 2983 batches | lr 0.02 | ms/batch  9.74 | loss  4.16 | ppl    63.76
| train-epoch  40 |  1200/ 2983 batches | lr 0.02 | ms/batch  9.78 | loss  4.16 | ppl    64.09
| train-epoch  40 |  1400/ 2983 batches | lr 0.02 | ms/batch  9.77 | loss  4.20 | ppl    66.45
| train-epoch  40 |  1600/ 2983 batches | lr 0.02 | ms/batch  9.72 | loss  4.25 | ppl    69.89
| train-epoch  40 |  1800/ 2983 batches | lr 0.02 | ms/batch  9.74 | loss  4.16 | ppl    63.78
| train-epoch  40 |  2000/ 2983 batches | lr 0.02 | ms/batch  9.74 | loss  4.19 | ppl    66.12
| train-epoch  40 |  2200/ 2983 batches | lr 0.02 | ms/batch  9.73 | loss  4.07 | ppl    58.62
| train-epoch  40 |  2400/ 2983 batches | lr 0.02 | ms/batch  9.71 | loss  4.10 | ppl    60.59
| train-epoch  40 |  2600/ 2983 batches | lr 0.02 | ms/batch  9.78 | loss  4.14 | ppl    63.04
| train-epoch  40 |  2800/ 2983 batches | lr 0.02 | ms/batch  9.76 | loss  4.09 | ppl    59.52
-----------------------------------------------------------------------------------------
| end of train epoch  40 | time: 30.65s | valid loss  4.66 | valid ppl   105.80
-----------------------------------------------------------------------------------------
required epochs  40 | actual epochs  60
pretrain epochs  40 | prune epochs   0 | retrain epochs  20
=========================================================================================
| End of training | test loss  4.61 | test ppl   100.15
=========================================================================================
python main.py --cuda --emsize 650 --nhid 650 --dropout 0.5 --epochs 40 --save model/baseline/model.pt
<class 'torch.Tensor'> torch.Size([33278, 650])
<class 'torch.Tensor'> torch.Size([2600, 650])
<class 'torch.Tensor'> torch.Size([2600, 650])
<class 'torch.Tensor'> torch.Size([2600])
<class 'torch.Tensor'> torch.Size([2600])
<class 'torch.Tensor'> torch.Size([2600, 650])
<class 'torch.Tensor'> torch.Size([2600, 650])
<class 'torch.Tensor'> torch.Size([2600])
<class 'torch.Tensor'> torch.Size([2600])
<class 'torch.Tensor'> torch.Size([33278, 650])
<class 'torch.Tensor'> torch.Size([33278])
RNNModel(
  (drop): Dropout(p=0.5)
  (encoder): Embedding(33278, 650)
  (rnn): LSTM(650, 650, num_layers=2, dropout=0.5)
  (decoder): Linear(in_features=650, out_features=33278, bias=True)
)
Dropout(p=0.5)
Embedding(33278, 650)
LSTM(650, 650, num_layers=2, dropout=0.5)
Linear(in_features=650, out_features=33278, bias=True)
| train-epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 22.44 | loss  7.74 | ppl  2289.44
| train-epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 22.18 | loss  6.83 | ppl   924.74
| train-epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 22.16 | loss  6.45 | ppl   630.61
| train-epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 22.22 | loss  6.28 | ppl   535.41
| train-epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.27 | loss  6.15 | ppl   468.04
| train-epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.32 | loss  6.09 | ppl   441.11
| train-epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.33 | loss  5.99 | ppl   398.26
| train-epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.26 | loss  5.99 | ppl   401.09
| train-epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  5.84 | ppl   344.27
| train-epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.44 | loss  5.82 | ppl   337.40
| train-epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  5.71 | ppl   302.18
| train-epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  5.72 | ppl   303.73
| train-epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.46 | loss  5.70 | ppl   298.17
| train-epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.44 | loss  5.59 | ppl   267.98
-----------------------------------------------------------------------------------------
| end of train epoch   1 | time: 69.46s | valid loss  5.52 | valid ppl   249.79
-----------------------------------------------------------------------------------------
| train-epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch 22.56 | loss  5.59 | ppl   267.17
| train-epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  5.57 | ppl   262.03
| train-epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch 22.44 | loss  5.40 | ppl   221.67
| train-epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch 22.46 | loss  5.41 | ppl   224.50
| train-epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.46 | loss  5.38 | ppl   217.69
| train-epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.45 | loss  5.38 | ppl   216.08
| train-epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.45 | loss  5.36 | ppl   213.47
| train-epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.46 | loss  5.42 | ppl   226.75
| train-epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.45 | loss  5.30 | ppl   199.50
| train-epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.46 | loss  5.31 | ppl   201.80
| train-epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  5.21 | ppl   182.73
| train-epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.54 | loss  5.23 | ppl   187.25
| train-epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.46 | loss  5.24 | ppl   188.62
| train-epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.45 | loss  5.16 | ppl   174.33
-----------------------------------------------------------------------------------------
| end of train epoch   2 | time: 69.81s | valid loss  5.21 | valid ppl   184.00
-----------------------------------------------------------------------------------------
| train-epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 22.54 | loss  5.21 | ppl   183.46
| train-epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch 22.53 | loss  5.22 | ppl   185.26
| train-epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  5.04 | ppl   153.80
| train-epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  5.08 | ppl   161.16
| train-epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  5.07 | ppl   158.83
| train-epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  5.07 | ppl   159.04
| train-epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  5.09 | ppl   162.59
| train-epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  5.15 | ppl   172.79
| train-epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  5.03 | ppl   152.87
| train-epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  5.06 | ppl   157.72
| train-epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  4.96 | ppl   142.54
| train-epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  4.99 | ppl   147.62
| train-epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  5.01 | ppl   149.27
| train-epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  4.94 | ppl   139.43
-----------------------------------------------------------------------------------------
| end of train epoch   3 | time: 69.71s | valid loss  5.05 | valid ppl   156.07
-----------------------------------------------------------------------------------------
| train-epoch   4 |   200/ 2983 batches | lr 20.00 | ms/batch 22.60 | loss  4.99 | ppl   147.59
| train-epoch   4 |   400/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  5.01 | ppl   150.46
| train-epoch   4 |   600/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  4.82 | ppl   124.03
| train-epoch   4 |   800/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  4.88 | ppl   131.69
| train-epoch   4 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.50 | loss  4.87 | ppl   130.51
| train-epoch   4 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  4.88 | ppl   131.66
| train-epoch   4 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.49 | loss  4.91 | ppl   135.65
| train-epoch   4 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  4.98 | ppl   145.86
| train-epoch   4 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.49 | loss  4.85 | ppl   128.25
| train-epoch   4 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.49 | loss  4.89 | ppl   132.68
| train-epoch   4 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.50 | loss  4.78 | ppl   119.62
| train-epoch   4 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  4.82 | ppl   124.31
| train-epoch   4 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.45 | loss  4.84 | ppl   127.07
| train-epoch   4 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  4.78 | ppl   118.73
-----------------------------------------------------------------------------------------
| end of train epoch   4 | time: 69.83s | valid loss  4.95 | valid ppl   141.18
-----------------------------------------------------------------------------------------
| train-epoch   5 |   200/ 2983 batches | lr 20.00 | ms/batch 22.31 | loss  4.84 | ppl   126.60
| train-epoch   5 |   400/ 2983 batches | lr 20.00 | ms/batch 22.36 | loss  4.86 | ppl   128.59
| train-epoch   5 |   600/ 2983 batches | lr 20.00 | ms/batch 22.17 | loss  4.67 | ppl   106.58
| train-epoch   5 |   800/ 2983 batches | lr 20.00 | ms/batch 22.18 | loss  4.73 | ppl   113.67
| train-epoch   5 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.14 | loss  4.72 | ppl   112.65
| train-epoch   5 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.16 | loss  4.74 | ppl   114.13
| train-epoch   5 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.15 | loss  4.78 | ppl   118.94
| train-epoch   5 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.15 | loss  4.85 | ppl   127.48
| train-epoch   5 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.15 | loss  4.73 | ppl   113.11
| train-epoch   5 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.15 | loss  4.76 | ppl   116.97
| train-epoch   5 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.15 | loss  4.66 | ppl   105.62
| train-epoch   5 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.16 | loss  4.70 | ppl   109.69
| train-epoch   5 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.18 | loss  4.71 | ppl   111.53
| train-epoch   5 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.15 | loss  4.66 | ppl   105.59
-----------------------------------------------------------------------------------------
| end of train epoch   5 | time: 68.94s | valid loss  4.90 | valid ppl   134.87
-----------------------------------------------------------------------------------------
| train-epoch   6 |   200/ 2983 batches | lr 20.00 | ms/batch 22.27 | loss  4.71 | ppl   111.54
| train-epoch   6 |   400/ 2983 batches | lr 20.00 | ms/batch 22.17 | loss  4.74 | ppl   114.39
| train-epoch   6 |   600/ 2983 batches | lr 20.00 | ms/batch 22.16 | loss  4.55 | ppl    94.41
| train-epoch   6 |   800/ 2983 batches | lr 20.00 | ms/batch 22.17 | loss  4.61 | ppl   100.35
| train-epoch   6 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.16 | loss  4.61 | ppl   100.94
| train-epoch   6 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.16 | loss  4.63 | ppl   102.35
| train-epoch   6 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.19 | loss  4.67 | ppl   107.05
| train-epoch   6 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.17 | loss  4.74 | ppl   114.27
| train-epoch   6 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.21 | loss  4.62 | ppl   101.89
| train-epoch   6 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.16 | loss  4.66 | ppl   105.40
| train-epoch   6 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.16 | loss  4.55 | ppl    94.98
| train-epoch   6 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.16 | loss  4.59 | ppl    98.77
| train-epoch   6 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.16 | loss  4.62 | ppl   101.36
| train-epoch   6 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.16 | loss  4.56 | ppl    95.45
-----------------------------------------------------------------------------------------
| end of train epoch   6 | time: 68.93s | valid loss  4.86 | valid ppl   128.60
-----------------------------------------------------------------------------------------
| train-epoch   7 |   200/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  4.61 | ppl   100.84
| train-epoch   7 |   400/ 2983 batches | lr 20.00 | ms/batch 22.34 | loss  4.64 | ppl   103.87
| train-epoch   7 |   600/ 2983 batches | lr 20.00 | ms/batch 22.32 | loss  4.45 | ppl    85.79
| train-epoch   7 |   800/ 2983 batches | lr 20.00 | ms/batch 22.32 | loss  4.51 | ppl    91.10
| train-epoch   7 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.31 | loss  4.53 | ppl    92.52
| train-epoch   7 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.33 | loss  4.54 | ppl    93.80
| train-epoch   7 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.33 | loss  4.58 | ppl    97.89
| train-epoch   7 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.32 | loss  4.66 | ppl   105.19
| train-epoch   7 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.33 | loss  4.54 | ppl    93.91
| train-epoch   7 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.32 | loss  4.58 | ppl    97.21
| train-epoch   7 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.27 | loss  4.47 | ppl    87.29
| train-epoch   7 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.28 | loss  4.51 | ppl    90.80
| train-epoch   7 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.31 | loss  4.54 | ppl    93.25
| train-epoch   7 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.32 | loss  4.48 | ppl    88.67
-----------------------------------------------------------------------------------------
| end of train epoch   7 | time: 69.36s | valid loss  4.85 | valid ppl   127.63
-----------------------------------------------------------------------------------------
| train-epoch   8 |   200/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  4.54 | ppl    93.37
| train-epoch   8 |   400/ 2983 batches | lr 20.00 | ms/batch 22.26 | loss  4.56 | ppl    95.53
| train-epoch   8 |   600/ 2983 batches | lr 20.00 | ms/batch 22.26 | loss  4.38 | ppl    79.73
| train-epoch   8 |   800/ 2983 batches | lr 20.00 | ms/batch 22.27 | loss  4.43 | ppl    84.03
| train-epoch   8 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.25 | loss  4.45 | ppl    85.80
| train-epoch   8 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.26 | loss  4.47 | ppl    87.27
| train-epoch   8 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.36 | loss  4.51 | ppl    90.64
| train-epoch   8 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.37 | loss  4.58 | ppl    97.71
| train-epoch   8 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.37 | loss  4.47 | ppl    87.20
| train-epoch   8 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.37 | loss  4.51 | ppl    90.76
| train-epoch   8 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  4.39 | ppl    80.88
| train-epoch   8 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  4.43 | ppl    84.16
| train-epoch   8 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  4.46 | ppl    86.90
| train-epoch   8 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  4.41 | ppl    82.23
-----------------------------------------------------------------------------------------
| end of train epoch   8 | time: 69.41s | valid loss  4.83 | valid ppl   125.48
-----------------------------------------------------------------------------------------
| train-epoch   9 |   200/ 2983 batches | lr 20.00 | ms/batch 22.34 | loss  4.47 | ppl    86.98
| train-epoch   9 |   400/ 2983 batches | lr 20.00 | ms/batch 22.24 | loss  4.49 | ppl    89.13
| train-epoch   9 |   600/ 2983 batches | lr 20.00 | ms/batch 22.24 | loss  4.31 | ppl    74.49
| train-epoch   9 |   800/ 2983 batches | lr 20.00 | ms/batch 22.23 | loss  4.37 | ppl    78.80
| train-epoch   9 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.21 | loss  4.39 | ppl    80.62
| train-epoch   9 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.22 | loss  4.40 | ppl    81.20
| train-epoch   9 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.22 | loss  4.45 | ppl    85.32
| train-epoch   9 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.24 | loss  4.52 | ppl    91.81
| train-epoch   9 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.23 | loss  4.41 | ppl    82.44
| train-epoch   9 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.23 | loss  4.44 | ppl    84.77
| train-epoch   9 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.22 | loss  4.33 | ppl    76.31
| train-epoch   9 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.23 | loss  4.38 | ppl    79.46
| train-epoch   9 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.24 | loss  4.41 | ppl    82.54
| train-epoch   9 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.23 | loss  4.36 | ppl    78.35
-----------------------------------------------------------------------------------------
| end of train epoch   9 | time: 69.11s | valid loss  4.81 | valid ppl   122.22
-----------------------------------------------------------------------------------------
| train-epoch  10 |   200/ 2983 batches | lr 20.00 | ms/batch 22.50 | loss  4.41 | ppl    82.05
| train-epoch  10 |   400/ 2983 batches | lr 20.00 | ms/batch 22.36 | loss  4.43 | ppl    83.66
| train-epoch  10 |   600/ 2983 batches | lr 20.00 | ms/batch 22.39 | loss  4.26 | ppl    70.53
| train-epoch  10 |   800/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  4.30 | ppl    73.94
| train-epoch  10 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  4.34 | ppl    76.51
| train-epoch  10 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.49 | loss  4.35 | ppl    77.43
| train-epoch  10 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.49 | loss  4.39 | ppl    80.78
| train-epoch  10 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  4.46 | ppl    86.68
| train-epoch  10 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  4.35 | ppl    77.79
| train-epoch  10 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  4.40 | ppl    81.08
| train-epoch  10 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  4.29 | ppl    72.70
| train-epoch  10 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.50 | loss  4.32 | ppl    75.36
| train-epoch  10 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.49 | loss  4.35 | ppl    77.29
| train-epoch  10 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.49 | loss  4.30 | ppl    73.85
-----------------------------------------------------------------------------------------
| end of train epoch  10 | time: 69.79s | valid loss  4.79 | valid ppl   120.02
-----------------------------------------------------------------------------------------
| train-epoch  11 |   200/ 2983 batches | lr 20.00 | ms/batch 22.55 | loss  4.35 | ppl    77.68
| train-epoch  11 |   400/ 2983 batches | lr 20.00 | ms/batch 22.45 | loss  4.38 | ppl    80.17
| train-epoch  11 |   600/ 2983 batches | lr 20.00 | ms/batch 22.46 | loss  4.21 | ppl    67.06
| train-epoch  11 |   800/ 2983 batches | lr 20.00 | ms/batch 22.49 | loss  4.26 | ppl    70.47
| train-epoch  11 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.52 | loss  4.29 | ppl    73.30
| train-epoch  11 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.50 | loss  4.30 | ppl    73.78
| train-epoch  11 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.51 | loss  4.34 | ppl    76.58
| train-epoch  11 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.52 | loss  4.42 | ppl    83.12
| train-epoch  11 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.52 | loss  4.31 | ppl    74.67
| train-epoch  11 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.50 | loss  4.35 | ppl    77.11
| train-epoch  11 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.50 | loss  4.23 | ppl    69.03
| train-epoch  11 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.54 | loss  4.27 | ppl    71.81
| train-epoch  11 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.53 | loss  4.31 | ppl    74.33
| train-epoch  11 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.52 | loss  4.27 | ppl    71.19
-----------------------------------------------------------------------------------------
| end of train epoch  11 | time: 69.93s | valid loss  4.78 | valid ppl   119.49
-----------------------------------------------------------------------------------------
| train-epoch  12 |   200/ 2983 batches | lr 20.00 | ms/batch 22.56 | loss  4.31 | ppl    74.56
| train-epoch  12 |   400/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  4.33 | ppl    76.17
| train-epoch  12 |   600/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  4.16 | ppl    63.92
| train-epoch  12 |   800/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  4.21 | ppl    67.09
| train-epoch  12 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  4.25 | ppl    70.20
| train-epoch  12 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.44 | loss  4.26 | ppl    70.70
| train-epoch  12 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  4.30 | ppl    73.71
| train-epoch  12 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.46 | loss  4.38 | ppl    79.59
| train-epoch  12 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.45 | loss  4.27 | ppl    71.40
| train-epoch  12 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.47 | loss  4.30 | ppl    74.06
| train-epoch  12 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.46 | loss  4.19 | ppl    66.25
| train-epoch  12 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.46 | loss  4.23 | ppl    68.79
| train-epoch  12 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  4.27 | ppl    71.34
| train-epoch  12 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.46 | loss  4.23 | ppl    68.45
-----------------------------------------------------------------------------------------
| end of train epoch  12 | time: 69.77s | valid loss  4.78 | valid ppl   119.34
-----------------------------------------------------------------------------------------
| train-epoch  13 |   200/ 2983 batches | lr 20.00 | ms/batch 22.52 | loss  4.27 | ppl    71.83
| train-epoch  13 |   400/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  4.30 | ppl    73.51
| train-epoch  13 |   600/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  4.12 | ppl    61.50
| train-epoch  13 |   800/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  4.17 | ppl    64.53
| train-epoch  13 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  4.21 | ppl    67.37
| train-epoch  13 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  4.22 | ppl    68.29
| train-epoch  13 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  4.26 | ppl    70.68
| train-epoch  13 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  4.34 | ppl    76.85
| train-epoch  13 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  4.23 | ppl    68.70
| train-epoch  13 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  4.27 | ppl    71.79
| train-epoch  13 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  4.17 | ppl    64.44
| train-epoch  13 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  4.19 | ppl    66.34
| train-epoch  13 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.39 | loss  4.23 | ppl    68.62
| train-epoch  13 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.39 | loss  4.19 | ppl    65.79
-----------------------------------------------------------------------------------------
| end of train epoch  13 | time: 69.65s | valid loss  4.78 | valid ppl   119.27
-----------------------------------------------------------------------------------------
| train-epoch  14 |   200/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  4.24 | ppl    69.10
| train-epoch  14 |   400/ 2983 batches | lr 20.00 | ms/batch 22.37 | loss  4.26 | ppl    70.65
| train-epoch  14 |   600/ 2983 batches | lr 20.00 | ms/batch 22.36 | loss  4.09 | ppl    59.55
| train-epoch  14 |   800/ 2983 batches | lr 20.00 | ms/batch 22.36 | loss  4.13 | ppl    62.10
| train-epoch  14 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  4.18 | ppl    65.66
| train-epoch  14 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  4.19 | ppl    66.03
| train-epoch  14 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.44 | loss  4.22 | ppl    68.29
| train-epoch  14 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.34 | loss  4.31 | ppl    74.28
| train-epoch  14 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.17 | loss  4.20 | ppl    66.70
| train-epoch  14 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.17 | loss  4.24 | ppl    69.17
| train-epoch  14 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.17 | loss  4.13 | ppl    62.36
| train-epoch  14 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.17 | loss  4.16 | ppl    64.25
| train-epoch  14 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.18 | loss  4.20 | ppl    66.99
| train-epoch  14 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.18 | loss  4.16 | ppl    63.92
-----------------------------------------------------------------------------------------
| end of train epoch  14 | time: 69.27s | valid loss  4.78 | valid ppl   118.75
-----------------------------------------------------------------------------------------
| train-epoch  15 |   200/ 2983 batches | lr 20.00 | ms/batch 22.46 | loss  4.21 | ppl    67.08
| train-epoch  15 |   400/ 2983 batches | lr 20.00 | ms/batch 22.33 | loss  4.23 | ppl    68.38
| train-epoch  15 |   600/ 2983 batches | lr 20.00 | ms/batch 22.36 | loss  4.06 | ppl    57.92
| train-epoch  15 |   800/ 2983 batches | lr 20.00 | ms/batch 22.36 | loss  4.10 | ppl    60.46
| train-epoch  15 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.36 | loss  4.15 | ppl    63.72
| train-epoch  15 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.36 | loss  4.16 | ppl    64.33
| train-epoch  15 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.35 | loss  4.19 | ppl    66.34
| train-epoch  15 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.34 | loss  4.28 | ppl    72.29
| train-epoch  15 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.35 | loss  4.17 | ppl    64.81
| train-epoch  15 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.35 | loss  4.21 | ppl    67.14
| train-epoch  15 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.35 | loss  4.09 | ppl    59.96
| train-epoch  15 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.34 | loss  4.14 | ppl    62.60
| train-epoch  15 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.36 | loss  4.17 | ppl    64.58
| train-epoch  15 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.34 | loss  4.13 | ppl    61.95
-----------------------------------------------------------------------------------------
| end of train epoch  15 | time: 69.47s | valid loss  4.80 | valid ppl   121.35
-----------------------------------------------------------------------------------------
| train-epoch  16 |   200/ 2983 batches | lr 5.00 | ms/batch 22.30 | loss  4.21 | ppl    67.19
| train-epoch  16 |   400/ 2983 batches | lr 5.00 | ms/batch 22.19 | loss  4.19 | ppl    66.22
| train-epoch  16 |   600/ 2983 batches | lr 5.00 | ms/batch 22.19 | loss  4.03 | ppl    56.28
| train-epoch  16 |   800/ 2983 batches | lr 5.00 | ms/batch 22.20 | loss  4.04 | ppl    57.09
| train-epoch  16 |  1000/ 2983 batches | lr 5.00 | ms/batch 22.23 | loss  4.07 | ppl    58.43
| train-epoch  16 |  1200/ 2983 batches | lr 5.00 | ms/batch 22.20 | loss  4.07 | ppl    58.50
| train-epoch  16 |  1400/ 2983 batches | lr 5.00 | ms/batch 22.20 | loss  4.07 | ppl    58.81
| train-epoch  16 |  1600/ 2983 batches | lr 5.00 | ms/batch 22.18 | loss  4.14 | ppl    62.98
| train-epoch  16 |  1800/ 2983 batches | lr 5.00 | ms/batch 22.19 | loss  4.02 | ppl    55.98
| train-epoch  16 |  2000/ 2983 batches | lr 5.00 | ms/batch 22.20 | loss  4.04 | ppl    56.99
| train-epoch  16 |  2200/ 2983 batches | lr 5.00 | ms/batch 22.19 | loss  3.92 | ppl    50.46
| train-epoch  16 |  2400/ 2983 batches | lr 5.00 | ms/batch 22.19 | loss  3.95 | ppl    51.87
| train-epoch  16 |  2600/ 2983 batches | lr 5.00 | ms/batch 22.20 | loss  3.96 | ppl    52.53
| train-epoch  16 |  2800/ 2983 batches | lr 5.00 | ms/batch 22.20 | loss  3.91 | ppl    49.67
-----------------------------------------------------------------------------------------
| end of train epoch  16 | time: 69.01s | valid loss  4.68 | valid ppl   107.97
-----------------------------------------------------------------------------------------
| train-epoch  17 |   200/ 2983 batches | lr 5.00 | ms/batch 22.35 | loss  4.08 | ppl    59.17
| train-epoch  17 |   400/ 2983 batches | lr 5.00 | ms/batch 22.26 | loss  4.08 | ppl    59.28
| train-epoch  17 |   600/ 2983 batches | lr 5.00 | ms/batch 22.23 | loss  3.92 | ppl    50.54
| train-epoch  17 |   800/ 2983 batches | lr 5.00 | ms/batch 22.24 | loss  3.95 | ppl    52.05
| train-epoch  17 |  1000/ 2983 batches | lr 5.00 | ms/batch 22.22 | loss  3.99 | ppl    53.82
| train-epoch  17 |  1200/ 2983 batches | lr 5.00 | ms/batch 22.23 | loss  4.00 | ppl    54.45
| train-epoch  17 |  1400/ 2983 batches | lr 5.00 | ms/batch 22.23 | loss  4.00 | ppl    54.56
| train-epoch  17 |  1600/ 2983 batches | lr 5.00 | ms/batch 22.21 | loss  4.07 | ppl    58.83
| train-epoch  17 |  1800/ 2983 batches | lr 5.00 | ms/batch 22.22 | loss  3.96 | ppl    52.70
| train-epoch  17 |  2000/ 2983 batches | lr 5.00 | ms/batch 22.24 | loss  3.99 | ppl    54.28
| train-epoch  17 |  2200/ 2983 batches | lr 5.00 | ms/batch 22.23 | loss  3.87 | ppl    47.73
| train-epoch  17 |  2400/ 2983 batches | lr 5.00 | ms/batch 22.22 | loss  3.90 | ppl    49.51
| train-epoch  17 |  2600/ 2983 batches | lr 5.00 | ms/batch 22.22 | loss  3.92 | ppl    50.55
| train-epoch  17 |  2800/ 2983 batches | lr 5.00 | ms/batch 22.22 | loss  3.88 | ppl    48.19
-----------------------------------------------------------------------------------------
| end of train epoch  17 | time: 69.11s | valid loss  4.67 | valid ppl   107.18
-----------------------------------------------------------------------------------------
| train-epoch  18 |   200/ 2983 batches | lr 5.00 | ms/batch 22.46 | loss  4.02 | ppl    55.72
| train-epoch  18 |   400/ 2983 batches | lr 5.00 | ms/batch 22.35 | loss  4.03 | ppl    56.46
| train-epoch  18 |   600/ 2983 batches | lr 5.00 | ms/batch 22.35 | loss  3.87 | ppl    47.97
| train-epoch  18 |   800/ 2983 batches | lr 5.00 | ms/batch 22.35 | loss  3.90 | ppl    49.55
| train-epoch  18 |  1000/ 2983 batches | lr 5.00 | ms/batch 22.34 | loss  3.94 | ppl    51.51
| train-epoch  18 |  1200/ 2983 batches | lr 5.00 | ms/batch 22.35 | loss  3.95 | ppl    52.11
| train-epoch  18 |  1400/ 2983 batches | lr 5.00 | ms/batch 22.35 | loss  3.97 | ppl    52.86
| train-epoch  18 |  1600/ 2983 batches | lr 5.00 | ms/batch 22.35 | loss  4.04 | ppl    56.92
| train-epoch  18 |  1800/ 2983 batches | lr 5.00 | ms/batch 22.34 | loss  3.93 | ppl    50.99
| train-epoch  18 |  2000/ 2983 batches | lr 5.00 | ms/batch 22.35 | loss  3.96 | ppl    52.57
| train-epoch  18 |  2200/ 2983 batches | lr 5.00 | ms/batch 22.34 | loss  3.84 | ppl    46.46
| train-epoch  18 |  2400/ 2983 batches | lr 5.00 | ms/batch 22.34 | loss  3.87 | ppl    48.14
| train-epoch  18 |  2600/ 2983 batches | lr 5.00 | ms/batch 22.34 | loss  3.90 | ppl    49.28
| train-epoch  18 |  2800/ 2983 batches | lr 5.00 | ms/batch 22.35 | loss  3.85 | ppl    47.05
-----------------------------------------------------------------------------------------
| end of train epoch  18 | time: 69.47s | valid loss  4.67 | valid ppl   106.44
-----------------------------------------------------------------------------------------
| train-epoch  19 |   200/ 2983 batches | lr 5.00 | ms/batch 22.29 | loss  3.98 | ppl    53.69
| train-epoch  19 |   400/ 2983 batches | lr 5.00 | ms/batch 22.17 | loss  4.00 | ppl    54.49
| train-epoch  19 |   600/ 2983 batches | lr 5.00 | ms/batch 22.18 | loss  3.83 | ppl    46.17
| train-epoch  19 |   800/ 2983 batches | lr 5.00 | ms/batch 22.17 | loss  3.87 | ppl    47.92
| train-epoch  19 |  1000/ 2983 batches | lr 5.00 | ms/batch 22.17 | loss  3.91 | ppl    50.01
| train-epoch  19 |  1200/ 2983 batches | lr 5.00 | ms/batch 22.18 | loss  3.92 | ppl    50.30
| train-epoch  19 |  1400/ 2983 batches | lr 5.00 | ms/batch 22.19 | loss  3.93 | ppl    51.07
| train-epoch  19 |  1600/ 2983 batches | lr 5.00 | ms/batch 22.19 | loss  4.01 | ppl    55.30
| train-epoch  19 |  1800/ 2983 batches | lr 5.00 | ms/batch 22.18 | loss  3.90 | ppl    49.57
| train-epoch  19 |  2000/ 2983 batches | lr 5.00 | ms/batch 22.18 | loss  3.93 | ppl    50.92
| train-epoch  19 |  2200/ 2983 batches | lr 5.00 | ms/batch 22.18 | loss  3.81 | ppl    45.07
| train-epoch  19 |  2400/ 2983 batches | lr 5.00 | ms/batch 22.18 | loss  3.85 | ppl    46.79
| train-epoch  19 |  2600/ 2983 batches | lr 5.00 | ms/batch 22.18 | loss  3.87 | ppl    48.03
| train-epoch  19 |  2800/ 2983 batches | lr 5.00 | ms/batch 22.17 | loss  3.83 | ppl    46.15
-----------------------------------------------------------------------------------------
| end of train epoch  19 | time: 68.97s | valid loss  4.66 | valid ppl   105.98
-----------------------------------------------------------------------------------------
| train-epoch  20 |   200/ 2983 batches | lr 5.00 | ms/batch 22.29 | loss  3.96 | ppl    52.52
| train-epoch  20 |   400/ 2983 batches | lr 5.00 | ms/batch 22.31 | loss  3.96 | ppl    52.69
| train-epoch  20 |   600/ 2983 batches | lr 5.00 | ms/batch 22.17 | loss  3.80 | ppl    44.90
| train-epoch  20 |   800/ 2983 batches | lr 5.00 | ms/batch 22.17 | loss  3.84 | ppl    46.47
| train-epoch  20 |  1000/ 2983 batches | lr 5.00 | ms/batch 22.18 | loss  3.88 | ppl    48.49
| train-epoch  20 |  1200/ 2983 batches | lr 5.00 | ms/batch 22.18 | loss  3.89 | ppl    48.93
| train-epoch  20 |  1400/ 2983 batches | lr 5.00 | ms/batch 22.19 | loss  3.91 | ppl    49.77
| train-epoch  20 |  1600/ 2983 batches | lr 5.00 | ms/batch 22.19 | loss  3.99 | ppl    53.86
| train-epoch  20 |  1800/ 2983 batches | lr 5.00 | ms/batch 22.18 | loss  3.88 | ppl    48.27
| train-epoch  20 |  2000/ 2983 batches | lr 5.00 | ms/batch 22.17 | loss  3.91 | ppl    49.93
| train-epoch  20 |  2200/ 2983 batches | lr 5.00 | ms/batch 22.19 | loss  3.79 | ppl    44.22
| train-epoch  20 |  2400/ 2983 batches | lr 5.00 | ms/batch 22.19 | loss  3.83 | ppl    45.91
| train-epoch  20 |  2600/ 2983 batches | lr 5.00 | ms/batch 22.18 | loss  3.85 | ppl    47.22
| train-epoch  20 |  2800/ 2983 batches | lr 5.00 | ms/batch 22.17 | loss  3.80 | ppl    44.91
-----------------------------------------------------------------------------------------
| end of train epoch  20 | time: 68.99s | valid loss  4.67 | valid ppl   106.60
-----------------------------------------------------------------------------------------
| train-epoch  21 |   200/ 2983 batches | lr 1.25 | ms/batch 22.38 | loss  3.98 | ppl    53.64
| train-epoch  21 |   400/ 2983 batches | lr 1.25 | ms/batch 22.28 | loss  4.00 | ppl    54.69
| train-epoch  21 |   600/ 2983 batches | lr 1.25 | ms/batch 22.27 | loss  3.81 | ppl    45.18
| train-epoch  21 |   800/ 2983 batches | lr 1.25 | ms/batch 22.27 | loss  3.87 | ppl    47.83
| train-epoch  21 |  1000/ 2983 batches | lr 1.25 | ms/batch 22.29 | loss  3.90 | ppl    49.40
| train-epoch  21 |  1200/ 2983 batches | lr 1.25 | ms/batch 22.27 | loss  3.89 | ppl    49.10
| train-epoch  21 |  1400/ 2983 batches | lr 1.25 | ms/batch 22.27 | loss  3.93 | ppl    50.75
| train-epoch  21 |  1600/ 2983 batches | lr 1.25 | ms/batch 22.28 | loss  3.97 | ppl    52.77
| train-epoch  21 |  1800/ 2983 batches | lr 1.25 | ms/batch 22.29 | loss  3.87 | ppl    48.06
| train-epoch  21 |  2000/ 2983 batches | lr 1.25 | ms/batch 22.27 | loss  3.90 | ppl    49.24
| train-epoch  21 |  2200/ 2983 batches | lr 1.25 | ms/batch 22.26 | loss  3.76 | ppl    42.83
| train-epoch  21 |  2400/ 2983 batches | lr 1.25 | ms/batch 22.28 | loss  3.80 | ppl    44.90
| train-epoch  21 |  2600/ 2983 batches | lr 1.25 | ms/batch 22.28 | loss  3.82 | ppl    45.71
| train-epoch  21 |  2800/ 2983 batches | lr 1.25 | ms/batch 22.27 | loss  3.77 | ppl    43.27
-----------------------------------------------------------------------------------------
| end of train epoch  21 | time: 69.25s | valid loss  4.65 | valid ppl   104.58
-----------------------------------------------------------------------------------------
| train-epoch  22 |   200/ 2983 batches | lr 1.25 | ms/batch 22.34 | loss  3.97 | ppl    52.75
| train-epoch  22 |   400/ 2983 batches | lr 1.25 | ms/batch 22.25 | loss  3.97 | ppl    53.19
| train-epoch  22 |   600/ 2983 batches | lr 1.25 | ms/batch 22.23 | loss  3.77 | ppl    43.60
| train-epoch  22 |   800/ 2983 batches | lr 1.25 | ms/batch 22.23 | loss  3.83 | ppl    46.29
| train-epoch  22 |  1000/ 2983 batches | lr 1.25 | ms/batch 22.23 | loss  3.87 | ppl    47.88
| train-epoch  22 |  1200/ 2983 batches | lr 1.25 | ms/batch 22.23 | loss  3.86 | ppl    47.57
| train-epoch  22 |  1400/ 2983 batches | lr 1.25 | ms/batch 22.21 | loss  3.90 | ppl    49.50
| train-epoch  22 |  1600/ 2983 batches | lr 1.25 | ms/batch 22.22 | loss  3.95 | ppl    51.91
| train-epoch  22 |  1800/ 2983 batches | lr 1.25 | ms/batch 22.22 | loss  3.85 | ppl    47.10
| train-epoch  22 |  2000/ 2983 batches | lr 1.25 | ms/batch 22.23 | loss  3.88 | ppl    48.27
| train-epoch  22 |  2200/ 2983 batches | lr 1.25 | ms/batch 22.22 | loss  3.75 | ppl    42.35
| train-epoch  22 |  2400/ 2983 batches | lr 1.25 | ms/batch 22.23 | loss  3.78 | ppl    44.02
| train-epoch  22 |  2600/ 2983 batches | lr 1.25 | ms/batch 22.22 | loss  3.82 | ppl    45.53
| train-epoch  22 |  2800/ 2983 batches | lr 1.25 | ms/batch 22.22 | loss  3.76 | ppl    42.78
-----------------------------------------------------------------------------------------
| end of train epoch  22 | time: 69.10s | valid loss  4.65 | valid ppl   104.36
-----------------------------------------------------------------------------------------
| train-epoch  23 |   200/ 2983 batches | lr 1.25 | ms/batch 22.32 | loss  3.95 | ppl    51.89
| train-epoch  23 |   400/ 2983 batches | lr 1.25 | ms/batch 22.29 | loss  3.97 | ppl    52.85
| train-epoch  23 |   600/ 2983 batches | lr 1.25 | ms/batch 22.28 | loss  3.76 | ppl    42.94
| train-epoch  23 |   800/ 2983 batches | lr 1.25 | ms/batch 22.28 | loss  3.81 | ppl    45.34
| train-epoch  23 |  1000/ 2983 batches | lr 1.25 | ms/batch 22.27 | loss  3.85 | ppl    47.16
| train-epoch  23 |  1200/ 2983 batches | lr 1.25 | ms/batch 22.28 | loss  3.85 | ppl    46.80
| train-epoch  23 |  1400/ 2983 batches | lr 1.25 | ms/batch 22.29 | loss  3.89 | ppl    48.68
| train-epoch  23 |  1600/ 2983 batches | lr 1.25 | ms/batch 22.22 | loss  3.94 | ppl    51.23
| train-epoch  23 |  1800/ 2983 batches | lr 1.25 | ms/batch 22.19 | loss  3.84 | ppl    46.30
| train-epoch  23 |  2000/ 2983 batches | lr 1.25 | ms/batch 22.19 | loss  3.88 | ppl    48.20
| train-epoch  23 |  2200/ 2983 batches | lr 1.25 | ms/batch 22.22 | loss  3.74 | ppl    41.98
| train-epoch  23 |  2400/ 2983 batches | lr 1.25 | ms/batch 22.22 | loss  3.78 | ppl    43.82
| train-epoch  23 |  2600/ 2983 batches | lr 1.25 | ms/batch 22.23 | loss  3.81 | ppl    45.06
| train-epoch  23 |  2800/ 2983 batches | lr 1.25 | ms/batch 22.22 | loss  3.75 | ppl    42.67
-----------------------------------------------------------------------------------------
| end of train epoch  23 | time: 69.14s | valid loss  4.65 | valid ppl   104.37
-----------------------------------------------------------------------------------------
| train-epoch  24 |   200/ 2983 batches | lr 0.31 | ms/batch 22.51 | loss  3.97 | ppl    52.91
| train-epoch  24 |   400/ 2983 batches | lr 0.31 | ms/batch 22.37 | loss  4.06 | ppl    57.93
| train-epoch  24 |   600/ 2983 batches | lr 0.31 | ms/batch 22.38 | loss  3.84 | ppl    46.64
| train-epoch  24 |   800/ 2983 batches | lr 0.31 | ms/batch 22.38 | loss  3.86 | ppl    47.70
| train-epoch  24 |  1000/ 2983 batches | lr 0.31 | ms/batch 22.37 | loss  3.89 | ppl    49.10
| train-epoch  24 |  1200/ 2983 batches | lr 0.31 | ms/batch 22.38 | loss  3.88 | ppl    48.28
| train-epoch  24 |  1400/ 2983 batches | lr 0.31 | ms/batch 22.36 | loss  3.90 | ppl    49.55
| train-epoch  24 |  1600/ 2983 batches | lr 0.31 | ms/batch 22.38 | loss  3.96 | ppl    52.33
| train-epoch  24 |  1800/ 2983 batches | lr 0.31 | ms/batch 22.38 | loss  3.87 | ppl    48.10
| train-epoch  24 |  2000/ 2983 batches | lr 0.31 | ms/batch 22.38 | loss  3.91 | ppl    49.77
| train-epoch  24 |  2200/ 2983 batches | lr 0.31 | ms/batch 22.39 | loss  3.77 | ppl    43.56
| train-epoch  24 |  2400/ 2983 batches | lr 0.31 | ms/batch 22.38 | loss  3.79 | ppl    44.13
| train-epoch  24 |  2600/ 2983 batches | lr 0.31 | ms/batch 22.38 | loss  3.81 | ppl    45.07
| train-epoch  24 |  2800/ 2983 batches | lr 0.31 | ms/batch 22.38 | loss  3.77 | ppl    43.30
-----------------------------------------------------------------------------------------
| end of train epoch  24 | time: 69.56s | valid loss  4.62 | valid ppl   101.05
-----------------------------------------------------------------------------------------
| train-epoch  25 |   200/ 2983 batches | lr 0.31 | ms/batch 22.45 | loss  3.96 | ppl    52.32
| train-epoch  25 |   400/ 2983 batches | lr 0.31 | ms/batch 22.28 | loss  4.01 | ppl    54.90
| train-epoch  25 |   600/ 2983 batches | lr 0.31 | ms/batch 22.28 | loss  3.82 | ppl    45.59
| train-epoch  25 |   800/ 2983 batches | lr 0.31 | ms/batch 22.29 | loss  3.85 | ppl    46.77
| train-epoch  25 |  1000/ 2983 batches | lr 0.31 | ms/batch 22.29 | loss  3.88 | ppl    48.29
| train-epoch  25 |  1200/ 2983 batches | lr 0.31 | ms/batch 22.29 | loss  3.86 | ppl    47.58
| train-epoch  25 |  1400/ 2983 batches | lr 0.31 | ms/batch 22.27 | loss  3.90 | ppl    49.27
| train-epoch  25 |  1600/ 2983 batches | lr 0.31 | ms/batch 22.28 | loss  3.95 | ppl    51.98
| train-epoch  25 |  1800/ 2983 batches | lr 0.31 | ms/batch 22.28 | loss  3.86 | ppl    47.54
| train-epoch  25 |  2000/ 2983 batches | lr 0.31 | ms/batch 22.28 | loss  3.90 | ppl    49.33
| train-epoch  25 |  2200/ 2983 batches | lr 0.31 | ms/batch 22.28 | loss  3.76 | ppl    43.13
| train-epoch  25 |  2400/ 2983 batches | lr 0.31 | ms/batch 22.28 | loss  3.78 | ppl    43.75
| train-epoch  25 |  2600/ 2983 batches | lr 0.31 | ms/batch 22.29 | loss  3.81 | ppl    45.17
| train-epoch  25 |  2800/ 2983 batches | lr 0.31 | ms/batch 22.29 | loss  3.77 | ppl    43.21
-----------------------------------------------------------------------------------------
| end of train epoch  25 | time: 69.29s | valid loss  4.62 | valid ppl   100.99
-----------------------------------------------------------------------------------------
| train-epoch  26 |   200/ 2983 batches | lr 0.31 | ms/batch 22.34 | loss  3.95 | ppl    51.69
| train-epoch  26 |   400/ 2983 batches | lr 0.31 | ms/batch 22.22 | loss  4.00 | ppl    54.45
| train-epoch  26 |   600/ 2983 batches | lr 0.31 | ms/batch 22.23 | loss  3.82 | ppl    45.38
| train-epoch  26 |   800/ 2983 batches | lr 0.31 | ms/batch 22.21 | loss  3.86 | ppl    47.33
| train-epoch  26 |  1000/ 2983 batches | lr 0.31 | ms/batch 22.22 | loss  3.87 | ppl    48.03
| train-epoch  26 |  1200/ 2983 batches | lr 0.31 | ms/batch 22.23 | loss  3.86 | ppl    47.34
| train-epoch  26 |  1400/ 2983 batches | lr 0.31 | ms/batch 22.22 | loss  3.89 | ppl    48.89
| train-epoch  26 |  1600/ 2983 batches | lr 0.31 | ms/batch 22.22 | loss  3.95 | ppl    51.81
| train-epoch  26 |  1800/ 2983 batches | lr 0.31 | ms/batch 22.23 | loss  3.85 | ppl    47.17
| train-epoch  26 |  2000/ 2983 batches | lr 0.31 | ms/batch 22.23 | loss  3.89 | ppl    48.90
| train-epoch  26 |  2200/ 2983 batches | lr 0.31 | ms/batch 22.22 | loss  3.76 | ppl    42.90
| train-epoch  26 |  2400/ 2983 batches | lr 0.31 | ms/batch 22.22 | loss  3.78 | ppl    43.88
| train-epoch  26 |  2600/ 2983 batches | lr 0.31 | ms/batch 22.22 | loss  3.82 | ppl    45.44
| train-epoch  26 |  2800/ 2983 batches | lr 0.31 | ms/batch 22.22 | loss  3.77 | ppl    43.43
-----------------------------------------------------------------------------------------
| end of train epoch  26 | time: 69.09s | valid loss  4.62 | valid ppl   101.03
-----------------------------------------------------------------------------------------
| train-epoch  27 |   200/ 2983 batches | lr 0.08 | ms/batch 22.47 | loss  3.95 | ppl    52.18
| train-epoch  27 |   400/ 2983 batches | lr 0.08 | ms/batch 22.35 | loss  4.03 | ppl    56.08
| train-epoch  27 |   600/ 2983 batches | lr 0.08 | ms/batch 22.35 | loss  3.86 | ppl    47.45
| train-epoch  27 |   800/ 2983 batches | lr 0.08 | ms/batch 22.37 | loss  3.90 | ppl    49.26
| train-epoch  27 |  1000/ 2983 batches | lr 0.08 | ms/batch 22.37 | loss  3.93 | ppl    50.79
| train-epoch  27 |  1200/ 2983 batches | lr 0.08 | ms/batch 22.36 | loss  3.91 | ppl    50.08
| train-epoch  27 |  1400/ 2983 batches | lr 0.08 | ms/batch 22.37 | loss  3.94 | ppl    51.60
| train-epoch  27 |  1600/ 2983 batches | lr 0.08 | ms/batch 22.37 | loss  3.99 | ppl    54.02
| train-epoch  27 |  1800/ 2983 batches | lr 0.08 | ms/batch 22.38 | loss  3.89 | ppl    49.12
| train-epoch  27 |  2000/ 2983 batches | lr 0.08 | ms/batch 22.38 | loss  3.90 | ppl    49.24
| train-epoch  27 |  2200/ 2983 batches | lr 0.08 | ms/batch 22.38 | loss  3.77 | ppl    43.27
| train-epoch  27 |  2400/ 2983 batches | lr 0.08 | ms/batch 22.38 | loss  3.79 | ppl    44.34
| train-epoch  27 |  2600/ 2983 batches | lr 0.08 | ms/batch 22.37 | loss  3.82 | ppl    45.67
| train-epoch  27 |  2800/ 2983 batches | lr 0.08 | ms/batch 22.37 | loss  3.77 | ppl    43.29
-----------------------------------------------------------------------------------------
| end of train epoch  27 | time: 69.53s | valid loss  4.60 | valid ppl    99.96
-----------------------------------------------------------------------------------------
| train-epoch  28 |   200/ 2983 batches | lr 0.08 | ms/batch 22.32 | loss  3.96 | ppl    52.70
| train-epoch  28 |   400/ 2983 batches | lr 0.08 | ms/batch 22.20 | loss  4.01 | ppl    54.99
| train-epoch  28 |   600/ 2983 batches | lr 0.08 | ms/batch 22.20 | loss  3.85 | ppl    46.78
| train-epoch  28 |   800/ 2983 batches | lr 0.08 | ms/batch 22.20 | loss  3.88 | ppl    48.34
| train-epoch  28 |  1000/ 2983 batches | lr 0.08 | ms/batch 22.21 | loss  3.91 | ppl    49.68
| train-epoch  28 |  1200/ 2983 batches | lr 0.08 | ms/batch 22.21 | loss  3.89 | ppl    48.94
| train-epoch  28 |  1400/ 2983 batches | lr 0.08 | ms/batch 22.24 | loss  3.93 | ppl    50.74
| train-epoch  28 |  1600/ 2983 batches | lr 0.08 | ms/batch 22.26 | loss  3.98 | ppl    53.45
| train-epoch  28 |  1800/ 2983 batches | lr 0.08 | ms/batch 22.24 | loss  3.88 | ppl    48.38
| train-epoch  28 |  2000/ 2983 batches | lr 0.08 | ms/batch 22.28 | loss  3.89 | ppl    49.03
| train-epoch  28 |  2200/ 2983 batches | lr 0.08 | ms/batch 22.38 | loss  3.78 | ppl    43.87
| train-epoch  28 |  2400/ 2983 batches | lr 0.08 | ms/batch 22.36 | loss  3.79 | ppl    44.38
| train-epoch  28 |  2600/ 2983 batches | lr 0.08 | ms/batch 22.36 | loss  3.82 | ppl    45.60
| train-epoch  28 |  2800/ 2983 batches | lr 0.08 | ms/batch 22.36 | loss  3.78 | ppl    43.77
-----------------------------------------------------------------------------------------
| end of train epoch  28 | time: 69.24s | valid loss  4.60 | valid ppl    99.76
-----------------------------------------------------------------------------------------
| train-epoch  29 |   200/ 2983 batches | lr 0.08 | ms/batch 22.53 | loss  3.96 | ppl    52.66
| train-epoch  29 |   400/ 2983 batches | lr 0.08 | ms/batch 22.41 | loss  4.00 | ppl    54.78
| train-epoch  29 |   600/ 2983 batches | lr 0.08 | ms/batch 22.43 | loss  3.83 | ppl    46.21
| train-epoch  29 |   800/ 2983 batches | lr 0.08 | ms/batch 22.42 | loss  3.86 | ppl    47.66
| train-epoch  29 |  1000/ 2983 batches | lr 0.08 | ms/batch 22.41 | loss  3.89 | ppl    48.82
| train-epoch  29 |  1200/ 2983 batches | lr 0.08 | ms/batch 22.41 | loss  3.88 | ppl    48.59
| train-epoch  29 |  1400/ 2983 batches | lr 0.08 | ms/batch 22.40 | loss  3.92 | ppl    50.42
| train-epoch  29 |  1600/ 2983 batches | lr 0.08 | ms/batch 22.39 | loss  3.98 | ppl    53.31
| train-epoch  29 |  1800/ 2983 batches | lr 0.08 | ms/batch 22.45 | loss  3.87 | ppl    48.12
| train-epoch  29 |  2000/ 2983 batches | lr 0.08 | ms/batch 22.42 | loss  3.89 | ppl    49.08
| train-epoch  29 |  2200/ 2983 batches | lr 0.08 | ms/batch 22.42 | loss  3.78 | ppl    43.68
| train-epoch  29 |  2400/ 2983 batches | lr 0.08 | ms/batch 22.41 | loss  3.79 | ppl    44.47
| train-epoch  29 |  2600/ 2983 batches | lr 0.08 | ms/batch 22.37 | loss  3.82 | ppl    45.55
| train-epoch  29 |  2800/ 2983 batches | lr 0.08 | ms/batch 22.40 | loss  3.78 | ppl    43.97
-----------------------------------------------------------------------------------------
| end of train epoch  29 | time: 69.65s | valid loss  4.60 | valid ppl    99.70
-----------------------------------------------------------------------------------------
| train-epoch  30 |   200/ 2983 batches | lr 0.08 | ms/batch 22.36 | loss  3.97 | ppl    53.08
| train-epoch  30 |   400/ 2983 batches | lr 0.08 | ms/batch 22.23 | loss  4.00 | ppl    54.75
| train-epoch  30 |   600/ 2983 batches | lr 0.08 | ms/batch 22.24 | loss  3.83 | ppl    45.93
| train-epoch  30 |   800/ 2983 batches | lr 0.08 | ms/batch 22.24 | loss  3.86 | ppl    47.44
| train-epoch  30 |  1000/ 2983 batches | lr 0.08 | ms/batch 22.24 | loss  3.88 | ppl    48.61
| train-epoch  30 |  1200/ 2983 batches | lr 0.08 | ms/batch 22.27 | loss  3.88 | ppl    48.50
| train-epoch  30 |  1400/ 2983 batches | lr 0.08 | ms/batch 22.24 | loss  3.92 | ppl    50.52
| train-epoch  30 |  1600/ 2983 batches | lr 0.08 | ms/batch 22.24 | loss  3.97 | ppl    53.12
| train-epoch  30 |  1800/ 2983 batches | lr 0.08 | ms/batch 22.26 | loss  3.87 | ppl    48.12
| train-epoch  30 |  2000/ 2983 batches | lr 0.08 | ms/batch 22.25 | loss  3.90 | ppl    49.25
| train-epoch  30 |  2200/ 2983 batches | lr 0.08 | ms/batch 22.24 | loss  3.78 | ppl    43.92
| train-epoch  30 |  2400/ 2983 batches | lr 0.08 | ms/batch 22.24 | loss  3.79 | ppl    44.44
| train-epoch  30 |  2600/ 2983 batches | lr 0.08 | ms/batch 22.25 | loss  3.82 | ppl    45.71
| train-epoch  30 |  2800/ 2983 batches | lr 0.08 | ms/batch 22.24 | loss  3.79 | ppl    44.07
-----------------------------------------------------------------------------------------
| end of train epoch  30 | time: 69.16s | valid loss  4.60 | valid ppl    99.69
-----------------------------------------------------------------------------------------
| train-epoch  31 |   200/ 2983 batches | lr 0.08 | ms/batch 22.38 | loss  3.96 | ppl    52.56
| train-epoch  31 |   400/ 2983 batches | lr 0.08 | ms/batch 22.27 | loss  4.00 | ppl    54.59
| train-epoch  31 |   600/ 2983 batches | lr 0.08 | ms/batch 22.25 | loss  3.82 | ppl    45.64
| train-epoch  31 |   800/ 2983 batches | lr 0.08 | ms/batch 22.25 | loss  3.85 | ppl    47.07
| train-epoch  31 |  1000/ 2983 batches | lr 0.08 | ms/batch 22.26 | loss  3.88 | ppl    48.58
| train-epoch  31 |  1200/ 2983 batches | lr 0.08 | ms/batch 22.26 | loss  3.88 | ppl    48.39
| train-epoch  31 |  1400/ 2983 batches | lr 0.08 | ms/batch 22.27 | loss  3.91 | ppl    50.09
| train-epoch  31 |  1600/ 2983 batches | lr 0.08 | ms/batch 22.27 | loss  3.98 | ppl    53.38
| train-epoch  31 |  1800/ 2983 batches | lr 0.08 | ms/batch 22.35 | loss  3.88 | ppl    48.35
| train-epoch  31 |  2000/ 2983 batches | lr 0.08 | ms/batch 22.43 | loss  3.89 | ppl    49.04
| train-epoch  31 |  2200/ 2983 batches | lr 0.08 | ms/batch 22.43 | loss  3.78 | ppl    43.86
| train-epoch  31 |  2400/ 2983 batches | lr 0.08 | ms/batch 22.51 | loss  3.79 | ppl    44.38
| train-epoch  31 |  2600/ 2983 batches | lr 0.08 | ms/batch 22.37 | loss  3.83 | ppl    45.89
| train-epoch  31 |  2800/ 2983 batches | lr 0.08 | ms/batch 22.27 | loss  3.78 | ppl    43.99
-----------------------------------------------------------------------------------------
| end of train epoch  31 | time: 69.37s | valid loss  4.60 | valid ppl    99.62
-----------------------------------------------------------------------------------------
| train-epoch  32 |   200/ 2983 batches | lr 0.08 | ms/batch 22.51 | loss  3.96 | ppl    52.46
| train-epoch  32 |   400/ 2983 batches | lr 0.08 | ms/batch 22.43 | loss  4.00 | ppl    54.35
| train-epoch  32 |   600/ 2983 batches | lr 0.08 | ms/batch 22.45 | loss  3.82 | ppl    45.39
| train-epoch  32 |   800/ 2983 batches | lr 0.08 | ms/batch 22.42 | loss  3.85 | ppl    46.94
| train-epoch  32 |  1000/ 2983 batches | lr 0.08 | ms/batch 22.42 | loss  3.88 | ppl    48.44
| train-epoch  32 |  1200/ 2983 batches | lr 0.08 | ms/batch 22.43 | loss  3.87 | ppl    48.03
| train-epoch  32 |  1400/ 2983 batches | lr 0.08 | ms/batch 22.42 | loss  3.92 | ppl    50.35
| train-epoch  32 |  1600/ 2983 batches | lr 0.08 | ms/batch 22.41 | loss  3.97 | ppl    53.13
| train-epoch  32 |  1800/ 2983 batches | lr 0.08 | ms/batch 22.41 | loss  3.87 | ppl    47.99
| train-epoch  32 |  2000/ 2983 batches | lr 0.08 | ms/batch 22.42 | loss  3.90 | ppl    49.19
| train-epoch  32 |  2200/ 2983 batches | lr 0.08 | ms/batch 22.41 | loss  3.78 | ppl    43.86
| train-epoch  32 |  2400/ 2983 batches | lr 0.08 | ms/batch 22.41 | loss  3.79 | ppl    44.47
| train-epoch  32 |  2600/ 2983 batches | lr 0.08 | ms/batch 22.41 | loss  3.82 | ppl    45.63
| train-epoch  32 |  2800/ 2983 batches | lr 0.08 | ms/batch 22.42 | loss  3.78 | ppl    43.92
-----------------------------------------------------------------------------------------
| end of train epoch  32 | time: 69.68s | valid loss  4.60 | valid ppl    99.61
-----------------------------------------------------------------------------------------
| train-epoch  33 |   200/ 2983 batches | lr 0.08 | ms/batch 22.35 | loss  3.96 | ppl    52.47
| train-epoch  33 |   400/ 2983 batches | lr 0.08 | ms/batch 22.22 | loss  3.99 | ppl    54.24
| train-epoch  33 |   600/ 2983 batches | lr 0.08 | ms/batch 22.23 | loss  3.82 | ppl    45.46
| train-epoch  33 |   800/ 2983 batches | lr 0.08 | ms/batch 22.23 | loss  3.85 | ppl    47.00
| train-epoch  33 |  1000/ 2983 batches | lr 0.08 | ms/batch 22.24 | loss  3.88 | ppl    48.49
| train-epoch  33 |  1200/ 2983 batches | lr 0.08 | ms/batch 22.22 | loss  3.87 | ppl    48.12
| train-epoch  33 |  1400/ 2983 batches | lr 0.08 | ms/batch 22.23 | loss  3.91 | ppl    49.90
| train-epoch  33 |  1600/ 2983 batches | lr 0.08 | ms/batch 22.22 | loss  3.97 | ppl    52.94
| train-epoch  33 |  1800/ 2983 batches | lr 0.08 | ms/batch 22.22 | loss  3.87 | ppl    48.18
| train-epoch  33 |  2000/ 2983 batches | lr 0.08 | ms/batch 22.21 | loss  3.89 | ppl    48.95
| train-epoch  33 |  2200/ 2983 batches | lr 0.08 | ms/batch 22.21 | loss  3.77 | ppl    43.31
| train-epoch  33 |  2400/ 2983 batches | lr 0.08 | ms/batch 22.23 | loss  3.79 | ppl    44.29
| train-epoch  33 |  2600/ 2983 batches | lr 0.08 | ms/batch 22.21 | loss  3.82 | ppl    45.69
| train-epoch  33 |  2800/ 2983 batches | lr 0.08 | ms/batch 22.23 | loss  3.78 | ppl    43.83
-----------------------------------------------------------------------------------------
| end of train epoch  33 | time: 69.09s | valid loss  4.60 | valid ppl    99.60
-----------------------------------------------------------------------------------------
| train-epoch  34 |   200/ 2983 batches | lr 0.08 | ms/batch 22.35 | loss  3.96 | ppl    52.32
| train-epoch  34 |   400/ 2983 batches | lr 0.08 | ms/batch 22.24 | loss  3.99 | ppl    54.17
| train-epoch  34 |   600/ 2983 batches | lr 0.08 | ms/batch 22.24 | loss  3.81 | ppl    45.18
| train-epoch  34 |   800/ 2983 batches | lr 0.08 | ms/batch 22.24 | loss  3.84 | ppl    46.74
| train-epoch  34 |  1000/ 2983 batches | lr 0.08 | ms/batch 22.24 | loss  3.89 | ppl    48.68
| train-epoch  34 |  1200/ 2983 batches | lr 0.08 | ms/batch 22.24 | loss  3.87 | ppl    48.10
| train-epoch  34 |  1400/ 2983 batches | lr 0.08 | ms/batch 22.25 | loss  3.91 | ppl    49.89
| train-epoch  34 |  1600/ 2983 batches | lr 0.08 | ms/batch 22.25 | loss  3.97 | ppl    53.06
| train-epoch  34 |  1800/ 2983 batches | lr 0.08 | ms/batch 22.26 | loss  3.87 | ppl    47.79
| train-epoch  34 |  2000/ 2983 batches | lr 0.08 | ms/batch 22.28 | loss  3.89 | ppl    49.02
| train-epoch  34 |  2200/ 2983 batches | lr 0.08 | ms/batch 22.25 | loss  3.77 | ppl    43.56
| train-epoch  34 |  2400/ 2983 batches | lr 0.08 | ms/batch 22.26 | loss  3.79 | ppl    44.08
| train-epoch  34 |  2600/ 2983 batches | lr 0.08 | ms/batch 22.25 | loss  3.82 | ppl    45.69
| train-epoch  34 |  2800/ 2983 batches | lr 0.08 | ms/batch 22.25 | loss  3.78 | ppl    43.90
-----------------------------------------------------------------------------------------
| end of train epoch  34 | time: 69.17s | valid loss  4.60 | valid ppl    99.59
-----------------------------------------------------------------------------------------
| train-epoch  35 |   200/ 2983 batches | lr 0.08 | ms/batch 22.47 | loss  3.96 | ppl    52.23
| train-epoch  35 |   400/ 2983 batches | lr 0.08 | ms/batch 22.34 | loss  3.99 | ppl    53.84
| train-epoch  35 |   600/ 2983 batches | lr 0.08 | ms/batch 22.35 | loss  3.82 | ppl    45.48
| train-epoch  35 |   800/ 2983 batches | lr 0.08 | ms/batch 22.34 | loss  3.86 | ppl    47.41
| train-epoch  35 |  1000/ 2983 batches | lr 0.08 | ms/batch 22.34 | loss  3.88 | ppl    48.32
| train-epoch  35 |  1200/ 2983 batches | lr 0.08 | ms/batch 22.33 | loss  3.87 | ppl    47.93
| train-epoch  35 |  1400/ 2983 batches | lr 0.08 | ms/batch 22.33 | loss  3.91 | ppl    49.78
| train-epoch  35 |  1600/ 2983 batches | lr 0.08 | ms/batch 22.35 | loss  3.97 | ppl    52.97
| train-epoch  35 |  1800/ 2983 batches | lr 0.08 | ms/batch 22.33 | loss  3.87 | ppl    48.14
| train-epoch  35 |  2000/ 2983 batches | lr 0.08 | ms/batch 22.34 | loss  3.89 | ppl    48.99
| train-epoch  35 |  2200/ 2983 batches | lr 0.08 | ms/batch 22.33 | loss  3.77 | ppl    43.41
| train-epoch  35 |  2400/ 2983 batches | lr 0.08 | ms/batch 22.33 | loss  3.79 | ppl    44.37
| train-epoch  35 |  2600/ 2983 batches | lr 0.08 | ms/batch 22.33 | loss  3.81 | ppl    45.34
| train-epoch  35 |  2800/ 2983 batches | lr 0.08 | ms/batch 22.33 | loss  3.78 | ppl    43.65
-----------------------------------------------------------------------------------------
| end of train epoch  35 | time: 69.43s | valid loss  4.60 | valid ppl    99.53
-----------------------------------------------------------------------------------------
| train-epoch  36 |   200/ 2983 batches | lr 0.08 | ms/batch 22.41 | loss  3.96 | ppl    52.34
| train-epoch  36 |   400/ 2983 batches | lr 0.08 | ms/batch 22.35 | loss  3.98 | ppl    53.74
| train-epoch  36 |   600/ 2983 batches | lr 0.08 | ms/batch 22.40 | loss  3.81 | ppl    45.14
| train-epoch  36 |   800/ 2983 batches | lr 0.08 | ms/batch 22.40 | loss  3.84 | ppl    46.57
| train-epoch  36 |  1000/ 2983 batches | lr 0.08 | ms/batch 22.41 | loss  3.88 | ppl    48.22
| train-epoch  36 |  1200/ 2983 batches | lr 0.08 | ms/batch 22.40 | loss  3.87 | ppl    47.87
| train-epoch  36 |  1400/ 2983 batches | lr 0.08 | ms/batch 22.40 | loss  3.91 | ppl    49.99
| train-epoch  36 |  1600/ 2983 batches | lr 0.08 | ms/batch 22.39 | loss  3.97 | ppl    52.82
| train-epoch  36 |  1800/ 2983 batches | lr 0.08 | ms/batch 22.39 | loss  3.87 | ppl    48.08
| train-epoch  36 |  2000/ 2983 batches | lr 0.08 | ms/batch 22.40 | loss  3.89 | ppl    48.82
| train-epoch  36 |  2200/ 2983 batches | lr 0.08 | ms/batch 22.41 | loss  3.77 | ppl    43.35
| train-epoch  36 |  2400/ 2983 batches | lr 0.08 | ms/batch 22.39 | loss  3.79 | ppl    44.14
| train-epoch  36 |  2600/ 2983 batches | lr 0.08 | ms/batch 22.39 | loss  3.82 | ppl    45.72
| train-epoch  36 |  2800/ 2983 batches | lr 0.08 | ms/batch 22.39 | loss  3.78 | ppl    43.85
-----------------------------------------------------------------------------------------
| end of train epoch  36 | time: 69.57s | valid loss  4.60 | valid ppl    99.55
-----------------------------------------------------------------------------------------
| train-epoch  37 |   200/ 2983 batches | lr 0.02 | ms/batch 22.33 | loss  3.97 | ppl    52.74
| train-epoch  37 |   400/ 2983 batches | lr 0.02 | ms/batch 22.20 | loss  3.99 | ppl    54.31
| train-epoch  37 |   600/ 2983 batches | lr 0.02 | ms/batch 22.20 | loss  3.81 | ppl    45.36
| train-epoch  37 |   800/ 2983 batches | lr 0.02 | ms/batch 22.39 | loss  3.85 | ppl    47.05
| train-epoch  37 |  1000/ 2983 batches | lr 0.02 | ms/batch 22.23 | loss  3.89 | ppl    48.83
| train-epoch  37 |  1200/ 2983 batches | lr 0.02 | ms/batch 22.20 | loss  3.89 | ppl    48.73
| train-epoch  37 |  1400/ 2983 batches | lr 0.02 | ms/batch 22.20 | loss  3.92 | ppl    50.35
| train-epoch  37 |  1600/ 2983 batches | lr 0.02 | ms/batch 22.21 | loss  3.98 | ppl    53.26
| train-epoch  37 |  1800/ 2983 batches | lr 0.02 | ms/batch 22.22 | loss  3.87 | ppl    48.00
| train-epoch  37 |  2000/ 2983 batches | lr 0.02 | ms/batch 22.21 | loss  3.89 | ppl    49.12
| train-epoch  37 |  2200/ 2983 batches | lr 0.02 | ms/batch 22.21 | loss  3.77 | ppl    43.19
| train-epoch  37 |  2400/ 2983 batches | lr 0.02 | ms/batch 22.21 | loss  3.80 | ppl    44.50
| train-epoch  37 |  2600/ 2983 batches | lr 0.02 | ms/batch 22.21 | loss  3.82 | ppl    45.56
| train-epoch  37 |  2800/ 2983 batches | lr 0.02 | ms/batch 22.21 | loss  3.77 | ppl    43.54
-----------------------------------------------------------------------------------------
| end of train epoch  37 | time: 69.08s | valid loss  4.60 | valid ppl    99.48
-----------------------------------------------------------------------------------------
| train-epoch  38 |   200/ 2983 batches | lr 0.02 | ms/batch 22.47 | loss  3.96 | ppl    52.26
| train-epoch  38 |   400/ 2983 batches | lr 0.02 | ms/batch 22.38 | loss  3.99 | ppl    54.30
| train-epoch  38 |   600/ 2983 batches | lr 0.02 | ms/batch 22.38 | loss  3.81 | ppl    45.31
| train-epoch  38 |   800/ 2983 batches | lr 0.02 | ms/batch 22.39 | loss  3.85 | ppl    46.92
| train-epoch  38 |  1000/ 2983 batches | lr 0.02 | ms/batch 22.38 | loss  3.88 | ppl    48.66
| train-epoch  38 |  1200/ 2983 batches | lr 0.02 | ms/batch 22.38 | loss  3.88 | ppl    48.58
| train-epoch  38 |  1400/ 2983 batches | lr 0.02 | ms/batch 22.39 | loss  3.92 | ppl    50.52
| train-epoch  38 |  1600/ 2983 batches | lr 0.02 | ms/batch 22.38 | loss  3.97 | ppl    53.15
| train-epoch  38 |  1800/ 2983 batches | lr 0.02 | ms/batch 22.38 | loss  3.88 | ppl    48.56
| train-epoch  38 |  2000/ 2983 batches | lr 0.02 | ms/batch 22.40 | loss  3.89 | ppl    49.08
| train-epoch  38 |  2200/ 2983 batches | lr 0.02 | ms/batch 22.38 | loss  3.77 | ppl    43.46
| train-epoch  38 |  2400/ 2983 batches | lr 0.02 | ms/batch 22.37 | loss  3.79 | ppl    44.32
| train-epoch  38 |  2600/ 2983 batches | lr 0.02 | ms/batch 22.38 | loss  3.82 | ppl    45.54
| train-epoch  38 |  2800/ 2983 batches | lr 0.02 | ms/batch 22.39 | loss  3.78 | ppl    43.72
-----------------------------------------------------------------------------------------
| end of train epoch  38 | time: 69.56s | valid loss  4.60 | valid ppl    99.45
-----------------------------------------------------------------------------------------
| train-epoch  39 |   200/ 2983 batches | lr 0.02 | ms/batch 22.38 | loss  3.95 | ppl    52.09
| train-epoch  39 |   400/ 2983 batches | lr 0.02 | ms/batch 22.26 | loss  4.00 | ppl    54.46
| train-epoch  39 |   600/ 2983 batches | lr 0.02 | ms/batch 22.25 | loss  3.81 | ppl    45.37
| train-epoch  39 |   800/ 2983 batches | lr 0.02 | ms/batch 22.26 | loss  3.85 | ppl    46.91
| train-epoch  39 |  1000/ 2983 batches | lr 0.02 | ms/batch 22.28 | loss  3.88 | ppl    48.51
| train-epoch  39 |  1200/ 2983 batches | lr 0.02 | ms/batch 22.26 | loss  3.88 | ppl    48.63
| train-epoch  39 |  1400/ 2983 batches | lr 0.02 | ms/batch 22.26 | loss  3.92 | ppl    50.29
| train-epoch  39 |  1600/ 2983 batches | lr 0.02 | ms/batch 22.28 | loss  3.97 | ppl    53.25
| train-epoch  39 |  1800/ 2983 batches | lr 0.02 | ms/batch 22.25 | loss  3.88 | ppl    48.30
| train-epoch  39 |  2000/ 2983 batches | lr 0.02 | ms/batch 22.27 | loss  3.89 | ppl    48.98
| train-epoch  39 |  2200/ 2983 batches | lr 0.02 | ms/batch 22.26 | loss  3.77 | ppl    43.28
| train-epoch  39 |  2400/ 2983 batches | lr 0.02 | ms/batch 22.38 | loss  3.79 | ppl    44.22
| train-epoch  39 |  2600/ 2983 batches | lr 0.02 | ms/batch 22.39 | loss  3.82 | ppl    45.59
| train-epoch  39 |  2800/ 2983 batches | lr 0.02 | ms/batch 22.38 | loss  3.78 | ppl    43.75
-----------------------------------------------------------------------------------------
| end of train epoch  39 | time: 69.31s | valid loss  4.60 | valid ppl    99.43
-----------------------------------------------------------------------------------------
| train-epoch  40 |   200/ 2983 batches | lr 0.02 | ms/batch 22.47 | loss  3.96 | ppl    52.64
| train-epoch  40 |   400/ 2983 batches | lr 0.02 | ms/batch 22.36 | loss  3.99 | ppl    54.07
| train-epoch  40 |   600/ 2983 batches | lr 0.02 | ms/batch 22.36 | loss  3.82 | ppl    45.44
| train-epoch  40 |   800/ 2983 batches | lr 0.02 | ms/batch 22.38 | loss  3.85 | ppl    46.94
| train-epoch  40 |  1000/ 2983 batches | lr 0.02 | ms/batch 22.39 | loss  3.88 | ppl    48.35
| train-epoch  40 |  1200/ 2983 batches | lr 0.02 | ms/batch 22.37 | loss  3.88 | ppl    48.40
| train-epoch  40 |  1400/ 2983 batches | lr 0.02 | ms/batch 22.36 | loss  3.92 | ppl    50.46
| train-epoch  40 |  1600/ 2983 batches | lr 0.02 | ms/batch 22.38 | loss  3.97 | ppl    53.03
| train-epoch  40 |  1800/ 2983 batches | lr 0.02 | ms/batch 22.35 | loss  3.87 | ppl    48.07
| train-epoch  40 |  2000/ 2983 batches | lr 0.02 | ms/batch 22.36 | loss  3.89 | ppl    48.79
| train-epoch  40 |  2200/ 2983 batches | lr 0.02 | ms/batch 22.36 | loss  3.77 | ppl    43.28
| train-epoch  40 |  2400/ 2983 batches | lr 0.02 | ms/batch 22.36 | loss  3.78 | ppl    43.91
| train-epoch  40 |  2600/ 2983 batches | lr 0.02 | ms/batch 22.36 | loss  3.82 | ppl    45.56
| train-epoch  40 |  2800/ 2983 batches | lr 0.02 | ms/batch 22.36 | loss  3.77 | ppl    43.50
-----------------------------------------------------------------------------------------
| end of train epoch  40 | time: 69.55s | valid loss  4.60 | valid ppl    99.42
-----------------------------------------------------------------------------------------
required epochs  40 | actual epochs  60
pretrain epochs  40 | prune epochs   0 | retrain epochs  20
=========================================================================================
| End of training | test loss  4.54 | test ppl    94.10
=========================================================================================
python main.py --cuda --emsize 650 --nhid 650 --dropout 0.5 --epochs 40 --tied --save model/baseline/model.pt
<class 'torch.Tensor'> torch.Size([33278, 650])
<class 'torch.Tensor'> torch.Size([2600, 650])
<class 'torch.Tensor'> torch.Size([2600, 650])
<class 'torch.Tensor'> torch.Size([2600])
<class 'torch.Tensor'> torch.Size([2600])
<class 'torch.Tensor'> torch.Size([2600, 650])
<class 'torch.Tensor'> torch.Size([2600, 650])
<class 'torch.Tensor'> torch.Size([2600])
<class 'torch.Tensor'> torch.Size([2600])
<class 'torch.Tensor'> torch.Size([33278])
RNNModel(
  (drop): Dropout(p=0.5)
  (encoder): Embedding(33278, 650)
  (rnn): LSTM(650, 650, num_layers=2, dropout=0.5)
  (decoder): Linear(in_features=650, out_features=33278, bias=True)
)
Dropout(p=0.5)
Embedding(33278, 650)
LSTM(650, 650, num_layers=2, dropout=0.5)
Linear(in_features=650, out_features=33278, bias=True)
| train-epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 21.76 | loss  7.74 | ppl  2297.39
| train-epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 21.50 | loss  6.78 | ppl   880.76
| train-epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 21.51 | loss  6.39 | ppl   594.52
| train-epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 21.57 | loss  6.24 | ppl   510.38
| train-epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.59 | loss  6.11 | ppl   450.04
| train-epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.62 | loss  6.04 | ppl   420.21
| train-epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.65 | loss  5.93 | ppl   377.78
| train-epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.62 | loss  5.94 | ppl   380.68
| train-epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.66 | loss  5.79 | ppl   326.74
| train-epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.67 | loss  5.75 | ppl   315.38
| train-epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.67 | loss  5.65 | ppl   284.08
| train-epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.67 | loss  5.65 | ppl   283.66
| train-epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.66 | loss  5.64 | ppl   281.90
| train-epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.67 | loss  5.53 | ppl   252.41
-----------------------------------------------------------------------------------------
| end of train epoch   1 | time: 67.30s | valid loss  5.42 | valid ppl   226.46
-----------------------------------------------------------------------------------------
| train-epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch 21.81 | loss  5.54 | ppl   254.04
| train-epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch 21.67 | loss  5.52 | ppl   248.65
| train-epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch 21.68 | loss  5.34 | ppl   208.78
| train-epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch 21.68 | loss  5.36 | ppl   213.67
| train-epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.67 | loss  5.34 | ppl   208.20
| train-epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.68 | loss  5.33 | ppl   205.83
| train-epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.67 | loss  5.32 | ppl   204.94
| train-epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.66 | loss  5.38 | ppl   216.98
| train-epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.67 | loss  5.25 | ppl   190.33
| train-epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.68 | loss  5.27 | ppl   193.77
| train-epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.66 | loss  5.18 | ppl   176.81
| train-epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.67 | loss  5.19 | ppl   179.73
| train-epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.67 | loss  5.20 | ppl   182.16
| train-epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.68 | loss  5.13 | ppl   168.66
-----------------------------------------------------------------------------------------
| end of train epoch   2 | time: 67.44s | valid loss  5.11 | valid ppl   165.62
-----------------------------------------------------------------------------------------
| train-epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  5.17 | ppl   175.86
| train-epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch 21.62 | loss  5.19 | ppl   179.03
| train-epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  5.01 | ppl   149.52
| train-epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  5.06 | ppl   157.73
| train-epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.62 | loss  5.04 | ppl   155.22
| train-epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  5.05 | ppl   155.58
| train-epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.62 | loss  5.07 | ppl   159.35
| train-epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  5.14 | ppl   170.24
| train-epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  5.00 | ppl   149.12
| train-epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.64 | loss  5.04 | ppl   153.87
| train-epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  4.94 | ppl   139.40
| train-epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  4.97 | ppl   144.13
| train-epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.64 | loss  4.99 | ppl   146.75
| train-epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  4.92 | ppl   137.24
-----------------------------------------------------------------------------------------
| end of train epoch   3 | time: 67.32s | valid loss  4.96 | valid ppl   143.31
-----------------------------------------------------------------------------------------
| train-epoch   4 |   200/ 2983 batches | lr 20.00 | ms/batch 21.87 | loss  4.97 | ppl   144.44
| train-epoch   4 |   400/ 2983 batches | lr 20.00 | ms/batch 21.76 | loss  4.99 | ppl   146.72
| train-epoch   4 |   600/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.82 | ppl   123.37
| train-epoch   4 |   800/ 2983 batches | lr 20.00 | ms/batch 21.76 | loss  4.88 | ppl   131.21
| train-epoch   4 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.87 | ppl   130.36
| train-epoch   4 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.72 | loss  4.87 | ppl   130.95
| train-epoch   4 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  4.91 | ppl   135.32
| train-epoch   4 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.98 | ppl   145.16
| train-epoch   4 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.85 | ppl   128.15
| train-epoch   4 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.89 | ppl   132.86
| train-epoch   4 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.79 | ppl   120.21
| train-epoch   4 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  4.83 | ppl   124.90
| train-epoch   4 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  4.85 | ppl   127.57
| train-epoch   4 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  4.78 | ppl   119.54
-----------------------------------------------------------------------------------------
| end of train epoch   4 | time: 67.67s | valid loss  4.87 | valid ppl   130.15
-----------------------------------------------------------------------------------------
| train-epoch   5 |   200/ 2983 batches | lr 20.00 | ms/batch 21.69 | loss  4.84 | ppl   125.84
| train-epoch   5 |   400/ 2983 batches | lr 20.00 | ms/batch 21.59 | loss  4.86 | ppl   129.60
| train-epoch   5 |   600/ 2983 batches | lr 20.00 | ms/batch 21.59 | loss  4.69 | ppl   108.35
| train-epoch   5 |   800/ 2983 batches | lr 20.00 | ms/batch 21.58 | loss  4.74 | ppl   114.90
| train-epoch   5 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.58 | loss  4.75 | ppl   115.61
| train-epoch   5 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.59 | loss  4.75 | ppl   116.13
| train-epoch   5 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.59 | loss  4.80 | ppl   121.35
| train-epoch   5 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.59 | loss  4.86 | ppl   128.86
| train-epoch   5 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.59 | loss  4.74 | ppl   114.97
| train-epoch   5 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.58 | loss  4.78 | ppl   119.34
| train-epoch   5 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.59 | loss  4.68 | ppl   107.38
| train-epoch   5 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.59 | loss  4.72 | ppl   111.95
| train-epoch   5 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.66 | loss  4.74 | ppl   114.76
| train-epoch   5 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.72 | loss  4.68 | ppl   108.12
-----------------------------------------------------------------------------------------
| end of train epoch   5 | time: 67.25s | valid loss  4.82 | valid ppl   124.22
-----------------------------------------------------------------------------------------
| train-epoch   6 |   200/ 2983 batches | lr 20.00 | ms/batch 21.82 | loss  4.74 | ppl   113.93
| train-epoch   6 |   400/ 2983 batches | lr 20.00 | ms/batch 21.70 | loss  4.76 | ppl   116.87
| train-epoch   6 |   600/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.58 | ppl    97.76
| train-epoch   6 |   800/ 2983 batches | lr 20.00 | ms/batch 21.72 | loss  4.64 | ppl   103.71
| train-epoch   6 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.71 | loss  4.65 | ppl   104.90
| train-epoch   6 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.71 | loss  4.67 | ppl   106.23
| train-epoch   6 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.70 | loss  4.71 | ppl   110.67
| train-epoch   6 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.70 | loss  4.77 | ppl   118.15
| train-epoch   6 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.69 | loss  4.65 | ppl   104.98
| train-epoch   6 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.70 | loss  4.70 | ppl   110.36
| train-epoch   6 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.69 | loss  4.59 | ppl    98.89
| train-epoch   6 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.69 | loss  4.63 | ppl   102.68
| train-epoch   6 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.70 | loss  4.66 | ppl   105.35
| train-epoch   6 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.69 | loss  4.60 | ppl    99.83
-----------------------------------------------------------------------------------------
| end of train epoch   6 | time: 67.54s | valid loss  4.78 | valid ppl   119.55
-----------------------------------------------------------------------------------------
| train-epoch   7 |   200/ 2983 batches | lr 20.00 | ms/batch 21.68 | loss  4.65 | ppl   104.90
| train-epoch   7 |   400/ 2983 batches | lr 20.00 | ms/batch 21.57 | loss  4.68 | ppl   108.00
| train-epoch   7 |   600/ 2983 batches | lr 20.00 | ms/batch 21.56 | loss  4.51 | ppl    90.49
| train-epoch   7 |   800/ 2983 batches | lr 20.00 | ms/batch 21.59 | loss  4.56 | ppl    95.95
| train-epoch   7 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.57 | loss  4.58 | ppl    97.33
| train-epoch   7 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.58 | loss  4.59 | ppl    98.35
| train-epoch   7 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.58 | loss  4.63 | ppl   103.02
| train-epoch   7 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.57 | loss  4.70 | ppl   109.47
| train-epoch   7 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.58 | loss  4.59 | ppl    98.34
| train-epoch   7 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.58 | loss  4.63 | ppl   102.57
| train-epoch   7 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.57 | loss  4.52 | ppl    92.15
| train-epoch   7 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.60 | loss  4.57 | ppl    96.19
| train-epoch   7 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.56 | loss  4.59 | ppl    98.31
| train-epoch   7 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.58 | loss  4.54 | ppl    93.65
-----------------------------------------------------------------------------------------
| end of train epoch   7 | time: 67.16s | valid loss  4.76 | valid ppl   116.95
-----------------------------------------------------------------------------------------
| train-epoch   8 |   200/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.59 | ppl    98.06
| train-epoch   8 |   400/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  4.62 | ppl   101.01
| train-epoch   8 |   600/ 2983 batches | lr 20.00 | ms/batch 21.62 | loss  4.44 | ppl    84.53
| train-epoch   8 |   800/ 2983 batches | lr 20.00 | ms/batch 21.64 | loss  4.50 | ppl    89.94
| train-epoch   8 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  4.52 | ppl    91.94
| train-epoch   8 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  4.53 | ppl    93.16
| train-epoch   8 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  4.57 | ppl    96.99
| train-epoch   8 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  4.64 | ppl   103.77
| train-epoch   8 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.64 | loss  4.54 | ppl    93.32
| train-epoch   8 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.64 | loss  4.58 | ppl    97.05
| train-epoch   8 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.64 | loss  4.47 | ppl    87.13
| train-epoch   8 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.64 | loss  4.50 | ppl    90.44
| train-epoch   8 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.64 | loss  4.53 | ppl    93.02
| train-epoch   8 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.66 | loss  4.49 | ppl    89.05
-----------------------------------------------------------------------------------------
| end of train epoch   8 | time: 67.34s | valid loss  4.73 | valid ppl   113.67
-----------------------------------------------------------------------------------------
| train-epoch   9 |   200/ 2983 batches | lr 20.00 | ms/batch 21.92 | loss  4.53 | ppl    93.22
| train-epoch   9 |   400/ 2983 batches | lr 20.00 | ms/batch 21.81 | loss  4.56 | ppl    95.64
| train-epoch   9 |   600/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.38 | ppl    80.10
| train-epoch   9 |   800/ 2983 batches | lr 20.00 | ms/batch 21.80 | loss  4.44 | ppl    85.13
| train-epoch   9 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.82 | loss  4.46 | ppl    86.74
| train-epoch   9 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.81 | loss  4.48 | ppl    88.21
| train-epoch   9 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.80 | loss  4.52 | ppl    91.77
| train-epoch   9 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.81 | loss  4.59 | ppl    98.88
| train-epoch   9 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  4.49 | ppl    88.80
| train-epoch   9 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.70 | loss  4.52 | ppl    92.10
| train-epoch   9 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.69 | loss  4.41 | ppl    82.65
| train-epoch   9 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.69 | loss  4.46 | ppl    86.28
| train-epoch   9 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.69 | loss  4.48 | ppl    88.63
| train-epoch   9 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.69 | loss  4.44 | ppl    84.85
-----------------------------------------------------------------------------------------
| end of train epoch   9 | time: 67.69s | valid loss  4.72 | valid ppl   112.34
-----------------------------------------------------------------------------------------
| train-epoch  10 |   200/ 2983 batches | lr 20.00 | ms/batch 21.72 | loss  4.49 | ppl    89.24
| train-epoch  10 |   400/ 2983 batches | lr 20.00 | ms/batch 21.62 | loss  4.51 | ppl    90.97
| train-epoch  10 |   600/ 2983 batches | lr 20.00 | ms/batch 21.61 | loss  4.34 | ppl    76.77
| train-epoch  10 |   800/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  4.39 | ppl    80.78
| train-epoch  10 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  4.43 | ppl    83.76
| train-epoch  10 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  4.44 | ppl    84.74
| train-epoch  10 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  4.48 | ppl    87.93
| train-epoch  10 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.62 | loss  4.55 | ppl    94.59
| train-epoch  10 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.68 | loss  4.44 | ppl    85.17
| train-epoch  10 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  4.49 | ppl    88.68
| train-epoch  10 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.37 | ppl    78.92
| train-epoch  10 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  4.41 | ppl    82.61
| train-epoch  10 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  4.45 | ppl    85.44
| train-epoch  10 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.39 | ppl    80.77
-----------------------------------------------------------------------------------------
| end of train epoch  10 | time: 67.45s | valid loss  4.71 | valid ppl   110.82
-----------------------------------------------------------------------------------------
| train-epoch  11 |   200/ 2983 batches | lr 20.00 | ms/batch 21.88 | loss  4.45 | ppl    85.54
| train-epoch  11 |   400/ 2983 batches | lr 20.00 | ms/batch 21.77 | loss  4.47 | ppl    87.63
| train-epoch  11 |   600/ 2983 batches | lr 20.00 | ms/batch 21.77 | loss  4.30 | ppl    73.61
| train-epoch  11 |   800/ 2983 batches | lr 20.00 | ms/batch 21.76 | loss  4.35 | ppl    77.85
| train-epoch  11 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.77 | loss  4.39 | ppl    80.55
| train-epoch  11 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.77 | loss  4.40 | ppl    81.36
| train-epoch  11 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.76 | loss  4.44 | ppl    84.68
| train-epoch  11 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.76 | loss  4.51 | ppl    90.97
| train-epoch  11 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.76 | loss  4.40 | ppl    81.86
| train-epoch  11 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.76 | loss  4.44 | ppl    85.14
| train-epoch  11 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.34 | ppl    76.41
| train-epoch  11 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.76 | loss  4.38 | ppl    79.61
| train-epoch  11 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.77 | loss  4.41 | ppl    82.06
| train-epoch  11 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.76 | loss  4.37 | ppl    78.67
-----------------------------------------------------------------------------------------
| end of train epoch  11 | time: 67.71s | valid loss  4.70 | valid ppl   110.19
-----------------------------------------------------------------------------------------
| train-epoch  12 |   200/ 2983 batches | lr 20.00 | ms/batch 21.71 | loss  4.41 | ppl    82.40
| train-epoch  12 |   400/ 2983 batches | lr 20.00 | ms/batch 21.61 | loss  4.44 | ppl    84.36
| train-epoch  12 |   600/ 2983 batches | lr 20.00 | ms/batch 21.60 | loss  4.26 | ppl    71.01
| train-epoch  12 |   800/ 2983 batches | lr 20.00 | ms/batch 21.59 | loss  4.32 | ppl    75.00
| train-epoch  12 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.60 | loss  4.35 | ppl    77.85
| train-epoch  12 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.60 | loss  4.37 | ppl    79.02
| train-epoch  12 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.60 | loss  4.41 | ppl    81.91
| train-epoch  12 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.60 | loss  4.48 | ppl    88.43
| train-epoch  12 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.60 | loss  4.37 | ppl    79.42
| train-epoch  12 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.60 | loss  4.41 | ppl    82.56
| train-epoch  12 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.60 | loss  4.30 | ppl    73.73
| train-epoch  12 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.60 | loss  4.34 | ppl    76.92
| train-epoch  12 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.61 | loss  4.38 | ppl    79.61
| train-epoch  12 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.60 | loss  4.33 | ppl    75.87
-----------------------------------------------------------------------------------------
| end of train epoch  12 | time: 67.23s | valid loss  4.69 | valid ppl   108.78
-----------------------------------------------------------------------------------------
| train-epoch  13 |   200/ 2983 batches | lr 20.00 | ms/batch 21.71 | loss  4.38 | ppl    79.61
| train-epoch  13 |   400/ 2983 batches | lr 20.00 | ms/batch 21.62 | loss  4.41 | ppl    82.11
| train-epoch  13 |   600/ 2983 batches | lr 20.00 | ms/batch 21.79 | loss  4.23 | ppl    68.71
| train-epoch  13 |   800/ 2983 batches | lr 20.00 | ms/batch 21.80 | loss  4.29 | ppl    72.75
| train-epoch  13 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.79 | loss  4.32 | ppl    75.06
| train-epoch  13 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.78 | loss  4.34 | ppl    76.36
| train-epoch  13 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.80 | loss  4.38 | ppl    79.53
| train-epoch  13 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.78 | loss  4.45 | ppl    85.48
| train-epoch  13 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.79 | loss  4.35 | ppl    77.60
| train-epoch  13 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.78 | loss  4.39 | ppl    80.36
| train-epoch  13 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.79 | loss  4.27 | ppl    71.55
| train-epoch  13 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.79 | loss  4.31 | ppl    74.69
| train-epoch  13 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.80 | loss  4.34 | ppl    76.85
| train-epoch  13 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.79 | loss  4.31 | ppl    74.21
-----------------------------------------------------------------------------------------
| end of train epoch  13 | time: 67.72s | valid loss  4.69 | valid ppl   108.36
-----------------------------------------------------------------------------------------
| train-epoch  14 |   200/ 2983 batches | lr 20.00 | ms/batch 21.89 | loss  4.35 | ppl    77.39
| train-epoch  14 |   400/ 2983 batches | lr 20.00 | ms/batch 21.78 | loss  4.38 | ppl    79.57
| train-epoch  14 |   600/ 2983 batches | lr 20.00 | ms/batch 21.70 | loss  4.21 | ppl    67.18
| train-epoch  14 |   800/ 2983 batches | lr 20.00 | ms/batch 21.66 | loss  4.27 | ppl    71.17
| train-epoch  14 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.66 | loss  4.30 | ppl    73.40
| train-epoch  14 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.66 | loss  4.31 | ppl    74.60
| train-epoch  14 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.67 | loss  4.35 | ppl    77.63
| train-epoch  14 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.67 | loss  4.43 | ppl    83.78
| train-epoch  14 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.67 | loss  4.32 | ppl    75.16
| train-epoch  14 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.67 | loss  4.36 | ppl    78.64
| train-epoch  14 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.66 | loss  4.25 | ppl    70.07
| train-epoch  14 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.66 | loss  4.29 | ppl    72.88
| train-epoch  14 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.66 | loss  4.32 | ppl    75.41
| train-epoch  14 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.66 | loss  4.28 | ppl    72.03
-----------------------------------------------------------------------------------------
| end of train epoch  14 | time: 67.47s | valid loss  4.68 | valid ppl   107.67
-----------------------------------------------------------------------------------------
| train-epoch  15 |   200/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  4.33 | ppl    75.63
| train-epoch  15 |   400/ 2983 batches | lr 20.00 | ms/batch 21.61 | loss  4.35 | ppl    77.67
| train-epoch  15 |   600/ 2983 batches | lr 20.00 | ms/batch 21.62 | loss  4.18 | ppl    65.11
| train-epoch  15 |   800/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  4.24 | ppl    69.35
| train-epoch  15 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.61 | loss  4.27 | ppl    71.75
| train-epoch  15 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.61 | loss  4.29 | ppl    72.69
| train-epoch  15 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.61 | loss  4.32 | ppl    75.37
| train-epoch  15 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.62 | loss  4.40 | ppl    81.37
| train-epoch  15 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.62 | loss  4.30 | ppl    73.98
| train-epoch  15 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.62 | loss  4.34 | ppl    76.86
| train-epoch  15 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  4.22 | ppl    68.27
| train-epoch  15 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  4.26 | ppl    70.94
| train-epoch  15 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.62 | loss  4.30 | ppl    73.55
| train-epoch  15 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  4.26 | ppl    71.01
-----------------------------------------------------------------------------------------
| end of train epoch  15 | time: 67.29s | valid loss  4.69 | valid ppl   108.36
-----------------------------------------------------------------------------------------
| train-epoch  16 |   200/ 2983 batches | lr 5.00 | ms/batch 21.71 | loss  4.33 | ppl    76.32
| train-epoch  16 |   400/ 2983 batches | lr 5.00 | ms/batch 21.60 | loss  4.33 | ppl    75.63
| train-epoch  16 |   600/ 2983 batches | lr 5.00 | ms/batch 21.60 | loss  4.15 | ppl    63.20
| train-epoch  16 |   800/ 2983 batches | lr 5.00 | ms/batch 21.60 | loss  4.18 | ppl    65.61
| train-epoch  16 |  1000/ 2983 batches | lr 5.00 | ms/batch 21.61 | loss  4.20 | ppl    66.84
| train-epoch  16 |  1200/ 2983 batches | lr 5.00 | ms/batch 21.61 | loss  4.19 | ppl    66.27
| train-epoch  16 |  1400/ 2983 batches | lr 5.00 | ms/batch 21.60 | loss  4.21 | ppl    67.57
| train-epoch  16 |  1600/ 2983 batches | lr 5.00 | ms/batch 21.61 | loss  4.27 | ppl    71.47
| train-epoch  16 |  1800/ 2983 batches | lr 5.00 | ms/batch 21.60 | loss  4.16 | ppl    64.34
| train-epoch  16 |  2000/ 2983 batches | lr 5.00 | ms/batch 21.60 | loss  4.19 | ppl    66.16
| train-epoch  16 |  2200/ 2983 batches | lr 5.00 | ms/batch 21.60 | loss  4.05 | ppl    57.54
| train-epoch  16 |  2400/ 2983 batches | lr 5.00 | ms/batch 21.61 | loss  4.09 | ppl    59.73
| train-epoch  16 |  2600/ 2983 batches | lr 5.00 | ms/batch 21.60 | loss  4.10 | ppl    60.19
| train-epoch  16 |  2800/ 2983 batches | lr 5.00 | ms/batch 21.60 | loss  4.05 | ppl    57.38
-----------------------------------------------------------------------------------------
| end of train epoch  16 | time: 67.24s | valid loss  4.60 | valid ppl    99.31
-----------------------------------------------------------------------------------------
| train-epoch  17 |   200/ 2983 batches | lr 5.00 | ms/batch 21.83 | loss  4.20 | ppl    66.55
| train-epoch  17 |   400/ 2983 batches | lr 5.00 | ms/batch 21.73 | loss  4.22 | ppl    68.01
| train-epoch  17 |   600/ 2983 batches | lr 5.00 | ms/batch 21.71 | loss  4.04 | ppl    56.85
| train-epoch  17 |   800/ 2983 batches | lr 5.00 | ms/batch 21.83 | loss  4.09 | ppl    59.79
| train-epoch  17 |  1000/ 2983 batches | lr 5.00 | ms/batch 21.85 | loss  4.12 | ppl    61.52
| train-epoch  17 |  1200/ 2983 batches | lr 5.00 | ms/batch 21.82 | loss  4.12 | ppl    61.71
| train-epoch  17 |  1400/ 2983 batches | lr 5.00 | ms/batch 21.86 | loss  4.15 | ppl    63.55
| train-epoch  17 |  1600/ 2983 batches | lr 5.00 | ms/batch 21.84 | loss  4.21 | ppl    67.48
| train-epoch  17 |  1800/ 2983 batches | lr 5.00 | ms/batch 21.83 | loss  4.11 | ppl    60.73
| train-epoch  17 |  2000/ 2983 batches | lr 5.00 | ms/batch 21.70 | loss  4.14 | ppl    62.75
| train-epoch  17 |  2200/ 2983 batches | lr 5.00 | ms/batch 21.68 | loss  4.01 | ppl    55.18
| train-epoch  17 |  2400/ 2983 batches | lr 5.00 | ms/batch 21.67 | loss  4.05 | ppl    57.20
| train-epoch  17 |  2600/ 2983 batches | lr 5.00 | ms/batch 21.67 | loss  4.07 | ppl    58.32
| train-epoch  17 |  2800/ 2983 batches | lr 5.00 | ms/batch 21.67 | loss  4.03 | ppl    55.99
-----------------------------------------------------------------------------------------
| end of train epoch  17 | time: 67.68s | valid loss  4.59 | valid ppl    98.21
-----------------------------------------------------------------------------------------
| train-epoch  18 |   200/ 2983 batches | lr 5.00 | ms/batch 21.70 | loss  4.15 | ppl    63.39
| train-epoch  18 |   400/ 2983 batches | lr 5.00 | ms/batch 21.59 | loss  4.17 | ppl    64.70
| train-epoch  18 |   600/ 2983 batches | lr 5.00 | ms/batch 21.58 | loss  3.99 | ppl    54.05
| train-epoch  18 |   800/ 2983 batches | lr 5.00 | ms/batch 21.59 | loss  4.05 | ppl    57.21
| train-epoch  18 |  1000/ 2983 batches | lr 5.00 | ms/batch 21.60 | loss  4.07 | ppl    58.61
| train-epoch  18 |  1200/ 2983 batches | lr 5.00 | ms/batch 21.61 | loss  4.08 | ppl    59.24
| train-epoch  18 |  1400/ 2983 batches | lr 5.00 | ms/batch 21.63 | loss  4.11 | ppl    61.08
| train-epoch  18 |  1600/ 2983 batches | lr 5.00 | ms/batch 21.64 | loss  4.17 | ppl    64.92
| train-epoch  18 |  1800/ 2983 batches | lr 5.00 | ms/batch 21.64 | loss  4.08 | ppl    59.21
| train-epoch  18 |  2000/ 2983 batches | lr 5.00 | ms/batch 21.63 | loss  4.11 | ppl    60.89
| train-epoch  18 |  2200/ 2983 batches | lr 5.00 | ms/batch 21.64 | loss  3.98 | ppl    53.55
| train-epoch  18 |  2400/ 2983 batches | lr 5.00 | ms/batch 21.64 | loss  4.02 | ppl    55.42
| train-epoch  18 |  2600/ 2983 batches | lr 5.00 | ms/batch 21.65 | loss  4.04 | ppl    56.65
| train-epoch  18 |  2800/ 2983 batches | lr 5.00 | ms/batch 21.63 | loss  4.00 | ppl    54.64
-----------------------------------------------------------------------------------------
| end of train epoch  18 | time: 67.29s | valid loss  4.58 | valid ppl    97.77
-----------------------------------------------------------------------------------------
| train-epoch  19 |   200/ 2983 batches | lr 5.00 | ms/batch 21.64 | loss  4.11 | ppl    61.17
| train-epoch  19 |   400/ 2983 batches | lr 5.00 | ms/batch 21.53 | loss  4.14 | ppl    62.55
| train-epoch  19 |   600/ 2983 batches | lr 5.00 | ms/batch 21.52 | loss  3.96 | ppl    52.54
| train-epoch  19 |   800/ 2983 batches | lr 5.00 | ms/batch 21.53 | loss  4.01 | ppl    55.34
| train-epoch  19 |  1000/ 2983 batches | lr 5.00 | ms/batch 21.53 | loss  4.04 | ppl    57.00
| train-epoch  19 |  1200/ 2983 batches | lr 5.00 | ms/batch 21.53 | loss  4.05 | ppl    57.55
| train-epoch  19 |  1400/ 2983 batches | lr 5.00 | ms/batch 21.54 | loss  4.08 | ppl    59.29
| train-epoch  19 |  1600/ 2983 batches | lr 5.00 | ms/batch 21.53 | loss  4.14 | ppl    62.98
| train-epoch  19 |  1800/ 2983 batches | lr 5.00 | ms/batch 21.53 | loss  4.05 | ppl    57.44
| train-epoch  19 |  2000/ 2983 batches | lr 5.00 | ms/batch 21.52 | loss  4.08 | ppl    59.26
| train-epoch  19 |  2200/ 2983 batches | lr 5.00 | ms/batch 21.53 | loss  3.96 | ppl    52.28
| train-epoch  19 |  2400/ 2983 batches | lr 5.00 | ms/batch 21.52 | loss  3.99 | ppl    54.28
| train-epoch  19 |  2600/ 2983 batches | lr 5.00 | ms/batch 21.53 | loss  4.02 | ppl    55.43
| train-epoch  19 |  2800/ 2983 batches | lr 5.00 | ms/batch 21.53 | loss  3.98 | ppl    53.33
-----------------------------------------------------------------------------------------
| end of train epoch  19 | time: 67.02s | valid loss  4.58 | valid ppl    97.44
-----------------------------------------------------------------------------------------
| train-epoch  20 |   200/ 2983 batches | lr 5.00 | ms/batch 21.82 | loss  4.09 | ppl    59.57
| train-epoch  20 |   400/ 2983 batches | lr 5.00 | ms/batch 21.71 | loss  4.11 | ppl    61.14
| train-epoch  20 |   600/ 2983 batches | lr 5.00 | ms/batch 21.72 | loss  3.93 | ppl    50.87
| train-epoch  20 |   800/ 2983 batches | lr 5.00 | ms/batch 21.72 | loss  3.98 | ppl    53.47
| train-epoch  20 |  1000/ 2983 batches | lr 5.00 | ms/batch 21.71 | loss  4.01 | ppl    55.33
| train-epoch  20 |  1200/ 2983 batches | lr 5.00 | ms/batch 21.72 | loss  4.02 | ppl    55.90
| train-epoch  20 |  1400/ 2983 batches | lr 5.00 | ms/batch 21.71 | loss  4.06 | ppl    57.90
| train-epoch  20 |  1600/ 2983 batches | lr 5.00 | ms/batch 21.72 | loss  4.12 | ppl    61.76
| train-epoch  20 |  1800/ 2983 batches | lr 5.00 | ms/batch 21.71 | loss  4.03 | ppl    56.02
| train-epoch  20 |  2000/ 2983 batches | lr 5.00 | ms/batch 21.72 | loss  4.06 | ppl    57.96
| train-epoch  20 |  2200/ 2983 batches | lr 5.00 | ms/batch 21.70 | loss  3.93 | ppl    51.12
| train-epoch  20 |  2400/ 2983 batches | lr 5.00 | ms/batch 21.71 | loss  3.97 | ppl    52.91
| train-epoch  20 |  2600/ 2983 batches | lr 5.00 | ms/batch 21.71 | loss  4.00 | ppl    54.52
| train-epoch  20 |  2800/ 2983 batches | lr 5.00 | ms/batch 21.70 | loss  3.96 | ppl    52.23
-----------------------------------------------------------------------------------------
| end of train epoch  20 | time: 67.56s | valid loss  4.57 | valid ppl    96.99
-----------------------------------------------------------------------------------------
| train-epoch  21 |   200/ 2983 batches | lr 5.00 | ms/batch 21.69 | loss  4.06 | ppl    57.75
| train-epoch  21 |   400/ 2983 batches | lr 5.00 | ms/batch 21.58 | loss  4.09 | ppl    59.68
| train-epoch  21 |   600/ 2983 batches | lr 5.00 | ms/batch 21.58 | loss  3.91 | ppl    49.76
| train-epoch  21 |   800/ 2983 batches | lr 5.00 | ms/batch 21.60 | loss  3.96 | ppl    52.46
| train-epoch  21 |  1000/ 2983 batches | lr 5.00 | ms/batch 21.57 | loss  4.00 | ppl    54.44
| train-epoch  21 |  1200/ 2983 batches | lr 5.00 | ms/batch 21.56 | loss  4.01 | ppl    54.88
| train-epoch  21 |  1400/ 2983 batches | lr 5.00 | ms/batch 21.57 | loss  4.04 | ppl    56.59
| train-epoch  21 |  1600/ 2983 batches | lr 5.00 | ms/batch 21.57 | loss  4.10 | ppl    60.30
| train-epoch  21 |  1800/ 2983 batches | lr 5.00 | ms/batch 21.56 | loss  4.01 | ppl    54.91
| train-epoch  21 |  2000/ 2983 batches | lr 5.00 | ms/batch 21.56 | loss  4.04 | ppl    56.65
| train-epoch  21 |  2200/ 2983 batches | lr 5.00 | ms/batch 21.55 | loss  3.91 | ppl    50.06
| train-epoch  21 |  2400/ 2983 batches | lr 5.00 | ms/batch 21.57 | loss  3.95 | ppl    52.16
| train-epoch  21 |  2600/ 2983 batches | lr 5.00 | ms/batch 21.56 | loss  3.97 | ppl    53.15
| train-epoch  21 |  2800/ 2983 batches | lr 5.00 | ms/batch 21.59 | loss  3.94 | ppl    51.48
-----------------------------------------------------------------------------------------
| end of train epoch  21 | time: 67.14s | valid loss  4.57 | valid ppl    96.84
-----------------------------------------------------------------------------------------
| train-epoch  22 |   200/ 2983 batches | lr 5.00 | ms/batch 21.74 | loss  4.03 | ppl    56.44
| train-epoch  22 |   400/ 2983 batches | lr 5.00 | ms/batch 21.62 | loss  4.06 | ppl    58.16
| train-epoch  22 |   600/ 2983 batches | lr 5.00 | ms/batch 21.63 | loss  3.89 | ppl    48.90
| train-epoch  22 |   800/ 2983 batches | lr 5.00 | ms/batch 21.63 | loss  3.94 | ppl    51.34
| train-epoch  22 |  1000/ 2983 batches | lr 5.00 | ms/batch 21.65 | loss  3.98 | ppl    53.32
| train-epoch  22 |  1200/ 2983 batches | lr 5.00 | ms/batch 21.64 | loss  3.98 | ppl    53.67
| train-epoch  22 |  1400/ 2983 batches | lr 5.00 | ms/batch 21.67 | loss  4.01 | ppl    55.04
| train-epoch  22 |  1600/ 2983 batches | lr 5.00 | ms/batch 21.63 | loss  4.08 | ppl    58.95
| train-epoch  22 |  1800/ 2983 batches | lr 5.00 | ms/batch 21.64 | loss  3.99 | ppl    54.04
| train-epoch  22 |  2000/ 2983 batches | lr 5.00 | ms/batch 21.63 | loss  4.02 | ppl    55.79
| train-epoch  22 |  2200/ 2983 batches | lr 5.00 | ms/batch 21.65 | loss  3.90 | ppl    49.28
| train-epoch  22 |  2400/ 2983 batches | lr 5.00 | ms/batch 21.64 | loss  3.94 | ppl    51.36
| train-epoch  22 |  2600/ 2983 batches | lr 5.00 | ms/batch 21.64 | loss  3.96 | ppl    52.53
| train-epoch  22 |  2800/ 2983 batches | lr 5.00 | ms/batch 21.66 | loss  3.93 | ppl    50.77
-----------------------------------------------------------------------------------------
| end of train epoch  22 | time: 67.34s | valid loss  4.57 | valid ppl    96.57
-----------------------------------------------------------------------------------------
| train-epoch  23 |   200/ 2983 batches | lr 5.00 | ms/batch 21.78 | loss  4.01 | ppl    55.24
| train-epoch  23 |   400/ 2983 batches | lr 5.00 | ms/batch 21.67 | loss  4.04 | ppl    57.05
| train-epoch  23 |   600/ 2983 batches | lr 5.00 | ms/batch 21.68 | loss  3.87 | ppl    48.08
| train-epoch  23 |   800/ 2983 batches | lr 5.00 | ms/batch 21.68 | loss  3.92 | ppl    50.51
| train-epoch  23 |  1000/ 2983 batches | lr 5.00 | ms/batch 21.68 | loss  3.96 | ppl    52.52
| train-epoch  23 |  1200/ 2983 batches | lr 5.00 | ms/batch 21.67 | loss  3.97 | ppl    52.95
| train-epoch  23 |  1400/ 2983 batches | lr 5.00 | ms/batch 21.62 | loss  4.00 | ppl    54.53
| train-epoch  23 |  1600/ 2983 batches | lr 5.00 | ms/batch 21.62 | loss  4.06 | ppl    58.10
| train-epoch  23 |  1800/ 2983 batches | lr 5.00 | ms/batch 21.62 | loss  3.97 | ppl    53.07
| train-epoch  23 |  2000/ 2983 batches | lr 5.00 | ms/batch 21.63 | loss  4.01 | ppl    54.89
| train-epoch  23 |  2200/ 2983 batches | lr 5.00 | ms/batch 21.63 | loss  3.88 | ppl    48.43
| train-epoch  23 |  2400/ 2983 batches | lr 5.00 | ms/batch 21.63 | loss  3.92 | ppl    50.27
| train-epoch  23 |  2600/ 2983 batches | lr 5.00 | ms/batch 21.63 | loss  3.95 | ppl    51.78
| train-epoch  23 |  2800/ 2983 batches | lr 5.00 | ms/batch 21.62 | loss  3.91 | ppl    49.98
-----------------------------------------------------------------------------------------
| end of train epoch  23 | time: 67.36s | valid loss  4.57 | valid ppl    96.38
-----------------------------------------------------------------------------------------
| train-epoch  24 |   200/ 2983 batches | lr 5.00 | ms/batch 21.69 | loss  4.00 | ppl    54.43
| train-epoch  24 |   400/ 2983 batches | lr 5.00 | ms/batch 21.58 | loss  4.03 | ppl    56.04
| train-epoch  24 |   600/ 2983 batches | lr 5.00 | ms/batch 21.62 | loss  3.85 | ppl    46.83
| train-epoch  24 |   800/ 2983 batches | lr 5.00 | ms/batch 21.63 | loss  3.90 | ppl    49.44
| train-epoch  24 |  1000/ 2983 batches | lr 5.00 | ms/batch 21.65 | loss  3.94 | ppl    51.61
| train-epoch  24 |  1200/ 2983 batches | lr 5.00 | ms/batch 21.64 | loss  3.95 | ppl    52.17
| train-epoch  24 |  1400/ 2983 batches | lr 5.00 | ms/batch 21.66 | loss  3.98 | ppl    53.71
| train-epoch  24 |  1600/ 2983 batches | lr 5.00 | ms/batch 21.62 | loss  4.04 | ppl    57.07
| train-epoch  24 |  1800/ 2983 batches | lr 5.00 | ms/batch 21.64 | loss  3.96 | ppl    52.22
| train-epoch  24 |  2000/ 2983 batches | lr 5.00 | ms/batch 21.63 | loss  3.99 | ppl    54.10
| train-epoch  24 |  2200/ 2983 batches | lr 5.00 | ms/batch 21.63 | loss  3.86 | ppl    47.53
| train-epoch  24 |  2400/ 2983 batches | lr 5.00 | ms/batch 21.63 | loss  3.90 | ppl    49.47
| train-epoch  24 |  2600/ 2983 batches | lr 5.00 | ms/batch 21.63 | loss  3.92 | ppl    50.60
| train-epoch  24 |  2800/ 2983 batches | lr 5.00 | ms/batch 21.64 | loss  3.90 | ppl    49.42
-----------------------------------------------------------------------------------------
| end of train epoch  24 | time: 67.31s | valid loss  4.57 | valid ppl    96.29
-----------------------------------------------------------------------------------------
| train-epoch  25 |   200/ 2983 batches | lr 5.00 | ms/batch 21.76 | loss  3.98 | ppl    53.53
| train-epoch  25 |   400/ 2983 batches | lr 5.00 | ms/batch 21.65 | loss  4.01 | ppl    55.33
| train-epoch  25 |   600/ 2983 batches | lr 5.00 | ms/batch 21.66 | loss  3.84 | ppl    46.42
| train-epoch  25 |   800/ 2983 batches | lr 5.00 | ms/batch 21.66 | loss  3.88 | ppl    48.61
| train-epoch  25 |  1000/ 2983 batches | lr 5.00 | ms/batch 21.66 | loss  3.93 | ppl    50.78
| train-epoch  25 |  1200/ 2983 batches | lr 5.00 | ms/batch 21.65 | loss  3.94 | ppl    51.42
| train-epoch  25 |  1400/ 2983 batches | lr 5.00 | ms/batch 21.66 | loss  3.96 | ppl    52.41
| train-epoch  25 |  1600/ 2983 batches | lr 5.00 | ms/batch 21.67 | loss  4.03 | ppl    56.16
| train-epoch  25 |  1800/ 2983 batches | lr 5.00 | ms/batch 21.65 | loss  3.94 | ppl    51.45
| train-epoch  25 |  2000/ 2983 batches | lr 5.00 | ms/batch 21.66 | loss  3.98 | ppl    53.37
| train-epoch  25 |  2200/ 2983 batches | lr 5.00 | ms/batch 21.65 | loss  3.85 | ppl    46.81
| train-epoch  25 |  2400/ 2983 batches | lr 5.00 | ms/batch 21.66 | loss  3.89 | ppl    48.92
| train-epoch  25 |  2600/ 2983 batches | lr 5.00 | ms/batch 21.65 | loss  3.92 | ppl    50.34
| train-epoch  25 |  2800/ 2983 batches | lr 5.00 | ms/batch 21.66 | loss  3.88 | ppl    48.60
-----------------------------------------------------------------------------------------
| end of train epoch  25 | time: 67.40s | valid loss  4.57 | valid ppl    96.48
-----------------------------------------------------------------------------------------
| train-epoch  26 |   200/ 2983 batches | lr 1.25 | ms/batch 21.85 | loss  3.99 | ppl    54.15
| train-epoch  26 |   400/ 2983 batches | lr 1.25 | ms/batch 21.75 | loss  4.03 | ppl    56.03
| train-epoch  26 |   600/ 2983 batches | lr 1.25 | ms/batch 21.74 | loss  3.85 | ppl    46.91
| train-epoch  26 |   800/ 2983 batches | lr 1.25 | ms/batch 21.75 | loss  3.88 | ppl    48.51
| train-epoch  26 |  1000/ 2983 batches | lr 1.25 | ms/batch 21.74 | loss  3.93 | ppl    50.81
| train-epoch  26 |  1200/ 2983 batches | lr 1.25 | ms/batch 21.73 | loss  3.94 | ppl    51.44
| train-epoch  26 |  1400/ 2983 batches | lr 1.25 | ms/batch 21.74 | loss  3.95 | ppl    51.97
| train-epoch  26 |  1600/ 2983 batches | lr 1.25 | ms/batch 21.74 | loss  4.01 | ppl    55.04
| train-epoch  26 |  1800/ 2983 batches | lr 1.25 | ms/batch 21.73 | loss  3.92 | ppl    50.40
| train-epoch  26 |  2000/ 2983 batches | lr 1.25 | ms/batch 21.74 | loss  3.96 | ppl    52.69
| train-epoch  26 |  2200/ 2983 batches | lr 1.25 | ms/batch 21.74 | loss  3.82 | ppl    45.62
| train-epoch  26 |  2400/ 2983 batches | lr 1.25 | ms/batch 21.74 | loss  3.85 | ppl    46.94
| train-epoch  26 |  2600/ 2983 batches | lr 1.25 | ms/batch 21.74 | loss  3.87 | ppl    48.17
| train-epoch  26 |  2800/ 2983 batches | lr 1.25 | ms/batch 21.73 | loss  3.84 | ppl    46.42
-----------------------------------------------------------------------------------------
| end of train epoch  26 | time: 67.64s | valid loss  4.55 | valid ppl    94.18
-----------------------------------------------------------------------------------------
| train-epoch  27 |   200/ 2983 batches | lr 1.25 | ms/batch 21.72 | loss  3.97 | ppl    53.21
| train-epoch  27 |   400/ 2983 batches | lr 1.25 | ms/batch 21.61 | loss  3.99 | ppl    54.23
| train-epoch  27 |   600/ 2983 batches | lr 1.25 | ms/batch 21.61 | loss  3.82 | ppl    45.41
| train-epoch  27 |   800/ 2983 batches | lr 1.25 | ms/batch 21.61 | loss  3.85 | ppl    47.20
| train-epoch  27 |  1000/ 2983 batches | lr 1.25 | ms/batch 21.61 | loss  3.90 | ppl    49.59
| train-epoch  27 |  1200/ 2983 batches | lr 1.25 | ms/batch 21.62 | loss  3.92 | ppl    50.42
| train-epoch  27 |  1400/ 2983 batches | lr 1.25 | ms/batch 21.60 | loss  3.93 | ppl    51.06
| train-epoch  27 |  1600/ 2983 batches | lr 1.25 | ms/batch 21.62 | loss  3.99 | ppl    53.84
| train-epoch  27 |  1800/ 2983 batches | lr 1.25 | ms/batch 21.60 | loss  3.90 | ppl    49.60
| train-epoch  27 |  2000/ 2983 batches | lr 1.25 | ms/batch 21.60 | loss  3.95 | ppl    51.77
| train-epoch  27 |  2200/ 2983 batches | lr 1.25 | ms/batch 21.62 | loss  3.81 | ppl    45.00
| train-epoch  27 |  2400/ 2983 batches | lr 1.25 | ms/batch 21.61 | loss  3.83 | ppl    46.19
| train-epoch  27 |  2600/ 2983 batches | lr 1.25 | ms/batch 21.61 | loss  3.87 | ppl    47.94
| train-epoch  27 |  2800/ 2983 batches | lr 1.25 | ms/batch 21.61 | loss  3.84 | ppl    46.32
-----------------------------------------------------------------------------------------
| end of train epoch  27 | time: 67.25s | valid loss  4.54 | valid ppl    93.84
-----------------------------------------------------------------------------------------
| train-epoch  28 |   200/ 2983 batches | lr 1.25 | ms/batch 21.68 | loss  3.96 | ppl    52.46
| train-epoch  28 |   400/ 2983 batches | lr 1.25 | ms/batch 21.58 | loss  3.98 | ppl    53.44
| train-epoch  28 |   600/ 2983 batches | lr 1.25 | ms/batch 21.58 | loss  3.80 | ppl    44.84
| train-epoch  28 |   800/ 2983 batches | lr 1.25 | ms/batch 21.57 | loss  3.84 | ppl    46.54
| train-epoch  28 |  1000/ 2983 batches | lr 1.25 | ms/batch 21.57 | loss  3.89 | ppl    48.84
| train-epoch  28 |  1200/ 2983 batches | lr 1.25 | ms/batch 21.57 | loss  3.91 | ppl    49.87
| train-epoch  28 |  1400/ 2983 batches | lr 1.25 | ms/batch 21.56 | loss  3.92 | ppl    50.34
| train-epoch  28 |  1600/ 2983 batches | lr 1.25 | ms/batch 21.58 | loss  3.98 | ppl    53.62
| train-epoch  28 |  1800/ 2983 batches | lr 1.25 | ms/batch 21.58 | loss  3.90 | ppl    49.24
| train-epoch  28 |  2000/ 2983 batches | lr 1.25 | ms/batch 21.58 | loss  3.94 | ppl    51.62
| train-epoch  28 |  2200/ 2983 batches | lr 1.25 | ms/batch 21.58 | loss  3.81 | ppl    44.99
| train-epoch  28 |  2400/ 2983 batches | lr 1.25 | ms/batch 21.57 | loss  3.83 | ppl    46.14
| train-epoch  28 |  2600/ 2983 batches | lr 1.25 | ms/batch 21.57 | loss  3.87 | ppl    47.80
| train-epoch  28 |  2800/ 2983 batches | lr 1.25 | ms/batch 21.57 | loss  3.83 | ppl    46.09
-----------------------------------------------------------------------------------------
| end of train epoch  28 | time: 67.15s | valid loss  4.54 | valid ppl    93.83
-----------------------------------------------------------------------------------------
| train-epoch  29 |   200/ 2983 batches | lr 1.25 | ms/batch 21.85 | loss  3.95 | ppl    51.78
| train-epoch  29 |   400/ 2983 batches | lr 1.25 | ms/batch 21.75 | loss  3.97 | ppl    52.80
| train-epoch  29 |   600/ 2983 batches | lr 1.25 | ms/batch 21.73 | loss  3.79 | ppl    44.32
| train-epoch  29 |   800/ 2983 batches | lr 1.25 | ms/batch 21.75 | loss  3.83 | ppl    46.18
| train-epoch  29 |  1000/ 2983 batches | lr 1.25 | ms/batch 21.75 | loss  3.88 | ppl    48.36
| train-epoch  29 |  1200/ 2983 batches | lr 1.25 | ms/batch 21.74 | loss  3.90 | ppl    49.45
| train-epoch  29 |  1400/ 2983 batches | lr 1.25 | ms/batch 21.74 | loss  3.91 | ppl    49.97
| train-epoch  29 |  1600/ 2983 batches | lr 1.25 | ms/batch 21.75 | loss  3.98 | ppl    53.37
| train-epoch  29 |  1800/ 2983 batches | lr 1.25 | ms/batch 21.74 | loss  3.89 | ppl    48.93
| train-epoch  29 |  2000/ 2983 batches | lr 1.25 | ms/batch 21.73 | loss  3.93 | ppl    51.13
| train-epoch  29 |  2200/ 2983 batches | lr 1.25 | ms/batch 21.74 | loss  3.80 | ppl    44.56
| train-epoch  29 |  2400/ 2983 batches | lr 1.25 | ms/batch 21.74 | loss  3.82 | ppl    45.75
| train-epoch  29 |  2600/ 2983 batches | lr 1.25 | ms/batch 21.74 | loss  3.86 | ppl    47.26
| train-epoch  29 |  2800/ 2983 batches | lr 1.25 | ms/batch 21.75 | loss  3.82 | ppl    45.83
-----------------------------------------------------------------------------------------
| end of train epoch  29 | time: 67.65s | valid loss  4.54 | valid ppl    93.73
-----------------------------------------------------------------------------------------
| train-epoch  30 |   200/ 2983 batches | lr 1.25 | ms/batch 21.73 | loss  3.94 | ppl    51.41
| train-epoch  30 |   400/ 2983 batches | lr 1.25 | ms/batch 21.62 | loss  3.96 | ppl    52.31
| train-epoch  30 |   600/ 2983 batches | lr 1.25 | ms/batch 21.61 | loss  3.79 | ppl    44.26
| train-epoch  30 |   800/ 2983 batches | lr 1.25 | ms/batch 21.62 | loss  3.82 | ppl    45.82
| train-epoch  30 |  1000/ 2983 batches | lr 1.25 | ms/batch 21.62 | loss  3.87 | ppl    47.73
| train-epoch  30 |  1200/ 2983 batches | lr 1.25 | ms/batch 21.62 | loss  3.89 | ppl    49.04
| train-epoch  30 |  1400/ 2983 batches | lr 1.25 | ms/batch 21.63 | loss  3.91 | ppl    49.82
| train-epoch  30 |  1600/ 2983 batches | lr 1.25 | ms/batch 21.63 | loss  3.97 | ppl    52.96
| train-epoch  30 |  1800/ 2983 batches | lr 1.25 | ms/batch 21.64 | loss  3.88 | ppl    48.39
| train-epoch  30 |  2000/ 2983 batches | lr 1.25 | ms/batch 21.62 | loss  3.93 | ppl    50.70
| train-epoch  30 |  2200/ 2983 batches | lr 1.25 | ms/batch 21.63 | loss  3.79 | ppl    44.29
| train-epoch  30 |  2400/ 2983 batches | lr 1.25 | ms/batch 21.62 | loss  3.81 | ppl    45.31
| train-epoch  30 |  2600/ 2983 batches | lr 1.25 | ms/batch 21.62 | loss  3.85 | ppl    46.86
| train-epoch  30 |  2800/ 2983 batches | lr 1.25 | ms/batch 21.62 | loss  3.82 | ppl    45.50
-----------------------------------------------------------------------------------------
| end of train epoch  30 | time: 67.29s | valid loss  4.54 | valid ppl    93.70
-----------------------------------------------------------------------------------------
| train-epoch  31 |   200/ 2983 batches | lr 1.25 | ms/batch 21.75 | loss  3.93 | ppl    51.12
| train-epoch  31 |   400/ 2983 batches | lr 1.25 | ms/batch 21.64 | loss  3.95 | ppl    51.93
| train-epoch  31 |   600/ 2983 batches | lr 1.25 | ms/batch 21.65 | loss  3.77 | ppl    43.55
| train-epoch  31 |   800/ 2983 batches | lr 1.25 | ms/batch 21.64 | loss  3.82 | ppl    45.51
| train-epoch  31 |  1000/ 2983 batches | lr 1.25 | ms/batch 21.65 | loss  3.86 | ppl    47.38
| train-epoch  31 |  1200/ 2983 batches | lr 1.25 | ms/batch 21.65 | loss  3.89 | ppl    48.68
| train-epoch  31 |  1400/ 2983 batches | lr 1.25 | ms/batch 21.64 | loss  3.90 | ppl    49.39
| train-epoch  31 |  1600/ 2983 batches | lr 1.25 | ms/batch 21.64 | loss  3.96 | ppl    52.43
| train-epoch  31 |  1800/ 2983 batches | lr 1.25 | ms/batch 21.64 | loss  3.88 | ppl    48.23
| train-epoch  31 |  2000/ 2983 batches | lr 1.25 | ms/batch 21.63 | loss  3.92 | ppl    50.31
| train-epoch  31 |  2200/ 2983 batches | lr 1.25 | ms/batch 21.63 | loss  3.79 | ppl    44.05
| train-epoch  31 |  2400/ 2983 batches | lr 1.25 | ms/batch 21.64 | loss  3.82 | ppl    45.42
| train-epoch  31 |  2600/ 2983 batches | lr 1.25 | ms/batch 21.65 | loss  3.85 | ppl    46.93
| train-epoch  31 |  2800/ 2983 batches | lr 1.25 | ms/batch 21.64 | loss  3.81 | ppl    45.37
-----------------------------------------------------------------------------------------
| end of train epoch  31 | time: 67.35s | valid loss  4.54 | valid ppl    93.83
-----------------------------------------------------------------------------------------
| train-epoch  32 |   200/ 2983 batches | lr 0.31 | ms/batch 21.88 | loss  3.95 | ppl    51.91
| train-epoch  32 |   400/ 2983 batches | lr 0.31 | ms/batch 21.78 | loss  3.98 | ppl    53.47
| train-epoch  32 |   600/ 2983 batches | lr 0.31 | ms/batch 21.77 | loss  3.81 | ppl    45.17
| train-epoch  32 |   800/ 2983 batches | lr 0.31 | ms/batch 21.77 | loss  3.86 | ppl    47.23
| train-epoch  32 |  1000/ 2983 batches | lr 0.31 | ms/batch 21.76 | loss  3.87 | ppl    48.15
| train-epoch  32 |  1200/ 2983 batches | lr 0.31 | ms/batch 21.77 | loss  3.90 | ppl    49.40
| train-epoch  32 |  1400/ 2983 batches | lr 0.31 | ms/batch 21.76 | loss  3.94 | ppl    51.42
| train-epoch  32 |  1600/ 2983 batches | lr 0.31 | ms/batch 21.76 | loss  3.99 | ppl    54.07
| train-epoch  32 |  1800/ 2983 batches | lr 0.31 | ms/batch 21.74 | loss  3.88 | ppl    48.47
| train-epoch  32 |  2000/ 2983 batches | lr 0.31 | ms/batch 21.75 | loss  3.92 | ppl    50.20
| train-epoch  32 |  2200/ 2983 batches | lr 0.31 | ms/batch 21.76 | loss  3.80 | ppl    44.60
| train-epoch  32 |  2400/ 2983 batches | lr 0.31 | ms/batch 21.75 | loss  3.85 | ppl    46.78
| train-epoch  32 |  2600/ 2983 batches | lr 0.31 | ms/batch 21.74 | loss  3.87 | ppl    48.07
| train-epoch  32 |  2800/ 2983 batches | lr 0.31 | ms/batch 21.75 | loss  3.81 | ppl    45.12
-----------------------------------------------------------------------------------------
| end of train epoch  32 | time: 67.70s | valid loss  4.53 | valid ppl    92.90
-----------------------------------------------------------------------------------------
| train-epoch  33 |   200/ 2983 batches | lr 0.31 | ms/batch 21.69 | loss  3.96 | ppl    52.49
| train-epoch  33 |   400/ 2983 batches | lr 0.31 | ms/batch 21.59 | loss  3.98 | ppl    53.70
| train-epoch  33 |   600/ 2983 batches | lr 0.31 | ms/batch 21.58 | loss  3.80 | ppl    44.63
| train-epoch  33 |   800/ 2983 batches | lr 0.31 | ms/batch 21.59 | loss  3.84 | ppl    46.55
| train-epoch  33 |  1000/ 2983 batches | lr 0.31 | ms/batch 21.59 | loss  3.87 | ppl    47.76
| train-epoch  33 |  1200/ 2983 batches | lr 0.31 | ms/batch 21.59 | loss  3.90 | ppl    49.37
| train-epoch  33 |  1400/ 2983 batches | lr 0.31 | ms/batch 21.59 | loss  3.93 | ppl    50.89
| train-epoch  33 |  1600/ 2983 batches | lr 0.31 | ms/batch 21.60 | loss  3.99 | ppl    54.00
| train-epoch  33 |  1800/ 2983 batches | lr 0.31 | ms/batch 21.59 | loss  3.88 | ppl    48.24
| train-epoch  33 |  2000/ 2983 batches | lr 0.31 | ms/batch 21.59 | loss  3.91 | ppl    49.99
| train-epoch  33 |  2200/ 2983 batches | lr 0.31 | ms/batch 21.58 | loss  3.79 | ppl    44.29
| train-epoch  33 |  2400/ 2983 batches | lr 0.31 | ms/batch 21.58 | loss  3.84 | ppl    46.39
| train-epoch  33 |  2600/ 2983 batches | lr 0.31 | ms/batch 21.59 | loss  3.87 | ppl    48.08
| train-epoch  33 |  2800/ 2983 batches | lr 0.31 | ms/batch 21.58 | loss  3.81 | ppl    45.34
-----------------------------------------------------------------------------------------
| end of train epoch  33 | time: 67.19s | valid loss  4.53 | valid ppl    92.72
-----------------------------------------------------------------------------------------
| train-epoch  34 |   200/ 2983 batches | lr 0.31 | ms/batch 21.86 | loss  3.95 | ppl    52.06
| train-epoch  34 |   400/ 2983 batches | lr 0.31 | ms/batch 21.75 | loss  3.97 | ppl    52.94
| train-epoch  34 |   600/ 2983 batches | lr 0.31 | ms/batch 21.73 | loss  3.80 | ppl    44.54
| train-epoch  34 |   800/ 2983 batches | lr 0.31 | ms/batch 21.73 | loss  3.84 | ppl    46.40
| train-epoch  34 |  1000/ 2983 batches | lr 0.31 | ms/batch 21.76 | loss  3.86 | ppl    47.62
| train-epoch  34 |  1200/ 2983 batches | lr 0.31 | ms/batch 21.74 | loss  3.89 | ppl    48.74
| train-epoch  34 |  1400/ 2983 batches | lr 0.31 | ms/batch 21.74 | loss  3.93 | ppl    50.70
| train-epoch  34 |  1600/ 2983 batches | lr 0.31 | ms/batch 21.75 | loss  3.98 | ppl    53.47
| train-epoch  34 |  1800/ 2983 batches | lr 0.31 | ms/batch 21.74 | loss  3.87 | ppl    47.99
| train-epoch  34 |  2000/ 2983 batches | lr 0.31 | ms/batch 21.75 | loss  3.91 | ppl    49.93
| train-epoch  34 |  2200/ 2983 batches | lr 0.31 | ms/batch 21.73 | loss  3.79 | ppl    44.29
| train-epoch  34 |  2400/ 2983 batches | lr 0.31 | ms/batch 21.74 | loss  3.83 | ppl    46.18
| train-epoch  34 |  2600/ 2983 batches | lr 0.31 | ms/batch 21.77 | loss  3.87 | ppl    47.96
| train-epoch  34 |  2800/ 2983 batches | lr 0.31 | ms/batch 21.74 | loss  3.81 | ppl    45.05
-----------------------------------------------------------------------------------------
| end of train epoch  34 | time: 67.67s | valid loss  4.53 | valid ppl    92.71
-----------------------------------------------------------------------------------------
| train-epoch  35 |   200/ 2983 batches | lr 0.31 | ms/batch 21.91 | loss  3.95 | ppl    52.03
| train-epoch  35 |   400/ 2983 batches | lr 0.31 | ms/batch 21.79 | loss  3.97 | ppl    53.02
| train-epoch  35 |   600/ 2983 batches | lr 0.31 | ms/batch 21.78 | loss  3.79 | ppl    44.34
| train-epoch  35 |   800/ 2983 batches | lr 0.31 | ms/batch 21.79 | loss  3.83 | ppl    46.08
| train-epoch  35 |  1000/ 2983 batches | lr 0.31 | ms/batch 21.80 | loss  3.86 | ppl    47.35
| train-epoch  35 |  1200/ 2983 batches | lr 0.31 | ms/batch 21.80 | loss  3.88 | ppl    48.57
| train-epoch  35 |  1400/ 2983 batches | lr 0.31 | ms/batch 21.81 | loss  3.93 | ppl    50.72
| train-epoch  35 |  1600/ 2983 batches | lr 0.31 | ms/batch 21.81 | loss  3.99 | ppl    54.10
| train-epoch  35 |  1800/ 2983 batches | lr 0.31 | ms/batch 21.82 | loss  3.87 | ppl    47.94
| train-epoch  35 |  2000/ 2983 batches | lr 0.31 | ms/batch 21.81 | loss  3.91 | ppl    49.75
| train-epoch  35 |  2200/ 2983 batches | lr 0.31 | ms/batch 21.83 | loss  3.79 | ppl    44.26
| train-epoch  35 |  2400/ 2983 batches | lr 0.31 | ms/batch 21.81 | loss  3.84 | ppl    46.31
| train-epoch  35 |  2600/ 2983 batches | lr 0.31 | ms/batch 21.80 | loss  3.86 | ppl    47.59
| train-epoch  35 |  2800/ 2983 batches | lr 0.31 | ms/batch 21.78 | loss  3.81 | ppl    45.30
-----------------------------------------------------------------------------------------
| end of train epoch  35 | time: 67.83s | valid loss  4.53 | valid ppl    92.59
-----------------------------------------------------------------------------------------
| train-epoch  36 |   200/ 2983 batches | lr 0.31 | ms/batch 21.87 | loss  3.95 | ppl    51.69
| train-epoch  36 |   400/ 2983 batches | lr 0.31 | ms/batch 21.77 | loss  3.96 | ppl    52.67
| train-epoch  36 |   600/ 2983 batches | lr 0.31 | ms/batch 21.75 | loss  3.79 | ppl    44.06
| train-epoch  36 |   800/ 2983 batches | lr 0.31 | ms/batch 21.77 | loss  3.82 | ppl    45.77
| train-epoch  36 |  1000/ 2983 batches | lr 0.31 | ms/batch 21.76 | loss  3.86 | ppl    47.32
| train-epoch  36 |  1200/ 2983 batches | lr 0.31 | ms/batch 21.76 | loss  3.88 | ppl    48.49
| train-epoch  36 |  1400/ 2983 batches | lr 0.31 | ms/batch 21.76 | loss  3.92 | ppl    50.23
| train-epoch  36 |  1600/ 2983 batches | lr 0.31 | ms/batch 21.77 | loss  3.98 | ppl    53.73
| train-epoch  36 |  1800/ 2983 batches | lr 0.31 | ms/batch 21.77 | loss  3.87 | ppl    47.90
| train-epoch  36 |  2000/ 2983 batches | lr 0.31 | ms/batch 21.76 | loss  3.91 | ppl    49.81
| train-epoch  36 |  2200/ 2983 batches | lr 0.31 | ms/batch 21.77 | loss  3.78 | ppl    43.81
| train-epoch  36 |  2400/ 2983 batches | lr 0.31 | ms/batch 21.77 | loss  3.83 | ppl    46.15
| train-epoch  36 |  2600/ 2983 batches | lr 0.31 | ms/batch 21.76 | loss  3.86 | ppl    47.61
| train-epoch  36 |  2800/ 2983 batches | lr 0.31 | ms/batch 21.78 | loss  3.80 | ppl    44.88
-----------------------------------------------------------------------------------------
| end of train epoch  36 | time: 67.73s | valid loss  4.53 | valid ppl    92.54
-----------------------------------------------------------------------------------------
| train-epoch  37 |   200/ 2983 batches | lr 0.31 | ms/batch 21.86 | loss  3.94 | ppl    51.43
| train-epoch  37 |   400/ 2983 batches | lr 0.31 | ms/batch 21.74 | loss  3.97 | ppl    52.75
| train-epoch  37 |   600/ 2983 batches | lr 0.31 | ms/batch 21.74 | loss  3.78 | ppl    43.96
| train-epoch  37 |   800/ 2983 batches | lr 0.31 | ms/batch 21.73 | loss  3.82 | ppl    45.66
| train-epoch  37 |  1000/ 2983 batches | lr 0.31 | ms/batch 21.75 | loss  3.85 | ppl    46.98
| train-epoch  37 |  1200/ 2983 batches | lr 0.31 | ms/batch 21.74 | loss  3.88 | ppl    48.41
| train-epoch  37 |  1400/ 2983 batches | lr 0.31 | ms/batch 21.74 | loss  3.92 | ppl    50.25
| train-epoch  37 |  1600/ 2983 batches | lr 0.31 | ms/batch 21.74 | loss  3.98 | ppl    53.37
| train-epoch  37 |  1800/ 2983 batches | lr 0.31 | ms/batch 21.74 | loss  3.87 | ppl    47.92
| train-epoch  37 |  2000/ 2983 batches | lr 0.31 | ms/batch 21.72 | loss  3.90 | ppl    49.48
| train-epoch  37 |  2200/ 2983 batches | lr 0.31 | ms/batch 21.61 | loss  3.78 | ppl    43.77
| train-epoch  37 |  2400/ 2983 batches | lr 0.31 | ms/batch 21.60 | loss  3.83 | ppl    46.16
| train-epoch  37 |  2600/ 2983 batches | lr 0.31 | ms/batch 21.61 | loss  3.87 | ppl    47.75
| train-epoch  37 |  2800/ 2983 batches | lr 0.31 | ms/batch 21.60 | loss  3.81 | ppl    45.02
-----------------------------------------------------------------------------------------
| end of train epoch  37 | time: 67.51s | valid loss  4.53 | valid ppl    92.50
-----------------------------------------------------------------------------------------
| train-epoch  38 |   200/ 2983 batches | lr 0.31 | ms/batch 21.85 | loss  3.94 | ppl    51.51
| train-epoch  38 |   400/ 2983 batches | lr 0.31 | ms/batch 21.75 | loss  3.96 | ppl    52.26
| train-epoch  38 |   600/ 2983 batches | lr 0.31 | ms/batch 21.74 | loss  3.78 | ppl    43.89
| train-epoch  38 |   800/ 2983 batches | lr 0.31 | ms/batch 21.76 | loss  3.82 | ppl    45.56
| train-epoch  38 |  1000/ 2983 batches | lr 0.31 | ms/batch 21.74 | loss  3.85 | ppl    46.94
| train-epoch  38 |  1200/ 2983 batches | lr 0.31 | ms/batch 21.74 | loss  3.88 | ppl    48.25
| train-epoch  38 |  1400/ 2983 batches | lr 0.31 | ms/batch 21.74 | loss  3.91 | ppl    50.10
| train-epoch  38 |  1600/ 2983 batches | lr 0.31 | ms/batch 21.74 | loss  3.97 | ppl    53.16
| train-epoch  38 |  1800/ 2983 batches | lr 0.31 | ms/batch 21.74 | loss  3.86 | ppl    47.62
| train-epoch  38 |  2000/ 2983 batches | lr 0.31 | ms/batch 21.74 | loss  3.90 | ppl    49.49
| train-epoch  38 |  2200/ 2983 batches | lr 0.31 | ms/batch 21.74 | loss  3.78 | ppl    43.86
| train-epoch  38 |  2400/ 2983 batches | lr 0.31 | ms/batch 21.73 | loss  3.83 | ppl    45.95
| train-epoch  38 |  2600/ 2983 batches | lr 0.31 | ms/batch 21.74 | loss  3.86 | ppl    47.49
| train-epoch  38 |  2800/ 2983 batches | lr 0.31 | ms/batch 21.74 | loss  3.81 | ppl    44.96
-----------------------------------------------------------------------------------------
| end of train epoch  38 | time: 67.65s | valid loss  4.53 | valid ppl    92.55
-----------------------------------------------------------------------------------------
| train-epoch  39 |   200/ 2983 batches | lr 0.08 | ms/batch 21.77 | loss  3.95 | ppl    51.78
| train-epoch  39 |   400/ 2983 batches | lr 0.08 | ms/batch 21.66 | loss  3.99 | ppl    53.81
| train-epoch  39 |   600/ 2983 batches | lr 0.08 | ms/batch 21.66 | loss  3.81 | ppl    45.36
| train-epoch  39 |   800/ 2983 batches | lr 0.08 | ms/batch 21.65 | loss  3.88 | ppl    48.48
| train-epoch  39 |  1000/ 2983 batches | lr 0.08 | ms/batch 21.66 | loss  3.91 | ppl    49.76
| train-epoch  39 |  1200/ 2983 batches | lr 0.08 | ms/batch 21.66 | loss  3.89 | ppl    48.95
| train-epoch  39 |  1400/ 2983 batches | lr 0.08 | ms/batch 21.67 | loss  3.93 | ppl    50.88
| train-epoch  39 |  1600/ 2983 batches | lr 0.08 | ms/batch 21.66 | loss  4.01 | ppl    54.88
| train-epoch  39 |  1800/ 2983 batches | lr 0.08 | ms/batch 21.66 | loss  3.91 | ppl    49.84
| train-epoch  39 |  2000/ 2983 batches | lr 0.08 | ms/batch 21.66 | loss  3.94 | ppl    51.21
| train-epoch  39 |  2200/ 2983 batches | lr 0.08 | ms/batch 21.66 | loss  3.80 | ppl    44.73
| train-epoch  39 |  2400/ 2983 batches | lr 0.08 | ms/batch 21.65 | loss  3.83 | ppl    46.15
| train-epoch  39 |  2600/ 2983 batches | lr 0.08 | ms/batch 21.67 | loss  3.87 | ppl    47.88
| train-epoch  39 |  2800/ 2983 batches | lr 0.08 | ms/batch 21.65 | loss  3.82 | ppl    45.42
-----------------------------------------------------------------------------------------
| end of train epoch  39 | time: 67.40s | valid loss  4.52 | valid ppl    91.83
-----------------------------------------------------------------------------------------
| train-epoch  40 |   200/ 2983 batches | lr 0.08 | ms/batch 21.71 | loss  3.95 | ppl    51.84
| train-epoch  40 |   400/ 2983 batches | lr 0.08 | ms/batch 21.59 | loss  3.98 | ppl    53.41
| train-epoch  40 |   600/ 2983 batches | lr 0.08 | ms/batch 21.59 | loss  3.81 | ppl    45.01
| train-epoch  40 |   800/ 2983 batches | lr 0.08 | ms/batch 21.58 | loss  3.87 | ppl    47.80
| train-epoch  40 |  1000/ 2983 batches | lr 0.08 | ms/batch 21.59 | loss  3.89 | ppl    48.80
| train-epoch  40 |  1200/ 2983 batches | lr 0.08 | ms/batch 21.60 | loss  3.89 | ppl    48.69
| train-epoch  40 |  1400/ 2983 batches | lr 0.08 | ms/batch 21.60 | loss  3.92 | ppl    50.45
| train-epoch  40 |  1600/ 2983 batches | lr 0.08 | ms/batch 21.59 | loss  4.00 | ppl    54.59
| train-epoch  40 |  1800/ 2983 batches | lr 0.08 | ms/batch 21.59 | loss  3.90 | ppl    49.62
| train-epoch  40 |  2000/ 2983 batches | lr 0.08 | ms/batch 21.59 | loss  3.93 | ppl    50.88
| train-epoch  40 |  2200/ 2983 batches | lr 0.08 | ms/batch 21.60 | loss  3.80 | ppl    44.59
| train-epoch  40 |  2400/ 2983 batches | lr 0.08 | ms/batch 21.60 | loss  3.83 | ppl    46.15
| train-epoch  40 |  2600/ 2983 batches | lr 0.08 | ms/batch 21.58 | loss  3.88 | ppl    48.34
| train-epoch  40 |  2800/ 2983 batches | lr 0.08 | ms/batch 21.59 | loss  3.82 | ppl    45.66
-----------------------------------------------------------------------------------------
| end of train epoch  40 | time: 67.20s | valid loss  4.52 | valid ppl    91.69
-----------------------------------------------------------------------------------------
required epochs  40 | actual epochs  60
pretrain epochs  40 | prune epochs   0 | retrain epochs  20
=========================================================================================
| End of training | test loss  4.47 | test ppl    87.13
=========================================================================================
python main.py --cuda --emsize 1500 --nhid 1500 --dropout 0.65 --epochs 40 --save model/baseline/model.pt
<class 'torch.Tensor'> torch.Size([33278, 1500])
<class 'torch.Tensor'> torch.Size([6000, 1500])
<class 'torch.Tensor'> torch.Size([6000, 1500])
<class 'torch.Tensor'> torch.Size([6000])
<class 'torch.Tensor'> torch.Size([6000])
<class 'torch.Tensor'> torch.Size([6000, 1500])
<class 'torch.Tensor'> torch.Size([6000, 1500])
<class 'torch.Tensor'> torch.Size([6000])
<class 'torch.Tensor'> torch.Size([6000])
<class 'torch.Tensor'> torch.Size([33278, 1500])
<class 'torch.Tensor'> torch.Size([33278])
RNNModel(
  (drop): Dropout(p=0.65)
  (encoder): Embedding(33278, 1500)
  (rnn): LSTM(1500, 1500, num_layers=2, dropout=0.65)
  (decoder): Linear(in_features=1500, out_features=33278, bias=True)
)
Dropout(p=0.65)
Embedding(33278, 1500)
LSTM(1500, 1500, num_layers=2, dropout=0.65)
Linear(in_features=1500, out_features=33278, bias=True)
| train-epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 58.82 | loss  7.87 | ppl  2611.10
| train-epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 58.44 | loss  6.80 | ppl   893.96
| train-epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 58.50 | loss  6.44 | ppl   628.43
| train-epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 58.52 | loss  6.29 | ppl   540.87
| train-epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.55 | loss  6.18 | ppl   484.87
| train-epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.55 | loss  6.13 | ppl   458.85
| train-epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.60 | loss  6.03 | ppl   417.29
| train-epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.62 | loss  6.05 | ppl   423.83
| train-epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.62 | loss  5.91 | ppl   367.46
| train-epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.63 | loss  5.89 | ppl   362.49
| train-epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.66 | loss  5.79 | ppl   326.17
| train-epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.63 | loss  5.79 | ppl   327.80
| train-epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.57 | loss  5.78 | ppl   325.07
| train-epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.58 | loss  5.68 | ppl   291.94
-----------------------------------------------------------------------------------------
| end of train epoch   1 | time: 181.62s | valid loss  5.53 | valid ppl   251.50
-----------------------------------------------------------------------------------------
| train-epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch 58.53 | loss  5.66 | ppl   287.07
| train-epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch 58.32 | loss  5.64 | ppl   280.31
| train-epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch 58.31 | loss  5.47 | ppl   237.13
| train-epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch 58.33 | loss  5.49 | ppl   241.83
| train-epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.30 | loss  5.46 | ppl   235.64
| train-epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.29 | loss  5.45 | ppl   233.85
| train-epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.30 | loss  5.45 | ppl   231.74
| train-epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.37 | loss  5.50 | ppl   245.14
| train-epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.33 | loss  5.38 | ppl   216.35
| train-epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.32 | loss  5.40 | ppl   220.43
| train-epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.37 | loss  5.30 | ppl   200.53
| train-epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.31 | loss  5.33 | ppl   205.65
| train-epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.35 | loss  5.34 | ppl   207.57
| train-epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.37 | loss  5.26 | ppl   191.79
-----------------------------------------------------------------------------------------
| end of train epoch   2 | time: 180.89s | valid loss  5.23 | valid ppl   187.67
-----------------------------------------------------------------------------------------
| train-epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 59.35 | loss  5.30 | ppl   200.24
| train-epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch 59.03 | loss  5.30 | ppl   201.28
| train-epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 59.01 | loss  5.13 | ppl   168.19
| train-epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 59.07 | loss  5.17 | ppl   175.37
| train-epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 59.06 | loss  5.15 | ppl   173.18
| train-epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 59.04 | loss  5.15 | ppl   172.98
| train-epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.99 | loss  5.18 | ppl   177.47
| train-epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 59.04 | loss  5.24 | ppl   188.43
| train-epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 59.01 | loss  5.11 | ppl   165.84
| train-epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 59.03 | loss  5.14 | ppl   171.30
| train-epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 59.03 | loss  5.05 | ppl   155.78
| train-epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.99 | loss  5.07 | ppl   159.94
| train-epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch 59.00 | loss  5.09 | ppl   162.65
| train-epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 59.03 | loss  5.02 | ppl   151.55
-----------------------------------------------------------------------------------------
| end of train epoch   3 | time: 182.98s | valid loss  5.06 | valid ppl   158.24
-----------------------------------------------------------------------------------------
| train-epoch   4 |   200/ 2983 batches | lr 20.00 | ms/batch 59.15 | loss  5.07 | ppl   159.94
| train-epoch   4 |   400/ 2983 batches | lr 20.00 | ms/batch 58.84 | loss  5.09 | ppl   162.33
| train-epoch   4 |   600/ 2983 batches | lr 20.00 | ms/batch 58.89 | loss  4.91 | ppl   134.99
| train-epoch   4 |   800/ 2983 batches | lr 20.00 | ms/batch 58.88 | loss  4.96 | ppl   142.46
| train-epoch   4 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.90 | loss  4.96 | ppl   141.99
| train-epoch   4 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.88 | loss  4.96 | ppl   142.11
| train-epoch   4 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.86 | loss  4.99 | ppl   146.29
| train-epoch   4 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.84 | loss  5.05 | ppl   156.80
| train-epoch   4 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.86 | loss  4.93 | ppl   138.30
| train-epoch   4 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.88 | loss  4.96 | ppl   142.80
| train-epoch   4 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.87 | loss  4.86 | ppl   129.35
| train-epoch   4 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.91 | loss  4.90 | ppl   133.82
| train-epoch   4 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.87 | loss  4.92 | ppl   136.66
| train-epoch   4 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.90 | loss  4.85 | ppl   127.68
-----------------------------------------------------------------------------------------
| end of train epoch   4 | time: 182.53s | valid loss  4.96 | valid ppl   142.13
-----------------------------------------------------------------------------------------
| train-epoch   5 |   200/ 2983 batches | lr 20.00 | ms/batch 59.11 | loss  4.91 | ppl   135.11
| train-epoch   5 |   400/ 2983 batches | lr 20.00 | ms/batch 58.81 | loss  4.93 | ppl   138.48
| train-epoch   5 |   600/ 2983 batches | lr 20.00 | ms/batch 58.79 | loss  4.74 | ppl   114.60
| train-epoch   5 |   800/ 2983 batches | lr 20.00 | ms/batch 58.82 | loss  4.80 | ppl   121.50
| train-epoch   5 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.76 | loss  4.80 | ppl   121.24
| train-epoch   5 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.75 | loss  4.80 | ppl   121.96
| train-epoch   5 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.75 | loss  4.84 | ppl   126.88
| train-epoch   5 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.79 | loss  4.91 | ppl   135.70
| train-epoch   5 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.81 | loss  4.78 | ppl   119.70
| train-epoch   5 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.86 | loss  4.82 | ppl   124.37
| train-epoch   5 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.83 | loss  4.72 | ppl   111.78
| train-epoch   5 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.82 | loss  4.75 | ppl   115.83
| train-epoch   5 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.79 | loss  4.78 | ppl   118.72
| train-epoch   5 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.76 | loss  4.71 | ppl   111.52
-----------------------------------------------------------------------------------------
| end of train epoch   5 | time: 182.29s | valid loss  4.89 | valid ppl   132.79
-----------------------------------------------------------------------------------------
| train-epoch   6 |   200/ 2983 batches | lr 20.00 | ms/batch 59.28 | loss  4.77 | ppl   118.32
| train-epoch   6 |   400/ 2983 batches | lr 20.00 | ms/batch 58.92 | loss  4.79 | ppl   120.32
| train-epoch   6 |   600/ 2983 batches | lr 20.00 | ms/batch 59.07 | loss  4.61 | ppl   100.52
| train-epoch   6 |   800/ 2983 batches | lr 20.00 | ms/batch 59.10 | loss  4.67 | ppl   106.72
| train-epoch   6 |  1000/ 2983 batches | lr 20.00 | ms/batch 59.10 | loss  4.67 | ppl   106.74
| train-epoch   6 |  1200/ 2983 batches | lr 20.00 | ms/batch 59.13 | loss  4.68 | ppl   107.78
| train-epoch   6 |  1400/ 2983 batches | lr 20.00 | ms/batch 59.09 | loss  4.72 | ppl   112.25
| train-epoch   6 |  1600/ 2983 batches | lr 20.00 | ms/batch 59.14 | loss  4.79 | ppl   120.81
| train-epoch   6 |  1800/ 2983 batches | lr 20.00 | ms/batch 59.06 | loss  4.67 | ppl   106.35
| train-epoch   6 |  2000/ 2983 batches | lr 20.00 | ms/batch 59.12 | loss  4.70 | ppl   110.22
| train-epoch   6 |  2200/ 2983 batches | lr 20.00 | ms/batch 59.11 | loss  4.60 | ppl    99.18
| train-epoch   6 |  2400/ 2983 batches | lr 20.00 | ms/batch 59.11 | loss  4.63 | ppl   102.81
| train-epoch   6 |  2600/ 2983 batches | lr 20.00 | ms/batch 59.08 | loss  4.66 | ppl   106.03
| train-epoch   6 |  2800/ 2983 batches | lr 20.00 | ms/batch 59.12 | loss  4.60 | ppl    99.45
-----------------------------------------------------------------------------------------
| end of train epoch   6 | time: 183.17s | valid loss  4.83 | valid ppl   125.60
-----------------------------------------------------------------------------------------
| train-epoch   7 |   200/ 2983 batches | lr 20.00 | ms/batch 59.19 | loss  4.66 | ppl   105.24
| train-epoch   7 |   400/ 2983 batches | lr 20.00 | ms/batch 58.90 | loss  4.68 | ppl   107.34
| train-epoch   7 |   600/ 2983 batches | lr 20.00 | ms/batch 58.92 | loss  4.50 | ppl    89.84
| train-epoch   7 |   800/ 2983 batches | lr 20.00 | ms/batch 58.89 | loss  4.55 | ppl    94.62
| train-epoch   7 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.88 | loss  4.56 | ppl    96.04
| train-epoch   7 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.88 | loss  4.58 | ppl    97.07
| train-epoch   7 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.93 | loss  4.62 | ppl   101.62
| train-epoch   7 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.89 | loss  4.69 | ppl   108.62
| train-epoch   7 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.89 | loss  4.57 | ppl    96.12
| train-epoch   7 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.93 | loss  4.60 | ppl    99.82
| train-epoch   7 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.92 | loss  4.50 | ppl    89.75
| train-epoch   7 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.94 | loss  4.53 | ppl    92.57
| train-epoch   7 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.89 | loss  4.57 | ppl    96.19
| train-epoch   7 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.92 | loss  4.51 | ppl    90.90
-----------------------------------------------------------------------------------------
| end of train epoch   7 | time: 182.63s | valid loss  4.80 | valid ppl   121.35
-----------------------------------------------------------------------------------------
| train-epoch   8 |   200/ 2983 batches | lr 20.00 | ms/batch 59.34 | loss  4.56 | ppl    95.37
| train-epoch   8 |   400/ 2983 batches | lr 20.00 | ms/batch 59.06 | loss  4.58 | ppl    97.46
| train-epoch   8 |   600/ 2983 batches | lr 20.00 | ms/batch 59.06 | loss  4.40 | ppl    81.17
| train-epoch   8 |   800/ 2983 batches | lr 20.00 | ms/batch 58.97 | loss  4.46 | ppl    86.36
| train-epoch   8 |  1000/ 2983 batches | lr 20.00 | ms/batch 59.02 | loss  4.47 | ppl    87.17
| train-epoch   8 |  1200/ 2983 batches | lr 20.00 | ms/batch 59.01 | loss  4.48 | ppl    88.61
| train-epoch   8 |  1400/ 2983 batches | lr 20.00 | ms/batch 59.07 | loss  4.53 | ppl    92.99
| train-epoch   8 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.99 | loss  4.60 | ppl    99.50
| train-epoch   8 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.99 | loss  4.48 | ppl    88.00
| train-epoch   8 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.95 | loss  4.51 | ppl    91.26
| train-epoch   8 |  2200/ 2983 batches | lr 20.00 | ms/batch 59.00 | loss  4.40 | ppl    81.70
| train-epoch   8 |  2400/ 2983 batches | lr 20.00 | ms/batch 59.02 | loss  4.44 | ppl    85.02
| train-epoch   8 |  2600/ 2983 batches | lr 20.00 | ms/batch 59.01 | loss  4.48 | ppl    88.20
| train-epoch   8 |  2800/ 2983 batches | lr 20.00 | ms/batch 59.00 | loss  4.42 | ppl    82.80
-----------------------------------------------------------------------------------------
| end of train epoch   8 | time: 182.95s | valid loss  4.76 | valid ppl   116.19
-----------------------------------------------------------------------------------------
| train-epoch   9 |   200/ 2983 batches | lr 20.00 | ms/batch 58.78 | loss  4.47 | ppl    87.17
| train-epoch   9 |   400/ 2983 batches | lr 20.00 | ms/batch 58.45 | loss  4.49 | ppl    89.27
| train-epoch   9 |   600/ 2983 batches | lr 20.00 | ms/batch 58.61 | loss  4.32 | ppl    75.02
| train-epoch   9 |   800/ 2983 batches | lr 20.00 | ms/batch 58.47 | loss  4.37 | ppl    78.70
| train-epoch   9 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.50 | loss  4.39 | ppl    80.57
| train-epoch   9 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.49 | loss  4.40 | ppl    81.67
| train-epoch   9 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.47 | loss  4.44 | ppl    84.90
| train-epoch   9 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.48 | loss  4.52 | ppl    92.18
| train-epoch   9 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.51 | loss  4.40 | ppl    81.58
| train-epoch   9 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.50 | loss  4.44 | ppl    84.67
| train-epoch   9 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.46 | loss  4.33 | ppl    75.59
| train-epoch   9 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.52 | loss  4.37 | ppl    78.66
| train-epoch   9 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.49 | loss  4.40 | ppl    81.30
| train-epoch   9 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.50 | loss  4.34 | ppl    77.03
-----------------------------------------------------------------------------------------
| end of train epoch   9 | time: 181.41s | valid loss  4.75 | valid ppl   115.66
-----------------------------------------------------------------------------------------
| train-epoch  10 |   200/ 2983 batches | lr 20.00 | ms/batch 59.46 | loss  4.40 | ppl    81.24
| train-epoch  10 |   400/ 2983 batches | lr 20.00 | ms/batch 59.20 | loss  4.42 | ppl    82.89
| train-epoch  10 |   600/ 2983 batches | lr 20.00 | ms/batch 59.14 | loss  4.24 | ppl    69.25
| train-epoch  10 |   800/ 2983 batches | lr 20.00 | ms/batch 59.08 | loss  4.29 | ppl    72.86
| train-epoch  10 |  1000/ 2983 batches | lr 20.00 | ms/batch 59.12 | loss  4.32 | ppl    74.84
| train-epoch  10 |  1200/ 2983 batches | lr 20.00 | ms/batch 59.10 | loss  4.33 | ppl    75.91
| train-epoch  10 |  1400/ 2983 batches | lr 20.00 | ms/batch 59.12 | loss  4.37 | ppl    79.33
| train-epoch  10 |  1600/ 2983 batches | lr 20.00 | ms/batch 59.14 | loss  4.45 | ppl    85.31
| train-epoch  10 |  1800/ 2983 batches | lr 20.00 | ms/batch 59.15 | loss  4.33 | ppl    76.27
| train-epoch  10 |  2000/ 2983 batches | lr 20.00 | ms/batch 59.04 | loss  4.37 | ppl    78.92
| train-epoch  10 |  2200/ 2983 batches | lr 20.00 | ms/batch 59.15 | loss  4.25 | ppl    70.20
| train-epoch  10 |  2400/ 2983 batches | lr 20.00 | ms/batch 59.14 | loss  4.29 | ppl    73.09
| train-epoch  10 |  2600/ 2983 batches | lr 20.00 | ms/batch 59.13 | loss  4.33 | ppl    75.99
| train-epoch  10 |  2800/ 2983 batches | lr 20.00 | ms/batch 59.09 | loss  4.28 | ppl    72.19
-----------------------------------------------------------------------------------------
| end of train epoch  10 | time: 183.27s | valid loss  4.73 | valid ppl   113.53
-----------------------------------------------------------------------------------------
| train-epoch  11 |   200/ 2983 batches | lr 20.00 | ms/batch 59.22 | loss  4.33 | ppl    75.69
| train-epoch  11 |   400/ 2983 batches | lr 20.00 | ms/batch 58.88 | loss  4.35 | ppl    77.37
| train-epoch  11 |   600/ 2983 batches | lr 20.00 | ms/batch 58.85 | loss  4.17 | ppl    64.59
| train-epoch  11 |   800/ 2983 batches | lr 20.00 | ms/batch 58.92 | loss  4.22 | ppl    67.83
| train-epoch  11 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.91 | loss  4.25 | ppl    70.19
| train-epoch  11 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.90 | loss  4.26 | ppl    70.79
| train-epoch  11 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.94 | loss  4.30 | ppl    73.75
| train-epoch  11 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.85 | loss  4.38 | ppl    79.91
| train-epoch  11 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.95 | loss  4.27 | ppl    71.28
| train-epoch  11 |  2000/ 2983 batches | lr 20.00 | ms/batch 59.16 | loss  4.30 | ppl    73.59
| train-epoch  11 |  2200/ 2983 batches | lr 20.00 | ms/batch 59.29 | loss  4.18 | ppl    65.59
| train-epoch  11 |  2400/ 2983 batches | lr 20.00 | ms/batch 59.31 | loss  4.23 | ppl    68.56
| train-epoch  11 |  2600/ 2983 batches | lr 20.00 | ms/batch 59.37 | loss  4.27 | ppl    71.65
| train-epoch  11 |  2800/ 2983 batches | lr 20.00 | ms/batch 59.43 | loss  4.21 | ppl    67.60
-----------------------------------------------------------------------------------------
| end of train epoch  11 | time: 183.15s | valid loss  4.73 | valid ppl   113.23
-----------------------------------------------------------------------------------------
| train-epoch  12 |   200/ 2983 batches | lr 20.00 | ms/batch 59.63 | loss  4.26 | ppl    70.85
| train-epoch  12 |   400/ 2983 batches | lr 20.00 | ms/batch 59.23 | loss  4.28 | ppl    72.45
| train-epoch  12 |   600/ 2983 batches | lr 20.00 | ms/batch 59.20 | loss  4.11 | ppl    60.70
| train-epoch  12 |   800/ 2983 batches | lr 20.00 | ms/batch 59.24 | loss  4.16 | ppl    63.81
| train-epoch  12 |  1000/ 2983 batches | lr 20.00 | ms/batch 59.27 | loss  4.18 | ppl    65.67
| train-epoch  12 |  1200/ 2983 batches | lr 20.00 | ms/batch 59.26 | loss  4.20 | ppl    66.85
| train-epoch  12 |  1400/ 2983 batches | lr 20.00 | ms/batch 59.30 | loss  4.24 | ppl    69.54
| train-epoch  12 |  1600/ 2983 batches | lr 20.00 | ms/batch 59.24 | loss  4.32 | ppl    75.18
| train-epoch  12 |  1800/ 2983 batches | lr 20.00 | ms/batch 59.21 | loss  4.21 | ppl    67.25
| train-epoch  12 |  2000/ 2983 batches | lr 20.00 | ms/batch 59.28 | loss  4.24 | ppl    69.71
| train-epoch  12 |  2200/ 2983 batches | lr 20.00 | ms/batch 59.25 | loss  4.13 | ppl    61.99
| train-epoch  12 |  2400/ 2983 batches | lr 20.00 | ms/batch 59.24 | loss  4.16 | ppl    64.34
| train-epoch  12 |  2600/ 2983 batches | lr 20.00 | ms/batch 59.16 | loss  4.21 | ppl    67.28
| train-epoch  12 |  2800/ 2983 batches | lr 20.00 | ms/batch 59.17 | loss  4.16 | ppl    63.86
-----------------------------------------------------------------------------------------
| end of train epoch  12 | time: 183.67s | valid loss  4.76 | valid ppl   117.07
-----------------------------------------------------------------------------------------
| train-epoch  13 |   200/ 2983 batches | lr 5.00 | ms/batch 59.74 | loss  4.23 | ppl    68.53
| train-epoch  13 |   400/ 2983 batches | lr 5.00 | ms/batch 59.38 | loss  4.21 | ppl    67.28
| train-epoch  13 |   600/ 2983 batches | lr 5.00 | ms/batch 59.48 | loss  4.02 | ppl    55.92
| train-epoch  13 |   800/ 2983 batches | lr 5.00 | ms/batch 59.31 | loss  4.05 | ppl    57.21
| train-epoch  13 |  1000/ 2983 batches | lr 5.00 | ms/batch 59.34 | loss  4.06 | ppl    58.19
| train-epoch  13 |  1200/ 2983 batches | lr 5.00 | ms/batch 59.33 | loss  4.06 | ppl    58.04
| train-epoch  13 |  1400/ 2983 batches | lr 5.00 | ms/batch 59.32 | loss  4.09 | ppl    59.83
| train-epoch  13 |  1600/ 2983 batches | lr 5.00 | ms/batch 59.27 | loss  4.16 | ppl    64.13
| train-epoch  13 |  1800/ 2983 batches | lr 5.00 | ms/batch 59.35 | loss  4.04 | ppl    56.77
| train-epoch  13 |  2000/ 2983 batches | lr 5.00 | ms/batch 59.25 | loss  4.06 | ppl    57.75
| train-epoch  13 |  2200/ 2983 batches | lr 5.00 | ms/batch 59.30 | loss  3.92 | ppl    50.45
| train-epoch  13 |  2400/ 2983 batches | lr 5.00 | ms/batch 59.32 | loss  3.95 | ppl    51.68
| train-epoch  13 |  2600/ 2983 batches | lr 5.00 | ms/batch 59.36 | loss  3.97 | ppl    52.79
| train-epoch  13 |  2800/ 2983 batches | lr 5.00 | ms/batch 59.32 | loss  3.91 | ppl    49.95
-----------------------------------------------------------------------------------------
| end of train epoch  13 | time: 183.98s | valid loss  4.66 | valid ppl   106.10
-----------------------------------------------------------------------------------------
| train-epoch  14 |   200/ 2983 batches | lr 5.00 | ms/batch 59.69 | loss  4.09 | ppl    59.95
| train-epoch  14 |   400/ 2983 batches | lr 5.00 | ms/batch 59.35 | loss  4.09 | ppl    59.88
| train-epoch  14 |   600/ 2983 batches | lr 5.00 | ms/batch 59.35 | loss  3.91 | ppl    50.14
| train-epoch  14 |   800/ 2983 batches | lr 5.00 | ms/batch 59.44 | loss  3.95 | ppl    51.94
| train-epoch  14 |  1000/ 2983 batches | lr 5.00 | ms/batch 59.35 | loss  3.98 | ppl    53.27
| train-epoch  14 |  1200/ 2983 batches | lr 5.00 | ms/batch 59.29 | loss  3.98 | ppl    53.49
| train-epoch  14 |  1400/ 2983 batches | lr 5.00 | ms/batch 59.38 | loss  4.01 | ppl    55.14
| train-epoch  14 |  1600/ 2983 batches | lr 5.00 | ms/batch 59.43 | loss  4.08 | ppl    59.38
| train-epoch  14 |  1800/ 2983 batches | lr 5.00 | ms/batch 59.31 | loss  3.97 | ppl    53.22
| train-epoch  14 |  2000/ 2983 batches | lr 5.00 | ms/batch 59.41 | loss  4.00 | ppl    54.54
| train-epoch  14 |  2200/ 2983 batches | lr 5.00 | ms/batch 59.32 | loss  3.86 | ppl    47.70
| train-epoch  14 |  2400/ 2983 batches | lr 5.00 | ms/batch 59.33 | loss  3.89 | ppl    49.07
| train-epoch  14 |  2600/ 2983 batches | lr 5.00 | ms/batch 59.31 | loss  3.92 | ppl    50.34
| train-epoch  14 |  2800/ 2983 batches | lr 5.00 | ms/batch 59.31 | loss  3.87 | ppl    47.94
-----------------------------------------------------------------------------------------
| end of train epoch  14 | time: 184.00s | valid loss  4.65 | valid ppl   104.27
-----------------------------------------------------------------------------------------
| train-epoch  15 |   200/ 2983 batches | lr 5.00 | ms/batch 59.76 | loss  4.03 | ppl    56.33
| train-epoch  15 |   400/ 2983 batches | lr 5.00 | ms/batch 59.38 | loss  4.04 | ppl    56.82
| train-epoch  15 |   600/ 2983 batches | lr 5.00 | ms/batch 59.40 | loss  3.86 | ppl    47.24
| train-epoch  15 |   800/ 2983 batches | lr 5.00 | ms/batch 59.44 | loss  3.89 | ppl    49.04
| train-epoch  15 |  1000/ 2983 batches | lr 5.00 | ms/batch 59.39 | loss  3.92 | ppl    50.59
| train-epoch  15 |  1200/ 2983 batches | lr 5.00 | ms/batch 59.49 | loss  3.92 | ppl    50.52
| train-epoch  15 |  1400/ 2983 batches | lr 5.00 | ms/batch 59.50 | loss  3.96 | ppl    52.53
| train-epoch  15 |  1600/ 2983 batches | lr 5.00 | ms/batch 59.35 | loss  4.04 | ppl    56.75
| train-epoch  15 |  1800/ 2983 batches | lr 5.00 | ms/batch 59.44 | loss  3.93 | ppl    50.74
| train-epoch  15 |  2000/ 2983 batches | lr 5.00 | ms/batch 59.41 | loss  3.95 | ppl    52.08
| train-epoch  15 |  2200/ 2983 batches | lr 5.00 | ms/batch 59.47 | loss  3.82 | ppl    45.70
| train-epoch  15 |  2400/ 2983 batches | lr 5.00 | ms/batch 59.43 | loss  3.85 | ppl    46.95
| train-epoch  15 |  2600/ 2983 batches | lr 5.00 | ms/batch 59.32 | loss  3.88 | ppl    48.56
| train-epoch  15 |  2800/ 2983 batches | lr 5.00 | ms/batch 59.45 | loss  3.84 | ppl    46.32
-----------------------------------------------------------------------------------------
| end of train epoch  15 | time: 184.23s | valid loss  4.65 | valid ppl   104.87
-----------------------------------------------------------------------------------------
| train-epoch  16 |   200/ 2983 batches | lr 1.25 | ms/batch 59.21 | loss  4.04 | ppl    56.57
| train-epoch  16 |   400/ 2983 batches | lr 1.25 | ms/batch 58.92 | loss  4.05 | ppl    57.34
| train-epoch  16 |   600/ 2983 batches | lr 1.25 | ms/batch 58.89 | loss  3.84 | ppl    46.55
| train-epoch  16 |   800/ 2983 batches | lr 1.25 | ms/batch 58.90 | loss  3.87 | ppl    48.11
| train-epoch  16 |  1000/ 2983 batches | lr 1.25 | ms/batch 58.89 | loss  3.91 | ppl    49.77
| train-epoch  16 |  1200/ 2983 batches | lr 1.25 | ms/batch 58.86 | loss  3.94 | ppl    51.45
| train-epoch  16 |  1400/ 2983 batches | lr 1.25 | ms/batch 58.94 | loss  3.93 | ppl    51.07
| train-epoch  16 |  1600/ 2983 batches | lr 1.25 | ms/batch 58.91 | loss  4.03 | ppl    56.11
| train-epoch  16 |  1800/ 2983 batches | lr 1.25 | ms/batch 58.88 | loss  3.89 | ppl    49.07
| train-epoch  16 |  2000/ 2983 batches | lr 1.25 | ms/batch 58.93 | loss  3.92 | ppl    50.44
| train-epoch  16 |  2200/ 2983 batches | lr 1.25 | ms/batch 58.93 | loss  3.78 | ppl    43.73
| train-epoch  16 |  2400/ 2983 batches | lr 1.25 | ms/batch 58.93 | loss  3.81 | ppl    45.01
| train-epoch  16 |  2600/ 2983 batches | lr 1.25 | ms/batch 58.98 | loss  3.83 | ppl    46.20
| train-epoch  16 |  2800/ 2983 batches | lr 1.25 | ms/batch 58.93 | loss  3.78 | ppl    43.84
-----------------------------------------------------------------------------------------
| end of train epoch  16 | time: 182.60s | valid loss  4.62 | valid ppl   101.72
-----------------------------------------------------------------------------------------
| train-epoch  17 |   200/ 2983 batches | lr 1.25 | ms/batch 59.64 | loss  3.99 | ppl    54.09
| train-epoch  17 |   400/ 2983 batches | lr 1.25 | ms/batch 59.51 | loss  4.01 | ppl    55.08
| train-epoch  17 |   600/ 2983 batches | lr 1.25 | ms/batch 59.44 | loss  3.81 | ppl    45.04
| train-epoch  17 |   800/ 2983 batches | lr 1.25 | ms/batch 59.44 | loss  3.85 | ppl    46.85
| train-epoch  17 |  1000/ 2983 batches | lr 1.25 | ms/batch 59.48 | loss  3.87 | ppl    48.15
| train-epoch  17 |  1200/ 2983 batches | lr 1.25 | ms/batch 59.45 | loss  3.91 | ppl    49.92
| train-epoch  17 |  1400/ 2983 batches | lr 1.25 | ms/batch 59.40 | loss  3.91 | ppl    49.73
| train-epoch  17 |  1600/ 2983 batches | lr 1.25 | ms/batch 59.48 | loss  4.00 | ppl    54.72
| train-epoch  17 |  1800/ 2983 batches | lr 1.25 | ms/batch 59.38 | loss  3.87 | ppl    48.01
| train-epoch  17 |  2000/ 2983 batches | lr 1.25 | ms/batch 59.49 | loss  3.90 | ppl    49.39
| train-epoch  17 |  2200/ 2983 batches | lr 1.25 | ms/batch 59.45 | loss  3.76 | ppl    42.99
| train-epoch  17 |  2400/ 2983 batches | lr 1.25 | ms/batch 59.42 | loss  3.79 | ppl    44.38
| train-epoch  17 |  2600/ 2983 batches | lr 1.25 | ms/batch 59.44 | loss  3.82 | ppl    45.58
| train-epoch  17 |  2800/ 2983 batches | lr 1.25 | ms/batch 59.46 | loss  3.78 | ppl    43.60
-----------------------------------------------------------------------------------------
| end of train epoch  17 | time: 184.26s | valid loss  4.62 | valid ppl   101.14
-----------------------------------------------------------------------------------------
| train-epoch  18 |   200/ 2983 batches | lr 1.25 | ms/batch 59.66 | loss  3.98 | ppl    53.30
| train-epoch  18 |   400/ 2983 batches | lr 1.25 | ms/batch 59.26 | loss  3.99 | ppl    53.93
| train-epoch  18 |   600/ 2983 batches | lr 1.25 | ms/batch 59.47 | loss  3.79 | ppl    44.32
| train-epoch  18 |   800/ 2983 batches | lr 1.25 | ms/batch 59.39 | loss  3.84 | ppl    46.51
| train-epoch  18 |  1000/ 2983 batches | lr 1.25 | ms/batch 59.33 | loss  3.86 | ppl    47.41
| train-epoch  18 |  1200/ 2983 batches | lr 1.25 | ms/batch 59.37 | loss  3.89 | ppl    49.09
| train-epoch  18 |  1400/ 2983 batches | lr 1.25 | ms/batch 59.34 | loss  3.89 | ppl    48.85
| train-epoch  18 |  1600/ 2983 batches | lr 1.25 | ms/batch 59.33 | loss  3.99 | ppl    53.81
| train-epoch  18 |  1800/ 2983 batches | lr 1.25 | ms/batch 59.30 | loss  3.85 | ppl    47.19
| train-epoch  18 |  2000/ 2983 batches | lr 1.25 | ms/batch 59.28 | loss  3.89 | ppl    48.77
| train-epoch  18 |  2200/ 2983 batches | lr 1.25 | ms/batch 59.34 | loss  3.75 | ppl    42.31
| train-epoch  18 |  2400/ 2983 batches | lr 1.25 | ms/batch 59.34 | loss  3.78 | ppl    43.99
| train-epoch  18 |  2600/ 2983 batches | lr 1.25 | ms/batch 59.41 | loss  3.81 | ppl    44.93
| train-epoch  18 |  2800/ 2983 batches | lr 1.25 | ms/batch 59.29 | loss  3.76 | ppl    42.74
-----------------------------------------------------------------------------------------
| end of train epoch  18 | time: 183.97s | valid loss  4.61 | valid ppl   100.84
-----------------------------------------------------------------------------------------
| train-epoch  19 |   200/ 2983 batches | lr 1.25 | ms/batch 59.55 | loss  3.95 | ppl    51.90
| train-epoch  19 |   400/ 2983 batches | lr 1.25 | ms/batch 59.21 | loss  3.97 | ppl    53.12
| train-epoch  19 |   600/ 2983 batches | lr 1.25 | ms/batch 59.15 | loss  3.77 | ppl    43.46
| train-epoch  19 |   800/ 2983 batches | lr 1.25 | ms/batch 59.27 | loss  3.82 | ppl    45.75
| train-epoch  19 |  1000/ 2983 batches | lr 1.25 | ms/batch 59.22 | loss  3.84 | ppl    46.46
| train-epoch  19 |  1200/ 2983 batches | lr 1.25 | ms/batch 59.14 | loss  3.88 | ppl    48.50
| train-epoch  19 |  1400/ 2983 batches | lr 1.25 | ms/batch 59.23 | loss  3.88 | ppl    48.26
| train-epoch  19 |  1600/ 2983 batches | lr 1.25 | ms/batch 59.28 | loss  3.97 | ppl    53.00
| train-epoch  19 |  1800/ 2983 batches | lr 1.25 | ms/batch 59.25 | loss  3.84 | ppl    46.73
| train-epoch  19 |  2000/ 2983 batches | lr 1.25 | ms/batch 59.22 | loss  3.87 | ppl    48.17
| train-epoch  19 |  2200/ 2983 batches | lr 1.25 | ms/batch 59.25 | loss  3.73 | ppl    41.65
| train-epoch  19 |  2400/ 2983 batches | lr 1.25 | ms/batch 59.21 | loss  3.77 | ppl    43.32
| train-epoch  19 |  2600/ 2983 batches | lr 1.25 | ms/batch 59.21 | loss  3.80 | ppl    44.68
| train-epoch  19 |  2800/ 2983 batches | lr 1.25 | ms/batch 59.18 | loss  3.75 | ppl    42.59
-----------------------------------------------------------------------------------------
| end of train epoch  19 | time: 183.59s | valid loss  4.61 | valid ppl   100.47
-----------------------------------------------------------------------------------------
| train-epoch  20 |   200/ 2983 batches | lr 1.25 | ms/batch 59.68 | loss  3.94 | ppl    51.35
| train-epoch  20 |   400/ 2983 batches | lr 1.25 | ms/batch 59.27 | loss  3.95 | ppl    52.12
| train-epoch  20 |   600/ 2983 batches | lr 1.25 | ms/batch 59.33 | loss  3.75 | ppl    42.59
| train-epoch  20 |   800/ 2983 batches | lr 1.25 | ms/batch 59.36 | loss  3.81 | ppl    45.19
| train-epoch  20 |  1000/ 2983 batches | lr 1.25 | ms/batch 59.28 | loss  3.83 | ppl    45.95
| train-epoch  20 |  1200/ 2983 batches | lr 1.25 | ms/batch 59.33 | loss  3.86 | ppl    47.49
| train-epoch  20 |  1400/ 2983 batches | lr 1.25 | ms/batch 59.35 | loss  3.86 | ppl    47.51
| train-epoch  20 |  1600/ 2983 batches | lr 1.25 | ms/batch 59.32 | loss  3.95 | ppl    52.11
| train-epoch  20 |  1800/ 2983 batches | lr 1.25 | ms/batch 59.36 | loss  3.83 | ppl    45.92
| train-epoch  20 |  2000/ 2983 batches | lr 1.25 | ms/batch 59.32 | loss  3.86 | ppl    47.40
| train-epoch  20 |  2200/ 2983 batches | lr 1.25 | ms/batch 59.38 | loss  3.72 | ppl    41.35
| train-epoch  20 |  2400/ 2983 batches | lr 1.25 | ms/batch 59.32 | loss  3.75 | ppl    42.60
| train-epoch  20 |  2600/ 2983 batches | lr 1.25 | ms/batch 59.27 | loss  3.78 | ppl    43.90
| train-epoch  20 |  2800/ 2983 batches | lr 1.25 | ms/batch 59.29 | loss  3.74 | ppl    42.14
-----------------------------------------------------------------------------------------
| end of train epoch  20 | time: 183.92s | valid loss  4.61 | valid ppl   100.78
-----------------------------------------------------------------------------------------
| train-epoch  21 |   200/ 2983 batches | lr 0.31 | ms/batch 59.65 | loss  3.94 | ppl    51.64
| train-epoch  21 |   400/ 2983 batches | lr 0.31 | ms/batch 59.33 | loss  4.01 | ppl    54.91
| train-epoch  21 |   600/ 2983 batches | lr 0.31 | ms/batch 59.27 | loss  3.80 | ppl    44.64
| train-epoch  21 |   800/ 2983 batches | lr 0.31 | ms/batch 59.33 | loss  3.83 | ppl    45.97
| train-epoch  21 |  1000/ 2983 batches | lr 0.31 | ms/batch 59.32 | loss  3.86 | ppl    47.59
| train-epoch  21 |  1200/ 2983 batches | lr 0.31 | ms/batch 59.32 | loss  3.87 | ppl    48.12
| train-epoch  21 |  1400/ 2983 batches | lr 0.31 | ms/batch 59.36 | loss  3.91 | ppl    50.03
| train-epoch  21 |  1600/ 2983 batches | lr 0.31 | ms/batch 59.31 | loss  3.98 | ppl    53.32
| train-epoch  21 |  1800/ 2983 batches | lr 0.31 | ms/batch 59.34 | loss  3.87 | ppl    48.06
| train-epoch  21 |  2000/ 2983 batches | lr 0.31 | ms/batch 59.33 | loss  3.87 | ppl    47.77
| train-epoch  21 |  2200/ 2983 batches | lr 0.31 | ms/batch 59.36 | loss  3.73 | ppl    41.67
| train-epoch  21 |  2400/ 2983 batches | lr 0.31 | ms/batch 59.28 | loss  3.76 | ppl    43.15
| train-epoch  21 |  2600/ 2983 batches | lr 0.31 | ms/batch 59.31 | loss  3.83 | ppl    45.90
| train-epoch  21 |  2800/ 2983 batches | lr 0.31 | ms/batch 59.23 | loss  3.77 | ppl    43.53
-----------------------------------------------------------------------------------------
| end of train epoch  21 | time: 183.88s | valid loss  4.58 | valid ppl    97.60
-----------------------------------------------------------------------------------------
| train-epoch  22 |   200/ 2983 batches | lr 0.31 | ms/batch 59.69 | loss  3.98 | ppl    53.49
| train-epoch  22 |   400/ 2983 batches | lr 0.31 | ms/batch 59.29 | loss  3.99 | ppl    53.95
| train-epoch  22 |   600/ 2983 batches | lr 0.31 | ms/batch 59.37 | loss  3.77 | ppl    43.20
| train-epoch  22 |   800/ 2983 batches | lr 0.31 | ms/batch 59.40 | loss  3.82 | ppl    45.79
| train-epoch  22 |  1000/ 2983 batches | lr 0.31 | ms/batch 59.37 | loss  3.86 | ppl    47.30
| train-epoch  22 |  1200/ 2983 batches | lr 0.31 | ms/batch 59.46 | loss  3.87 | ppl    48.08
| train-epoch  22 |  1400/ 2983 batches | lr 0.31 | ms/batch 59.39 | loss  3.90 | ppl    49.32
| train-epoch  22 |  1600/ 2983 batches | lr 0.31 | ms/batch 59.72 | loss  3.98 | ppl    53.33
| train-epoch  22 |  1800/ 2983 batches | lr 0.31 | ms/batch 59.45 | loss  3.87 | ppl    47.85
| train-epoch  22 |  2000/ 2983 batches | lr 0.31 | ms/batch 59.13 | loss  3.87 | ppl    47.87
| train-epoch  22 |  2200/ 2983 batches | lr 0.31 | ms/batch 59.18 | loss  3.72 | ppl    41.30
| train-epoch  22 |  2400/ 2983 batches | lr 0.31 | ms/batch 59.31 | loss  3.75 | ppl    42.69
| train-epoch  22 |  2600/ 2983 batches | lr 0.31 | ms/batch 59.31 | loss  3.81 | ppl    45.32
| train-epoch  22 |  2800/ 2983 batches | lr 0.31 | ms/batch 59.38 | loss  3.76 | ppl    42.98
-----------------------------------------------------------------------------------------
| end of train epoch  22 | time: 184.06s | valid loss  4.57 | valid ppl    96.97
-----------------------------------------------------------------------------------------
| train-epoch  23 |   200/ 2983 batches | lr 0.31 | ms/batch 59.17 | loss  3.97 | ppl    53.04
| train-epoch  23 |   400/ 2983 batches | lr 0.31 | ms/batch 58.87 | loss  3.98 | ppl    53.41
| train-epoch  23 |   600/ 2983 batches | lr 0.31 | ms/batch 58.92 | loss  3.77 | ppl    43.45
| train-epoch  23 |   800/ 2983 batches | lr 0.31 | ms/batch 58.89 | loss  3.82 | ppl    45.70
| train-epoch  23 |  1000/ 2983 batches | lr 0.31 | ms/batch 58.96 | loss  3.84 | ppl    46.63
| train-epoch  23 |  1200/ 2983 batches | lr 0.31 | ms/batch 58.91 | loss  3.86 | ppl    47.51
| train-epoch  23 |  1400/ 2983 batches | lr 0.31 | ms/batch 58.89 | loss  3.90 | ppl    49.42
| train-epoch  23 |  1600/ 2983 batches | lr 0.31 | ms/batch 58.98 | loss  3.97 | ppl    53.03
| train-epoch  23 |  1800/ 2983 batches | lr 0.31 | ms/batch 58.93 | loss  3.87 | ppl    47.80
| train-epoch  23 |  2000/ 2983 batches | lr 0.31 | ms/batch 58.94 | loss  3.86 | ppl    47.67
| train-epoch  23 |  2200/ 2983 batches | lr 0.31 | ms/batch 58.96 | loss  3.72 | ppl    41.47
| train-epoch  23 |  2400/ 2983 batches | lr 0.31 | ms/batch 58.87 | loss  3.75 | ppl    42.54
| train-epoch  23 |  2600/ 2983 batches | lr 0.31 | ms/batch 58.96 | loss  3.81 | ppl    45.17
| train-epoch  23 |  2800/ 2983 batches | lr 0.31 | ms/batch 58.96 | loss  3.76 | ppl    42.91
-----------------------------------------------------------------------------------------
| end of train epoch  23 | time: 182.73s | valid loss  4.57 | valid ppl    97.00
-----------------------------------------------------------------------------------------
| train-epoch  24 |   200/ 2983 batches | lr 0.08 | ms/batch 59.97 | loss  3.99 | ppl    53.87
| train-epoch  24 |   400/ 2983 batches | lr 0.08 | ms/batch 59.55 | loss  4.01 | ppl    54.94
| train-epoch  24 |   600/ 2983 batches | lr 0.08 | ms/batch 59.68 | loss  3.84 | ppl    46.31
| train-epoch  24 |   800/ 2983 batches | lr 0.08 | ms/batch 59.49 | loss  3.88 | ppl    48.31
| train-epoch  24 |  1000/ 2983 batches | lr 0.08 | ms/batch 59.58 | loss  3.89 | ppl    49.06
| train-epoch  24 |  1200/ 2983 batches | lr 0.08 | ms/batch 59.54 | loss  3.88 | ppl    48.40
| train-epoch  24 |  1400/ 2983 batches | lr 0.08 | ms/batch 59.53 | loss  3.92 | ppl    50.24
| train-epoch  24 |  1600/ 2983 batches | lr 0.08 | ms/batch 59.58 | loss  3.99 | ppl    54.08
| train-epoch  24 |  1800/ 2983 batches | lr 0.08 | ms/batch 59.55 | loss  3.91 | ppl    49.89
| train-epoch  24 |  2000/ 2983 batches | lr 0.08 | ms/batch 59.48 | loss  3.93 | ppl    50.93
| train-epoch  24 |  2200/ 2983 batches | lr 0.08 | ms/batch 59.58 | loss  3.81 | ppl    45.04
| train-epoch  24 |  2400/ 2983 batches | lr 0.08 | ms/batch 59.48 | loss  3.81 | ppl    45.04
| train-epoch  24 |  2600/ 2983 batches | lr 0.08 | ms/batch 59.52 | loss  3.83 | ppl    46.14
| train-epoch  24 |  2800/ 2983 batches | lr 0.08 | ms/batch 59.59 | loss  3.75 | ppl    42.63
-----------------------------------------------------------------------------------------
| end of train epoch  24 | time: 184.60s | valid loss  4.56 | valid ppl    95.77
-----------------------------------------------------------------------------------------
| train-epoch  25 |   200/ 2983 batches | lr 0.08 | ms/batch 59.64 | loss  3.99 | ppl    53.97
| train-epoch  25 |   400/ 2983 batches | lr 0.08 | ms/batch 59.38 | loss  4.01 | ppl    55.09
| train-epoch  25 |   600/ 2983 batches | lr 0.08 | ms/batch 59.42 | loss  3.83 | ppl    45.96
| train-epoch  25 |   800/ 2983 batches | lr 0.08 | ms/batch 59.37 | loss  3.87 | ppl    47.78
| train-epoch  25 |  1000/ 2983 batches | lr 0.08 | ms/batch 59.35 | loss  3.88 | ppl    48.42
| train-epoch  25 |  1200/ 2983 batches | lr 0.08 | ms/batch 59.36 | loss  3.88 | ppl    48.60
| train-epoch  25 |  1400/ 2983 batches | lr 0.08 | ms/batch 59.27 | loss  3.93 | ppl    50.72
| train-epoch  25 |  1600/ 2983 batches | lr 0.08 | ms/batch 59.20 | loss  3.99 | ppl    54.22
| train-epoch  25 |  1800/ 2983 batches | lr 0.08 | ms/batch 59.44 | loss  3.89 | ppl    49.01
| train-epoch  25 |  2000/ 2983 batches | lr 0.08 | ms/batch 59.36 | loss  3.90 | ppl    49.28
| train-epoch  25 |  2200/ 2983 batches | lr 0.08 | ms/batch 59.36 | loss  3.77 | ppl    43.56
| train-epoch  25 |  2400/ 2983 batches | lr 0.08 | ms/batch 59.44 | loss  3.79 | ppl    44.10
| train-epoch  25 |  2600/ 2983 batches | lr 0.08 | ms/batch 59.41 | loss  3.82 | ppl    45.44
| train-epoch  25 |  2800/ 2983 batches | lr 0.08 | ms/batch 59.40 | loss  3.76 | ppl    43.05
-----------------------------------------------------------------------------------------
| end of train epoch  25 | time: 184.03s | valid loss  4.56 | valid ppl    95.78
-----------------------------------------------------------------------------------------
| train-epoch  26 |   200/ 2983 batches | lr 0.02 | ms/batch 59.66 | loss  4.00 | ppl    54.81
| train-epoch  26 |   400/ 2983 batches | lr 0.02 | ms/batch 59.34 | loss  4.03 | ppl    56.46
| train-epoch  26 |   600/ 2983 batches | lr 0.02 | ms/batch 59.18 | loss  3.85 | ppl    47.21
| train-epoch  26 |   800/ 2983 batches | lr 0.02 | ms/batch 59.24 | loss  3.90 | ppl    49.59
| train-epoch  26 |  1000/ 2983 batches | lr 0.02 | ms/batch 59.23 | loss  3.92 | ppl    50.58
| train-epoch  26 |  1200/ 2983 batches | lr 0.02 | ms/batch 59.16 | loss  3.92 | ppl    50.42
| train-epoch  26 |  1400/ 2983 batches | lr 0.02 | ms/batch 59.24 | loss  3.97 | ppl    53.00
| train-epoch  26 |  1600/ 2983 batches | lr 0.02 | ms/batch 59.28 | loss  4.01 | ppl    55.22
| train-epoch  26 |  1800/ 2983 batches | lr 0.02 | ms/batch 59.14 | loss  3.90 | ppl    49.53
| train-epoch  26 |  2000/ 2983 batches | lr 0.02 | ms/batch 59.22 | loss  3.91 | ppl    49.93
| train-epoch  26 |  2200/ 2983 batches | lr 0.02 | ms/batch 59.25 | loss  3.79 | ppl    44.34
| train-epoch  26 |  2400/ 2983 batches | lr 0.02 | ms/batch 59.23 | loss  3.80 | ppl    44.80
| train-epoch  26 |  2600/ 2983 batches | lr 0.02 | ms/batch 59.17 | loss  3.84 | ppl    46.34
| train-epoch  26 |  2800/ 2983 batches | lr 0.02 | ms/batch 59.14 | loss  3.78 | ppl    43.74
-----------------------------------------------------------------------------------------
| end of train epoch  26 | time: 183.63s | valid loss  4.56 | valid ppl    95.59
-----------------------------------------------------------------------------------------
| train-epoch  27 |   200/ 2983 batches | lr 0.02 | ms/batch 59.69 | loss  4.00 | ppl    54.82
| train-epoch  27 |   400/ 2983 batches | lr 0.02 | ms/batch 59.26 | loss  4.02 | ppl    55.84
| train-epoch  27 |   600/ 2983 batches | lr 0.02 | ms/batch 59.31 | loss  3.85 | ppl    46.97
| train-epoch  27 |   800/ 2983 batches | lr 0.02 | ms/batch 59.26 | loss  3.89 | ppl    49.14
| train-epoch  27 |  1000/ 2983 batches | lr 0.02 | ms/batch 59.29 | loss  3.92 | ppl    50.16
| train-epoch  27 |  1200/ 2983 batches | lr 0.02 | ms/batch 59.33 | loss  3.91 | ppl    50.12
| train-epoch  27 |  1400/ 2983 batches | lr 0.02 | ms/batch 59.27 | loss  3.96 | ppl    52.40
| train-epoch  27 |  1600/ 2983 batches | lr 0.02 | ms/batch 59.41 | loss  4.00 | ppl    54.87
| train-epoch  27 |  1800/ 2983 batches | lr 0.02 | ms/batch 59.32 | loss  3.90 | ppl    49.16
| train-epoch  27 |  2000/ 2983 batches | lr 0.02 | ms/batch 59.27 | loss  3.91 | ppl    49.99
| train-epoch  27 |  2200/ 2983 batches | lr 0.02 | ms/batch 59.31 | loss  3.79 | ppl    44.08
| train-epoch  27 |  2400/ 2983 batches | lr 0.02 | ms/batch 59.29 | loss  3.80 | ppl    44.64
| train-epoch  27 |  2600/ 2983 batches | lr 0.02 | ms/batch 59.36 | loss  3.84 | ppl    46.67
| train-epoch  27 |  2800/ 2983 batches | lr 0.02 | ms/batch 59.28 | loss  3.78 | ppl    43.95
-----------------------------------------------------------------------------------------
| end of train epoch  27 | time: 183.86s | valid loss  4.56 | valid ppl    95.53
-----------------------------------------------------------------------------------------
| train-epoch  28 |   200/ 2983 batches | lr 0.02 | ms/batch 59.62 | loss  4.02 | ppl    55.43
| train-epoch  28 |   400/ 2983 batches | lr 0.02 | ms/batch 59.32 | loss  4.03 | ppl    56.18
| train-epoch  28 |   600/ 2983 batches | lr 0.02 | ms/batch 59.24 | loss  3.85 | ppl    46.87
| train-epoch  28 |   800/ 2983 batches | lr 0.02 | ms/batch 59.30 | loss  3.90 | ppl    49.20
| train-epoch  28 |  1000/ 2983 batches | lr 0.02 | ms/batch 59.28 | loss  3.90 | ppl    49.58
| train-epoch  28 |  1200/ 2983 batches | lr 0.02 | ms/batch 59.25 | loss  3.91 | ppl    49.85
| train-epoch  28 |  1400/ 2983 batches | lr 0.02 | ms/batch 59.25 | loss  3.95 | ppl    51.82
| train-epoch  28 |  1600/ 2983 batches | lr 0.02 | ms/batch 59.27 | loss  4.00 | ppl    54.62
| train-epoch  28 |  1800/ 2983 batches | lr 0.02 | ms/batch 59.29 | loss  3.89 | ppl    48.84
| train-epoch  28 |  2000/ 2983 batches | lr 0.02 | ms/batch 59.34 | loss  3.91 | ppl    49.93
| train-epoch  28 |  2200/ 2983 batches | lr 0.02 | ms/batch 59.33 | loss  3.78 | ppl    43.86
| train-epoch  28 |  2400/ 2983 batches | lr 0.02 | ms/batch 59.34 | loss  3.80 | ppl    44.88
| train-epoch  28 |  2600/ 2983 batches | lr 0.02 | ms/batch 59.36 | loss  3.84 | ppl    46.65
| train-epoch  28 |  2800/ 2983 batches | lr 0.02 | ms/batch 59.26 | loss  3.79 | ppl    44.09
-----------------------------------------------------------------------------------------
| end of train epoch  28 | time: 183.84s | valid loss  4.56 | valid ppl    95.54
-----------------------------------------------------------------------------------------
| train-epoch  29 |   200/ 2983 batches | lr 0.00 | ms/batch 59.73 | loss  4.01 | ppl    54.92
| train-epoch  29 |   400/ 2983 batches | lr 0.00 | ms/batch 59.46 | loss  4.03 | ppl    56.09
| train-epoch  29 |   600/ 2983 batches | lr 0.00 | ms/batch 59.29 | loss  3.86 | ppl    47.25
| train-epoch  29 |   800/ 2983 batches | lr 0.00 | ms/batch 59.22 | loss  3.90 | ppl    49.28
| train-epoch  29 |  1000/ 2983 batches | lr 0.00 | ms/batch 59.37 | loss  3.91 | ppl    50.06
| train-epoch  29 |  1200/ 2983 batches | lr 0.00 | ms/batch 59.37 | loss  3.91 | ppl    49.79
| train-epoch  29 |  1400/ 2983 batches | lr 0.00 | ms/batch 59.27 | loss  3.96 | ppl    52.25
| train-epoch  29 |  1600/ 2983 batches | lr 0.00 | ms/batch 59.35 | loss  4.01 | ppl    55.19
| train-epoch  29 |  1800/ 2983 batches | lr 0.00 | ms/batch 59.29 | loss  3.89 | ppl    48.84
| train-epoch  29 |  2000/ 2983 batches | lr 0.00 | ms/batch 59.36 | loss  3.91 | ppl    49.78
| train-epoch  29 |  2200/ 2983 batches | lr 0.00 | ms/batch 59.28 | loss  3.79 | ppl    44.43
| train-epoch  29 |  2400/ 2983 batches | lr 0.00 | ms/batch 59.36 | loss  3.81 | ppl    44.94
| train-epoch  29 |  2600/ 2983 batches | lr 0.00 | ms/batch 59.23 | loss  3.84 | ppl    46.64
| train-epoch  29 |  2800/ 2983 batches | lr 0.00 | ms/batch 59.34 | loss  3.79 | ppl    44.26
-----------------------------------------------------------------------------------------
| end of train epoch  29 | time: 183.94s | valid loss  4.56 | valid ppl    95.56
-----------------------------------------------------------------------------------------
| train-epoch  30 |   200/ 2983 batches | lr 0.00 | ms/batch 59.23 | loss  4.01 | ppl    55.08
| train-epoch  30 |   400/ 2983 batches | lr 0.00 | ms/batch 58.84 | loss  4.03 | ppl    56.36
| train-epoch  30 |   600/ 2983 batches | lr 0.00 | ms/batch 58.95 | loss  3.85 | ppl    47.12
| train-epoch  30 |   800/ 2983 batches | lr 0.00 | ms/batch 58.97 | loss  3.90 | ppl    49.59
| train-epoch  30 |  1000/ 2983 batches | lr 0.00 | ms/batch 58.81 | loss  3.91 | ppl    50.13
| train-epoch  30 |  1200/ 2983 batches | lr 0.00 | ms/batch 58.94 | loss  3.91 | ppl    50.08
| train-epoch  30 |  1400/ 2983 batches | lr 0.00 | ms/batch 58.92 | loss  3.96 | ppl    52.42
| train-epoch  30 |  1600/ 2983 batches | lr 0.00 | ms/batch 58.90 | loss  4.01 | ppl    54.94
| train-epoch  30 |  1800/ 2983 batches | lr 0.00 | ms/batch 58.92 | loss  3.89 | ppl    49.13
| train-epoch  30 |  2000/ 2983 batches | lr 0.00 | ms/batch 58.86 | loss  3.91 | ppl    49.76
| train-epoch  30 |  2200/ 2983 batches | lr 0.00 | ms/batch 58.95 | loss  3.79 | ppl    44.45
| train-epoch  30 |  2400/ 2983 batches | lr 0.00 | ms/batch 58.93 | loss  3.81 | ppl    45.25
| train-epoch  30 |  2600/ 2983 batches | lr 0.00 | ms/batch 58.84 | loss  3.85 | ppl    47.08
| train-epoch  30 |  2800/ 2983 batches | lr 0.00 | ms/batch 58.94 | loss  3.79 | ppl    44.09
-----------------------------------------------------------------------------------------
| end of train epoch  30 | time: 182.67s | valid loss  4.56 | valid ppl    95.56
-----------------------------------------------------------------------------------------
| train-epoch  31 |   200/ 2983 batches | lr 0.00 | ms/batch 59.81 | loss  4.01 | ppl    55.14
| train-epoch  31 |   400/ 2983 batches | lr 0.00 | ms/batch 59.45 | loss  4.03 | ppl    56.13
| train-epoch  31 |   600/ 2983 batches | lr 0.00 | ms/batch 59.39 | loss  3.86 | ppl    47.27
| train-epoch  31 |   800/ 2983 batches | lr 0.00 | ms/batch 59.50 | loss  3.90 | ppl    49.26
| train-epoch  31 |  1000/ 2983 batches | lr 0.00 | ms/batch 59.31 | loss  3.91 | ppl    50.03
| train-epoch  31 |  1200/ 2983 batches | lr 0.00 | ms/batch 59.32 | loss  3.92 | ppl    50.25
| train-epoch  31 |  1400/ 2983 batches | lr 0.00 | ms/batch 59.40 | loss  3.96 | ppl    52.51
| train-epoch  31 |  1600/ 2983 batches | lr 0.00 | ms/batch 59.40 | loss  4.01 | ppl    55.05
| train-epoch  31 |  1800/ 2983 batches | lr 0.00 | ms/batch 59.34 | loss  3.89 | ppl    49.01
| train-epoch  31 |  2000/ 2983 batches | lr 0.00 | ms/batch 59.36 | loss  3.91 | ppl    49.90
| train-epoch  31 |  2200/ 2983 batches | lr 0.00 | ms/batch 59.39 | loss  3.80 | ppl    44.51
| train-epoch  31 |  2400/ 2983 batches | lr 0.00 | ms/batch 59.34 | loss  3.81 | ppl    44.94
| train-epoch  31 |  2600/ 2983 batches | lr 0.00 | ms/batch 59.39 | loss  3.85 | ppl    46.80
| train-epoch  31 |  2800/ 2983 batches | lr 0.00 | ms/batch 59.40 | loss  3.79 | ppl    44.25
-----------------------------------------------------------------------------------------
| end of train epoch  31 | time: 184.15s | valid loss  4.56 | valid ppl    95.56
-----------------------------------------------------------------------------------------
| train-epoch  32 |   200/ 2983 batches | lr 0.00 | ms/batch 59.67 | loss  4.01 | ppl    55.03
| train-epoch  32 |   400/ 2983 batches | lr 0.00 | ms/batch 59.31 | loss  4.03 | ppl    56.16
| train-epoch  32 |   600/ 2983 batches | lr 0.00 | ms/batch 59.31 | loss  3.86 | ppl    47.23
| train-epoch  32 |   800/ 2983 batches | lr 0.00 | ms/batch 59.29 | loss  3.90 | ppl    49.36
| train-epoch  32 |  1000/ 2983 batches | lr 0.00 | ms/batch 59.27 | loss  3.92 | ppl    50.44
| train-epoch  32 |  1200/ 2983 batches | lr 0.00 | ms/batch 59.31 | loss  3.91 | ppl    49.96
| train-epoch  32 |  1400/ 2983 batches | lr 0.00 | ms/batch 59.27 | loss  3.96 | ppl    52.47
| train-epoch  32 |  1600/ 2983 batches | lr 0.00 | ms/batch 59.21 | loss  4.01 | ppl    55.15
| train-epoch  32 |  1800/ 2983 batches | lr 0.00 | ms/batch 59.29 | loss  3.89 | ppl    48.97
| train-epoch  32 |  2000/ 2983 batches | lr 0.00 | ms/batch 59.18 | loss  3.91 | ppl    50.10
| train-epoch  32 |  2200/ 2983 batches | lr 0.00 | ms/batch 59.26 | loss  3.79 | ppl    44.29
| train-epoch  32 |  2400/ 2983 batches | lr 0.00 | ms/batch 59.25 | loss  3.81 | ppl    45.12
| train-epoch  32 |  2600/ 2983 batches | lr 0.00 | ms/batch 59.31 | loss  3.85 | ppl    46.93
| train-epoch  32 |  2800/ 2983 batches | lr 0.00 | ms/batch 59.34 | loss  3.79 | ppl    44.31
-----------------------------------------------------------------------------------------
| end of train epoch  32 | time: 183.77s | valid loss  4.56 | valid ppl    95.56
-----------------------------------------------------------------------------------------
| train-epoch  33 |   200/ 2983 batches | lr 0.00 | ms/batch 59.41 | loss  4.01 | ppl    55.06
| train-epoch  33 |   400/ 2983 batches | lr 0.00 | ms/batch 59.12 | loss  4.02 | ppl    55.79
| train-epoch  33 |   600/ 2983 batches | lr 0.00 | ms/batch 59.13 | loss  3.86 | ppl    47.27
| train-epoch  33 |   800/ 2983 batches | lr 0.00 | ms/batch 59.17 | loss  3.90 | ppl    49.39
| train-epoch  33 |  1000/ 2983 batches | lr 0.00 | ms/batch 59.11 | loss  3.92 | ppl    50.43
| train-epoch  33 |  1200/ 2983 batches | lr 0.00 | ms/batch 59.20 | loss  3.92 | ppl    50.15
| train-epoch  33 |  1400/ 2983 batches | lr 0.00 | ms/batch 59.07 | loss  3.96 | ppl    52.28
| train-epoch  33 |  1600/ 2983 batches | lr 0.00 | ms/batch 59.09 | loss  4.01 | ppl    55.05
| train-epoch  33 |  1800/ 2983 batches | lr 0.00 | ms/batch 59.19 | loss  3.89 | ppl    49.09
| train-epoch  33 |  2000/ 2983 batches | lr 0.00 | ms/batch 59.17 | loss  3.91 | ppl    49.70
| train-epoch  33 |  2200/ 2983 batches | lr 0.00 | ms/batch 59.14 | loss  3.79 | ppl    44.29
| train-epoch  33 |  2400/ 2983 batches | lr 0.00 | ms/batch 59.12 | loss  3.81 | ppl    45.06
| train-epoch  33 |  2600/ 2983 batches | lr 0.00 | ms/batch 59.12 | loss  3.85 | ppl    46.99
| train-epoch  33 |  2800/ 2983 batches | lr 0.00 | ms/batch 59.10 | loss  3.79 | ppl    44.16
-----------------------------------------------------------------------------------------
| end of train epoch  33 | time: 183.33s | valid loss  4.56 | valid ppl    95.56
-----------------------------------------------------------------------------------------
| train-epoch  34 |   200/ 2983 batches | lr 0.00 | ms/batch 59.60 | loss  4.01 | ppl    54.92
| train-epoch  34 |   400/ 2983 batches | lr 0.00 | ms/batch 59.28 | loss  4.03 | ppl    56.16
| train-epoch  34 |   600/ 2983 batches | lr 0.00 | ms/batch 59.35 | loss  3.86 | ppl    47.64
| train-epoch  34 |   800/ 2983 batches | lr 0.00 | ms/batch 59.30 | loss  3.90 | ppl    49.42
| train-epoch  34 |  1000/ 2983 batches | lr 0.00 | ms/batch 59.32 | loss  3.92 | ppl    50.24
| train-epoch  34 |  1200/ 2983 batches | lr 0.00 | ms/batch 59.29 | loss  3.92 | ppl    50.28
| train-epoch  34 |  1400/ 2983 batches | lr 0.00 | ms/batch 59.33 | loss  3.96 | ppl    52.26
| train-epoch  34 |  1600/ 2983 batches | lr 0.00 | ms/batch 59.26 | loss  4.01 | ppl    55.20
| train-epoch  34 |  1800/ 2983 batches | lr 0.00 | ms/batch 59.22 | loss  3.90 | ppl    49.30
| train-epoch  34 |  2000/ 2983 batches | lr 0.00 | ms/batch 59.37 | loss  3.91 | ppl    49.86
| train-epoch  34 |  2200/ 2983 batches | lr 0.00 | ms/batch 59.29 | loss  3.79 | ppl    44.45
| train-epoch  34 |  2400/ 2983 batches | lr 0.00 | ms/batch 59.23 | loss  3.81 | ppl    44.99
| train-epoch  34 |  2600/ 2983 batches | lr 0.00 | ms/batch 59.27 | loss  3.85 | ppl    46.94
| train-epoch  34 |  2800/ 2983 batches | lr 0.00 | ms/batch 59.27 | loss  3.79 | ppl    44.37
-----------------------------------------------------------------------------------------
| end of train epoch  34 | time: 183.72s | valid loss  4.56 | valid ppl    95.56
-----------------------------------------------------------------------------------------
| train-epoch  35 |   200/ 2983 batches | lr 0.00 | ms/batch 59.60 | loss  4.01 | ppl    55.04
| train-epoch  35 |   400/ 2983 batches | lr 0.00 | ms/batch 59.51 | loss  4.03 | ppl    56.27
| train-epoch  35 |   600/ 2983 batches | lr 0.00 | ms/batch 59.52 | loss  3.87 | ppl    47.75
| train-epoch  35 |   800/ 2983 batches | lr 0.00 | ms/batch 59.67 | loss  3.90 | ppl    49.41
| train-epoch  35 |  1000/ 2983 batches | lr 0.00 | ms/batch 59.49 | loss  3.92 | ppl    50.37
| train-epoch  35 |  1200/ 2983 batches | lr 0.00 | ms/batch 59.55 | loss  3.92 | ppl    50.33
| train-epoch  35 |  1400/ 2983 batches | lr 0.00 | ms/batch 59.43 | loss  3.96 | ppl    52.36
| train-epoch  35 |  1600/ 2983 batches | lr 0.00 | ms/batch 59.50 | loss  4.01 | ppl    55.00
| train-epoch  35 |  1800/ 2983 batches | lr 0.00 | ms/batch 59.52 | loss  3.89 | ppl    49.05
| train-epoch  35 |  2000/ 2983 batches | lr 0.00 | ms/batch 59.52 | loss  3.91 | ppl    49.87
| train-epoch  35 |  2200/ 2983 batches | lr 0.00 | ms/batch 59.61 | loss  3.80 | ppl    44.62
| train-epoch  35 |  2400/ 2983 batches | lr 0.00 | ms/batch 59.62 | loss  3.81 | ppl    45.11
| train-epoch  35 |  2600/ 2983 batches | lr 0.00 | ms/batch 59.53 | loss  3.85 | ppl    47.00
| train-epoch  35 |  2800/ 2983 batches | lr 0.00 | ms/batch 59.48 | loss  3.79 | ppl    44.11
-----------------------------------------------------------------------------------------
| end of train epoch  35 | time: 184.49s | valid loss  4.56 | valid ppl    95.56
-----------------------------------------------------------------------------------------
| train-epoch  36 |   200/ 2983 batches | lr 0.00 | ms/batch 59.95 | loss  4.00 | ppl    54.82
| train-epoch  36 |   400/ 2983 batches | lr 0.00 | ms/batch 59.52 | loss  4.03 | ppl    56.10
| train-epoch  36 |   600/ 2983 batches | lr 0.00 | ms/batch 59.63 | loss  3.86 | ppl    47.52
| train-epoch  36 |   800/ 2983 batches | lr 0.00 | ms/batch 59.48 | loss  3.91 | ppl    49.87
| train-epoch  36 |  1000/ 2983 batches | lr 0.00 | ms/batch 59.62 | loss  3.92 | ppl    50.22
| train-epoch  36 |  1200/ 2983 batches | lr 0.00 | ms/batch 59.61 | loss  3.92 | ppl    50.38
| train-epoch  36 |  1400/ 2983 batches | lr 0.00 | ms/batch 59.63 | loss  3.95 | ppl    52.15
| train-epoch  36 |  1600/ 2983 batches | lr 0.00 | ms/batch 59.55 | loss  4.01 | ppl    55.39
| train-epoch  36 |  1800/ 2983 batches | lr 0.00 | ms/batch 59.73 | loss  3.89 | ppl    49.09
| train-epoch  36 |  2000/ 2983 batches | lr 0.00 | ms/batch 59.44 | loss  3.91 | ppl    49.75
| train-epoch  36 |  2200/ 2983 batches | lr 0.00 | ms/batch 59.61 | loss  3.79 | ppl    44.35
| train-epoch  36 |  2400/ 2983 batches | lr 0.00 | ms/batch 59.60 | loss  3.81 | ppl    45.05
| train-epoch  36 |  2600/ 2983 batches | lr 0.00 | ms/batch 59.63 | loss  3.85 | ppl    46.91
| train-epoch  36 |  2800/ 2983 batches | lr 0.00 | ms/batch 59.88 | loss  3.79 | ppl    44.37
-----------------------------------------------------------------------------------------
| end of train epoch  36 | time: 184.78s | valid loss  4.56 | valid ppl    95.56
-----------------------------------------------------------------------------------------
| train-epoch  37 |   200/ 2983 batches | lr 0.00 | ms/batch 59.38 | loss  4.01 | ppl    55.05
| train-epoch  37 |   400/ 2983 batches | lr 0.00 | ms/batch 59.07 | loss  4.03 | ppl    56.10
| train-epoch  37 |   600/ 2983 batches | lr 0.00 | ms/batch 59.08 | loss  3.86 | ppl    47.52
| train-epoch  37 |   800/ 2983 batches | lr 0.00 | ms/batch 59.03 | loss  3.90 | ppl    49.65
| train-epoch  37 |  1000/ 2983 batches | lr 0.00 | ms/batch 59.01 | loss  3.92 | ppl    50.22
| train-epoch  37 |  1200/ 2983 batches | lr 0.00 | ms/batch 58.94 | loss  3.91 | ppl    49.88
| train-epoch  37 |  1400/ 2983 batches | lr 0.00 | ms/batch 59.03 | loss  3.96 | ppl    52.48
| train-epoch  37 |  1600/ 2983 batches | lr 0.00 | ms/batch 59.01 | loss  4.01 | ppl    55.25
| train-epoch  37 |  1800/ 2983 batches | lr 0.00 | ms/batch 59.03 | loss  3.90 | ppl    49.19
| train-epoch  37 |  2000/ 2983 batches | lr 0.00 | ms/batch 59.04 | loss  3.91 | ppl    49.99
| train-epoch  37 |  2200/ 2983 batches | lr 0.00 | ms/batch 59.01 | loss  3.79 | ppl    44.07
| train-epoch  37 |  2400/ 2983 batches | lr 0.00 | ms/batch 58.98 | loss  3.81 | ppl    45.05
| train-epoch  37 |  2600/ 2983 batches | lr 0.00 | ms/batch 59.06 | loss  3.85 | ppl    46.85
| train-epoch  37 |  2800/ 2983 batches | lr 0.00 | ms/batch 59.02 | loss  3.79 | ppl    44.19
-----------------------------------------------------------------------------------------
| end of train epoch  37 | time: 183.04s | valid loss  4.56 | valid ppl    95.56
-----------------------------------------------------------------------------------------
| train-epoch  38 |   200/ 2983 batches | lr 0.00 | ms/batch 60.04 | loss  4.00 | ppl    54.78
| train-epoch  38 |   400/ 2983 batches | lr 0.00 | ms/batch 59.68 | loss  4.03 | ppl    56.18
| train-epoch  38 |   600/ 2983 batches | lr 0.00 | ms/batch 59.60 | loss  3.85 | ppl    47.14
| train-epoch  38 |   800/ 2983 batches | lr 0.00 | ms/batch 59.67 | loss  3.90 | ppl    49.37
| train-epoch  38 |  1000/ 2983 batches | lr 0.00 | ms/batch 59.67 | loss  3.92 | ppl    50.20
| train-epoch  38 |  1200/ 2983 batches | lr 0.00 | ms/batch 59.73 | loss  3.92 | ppl    50.19
| train-epoch  38 |  1400/ 2983 batches | lr 0.00 | ms/batch 59.60 | loss  3.96 | ppl    52.55
| train-epoch  38 |  1600/ 2983 batches | lr 0.00 | ms/batch 59.86 | loss  4.02 | ppl    55.47
| train-epoch  38 |  1800/ 2983 batches | lr 0.00 | ms/batch 59.58 | loss  3.89 | ppl    48.96
| train-epoch  38 |  2000/ 2983 batches | lr 0.00 | ms/batch 59.67 | loss  3.92 | ppl    50.22
| train-epoch  38 |  2200/ 2983 batches | lr 0.00 | ms/batch 59.75 | loss  3.79 | ppl    44.46
| train-epoch  38 |  2400/ 2983 batches | lr 0.00 | ms/batch 59.86 | loss  3.81 | ppl    45.15
| train-epoch  38 |  2600/ 2983 batches | lr 0.00 | ms/batch 59.70 | loss  3.85 | ppl    47.03
| train-epoch  38 |  2800/ 2983 batches | lr 0.00 | ms/batch 59.68 | loss  3.79 | ppl    44.28
-----------------------------------------------------------------------------------------
| end of train epoch  38 | time: 185.03s | valid loss  4.56 | valid ppl    95.56
-----------------------------------------------------------------------------------------
| train-epoch  39 |   200/ 2983 batches | lr 0.00 | ms/batch 59.94 | loss  4.00 | ppl    54.80
| train-epoch  39 |   400/ 2983 batches | lr 0.00 | ms/batch 59.66 | loss  4.03 | ppl    56.41
| train-epoch  39 |   600/ 2983 batches | lr 0.00 | ms/batch 59.53 | loss  3.85 | ppl    47.20
| train-epoch  39 |   800/ 2983 batches | lr 0.00 | ms/batch 59.63 | loss  3.90 | ppl    49.47
| train-epoch  39 |  1000/ 2983 batches | lr 0.00 | ms/batch 59.66 | loss  3.92 | ppl    50.39
| train-epoch  39 |  1200/ 2983 batches | lr 0.00 | ms/batch 59.47 | loss  3.91 | ppl    50.10
| train-epoch  39 |  1400/ 2983 batches | lr 0.00 | ms/batch 59.63 | loss  3.95 | ppl    52.19
| train-epoch  39 |  1600/ 2983 batches | lr 0.00 | ms/batch 59.54 | loss  4.01 | ppl    55.04
| train-epoch  39 |  1800/ 2983 batches | lr 0.00 | ms/batch 59.62 | loss  3.89 | ppl    48.98
| train-epoch  39 |  2000/ 2983 batches | lr 0.00 | ms/batch 59.68 | loss  3.91 | ppl    49.92
| train-epoch  39 |  2200/ 2983 batches | lr 0.00 | ms/batch 59.58 | loss  3.79 | ppl    44.45
| train-epoch  39 |  2400/ 2983 batches | lr 0.00 | ms/batch 59.49 | loss  3.81 | ppl    45.34
| train-epoch  39 |  2600/ 2983 batches | lr 0.00 | ms/batch 59.59 | loss  3.85 | ppl    46.85
| train-epoch  39 |  2800/ 2983 batches | lr 0.00 | ms/batch 59.53 | loss  3.79 | ppl    44.06
-----------------------------------------------------------------------------------------
| end of train epoch  39 | time: 184.73s | valid loss  4.56 | valid ppl    95.56
-----------------------------------------------------------------------------------------
| train-epoch  40 |   200/ 2983 batches | lr 0.00 | ms/batch 59.83 | loss  4.01 | ppl    54.90
| train-epoch  40 |   400/ 2983 batches | lr 0.00 | ms/batch 59.37 | loss  4.03 | ppl    56.52
| train-epoch  40 |   600/ 2983 batches | lr 0.00 | ms/batch 59.42 | loss  3.87 | ppl    47.75
| train-epoch  40 |   800/ 2983 batches | lr 0.00 | ms/batch 59.42 | loss  3.90 | ppl    49.49
| train-epoch  40 |  1000/ 2983 batches | lr 0.00 | ms/batch 59.47 | loss  3.92 | ppl    50.35
| train-epoch  40 |  1200/ 2983 batches | lr 0.00 | ms/batch 59.44 | loss  3.92 | ppl    50.18
| train-epoch  40 |  1400/ 2983 batches | lr 0.00 | ms/batch 59.36 | loss  3.96 | ppl    52.36
| train-epoch  40 |  1600/ 2983 batches | lr 0.00 | ms/batch 59.29 | loss  4.01 | ppl    54.92
| train-epoch  40 |  1800/ 2983 batches | lr 0.00 | ms/batch 59.36 | loss  3.90 | ppl    49.31
| train-epoch  40 |  2000/ 2983 batches | lr 0.00 | ms/batch 59.41 | loss  3.91 | ppl    50.13
| train-epoch  40 |  2200/ 2983 batches | lr 0.00 | ms/batch 59.42 | loss  3.80 | ppl    44.64
| train-epoch  40 |  2400/ 2983 batches | lr 0.00 | ms/batch 59.37 | loss  3.81 | ppl    45.20
| train-epoch  40 |  2600/ 2983 batches | lr 0.00 | ms/batch 59.39 | loss  3.85 | ppl    46.89
| train-epoch  40 |  2800/ 2983 batches | lr 0.00 | ms/batch 59.36 | loss  3.78 | ppl    43.91
-----------------------------------------------------------------------------------------
| end of train epoch  40 | time: 184.15s | valid loss  4.56 | valid ppl    95.56
-----------------------------------------------------------------------------------------
required epochs  40 | actual epochs  60
pretrain epochs  40 | prune epochs   0 | retrain epochs  20
=========================================================================================
| End of training | test loss  4.51 | test ppl    90.65
=========================================================================================
python main.py --cuda --emsize 1500 --nhid 1500 --dropout 0.65 --epochs 40 --tied --save model/baseline/model.pt
<class 'torch.Tensor'> torch.Size([33278, 1500])
<class 'torch.Tensor'> torch.Size([6000, 1500])
<class 'torch.Tensor'> torch.Size([6000, 1500])
<class 'torch.Tensor'> torch.Size([6000])
<class 'torch.Tensor'> torch.Size([6000])
<class 'torch.Tensor'> torch.Size([6000, 1500])
<class 'torch.Tensor'> torch.Size([6000, 1500])
<class 'torch.Tensor'> torch.Size([6000])
<class 'torch.Tensor'> torch.Size([6000])
<class 'torch.Tensor'> torch.Size([33278])
RNNModel(
  (drop): Dropout(p=0.65)
  (encoder): Embedding(33278, 1500)
  (rnn): LSTM(1500, 1500, num_layers=2, dropout=0.65)
  (decoder): Linear(in_features=1500, out_features=33278, bias=True)
)
Dropout(p=0.65)
Embedding(33278, 1500)
LSTM(1500, 1500, num_layers=2, dropout=0.65)
Linear(in_features=1500, out_features=33278, bias=True)
| train-epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 57.74 | loss  7.94 | ppl  2819.11
| train-epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 57.26 | loss  6.84 | ppl   932.80
| train-epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 57.26 | loss  6.45 | ppl   631.39
| train-epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 57.35 | loss  6.30 | ppl   545.28
| train-epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.40 | loss  6.18 | ppl   484.46
| train-epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.36 | loss  6.12 | ppl   456.78
| train-epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.43 | loss  6.02 | ppl   411.93
| train-epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.43 | loss  6.03 | ppl   415.18
| train-epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.37 | loss  5.89 | ppl   359.80
| train-epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.47 | loss  5.86 | ppl   350.21
| train-epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.48 | loss  5.75 | ppl   313.41
| train-epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.46 | loss  5.76 | ppl   315.83
| train-epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.50 | loss  5.74 | ppl   311.87
| train-epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.51 | loss  5.64 | ppl   280.54
-----------------------------------------------------------------------------------------
| end of train epoch   1 | time: 178.22s | valid loss  5.48 | valid ppl   239.88
-----------------------------------------------------------------------------------------
| train-epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch 57.43 | loss  5.63 | ppl   278.30
| train-epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch 57.13 | loss  5.61 | ppl   272.19
| train-epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch 57.12 | loss  5.44 | ppl   230.34
| train-epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch 57.09 | loss  5.46 | ppl   234.93
| train-epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.11 | loss  5.43 | ppl   228.03
| train-epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.04 | loss  5.43 | ppl   227.51
| train-epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.11 | loss  5.42 | ppl   225.48
| train-epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.12 | loss  5.47 | ppl   237.33
| train-epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.10 | loss  5.34 | ppl   209.24
| train-epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.11 | loss  5.36 | ppl   213.39
| train-epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.12 | loss  5.27 | ppl   193.91
| train-epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.04 | loss  5.30 | ppl   200.47
| train-epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.12 | loss  5.31 | ppl   201.41
| train-epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.15 | loss  5.23 | ppl   186.55
-----------------------------------------------------------------------------------------
| end of train epoch   2 | time: 177.33s | valid loss  5.15 | valid ppl   172.05
-----------------------------------------------------------------------------------------
| train-epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 58.04 | loss  5.27 | ppl   194.85
| train-epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch 57.80 | loss  5.28 | ppl   196.78
| train-epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 57.64 | loss  5.10 | ppl   164.81
| train-epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 57.68 | loss  5.15 | ppl   172.29
| train-epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.71 | loss  5.14 | ppl   169.88
| train-epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.71 | loss  5.13 | ppl   169.72
| train-epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.72 | loss  5.15 | ppl   172.79
| train-epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.71 | loss  5.22 | ppl   184.48
| train-epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.64 | loss  5.09 | ppl   162.91
| train-epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.71 | loss  5.13 | ppl   168.49
| train-epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.70 | loss  5.03 | ppl   153.33
| train-epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.77 | loss  5.06 | ppl   158.08
| train-epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.74 | loss  5.08 | ppl   160.48
| train-epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.72 | loss  5.01 | ppl   149.50
-----------------------------------------------------------------------------------------
| end of train epoch   3 | time: 179.11s | valid loss  5.00 | valid ppl   148.08
-----------------------------------------------------------------------------------------
| train-epoch   4 |   200/ 2983 batches | lr 20.00 | ms/batch 58.01 | loss  5.06 | ppl   157.43
| train-epoch   4 |   400/ 2983 batches | lr 20.00 | ms/batch 57.75 | loss  5.08 | ppl   160.41
| train-epoch   4 |   600/ 2983 batches | lr 20.00 | ms/batch 57.69 | loss  4.90 | ppl   134.39
| train-epoch   4 |   800/ 2983 batches | lr 20.00 | ms/batch 57.71 | loss  4.96 | ppl   142.06
| train-epoch   4 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.66 | loss  4.95 | ppl   140.84
| train-epoch   4 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.63 | loss  4.95 | ppl   141.43
| train-epoch   4 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.66 | loss  4.98 | ppl   145.90
| train-epoch   4 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.65 | loss  5.05 | ppl   155.91
| train-epoch   4 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.70 | loss  4.92 | ppl   137.31
| train-epoch   4 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.69 | loss  4.97 | ppl   143.83
| train-epoch   4 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.69 | loss  4.86 | ppl   129.11
| train-epoch   4 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.69 | loss  4.90 | ppl   134.12
| train-epoch   4 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.63 | loss  4.92 | ppl   137.00
| train-epoch   4 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.67 | loss  4.86 | ppl   128.44
-----------------------------------------------------------------------------------------
| end of train epoch   4 | time: 179.03s | valid loss  4.90 | valid ppl   134.17
-----------------------------------------------------------------------------------------
| train-epoch   5 |   200/ 2983 batches | lr 20.00 | ms/batch 57.83 | loss  4.91 | ppl   135.21
| train-epoch   5 |   400/ 2983 batches | lr 20.00 | ms/batch 57.64 | loss  4.93 | ppl   138.26
| train-epoch   5 |   600/ 2983 batches | lr 20.00 | ms/batch 57.63 | loss  4.75 | ppl   115.60
| train-epoch   5 |   800/ 2983 batches | lr 20.00 | ms/batch 57.68 | loss  4.81 | ppl   123.24
| train-epoch   5 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.65 | loss  4.81 | ppl   122.36
| train-epoch   5 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.58 | loss  4.82 | ppl   124.10
| train-epoch   5 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.60 | loss  4.85 | ppl   128.10
| train-epoch   5 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.58 | loss  4.92 | ppl   136.80
| train-epoch   5 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.58 | loss  4.80 | ppl   121.05
| train-epoch   5 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.47 | loss  4.84 | ppl   126.95
| train-epoch   5 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.55 | loss  4.73 | ppl   113.85
| train-epoch   5 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.61 | loss  4.77 | ppl   118.28
| train-epoch   5 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.68 | loss  4.80 | ppl   121.23
| train-epoch   5 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.56 | loss  4.73 | ppl   113.85
-----------------------------------------------------------------------------------------
| end of train epoch   5 | time: 178.76s | valid loss  4.83 | valid ppl   124.83
-----------------------------------------------------------------------------------------
| train-epoch   6 |   200/ 2983 batches | lr 20.00 | ms/batch 58.02 | loss  4.79 | ppl   120.22
| train-epoch   6 |   400/ 2983 batches | lr 20.00 | ms/batch 57.72 | loss  4.82 | ppl   123.36
| train-epoch   6 |   600/ 2983 batches | lr 20.00 | ms/batch 57.70 | loss  4.63 | ppl   102.79
| train-epoch   6 |   800/ 2983 batches | lr 20.00 | ms/batch 57.70 | loss  4.69 | ppl   109.12
| train-epoch   6 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.72 | loss  4.70 | ppl   109.52
| train-epoch   6 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.74 | loss  4.70 | ppl   110.40
| train-epoch   6 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.63 | loss  4.75 | ppl   115.13
| train-epoch   6 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.74 | loss  4.82 | ppl   123.53
| train-epoch   6 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.76 | loss  4.70 | ppl   109.55
| train-epoch   6 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.87 | loss  4.74 | ppl   114.40
| train-epoch   6 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.85 | loss  4.63 | ppl   102.59
| train-epoch   6 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.79 | loss  4.67 | ppl   106.96
| train-epoch   6 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.71 | loss  4.70 | ppl   109.44
| train-epoch   6 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.77 | loss  4.64 | ppl   103.44
-----------------------------------------------------------------------------------------
| end of train epoch   6 | time: 179.22s | valid loss  4.77 | valid ppl   118.48
-----------------------------------------------------------------------------------------
| train-epoch   7 |   200/ 2983 batches | lr 20.00 | ms/batch 58.17 | loss  4.69 | ppl   109.02
| train-epoch   7 |   400/ 2983 batches | lr 20.00 | ms/batch 57.84 | loss  4.72 | ppl   112.02
| train-epoch   7 |   600/ 2983 batches | lr 20.00 | ms/batch 57.88 | loss  4.53 | ppl    93.17
| train-epoch   7 |   800/ 2983 batches | lr 20.00 | ms/batch 57.79 | loss  4.60 | ppl    99.25
| train-epoch   7 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.80 | loss  4.60 | ppl    99.61
| train-epoch   7 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.83 | loss  4.62 | ppl   101.09
| train-epoch   7 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.81 | loss  4.66 | ppl   105.46
| train-epoch   7 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.85 | loss  4.73 | ppl   113.13
| train-epoch   7 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.85 | loss  4.61 | ppl   100.93
| train-epoch   7 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.79 | loss  4.66 | ppl   105.46
| train-epoch   7 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.84 | loss  4.54 | ppl    93.76
| train-epoch   7 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.87 | loss  4.58 | ppl    97.64
| train-epoch   7 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.92 | loss  4.61 | ppl   100.75
| train-epoch   7 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.83 | loss  4.56 | ppl    95.22
-----------------------------------------------------------------------------------------
| end of train epoch   7 | time: 179.54s | valid loss  4.74 | valid ppl   114.55
-----------------------------------------------------------------------------------------
| train-epoch   8 |   200/ 2983 batches | lr 20.00 | ms/batch 58.21 | loss  4.61 | ppl   100.50
| train-epoch   8 |   400/ 2983 batches | lr 20.00 | ms/batch 57.86 | loss  4.63 | ppl   103.02
| train-epoch   8 |   600/ 2983 batches | lr 20.00 | ms/batch 57.95 | loss  4.45 | ppl    85.57
| train-epoch   8 |   800/ 2983 batches | lr 20.00 | ms/batch 57.87 | loss  4.51 | ppl    91.28
| train-epoch   8 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.96 | loss  4.53 | ppl    92.62
| train-epoch   8 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.91 | loss  4.54 | ppl    93.30
| train-epoch   8 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.86 | loss  4.58 | ppl    97.92
| train-epoch   8 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.95 | loss  4.65 | ppl   105.00
| train-epoch   8 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.98 | loss  4.55 | ppl    94.19
| train-epoch   8 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.96 | loss  4.58 | ppl    97.38
| train-epoch   8 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.88 | loss  4.47 | ppl    87.04
| train-epoch   8 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.90 | loss  4.51 | ppl    90.86
| train-epoch   8 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.91 | loss  4.54 | ppl    93.70
| train-epoch   8 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.02 | loss  4.48 | ppl    88.17
-----------------------------------------------------------------------------------------
| end of train epoch   8 | time: 179.79s | valid loss  4.73 | valid ppl   112.73
-----------------------------------------------------------------------------------------
| train-epoch   9 |   200/ 2983 batches | lr 20.00 | ms/batch 57.69 | loss  4.54 | ppl    93.53
| train-epoch   9 |   400/ 2983 batches | lr 20.00 | ms/batch 57.38 | loss  4.56 | ppl    95.57
| train-epoch   9 |   600/ 2983 batches | lr 20.00 | ms/batch 57.35 | loss  4.38 | ppl    79.91
| train-epoch   9 |   800/ 2983 batches | lr 20.00 | ms/batch 57.16 | loss  4.44 | ppl    84.43
| train-epoch   9 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.27 | loss  4.46 | ppl    86.79
| train-epoch   9 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.27 | loss  4.47 | ppl    87.59
| train-epoch   9 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.29 | loss  4.51 | ppl    91.29
| train-epoch   9 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.30 | loss  4.59 | ppl    98.53
| train-epoch   9 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.28 | loss  4.48 | ppl    88.15
| train-epoch   9 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.26 | loss  4.51 | ppl    91.25
| train-epoch   9 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.31 | loss  4.40 | ppl    81.26
| train-epoch   9 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.23 | loss  4.44 | ppl    85.16
| train-epoch   9 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.25 | loss  4.48 | ppl    87.96
| train-epoch   9 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.21 | loss  4.42 | ppl    83.38
-----------------------------------------------------------------------------------------
| end of train epoch   9 | time: 177.84s | valid loss  4.69 | valid ppl   108.87
-----------------------------------------------------------------------------------------
| train-epoch  10 |   200/ 2983 batches | lr 20.00 | ms/batch 58.12 | loss  4.47 | ppl    87.60
| train-epoch  10 |   400/ 2983 batches | lr 20.00 | ms/batch 57.88 | loss  4.49 | ppl    89.52
| train-epoch  10 |   600/ 2983 batches | lr 20.00 | ms/batch 57.90 | loss  4.32 | ppl    74.99
| train-epoch  10 |   800/ 2983 batches | lr 20.00 | ms/batch 57.92 | loss  4.37 | ppl    79.30
| train-epoch  10 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.96 | loss  4.40 | ppl    81.38
| train-epoch  10 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.85 | loss  4.41 | ppl    82.56
| train-epoch  10 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.84 | loss  4.45 | ppl    85.60
| train-epoch  10 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.77 | loss  4.53 | ppl    92.63
| train-epoch  10 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.80 | loss  4.42 | ppl    82.98
| train-epoch  10 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.85 | loss  4.46 | ppl    86.47
| train-epoch  10 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.84 | loss  4.34 | ppl    76.48
| train-epoch  10 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.86 | loss  4.38 | ppl    79.67
| train-epoch  10 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.82 | loss  4.42 | ppl    82.86
| train-epoch  10 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.75 | loss  4.36 | ppl    78.64
-----------------------------------------------------------------------------------------
| end of train epoch  10 | time: 179.52s | valid loss  4.68 | valid ppl   107.53
-----------------------------------------------------------------------------------------
| train-epoch  11 |   200/ 2983 batches | lr 20.00 | ms/batch 58.16 | loss  4.41 | ppl    82.50
| train-epoch  11 |   400/ 2983 batches | lr 20.00 | ms/batch 57.79 | loss  4.44 | ppl    84.97
| train-epoch  11 |   600/ 2983 batches | lr 20.00 | ms/batch 57.77 | loss  4.26 | ppl    70.97
| train-epoch  11 |   800/ 2983 batches | lr 20.00 | ms/batch 57.70 | loss  4.32 | ppl    75.17
| train-epoch  11 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.66 | loss  4.35 | ppl    77.33
| train-epoch  11 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.72 | loss  4.36 | ppl    78.28
| train-epoch  11 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.74 | loss  4.39 | ppl    80.75
| train-epoch  11 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.76 | loss  4.48 | ppl    88.12
| train-epoch  11 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.76 | loss  4.37 | ppl    78.73
| train-epoch  11 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.79 | loss  4.41 | ppl    82.13
| train-epoch  11 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.71 | loss  4.29 | ppl    72.83
| train-epoch  11 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.81 | loss  4.33 | ppl    76.05
| train-epoch  11 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.91 | loss  4.36 | ppl    78.47
| train-epoch  11 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.90 | loss  4.31 | ppl    74.61
-----------------------------------------------------------------------------------------
| end of train epoch  11 | time: 179.34s | valid loss  4.65 | valid ppl   104.75
-----------------------------------------------------------------------------------------
| train-epoch  12 |   200/ 2983 batches | lr 20.00 | ms/batch 57.96 | loss  4.37 | ppl    78.72
| train-epoch  12 |   400/ 2983 batches | lr 20.00 | ms/batch 57.69 | loss  4.39 | ppl    80.28
| train-epoch  12 |   600/ 2983 batches | lr 20.00 | ms/batch 57.69 | loss  4.21 | ppl    67.09
| train-epoch  12 |   800/ 2983 batches | lr 20.00 | ms/batch 57.65 | loss  4.26 | ppl    71.09
| train-epoch  12 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.79 | loss  4.30 | ppl    73.52
| train-epoch  12 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.80 | loss  4.31 | ppl    74.47
| train-epoch  12 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.65 | loss  4.35 | ppl    77.47
| train-epoch  12 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.58 | loss  4.43 | ppl    83.84
| train-epoch  12 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.66 | loss  4.32 | ppl    75.18
| train-epoch  12 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.63 | loss  4.36 | ppl    78.16
| train-epoch  12 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.68 | loss  4.24 | ppl    69.24
| train-epoch  12 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.64 | loss  4.28 | ppl    71.93
| train-epoch  12 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.67 | loss  4.32 | ppl    74.94
| train-epoch  12 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.59 | loss  4.27 | ppl    71.37
-----------------------------------------------------------------------------------------
| end of train epoch  12 | time: 179.00s | valid loss  4.65 | valid ppl   104.81
-----------------------------------------------------------------------------------------
| train-epoch  13 |   200/ 2983 batches | lr 5.00 | ms/batch 58.16 | loss  4.34 | ppl    76.34
| train-epoch  13 |   400/ 2983 batches | lr 5.00 | ms/batch 57.84 | loss  4.33 | ppl    75.86
| train-epoch  13 |   600/ 2983 batches | lr 5.00 | ms/batch 57.84 | loss  4.13 | ppl    62.29
| train-epoch  13 |   800/ 2983 batches | lr 5.00 | ms/batch 57.81 | loss  4.17 | ppl    64.76
| train-epoch  13 |  1000/ 2983 batches | lr 5.00 | ms/batch 57.76 | loss  4.20 | ppl    66.51
| train-epoch  13 |  1200/ 2983 batches | lr 5.00 | ms/batch 57.82 | loss  4.19 | ppl    65.93
| train-epoch  13 |  1400/ 2983 batches | lr 5.00 | ms/batch 57.81 | loss  4.20 | ppl    67.01
| train-epoch  13 |  1600/ 2983 batches | lr 5.00 | ms/batch 57.86 | loss  4.28 | ppl    72.15
| train-epoch  13 |  1800/ 2983 batches | lr 5.00 | ms/batch 57.82 | loss  4.16 | ppl    63.80
| train-epoch  13 |  2000/ 2983 batches | lr 5.00 | ms/batch 57.86 | loss  4.19 | ppl    65.75
| train-epoch  13 |  2200/ 2983 batches | lr 5.00 | ms/batch 57.76 | loss  4.04 | ppl    56.93
| train-epoch  13 |  2400/ 2983 batches | lr 5.00 | ms/batch 57.83 | loss  4.07 | ppl    58.49
| train-epoch  13 |  2600/ 2983 batches | lr 5.00 | ms/batch 57.82 | loss  4.09 | ppl    60.00
| train-epoch  13 |  2800/ 2983 batches | lr 5.00 | ms/batch 57.79 | loss  4.04 | ppl    56.61
-----------------------------------------------------------------------------------------
| end of train epoch  13 | time: 179.46s | valid loss  4.57 | valid ppl    96.88
-----------------------------------------------------------------------------------------
| train-epoch  14 |   200/ 2983 batches | lr 5.00 | ms/batch 58.02 | loss  4.20 | ppl    66.54
| train-epoch  14 |   400/ 2983 batches | lr 5.00 | ms/batch 57.65 | loss  4.22 | ppl    67.77
| train-epoch  14 |   600/ 2983 batches | lr 5.00 | ms/batch 57.74 | loss  4.03 | ppl    56.16
| train-epoch  14 |   800/ 2983 batches | lr 5.00 | ms/batch 57.71 | loss  4.08 | ppl    58.91
| train-epoch  14 |  1000/ 2983 batches | lr 5.00 | ms/batch 57.71 | loss  4.10 | ppl    60.62
| train-epoch  14 |  1200/ 2983 batches | lr 5.00 | ms/batch 57.72 | loss  4.11 | ppl    61.23
| train-epoch  14 |  1400/ 2983 batches | lr 5.00 | ms/batch 57.68 | loss  4.13 | ppl    62.38
| train-epoch  14 |  1600/ 2983 batches | lr 5.00 | ms/batch 57.63 | loss  4.21 | ppl    67.38
| train-epoch  14 |  1800/ 2983 batches | lr 5.00 | ms/batch 57.69 | loss  4.10 | ppl    60.06
| train-epoch  14 |  2000/ 2983 batches | lr 5.00 | ms/batch 57.69 | loss  4.13 | ppl    62.26
| train-epoch  14 |  2200/ 2983 batches | lr 5.00 | ms/batch 57.70 | loss  3.99 | ppl    53.89
| train-epoch  14 |  2400/ 2983 batches | lr 5.00 | ms/batch 57.72 | loss  4.02 | ppl    55.54
| train-epoch  14 |  2600/ 2983 batches | lr 5.00 | ms/batch 57.71 | loss  4.05 | ppl    57.24
| train-epoch  14 |  2800/ 2983 batches | lr 5.00 | ms/batch 57.72 | loss  4.01 | ppl    54.91
-----------------------------------------------------------------------------------------
| end of train epoch  14 | time: 179.07s | valid loss  4.56 | valid ppl    96.02
-----------------------------------------------------------------------------------------
| train-epoch  15 |   200/ 2983 batches | lr 5.00 | ms/batch 58.11 | loss  4.14 | ppl    62.94
| train-epoch  15 |   400/ 2983 batches | lr 5.00 | ms/batch 57.80 | loss  4.16 | ppl    64.27
| train-epoch  15 |   600/ 2983 batches | lr 5.00 | ms/batch 57.76 | loss  3.98 | ppl    53.34
| train-epoch  15 |   800/ 2983 batches | lr 5.00 | ms/batch 57.79 | loss  4.02 | ppl    55.86
| train-epoch  15 |  1000/ 2983 batches | lr 5.00 | ms/batch 57.70 | loss  4.06 | ppl    57.72
| train-epoch  15 |  1200/ 2983 batches | lr 5.00 | ms/batch 57.76 | loss  4.06 | ppl    58.11
| train-epoch  15 |  1400/ 2983 batches | lr 5.00 | ms/batch 57.78 | loss  4.09 | ppl    59.86
| train-epoch  15 |  1600/ 2983 batches | lr 5.00 | ms/batch 57.78 | loss  4.16 | ppl    64.36
| train-epoch  15 |  1800/ 2983 batches | lr 5.00 | ms/batch 57.76 | loss  4.05 | ppl    57.67
| train-epoch  15 |  2000/ 2983 batches | lr 5.00 | ms/batch 57.81 | loss  4.09 | ppl    59.61
| train-epoch  15 |  2200/ 2983 batches | lr 5.00 | ms/batch 57.79 | loss  3.95 | ppl    51.88
| train-epoch  15 |  2400/ 2983 batches | lr 5.00 | ms/batch 57.72 | loss  3.98 | ppl    53.60
| train-epoch  15 |  2600/ 2983 batches | lr 5.00 | ms/batch 57.81 | loss  4.01 | ppl    55.03
| train-epoch  15 |  2800/ 2983 batches | lr 5.00 | ms/batch 57.82 | loss  3.97 | ppl    52.90
-----------------------------------------------------------------------------------------
| end of train epoch  15 | time: 179.33s | valid loss  4.55 | valid ppl    94.98
-----------------------------------------------------------------------------------------
| train-epoch  16 |   200/ 2983 batches | lr 5.00 | ms/batch 57.58 | loss  4.10 | ppl    60.07
| train-epoch  16 |   400/ 2983 batches | lr 5.00 | ms/batch 57.23 | loss  4.12 | ppl    61.77
| train-epoch  16 |   600/ 2983 batches | lr 5.00 | ms/batch 57.25 | loss  3.94 | ppl    51.28
| train-epoch  16 |   800/ 2983 batches | lr 5.00 | ms/batch 57.27 | loss  3.98 | ppl    53.56
| train-epoch  16 |  1000/ 2983 batches | lr 5.00 | ms/batch 57.29 | loss  4.02 | ppl    55.61
| train-epoch  16 |  1200/ 2983 batches | lr 5.00 | ms/batch 57.26 | loss  4.02 | ppl    55.86
| train-epoch  16 |  1400/ 2983 batches | lr 5.00 | ms/batch 57.26 | loss  4.05 | ppl    57.48
| train-epoch  16 |  1600/ 2983 batches | lr 5.00 | ms/batch 57.28 | loss  4.13 | ppl    62.03
| train-epoch  16 |  1800/ 2983 batches | lr 5.00 | ms/batch 57.20 | loss  4.01 | ppl    55.19
| train-epoch  16 |  2000/ 2983 batches | lr 5.00 | ms/batch 57.24 | loss  4.06 | ppl    57.79
| train-epoch  16 |  2200/ 2983 batches | lr 5.00 | ms/batch 57.23 | loss  3.92 | ppl    50.57
| train-epoch  16 |  2400/ 2983 batches | lr 5.00 | ms/batch 57.23 | loss  3.95 | ppl    51.80
| train-epoch  16 |  2600/ 2983 batches | lr 5.00 | ms/batch 57.23 | loss  3.97 | ppl    53.18
| train-epoch  16 |  2800/ 2983 batches | lr 5.00 | ms/batch 57.26 | loss  3.94 | ppl    51.23
-----------------------------------------------------------------------------------------
| end of train epoch  16 | time: 177.74s | valid loss  4.56 | valid ppl    95.41
-----------------------------------------------------------------------------------------
| train-epoch  17 |   200/ 2983 batches | lr 1.25 | ms/batch 58.17 | loss  4.08 | ppl    59.43
| train-epoch  17 |   400/ 2983 batches | lr 1.25 | ms/batch 57.84 | loss  4.12 | ppl    61.28
| train-epoch  17 |   600/ 2983 batches | lr 1.25 | ms/batch 57.84 | loss  3.92 | ppl    50.37
| train-epoch  17 |   800/ 2983 batches | lr 1.25 | ms/batch 57.86 | loss  3.97 | ppl    53.06
| train-epoch  17 |  1000/ 2983 batches | lr 1.25 | ms/batch 57.86 | loss  4.01 | ppl    54.93
| train-epoch  17 |  1200/ 2983 batches | lr 1.25 | ms/batch 57.77 | loss  4.00 | ppl    54.59
| train-epoch  17 |  1400/ 2983 batches | lr 1.25 | ms/batch 57.86 | loss  4.03 | ppl    56.10
| train-epoch  17 |  1600/ 2983 batches | lr 1.25 | ms/batch 57.82 | loss  4.09 | ppl    59.99
| train-epoch  17 |  1800/ 2983 batches | lr 1.25 | ms/batch 57.82 | loss  3.99 | ppl    53.94
| train-epoch  17 |  2000/ 2983 batches | lr 1.25 | ms/batch 57.80 | loss  4.00 | ppl    54.75
| train-epoch  17 |  2200/ 2983 batches | lr 1.25 | ms/batch 57.86 | loss  3.88 | ppl    48.42
| train-epoch  17 |  2400/ 2983 batches | lr 1.25 | ms/batch 57.78 | loss  3.91 | ppl    49.79
| train-epoch  17 |  2600/ 2983 batches | lr 1.25 | ms/batch 57.84 | loss  3.93 | ppl    50.98
| train-epoch  17 |  2800/ 2983 batches | lr 1.25 | ms/batch 57.85 | loss  3.89 | ppl    48.69
-----------------------------------------------------------------------------------------
| end of train epoch  17 | time: 179.50s | valid loss  4.52 | valid ppl    92.02
-----------------------------------------------------------------------------------------
| train-epoch  18 |   200/ 2983 batches | lr 1.25 | ms/batch 58.09 | loss  4.06 | ppl    57.76
| train-epoch  18 |   400/ 2983 batches | lr 1.25 | ms/batch 57.73 | loss  4.08 | ppl    59.16
| train-epoch  18 |   600/ 2983 batches | lr 1.25 | ms/batch 57.71 | loss  3.90 | ppl    49.27
| train-epoch  18 |   800/ 2983 batches | lr 1.25 | ms/batch 57.81 | loss  3.94 | ppl    51.19
| train-epoch  18 |  1000/ 2983 batches | lr 1.25 | ms/batch 57.72 | loss  3.98 | ppl    53.51
| train-epoch  18 |  1200/ 2983 batches | lr 1.25 | ms/batch 57.75 | loss  3.97 | ppl    53.24
| train-epoch  18 |  1400/ 2983 batches | lr 1.25 | ms/batch 57.74 | loss  4.00 | ppl    54.76
| train-epoch  18 |  1600/ 2983 batches | lr 1.25 | ms/batch 57.74 | loss  4.07 | ppl    58.65
| train-epoch  18 |  1800/ 2983 batches | lr 1.25 | ms/batch 57.67 | loss  3.97 | ppl    53.19
| train-epoch  18 |  2000/ 2983 batches | lr 1.25 | ms/batch 57.78 | loss  3.99 | ppl    54.17
| train-epoch  18 |  2200/ 2983 batches | lr 1.25 | ms/batch 57.77 | loss  3.86 | ppl    47.55
| train-epoch  18 |  2400/ 2983 batches | lr 1.25 | ms/batch 57.74 | loss  3.89 | ppl    48.76
| train-epoch  18 |  2600/ 2983 batches | lr 1.25 | ms/batch 57.79 | loss  3.92 | ppl    50.26
| train-epoch  18 |  2800/ 2983 batches | lr 1.25 | ms/batch 57.75 | loss  3.87 | ppl    48.09
-----------------------------------------------------------------------------------------
| end of train epoch  18 | time: 179.22s | valid loss  4.52 | valid ppl    91.77
-----------------------------------------------------------------------------------------
| train-epoch  19 |   200/ 2983 batches | lr 1.25 | ms/batch 57.95 | loss  4.03 | ppl    56.26
| train-epoch  19 |   400/ 2983 batches | lr 1.25 | ms/batch 57.64 | loss  4.06 | ppl    57.97
| train-epoch  19 |   600/ 2983 batches | lr 1.25 | ms/batch 57.63 | loss  3.87 | ppl    48.05
| train-epoch  19 |   800/ 2983 batches | lr 1.25 | ms/batch 57.72 | loss  3.92 | ppl    50.57
| train-epoch  19 |  1000/ 2983 batches | lr 1.25 | ms/batch 57.76 | loss  3.96 | ppl    52.25
| train-epoch  19 |  1200/ 2983 batches | lr 1.25 | ms/batch 57.58 | loss  3.96 | ppl    52.70
| train-epoch  19 |  1400/ 2983 batches | lr 1.25 | ms/batch 57.68 | loss  3.99 | ppl    53.88
| train-epoch  19 |  1600/ 2983 batches | lr 1.25 | ms/batch 57.67 | loss  4.06 | ppl    57.89
| train-epoch  19 |  1800/ 2983 batches | lr 1.25 | ms/batch 57.66 | loss  3.96 | ppl    52.48
| train-epoch  19 |  2000/ 2983 batches | lr 1.25 | ms/batch 57.63 | loss  3.98 | ppl    53.57
| train-epoch  19 |  2200/ 2983 batches | lr 1.25 | ms/batch 57.69 | loss  3.86 | ppl    47.27
| train-epoch  19 |  2400/ 2983 batches | lr 1.25 | ms/batch 57.61 | loss  3.88 | ppl    48.25
| train-epoch  19 |  2600/ 2983 batches | lr 1.25 | ms/batch 57.60 | loss  3.90 | ppl    49.38
| train-epoch  19 |  2800/ 2983 batches | lr 1.25 | ms/batch 57.66 | loss  3.86 | ppl    47.53
-----------------------------------------------------------------------------------------
| end of train epoch  19 | time: 178.97s | valid loss  4.52 | valid ppl    91.56
-----------------------------------------------------------------------------------------
| train-epoch  20 |   200/ 2983 batches | lr 1.25 | ms/batch 58.13 | loss  4.02 | ppl    55.61
| train-epoch  20 |   400/ 2983 batches | lr 1.25 | ms/batch 57.79 | loss  4.05 | ppl    57.40
| train-epoch  20 |   600/ 2983 batches | lr 1.25 | ms/batch 57.68 | loss  3.86 | ppl    47.44
| train-epoch  20 |   800/ 2983 batches | lr 1.25 | ms/batch 57.77 | loss  3.90 | ppl    49.40
| train-epoch  20 |  1000/ 2983 batches | lr 1.25 | ms/batch 57.81 | loss  3.95 | ppl    51.75
| train-epoch  20 |  1200/ 2983 batches | lr 1.25 | ms/batch 57.78 | loss  3.96 | ppl    52.20
| train-epoch  20 |  1400/ 2983 batches | lr 1.25 | ms/batch 57.76 | loss  3.97 | ppl    53.25
| train-epoch  20 |  1600/ 2983 batches | lr 1.25 | ms/batch 57.77 | loss  4.04 | ppl    56.89
| train-epoch  20 |  1800/ 2983 batches | lr 1.25 | ms/batch 57.76 | loss  3.95 | ppl    51.98
| train-epoch  20 |  2000/ 2983 batches | lr 1.25 | ms/batch 57.37 | loss  3.96 | ppl    52.65
| train-epoch  20 |  2200/ 2983 batches | lr 1.25 | ms/batch 57.27 | loss  3.84 | ppl    46.53
| train-epoch  20 |  2400/ 2983 batches | lr 1.25 | ms/batch 57.64 | loss  3.87 | ppl    47.79
| train-epoch  20 |  2600/ 2983 batches | lr 1.25 | ms/batch 57.88 | loss  3.89 | ppl    48.76
| train-epoch  20 |  2800/ 2983 batches | lr 1.25 | ms/batch 57.87 | loss  3.85 | ppl    47.13
-----------------------------------------------------------------------------------------
| end of train epoch  20 | time: 179.17s | valid loss  4.51 | valid ppl    91.37
-----------------------------------------------------------------------------------------
| train-epoch  21 |   200/ 2983 batches | lr 1.25 | ms/batch 58.21 | loss  4.01 | ppl    54.87
| train-epoch  21 |   400/ 2983 batches | lr 1.25 | ms/batch 57.75 | loss  4.03 | ppl    56.44
| train-epoch  21 |   600/ 2983 batches | lr 1.25 | ms/batch 57.92 | loss  3.85 | ppl    47.13
| train-epoch  21 |   800/ 2983 batches | lr 1.25 | ms/batch 58.13 | loss  3.89 | ppl    48.75
| train-epoch  21 |  1000/ 2983 batches | lr 1.25 | ms/batch 58.00 | loss  3.94 | ppl    51.33
| train-epoch  21 |  1200/ 2983 batches | lr 1.25 | ms/batch 57.78 | loss  3.95 | ppl    51.92
| train-epoch  21 |  1400/ 2983 batches | lr 1.25 | ms/batch 57.80 | loss  3.96 | ppl    52.46
| train-epoch  21 |  1600/ 2983 batches | lr 1.25 | ms/batch 57.70 | loss  4.03 | ppl    56.39
| train-epoch  21 |  1800/ 2983 batches | lr 1.25 | ms/batch 57.85 | loss  3.94 | ppl    51.40
| train-epoch  21 |  2000/ 2983 batches | lr 1.25 | ms/batch 57.94 | loss  3.95 | ppl    51.84
| train-epoch  21 |  2200/ 2983 batches | lr 1.25 | ms/batch 57.92 | loss  3.83 | ppl    46.25
| train-epoch  21 |  2400/ 2983 batches | lr 1.25 | ms/batch 57.87 | loss  3.86 | ppl    47.25
| train-epoch  21 |  2600/ 2983 batches | lr 1.25 | ms/batch 57.82 | loss  3.88 | ppl    48.65
| train-epoch  21 |  2800/ 2983 batches | lr 1.25 | ms/batch 57.72 | loss  3.84 | ppl    46.65
-----------------------------------------------------------------------------------------
| end of train epoch  21 | time: 179.58s | valid loss  4.51 | valid ppl    91.29
-----------------------------------------------------------------------------------------
| train-epoch  22 |   200/ 2983 batches | lr 1.25 | ms/batch 58.22 | loss  3.99 | ppl    54.08
| train-epoch  22 |   400/ 2983 batches | lr 1.25 | ms/batch 57.86 | loss  4.02 | ppl    55.89
| train-epoch  22 |   600/ 2983 batches | lr 1.25 | ms/batch 57.90 | loss  3.84 | ppl    46.70
| train-epoch  22 |   800/ 2983 batches | lr 1.25 | ms/batch 57.86 | loss  3.87 | ppl    48.06
| train-epoch  22 |  1000/ 2983 batches | lr 1.25 | ms/batch 57.79 | loss  3.92 | ppl    50.59
| train-epoch  22 |  1200/ 2983 batches | lr 1.25 | ms/batch 57.90 | loss  3.93 | ppl    50.98
| train-epoch  22 |  1400/ 2983 batches | lr 1.25 | ms/batch 57.88 | loss  3.94 | ppl    51.58
| train-epoch  22 |  1600/ 2983 batches | lr 1.25 | ms/batch 57.92 | loss  4.02 | ppl    55.65
| train-epoch  22 |  1800/ 2983 batches | lr 1.25 | ms/batch 57.83 | loss  3.92 | ppl    50.58
| train-epoch  22 |  2000/ 2983 batches | lr 1.25 | ms/batch 57.82 | loss  3.94 | ppl    51.66
| train-epoch  22 |  2200/ 2983 batches | lr 1.25 | ms/batch 57.76 | loss  3.83 | ppl    45.91
| train-epoch  22 |  2400/ 2983 batches | lr 1.25 | ms/batch 57.82 | loss  3.85 | ppl    47.04
| train-epoch  22 |  2600/ 2983 batches | lr 1.25 | ms/batch 57.77 | loss  3.87 | ppl    47.94
| train-epoch  22 |  2800/ 2983 batches | lr 1.25 | ms/batch 57.80 | loss  3.84 | ppl    46.49
-----------------------------------------------------------------------------------------
| end of train epoch  22 | time: 179.52s | valid loss  4.51 | valid ppl    91.19
-----------------------------------------------------------------------------------------
| train-epoch  23 |   200/ 2983 batches | lr 1.25 | ms/batch 57.62 | loss  3.98 | ppl    53.34
| train-epoch  23 |   400/ 2983 batches | lr 1.25 | ms/batch 57.33 | loss  4.01 | ppl    55.34
| train-epoch  23 |   600/ 2983 batches | lr 1.25 | ms/batch 57.36 | loss  3.82 | ppl    45.82
| train-epoch  23 |   800/ 2983 batches | lr 1.25 | ms/batch 57.38 | loss  3.86 | ppl    47.44
| train-epoch  23 |  1000/ 2983 batches | lr 1.25 | ms/batch 57.33 | loss  3.91 | ppl    49.70
| train-epoch  23 |  1200/ 2983 batches | lr 1.25 | ms/batch 57.33 | loss  3.93 | ppl    50.73
| train-epoch  23 |  1400/ 2983 batches | lr 1.25 | ms/batch 57.27 | loss  3.94 | ppl    51.23
| train-epoch  23 |  1600/ 2983 batches | lr 1.25 | ms/batch 57.27 | loss  4.01 | ppl    55.36
| train-epoch  23 |  1800/ 2983 batches | lr 1.25 | ms/batch 57.30 | loss  3.92 | ppl    50.20
| train-epoch  23 |  2000/ 2983 batches | lr 1.25 | ms/batch 57.33 | loss  3.93 | ppl    51.13
| train-epoch  23 |  2200/ 2983 batches | lr 1.25 | ms/batch 57.33 | loss  3.82 | ppl    45.54
| train-epoch  23 |  2400/ 2983 batches | lr 1.25 | ms/batch 57.30 | loss  3.84 | ppl    46.43
| train-epoch  23 |  2600/ 2983 batches | lr 1.25 | ms/batch 57.27 | loss  3.86 | ppl    47.32
| train-epoch  23 |  2800/ 2983 batches | lr 1.25 | ms/batch 57.22 | loss  3.83 | ppl    45.88
-----------------------------------------------------------------------------------------
| end of train epoch  23 | time: 177.97s | valid loss  4.51 | valid ppl    90.84
-----------------------------------------------------------------------------------------
| train-epoch  24 |   200/ 2983 batches | lr 1.25 | ms/batch 58.39 | loss  3.96 | ppl    52.71
| train-epoch  24 |   400/ 2983 batches | lr 1.25 | ms/batch 58.06 | loss  4.00 | ppl    54.83
| train-epoch  24 |   600/ 2983 batches | lr 1.25 | ms/batch 58.06 | loss  3.81 | ppl    45.37
| train-epoch  24 |   800/ 2983 batches | lr 1.25 | ms/batch 57.96 | loss  3.85 | ppl    47.06
| train-epoch  24 |  1000/ 2983 batches | lr 1.25 | ms/batch 58.02 | loss  3.90 | ppl    49.42
| train-epoch  24 |  1200/ 2983 batches | lr 1.25 | ms/batch 57.91 | loss  3.91 | ppl    49.78
| train-epoch  24 |  1400/ 2983 batches | lr 1.25 | ms/batch 57.91 | loss  3.92 | ppl    50.65
| train-epoch  24 |  1600/ 2983 batches | lr 1.25 | ms/batch 57.95 | loss  4.00 | ppl    54.69
| train-epoch  24 |  1800/ 2983 batches | lr 1.25 | ms/batch 57.91 | loss  3.91 | ppl    49.73
| train-epoch  24 |  2000/ 2983 batches | lr 1.25 | ms/batch 57.79 | loss  3.92 | ppl    50.51
| train-epoch  24 |  2200/ 2983 batches | lr 1.25 | ms/batch 58.12 | loss  3.80 | ppl    44.85
| train-epoch  24 |  2400/ 2983 batches | lr 1.25 | ms/batch 58.05 | loss  3.83 | ppl    46.08
| train-epoch  24 |  2600/ 2983 batches | lr 1.25 | ms/batch 58.06 | loss  3.85 | ppl    47.00
| train-epoch  24 |  2800/ 2983 batches | lr 1.25 | ms/batch 57.98 | loss  3.82 | ppl    45.46
-----------------------------------------------------------------------------------------
| end of train epoch  24 | time: 179.97s | valid loss  4.51 | valid ppl    91.14
-----------------------------------------------------------------------------------------
| train-epoch  25 |   200/ 2983 batches | lr 0.31 | ms/batch 58.34 | loss  3.96 | ppl    52.68
| train-epoch  25 |   400/ 2983 batches | lr 0.31 | ms/batch 58.22 | loss  4.02 | ppl    55.66
| train-epoch  25 |   600/ 2983 batches | lr 0.31 | ms/batch 58.14 | loss  3.87 | ppl    47.77
| train-epoch  25 |   800/ 2983 batches | lr 0.31 | ms/batch 58.01 | loss  3.90 | ppl    49.44
| train-epoch  25 |  1000/ 2983 batches | lr 0.31 | ms/batch 58.02 | loss  3.91 | ppl    49.70
| train-epoch  25 |  1200/ 2983 batches | lr 0.31 | ms/batch 57.98 | loss  3.91 | ppl    50.02
| train-epoch  25 |  1400/ 2983 batches | lr 0.31 | ms/batch 57.86 | loss  3.94 | ppl    51.22
| train-epoch  25 |  1600/ 2983 batches | lr 0.31 | ms/batch 57.93 | loss  4.01 | ppl    55.31
| train-epoch  25 |  1800/ 2983 batches | lr 0.31 | ms/batch 57.89 | loss  3.93 | ppl    50.82
| train-epoch  25 |  2000/ 2983 batches | lr 0.31 | ms/batch 57.89 | loss  3.94 | ppl    51.38
| train-epoch  25 |  2200/ 2983 batches | lr 0.31 | ms/batch 57.83 | loss  3.80 | ppl    44.91
| train-epoch  25 |  2400/ 2983 batches | lr 0.31 | ms/batch 57.84 | loss  3.86 | ppl    47.25
| train-epoch  25 |  2600/ 2983 batches | lr 0.31 | ms/batch 57.88 | loss  3.88 | ppl    48.44
| train-epoch  25 |  2800/ 2983 batches | lr 0.31 | ms/batch 58.07 | loss  3.81 | ppl    45.00
-----------------------------------------------------------------------------------------
| end of train epoch  25 | time: 179.93s | valid loss  4.49 | valid ppl    89.39
-----------------------------------------------------------------------------------------
| train-epoch  26 |   200/ 2983 batches | lr 0.31 | ms/batch 58.15 | loss  3.99 | ppl    54.14
| train-epoch  26 |   400/ 2983 batches | lr 0.31 | ms/batch 57.85 | loss  4.01 | ppl    55.30
| train-epoch  26 |   600/ 2983 batches | lr 0.31 | ms/batch 57.69 | loss  3.84 | ppl    46.36
| train-epoch  26 |   800/ 2983 batches | lr 0.31 | ms/batch 58.10 | loss  3.88 | ppl    48.48
| train-epoch  26 |  1000/ 2983 batches | lr 0.31 | ms/batch 57.86 | loss  3.90 | ppl    49.27
| train-epoch  26 |  1200/ 2983 batches | lr 0.31 | ms/batch 57.82 | loss  3.91 | ppl    50.04
| train-epoch  26 |  1400/ 2983 batches | lr 0.31 | ms/batch 57.84 | loss  3.93 | ppl    51.00
| train-epoch  26 |  1600/ 2983 batches | lr 0.31 | ms/batch 57.80 | loss  4.00 | ppl    54.80
| train-epoch  26 |  1800/ 2983 batches | lr 0.31 | ms/batch 57.73 | loss  3.92 | ppl    50.54
| train-epoch  26 |  2000/ 2983 batches | lr 0.31 | ms/batch 57.84 | loss  3.93 | ppl    51.03
| train-epoch  26 |  2200/ 2983 batches | lr 0.31 | ms/batch 57.85 | loss  3.80 | ppl    44.86
| train-epoch  26 |  2400/ 2983 batches | lr 0.31 | ms/batch 57.82 | loss  3.86 | ppl    47.31
| train-epoch  26 |  2600/ 2983 batches | lr 0.31 | ms/batch 57.77 | loss  3.89 | ppl    48.69
| train-epoch  26 |  2800/ 2983 batches | lr 0.31 | ms/batch 57.72 | loss  3.80 | ppl    44.80
-----------------------------------------------------------------------------------------
| end of train epoch  26 | time: 179.43s | valid loss  4.50 | valid ppl    89.59
-----------------------------------------------------------------------------------------
| train-epoch  27 |   200/ 2983 batches | lr 0.08 | ms/batch 58.25 | loss  4.00 | ppl    54.41
| train-epoch  27 |   400/ 2983 batches | lr 0.08 | ms/batch 57.92 | loss  4.05 | ppl    57.41
| train-epoch  27 |   600/ 2983 batches | lr 0.08 | ms/batch 57.87 | loss  3.87 | ppl    48.12
| train-epoch  27 |   800/ 2983 batches | lr 0.08 | ms/batch 57.89 | loss  3.94 | ppl    51.36
| train-epoch  27 |  1000/ 2983 batches | lr 0.08 | ms/batch 57.88 | loss  3.96 | ppl    52.67
| train-epoch  27 |  1200/ 2983 batches | lr 0.08 | ms/batch 57.76 | loss  3.96 | ppl    52.39
| train-epoch  27 |  1400/ 2983 batches | lr 0.08 | ms/batch 57.91 | loss  3.99 | ppl    54.17
| train-epoch  27 |  1600/ 2983 batches | lr 0.08 | ms/batch 57.84 | loss  4.06 | ppl    58.00
| train-epoch  27 |  1800/ 2983 batches | lr 0.08 | ms/batch 57.92 | loss  3.95 | ppl    52.01
| train-epoch  27 |  2000/ 2983 batches | lr 0.08 | ms/batch 57.86 | loss  3.95 | ppl    52.06
| train-epoch  27 |  2200/ 2983 batches | lr 0.08 | ms/batch 57.87 | loss  3.80 | ppl    44.90
| train-epoch  27 |  2400/ 2983 batches | lr 0.08 | ms/batch 57.77 | loss  3.85 | ppl    46.84
| train-epoch  27 |  2600/ 2983 batches | lr 0.08 | ms/batch 57.88 | loss  3.89 | ppl    48.91
| train-epoch  27 |  2800/ 2983 batches | lr 0.08 | ms/batch 57.86 | loss  3.84 | ppl    46.55
-----------------------------------------------------------------------------------------
| end of train epoch  27 | time: 179.61s | valid loss  4.48 | valid ppl    88.47
-----------------------------------------------------------------------------------------
| train-epoch  28 |   200/ 2983 batches | lr 0.08 | ms/batch 58.16 | loss  4.03 | ppl    56.22
| train-epoch  28 |   400/ 2983 batches | lr 0.08 | ms/batch 57.74 | loss  4.07 | ppl    58.30
| train-epoch  28 |   600/ 2983 batches | lr 0.08 | ms/batch 57.77 | loss  3.86 | ppl    47.29
| train-epoch  28 |   800/ 2983 batches | lr 0.08 | ms/batch 57.80 | loss  3.91 | ppl    50.01
| train-epoch  28 |  1000/ 2983 batches | lr 0.08 | ms/batch 57.81 | loss  3.93 | ppl    50.80
| train-epoch  28 |  1200/ 2983 batches | lr 0.08 | ms/batch 57.80 | loss  3.93 | ppl    50.94
| train-epoch  28 |  1400/ 2983 batches | lr 0.08 | ms/batch 57.81 | loss  3.96 | ppl    52.56
| train-epoch  28 |  1600/ 2983 batches | lr 0.08 | ms/batch 57.77 | loss  4.03 | ppl    56.54
| train-epoch  28 |  1800/ 2983 batches | lr 0.08 | ms/batch 57.75 | loss  3.94 | ppl    51.29
| train-epoch  28 |  2000/ 2983 batches | lr 0.08 | ms/batch 57.80 | loss  3.95 | ppl    51.75
| train-epoch  28 |  2200/ 2983 batches | lr 0.08 | ms/batch 57.81 | loss  3.82 | ppl    45.39
| train-epoch  28 |  2400/ 2983 batches | lr 0.08 | ms/batch 57.78 | loss  3.85 | ppl    47.15
| train-epoch  28 |  2600/ 2983 batches | lr 0.08 | ms/batch 57.80 | loss  3.90 | ppl    49.46
| train-epoch  28 |  2800/ 2983 batches | lr 0.08 | ms/batch 57.78 | loss  3.84 | ppl    46.67
-----------------------------------------------------------------------------------------
| end of train epoch  28 | time: 179.35s | valid loss  4.48 | valid ppl    88.39
-----------------------------------------------------------------------------------------
| train-epoch  29 |   200/ 2983 batches | lr 0.08 | ms/batch 58.19 | loss  4.02 | ppl    55.72
| train-epoch  29 |   400/ 2983 batches | lr 0.08 | ms/batch 57.90 | loss  4.04 | ppl    56.97
| train-epoch  29 |   600/ 2983 batches | lr 0.08 | ms/batch 57.85 | loss  3.85 | ppl    46.78
| train-epoch  29 |   800/ 2983 batches | lr 0.08 | ms/batch 57.85 | loss  3.89 | ppl    49.09
| train-epoch  29 |  1000/ 2983 batches | lr 0.08 | ms/batch 57.77 | loss  3.93 | ppl    50.85
| train-epoch  29 |  1200/ 2983 batches | lr 0.08 | ms/batch 57.86 | loss  3.92 | ppl    50.43
| train-epoch  29 |  1400/ 2983 batches | lr 0.08 | ms/batch 57.85 | loss  3.96 | ppl    52.43
| train-epoch  29 |  1600/ 2983 batches | lr 0.08 | ms/batch 57.87 | loss  4.03 | ppl    56.31
| train-epoch  29 |  1800/ 2983 batches | lr 0.08 | ms/batch 57.89 | loss  3.94 | ppl    51.45
| train-epoch  29 |  2000/ 2983 batches | lr 0.08 | ms/batch 57.85 | loss  3.95 | ppl    51.87
| train-epoch  29 |  2200/ 2983 batches | lr 0.08 | ms/batch 57.77 | loss  3.82 | ppl    45.53
| train-epoch  29 |  2400/ 2983 batches | lr 0.08 | ms/batch 57.89 | loss  3.85 | ppl    47.00
| train-epoch  29 |  2600/ 2983 batches | lr 0.08 | ms/batch 57.83 | loss  3.90 | ppl    49.61
| train-epoch  29 |  2800/ 2983 batches | lr 0.08 | ms/batch 57.88 | loss  3.85 | ppl    46.77
-----------------------------------------------------------------------------------------
| end of train epoch  29 | time: 179.56s | valid loss  4.48 | valid ppl    88.37
-----------------------------------------------------------------------------------------
| train-epoch  30 |   200/ 2983 batches | lr 0.08 | ms/batch 57.65 | loss  4.01 | ppl    55.42
| train-epoch  30 |   400/ 2983 batches | lr 0.08 | ms/batch 57.23 | loss  4.04 | ppl    56.55
| train-epoch  30 |   600/ 2983 batches | lr 0.08 | ms/batch 57.32 | loss  3.84 | ppl    46.71
| train-epoch  30 |   800/ 2983 batches | lr 0.08 | ms/batch 57.37 | loss  3.90 | ppl    49.33
| train-epoch  30 |  1000/ 2983 batches | lr 0.08 | ms/batch 57.36 | loss  3.93 | ppl    50.81
| train-epoch  30 |  1200/ 2983 batches | lr 0.08 | ms/batch 57.34 | loss  3.92 | ppl    50.61
| train-epoch  30 |  1400/ 2983 batches | lr 0.08 | ms/batch 57.37 | loss  3.96 | ppl    52.64
| train-epoch  30 |  1600/ 2983 batches | lr 0.08 | ms/batch 57.28 | loss  4.03 | ppl    56.15
| train-epoch  30 |  1800/ 2983 batches | lr 0.08 | ms/batch 57.33 | loss  3.94 | ppl    51.19
| train-epoch  30 |  2000/ 2983 batches | lr 0.08 | ms/batch 57.31 | loss  3.95 | ppl    51.72
| train-epoch  30 |  2200/ 2983 batches | lr 0.08 | ms/batch 57.34 | loss  3.81 | ppl    45.26
| train-epoch  30 |  2400/ 2983 batches | lr 0.08 | ms/batch 57.37 | loss  3.85 | ppl    47.00
| train-epoch  30 |  2600/ 2983 batches | lr 0.08 | ms/batch 57.37 | loss  3.90 | ppl    49.54
| train-epoch  30 |  2800/ 2983 batches | lr 0.08 | ms/batch 57.24 | loss  3.84 | ppl    46.54
-----------------------------------------------------------------------------------------
| end of train epoch  30 | time: 177.98s | valid loss  4.48 | valid ppl    88.39
-----------------------------------------------------------------------------------------
| train-epoch  31 |   200/ 2983 batches | lr 0.02 | ms/batch 58.27 | loss  4.01 | ppl    55.26
| train-epoch  31 |   400/ 2983 batches | lr 0.02 | ms/batch 57.95 | loss  4.05 | ppl    57.28
| train-epoch  31 |   600/ 2983 batches | lr 0.02 | ms/batch 57.93 | loss  3.86 | ppl    47.60
| train-epoch  31 |   800/ 2983 batches | lr 0.02 | ms/batch 57.87 | loss  3.92 | ppl    50.36
| train-epoch  31 |  1000/ 2983 batches | lr 0.02 | ms/batch 57.90 | loss  3.95 | ppl    52.15
| train-epoch  31 |  1200/ 2983 batches | lr 0.02 | ms/batch 57.90 | loss  3.95 | ppl    52.18
| train-epoch  31 |  1400/ 2983 batches | lr 0.02 | ms/batch 57.92 | loss  3.98 | ppl    53.39
| train-epoch  31 |  1600/ 2983 batches | lr 0.02 | ms/batch 57.97 | loss  4.05 | ppl    57.54
| train-epoch  31 |  1800/ 2983 batches | lr 0.02 | ms/batch 57.90 | loss  3.96 | ppl    52.28
| train-epoch  31 |  2000/ 2983 batches | lr 0.02 | ms/batch 57.90 | loss  3.98 | ppl    53.41
| train-epoch  31 |  2200/ 2983 batches | lr 0.02 | ms/batch 57.87 | loss  3.84 | ppl    46.58
| train-epoch  31 |  2400/ 2983 batches | lr 0.02 | ms/batch 57.95 | loss  3.86 | ppl    47.43
| train-epoch  31 |  2600/ 2983 batches | lr 0.02 | ms/batch 57.92 | loss  3.90 | ppl    49.20
| train-epoch  31 |  2800/ 2983 batches | lr 0.02 | ms/batch 57.93 | loss  3.84 | ppl    46.66
-----------------------------------------------------------------------------------------
| end of train epoch  31 | time: 179.76s | valid loss  4.48 | valid ppl    88.24
-----------------------------------------------------------------------------------------
| train-epoch  32 |   200/ 2983 batches | lr 0.02 | ms/batch 58.09 | loss  4.01 | ppl    55.33
| train-epoch  32 |   400/ 2983 batches | lr 0.02 | ms/batch 57.86 | loss  4.06 | ppl    57.70
| train-epoch  32 |   600/ 2983 batches | lr 0.02 | ms/batch 57.84 | loss  3.86 | ppl    47.55
| train-epoch  32 |   800/ 2983 batches | lr 0.02 | ms/batch 57.88 | loss  3.92 | ppl    50.35
| train-epoch  32 |  1000/ 2983 batches | lr 0.02 | ms/batch 57.87 | loss  3.95 | ppl    52.16
| train-epoch  32 |  1200/ 2983 batches | lr 0.02 | ms/batch 57.86 | loss  3.95 | ppl    52.10
| train-epoch  32 |  1400/ 2983 batches | lr 0.02 | ms/batch 57.78 | loss  3.98 | ppl    53.55
| train-epoch  32 |  1600/ 2983 batches | lr 0.02 | ms/batch 57.91 | loss  4.05 | ppl    57.42
| train-epoch  32 |  1800/ 2983 batches | lr 0.02 | ms/batch 57.87 | loss  3.95 | ppl    52.02
| train-epoch  32 |  2000/ 2983 batches | lr 0.02 | ms/batch 57.86 | loss  3.97 | ppl    53.04
| train-epoch  32 |  2200/ 2983 batches | lr 0.02 | ms/batch 57.87 | loss  3.83 | ppl    46.07
| train-epoch  32 |  2400/ 2983 batches | lr 0.02 | ms/batch 57.85 | loss  3.85 | ppl    47.10
| train-epoch  32 |  2600/ 2983 batches | lr 0.02 | ms/batch 57.80 | loss  3.90 | ppl    49.49
| train-epoch  32 |  2800/ 2983 batches | lr 0.02 | ms/batch 57.84 | loss  3.84 | ppl    46.48
-----------------------------------------------------------------------------------------
| end of train epoch  32 | time: 179.54s | valid loss  4.48 | valid ppl    88.16
-----------------------------------------------------------------------------------------
| train-epoch  33 |   200/ 2983 batches | lr 0.02 | ms/batch 58.04 | loss  4.02 | ppl    55.79
| train-epoch  33 |   400/ 2983 batches | lr 0.02 | ms/batch 57.72 | loss  4.07 | ppl    58.32
| train-epoch  33 |   600/ 2983 batches | lr 0.02 | ms/batch 57.74 | loss  3.86 | ppl    47.36
| train-epoch  33 |   800/ 2983 batches | lr 0.02 | ms/batch 57.65 | loss  3.92 | ppl    50.21
| train-epoch  33 |  1000/ 2983 batches | lr 0.02 | ms/batch 57.76 | loss  3.95 | ppl    52.14
| train-epoch  33 |  1200/ 2983 batches | lr 0.02 | ms/batch 57.73 | loss  3.94 | ppl    51.59
| train-epoch  33 |  1400/ 2983 batches | lr 0.02 | ms/batch 57.74 | loss  3.98 | ppl    53.73
| train-epoch  33 |  1600/ 2983 batches | lr 0.02 | ms/batch 57.76 | loss  4.05 | ppl    57.45
| train-epoch  33 |  1800/ 2983 batches | lr 0.02 | ms/batch 57.80 | loss  3.95 | ppl    51.86
| train-epoch  33 |  2000/ 2983 batches | lr 0.02 | ms/batch 57.69 | loss  3.96 | ppl    52.41
| train-epoch  33 |  2200/ 2983 batches | lr 0.02 | ms/batch 57.83 | loss  3.83 | ppl    45.98
| train-epoch  33 |  2400/ 2983 batches | lr 0.02 | ms/batch 57.80 | loss  3.85 | ppl    46.94
| train-epoch  33 |  2600/ 2983 batches | lr 0.02 | ms/batch 57.75 | loss  3.90 | ppl    49.53
| train-epoch  33 |  2800/ 2983 batches | lr 0.02 | ms/batch 57.68 | loss  3.84 | ppl    46.65
-----------------------------------------------------------------------------------------
| end of train epoch  33 | time: 179.20s | valid loss  4.48 | valid ppl    88.09
-----------------------------------------------------------------------------------------
| train-epoch  34 |   200/ 2983 batches | lr 0.02 | ms/batch 58.28 | loss  4.02 | ppl    55.79
| train-epoch  34 |   400/ 2983 batches | lr 0.02 | ms/batch 57.94 | loss  4.06 | ppl    58.19
| train-epoch  34 |   600/ 2983 batches | lr 0.02 | ms/batch 57.92 | loss  3.86 | ppl    47.56
| train-epoch  34 |   800/ 2983 batches | lr 0.02 | ms/batch 57.88 | loss  3.92 | ppl    50.30
| train-epoch  34 |  1000/ 2983 batches | lr 0.02 | ms/batch 57.89 | loss  3.94 | ppl    51.57
| train-epoch  34 |  1200/ 2983 batches | lr 0.02 | ms/batch 57.75 | loss  3.95 | ppl    51.90
| train-epoch  34 |  1400/ 2983 batches | lr 0.02 | ms/batch 57.90 | loss  3.98 | ppl    53.31
| train-epoch  34 |  1600/ 2983 batches | lr 0.02 | ms/batch 57.86 | loss  4.05 | ppl    57.29
| train-epoch  34 |  1800/ 2983 batches | lr 0.02 | ms/batch 57.87 | loss  3.94 | ppl    51.56
| train-epoch  34 |  2000/ 2983 batches | lr 0.02 | ms/batch 57.88 | loss  3.96 | ppl    52.32
| train-epoch  34 |  2200/ 2983 batches | lr 0.02 | ms/batch 57.85 | loss  3.83 | ppl    45.97
| train-epoch  34 |  2400/ 2983 batches | lr 0.02 | ms/batch 57.77 | loss  3.85 | ppl    47.02
| train-epoch  34 |  2600/ 2983 batches | lr 0.02 | ms/batch 57.84 | loss  3.91 | ppl    49.72
| train-epoch  34 |  2800/ 2983 batches | lr 0.02 | ms/batch 57.89 | loss  3.85 | ppl    47.00
-----------------------------------------------------------------------------------------
| end of train epoch  34 | time: 179.61s | valid loss  4.48 | valid ppl    88.03
-----------------------------------------------------------------------------------------
| train-epoch  35 |   200/ 2983 batches | lr 0.02 | ms/batch 58.16 | loss  4.03 | ppl    56.02
| train-epoch  35 |   400/ 2983 batches | lr 0.02 | ms/batch 57.82 | loss  4.06 | ppl    57.75
| train-epoch  35 |   600/ 2983 batches | lr 0.02 | ms/batch 57.76 | loss  3.86 | ppl    47.52
| train-epoch  35 |   800/ 2983 batches | lr 0.02 | ms/batch 57.85 | loss  3.92 | ppl    50.31
| train-epoch  35 |  1000/ 2983 batches | lr 0.02 | ms/batch 57.80 | loss  3.95 | ppl    51.78
| train-epoch  35 |  1200/ 2983 batches | lr 0.02 | ms/batch 57.82 | loss  3.94 | ppl    51.46
| train-epoch  35 |  1400/ 2983 batches | lr 0.02 | ms/batch 57.82 | loss  3.98 | ppl    53.33
| train-epoch  35 |  1600/ 2983 batches | lr 0.02 | ms/batch 57.82 | loss  4.04 | ppl    57.09
| train-epoch  35 |  1800/ 2983 batches | lr 0.02 | ms/batch 57.74 | loss  3.94 | ppl    51.41
| train-epoch  35 |  2000/ 2983 batches | lr 0.02 | ms/batch 57.81 | loss  3.96 | ppl    52.29
| train-epoch  35 |  2200/ 2983 batches | lr 0.02 | ms/batch 57.81 | loss  3.83 | ppl    45.92
| train-epoch  35 |  2400/ 2983 batches | lr 0.02 | ms/batch 57.84 | loss  3.85 | ppl    46.78
| train-epoch  35 |  2600/ 2983 batches | lr 0.02 | ms/batch 57.82 | loss  3.90 | ppl    49.30
| train-epoch  35 |  2800/ 2983 batches | lr 0.02 | ms/batch 57.81 | loss  3.85 | ppl    46.94
-----------------------------------------------------------------------------------------
| end of train epoch  35 | time: 179.43s | valid loss  4.48 | valid ppl    88.01
-----------------------------------------------------------------------------------------
| train-epoch  36 |   200/ 2983 batches | lr 0.02 | ms/batch 58.19 | loss  4.03 | ppl    56.00
| train-epoch  36 |   400/ 2983 batches | lr 0.02 | ms/batch 57.93 | loss  4.06 | ppl    58.08
| train-epoch  36 |   600/ 2983 batches | lr 0.02 | ms/batch 57.89 | loss  3.86 | ppl    47.52
| train-epoch  36 |   800/ 2983 batches | lr 0.02 | ms/batch 57.84 | loss  3.92 | ppl    50.23
| train-epoch  36 |  1000/ 2983 batches | lr 0.02 | ms/batch 57.87 | loss  3.94 | ppl    51.62
| train-epoch  36 |  1200/ 2983 batches | lr 0.02 | ms/batch 57.78 | loss  3.94 | ppl    51.52
| train-epoch  36 |  1400/ 2983 batches | lr 0.02 | ms/batch 57.83 | loss  3.98 | ppl    53.39
| train-epoch  36 |  1600/ 2983 batches | lr 0.02 | ms/batch 57.83 | loss  4.04 | ppl    56.67
| train-epoch  36 |  1800/ 2983 batches | lr 0.02 | ms/batch 57.86 | loss  3.94 | ppl    51.48
| train-epoch  36 |  2000/ 2983 batches | lr 0.02 | ms/batch 57.84 | loss  3.96 | ppl    52.23
| train-epoch  36 |  2200/ 2983 batches | lr 0.02 | ms/batch 57.84 | loss  3.82 | ppl    45.79
| train-epoch  36 |  2400/ 2983 batches | lr 0.02 | ms/batch 57.78 | loss  3.84 | ppl    46.73
| train-epoch  36 |  2600/ 2983 batches | lr 0.02 | ms/batch 57.84 | loss  3.91 | ppl    49.69
| train-epoch  36 |  2800/ 2983 batches | lr 0.02 | ms/batch 57.88 | loss  3.84 | ppl    46.62
-----------------------------------------------------------------------------------------
| end of train epoch  36 | time: 179.55s | valid loss  4.48 | valid ppl    87.98
-----------------------------------------------------------------------------------------
| train-epoch  37 |   200/ 2983 batches | lr 0.02 | ms/batch 57.63 | loss  4.02 | ppl    55.97
| train-epoch  37 |   400/ 2983 batches | lr 0.02 | ms/batch 57.26 | loss  4.06 | ppl    58.08
| train-epoch  37 |   600/ 2983 batches | lr 0.02 | ms/batch 57.37 | loss  3.86 | ppl    47.33
| train-epoch  37 |   800/ 2983 batches | lr 0.02 | ms/batch 57.44 | loss  3.91 | ppl    50.12
| train-epoch  37 |  1000/ 2983 batches | lr 0.02 | ms/batch 57.46 | loss  3.93 | ppl    51.00
| train-epoch  37 |  1200/ 2983 batches | lr 0.02 | ms/batch 57.42 | loss  3.94 | ppl    51.17
| train-epoch  37 |  1400/ 2983 batches | lr 0.02 | ms/batch 57.44 | loss  3.97 | ppl    52.86
| train-epoch  37 |  1600/ 2983 batches | lr 0.02 | ms/batch 57.34 | loss  4.04 | ppl    56.99
| train-epoch  37 |  1800/ 2983 batches | lr 0.02 | ms/batch 57.45 | loss  3.94 | ppl    51.38
| train-epoch  37 |  2000/ 2983 batches | lr 0.02 | ms/batch 57.45 | loss  3.96 | ppl    52.22
| train-epoch  37 |  2200/ 2983 batches | lr 0.02 | ms/batch 57.47 | loss  3.82 | ppl    45.73
| train-epoch  37 |  2400/ 2983 batches | lr 0.02 | ms/batch 57.41 | loss  3.85 | ppl    47.20
| train-epoch  37 |  2600/ 2983 batches | lr 0.02 | ms/batch 57.46 | loss  3.90 | ppl    49.58
| train-epoch  37 |  2800/ 2983 batches | lr 0.02 | ms/batch 57.38 | loss  3.85 | ppl    47.05
-----------------------------------------------------------------------------------------
| end of train epoch  37 | time: 178.24s | valid loss  4.48 | valid ppl    87.96
-----------------------------------------------------------------------------------------
| train-epoch  38 |   200/ 2983 batches | lr 0.02 | ms/batch 58.37 | loss  4.02 | ppl    55.87
| train-epoch  38 |   400/ 2983 batches | lr 0.02 | ms/batch 58.07 | loss  4.06 | ppl    57.97
| train-epoch  38 |   600/ 2983 batches | lr 0.02 | ms/batch 58.01 | loss  3.86 | ppl    47.29
| train-epoch  38 |   800/ 2983 batches | lr 0.02 | ms/batch 58.07 | loss  3.91 | ppl    49.77
| train-epoch  38 |  1000/ 2983 batches | lr 0.02 | ms/batch 57.97 | loss  3.94 | ppl    51.42
| train-epoch  38 |  1200/ 2983 batches | lr 0.02 | ms/batch 57.98 | loss  3.94 | ppl    51.44
| train-epoch  38 |  1400/ 2983 batches | lr 0.02 | ms/batch 57.92 | loss  3.97 | ppl    52.97
| train-epoch  38 |  1600/ 2983 batches | lr 0.02 | ms/batch 57.91 | loss  4.04 | ppl    57.02
| train-epoch  38 |  1800/ 2983 batches | lr 0.02 | ms/batch 57.93 | loss  3.94 | ppl    51.30
| train-epoch  38 |  2000/ 2983 batches | lr 0.02 | ms/batch 57.94 | loss  3.96 | ppl    52.20
| train-epoch  38 |  2200/ 2983 batches | lr 0.02 | ms/batch 57.81 | loss  3.83 | ppl    45.98
| train-epoch  38 |  2400/ 2983 batches | lr 0.02 | ms/batch 57.87 | loss  3.85 | ppl    47.09
| train-epoch  38 |  2600/ 2983 batches | lr 0.02 | ms/batch 57.92 | loss  3.90 | ppl    49.44
| train-epoch  38 |  2800/ 2983 batches | lr 0.02 | ms/batch 57.88 | loss  3.85 | ppl    46.93
-----------------------------------------------------------------------------------------
| end of train epoch  38 | time: 179.85s | valid loss  4.48 | valid ppl    87.95
-----------------------------------------------------------------------------------------
| train-epoch  39 |   200/ 2983 batches | lr 0.02 | ms/batch 58.09 | loss  4.02 | ppl    55.64
| train-epoch  39 |   400/ 2983 batches | lr 0.02 | ms/batch 57.76 | loss  4.06 | ppl    57.92
| train-epoch  39 |   600/ 2983 batches | lr 0.02 | ms/batch 57.82 | loss  3.85 | ppl    47.04
| train-epoch  39 |   800/ 2983 batches | lr 0.02 | ms/batch 57.83 | loss  3.90 | ppl    49.62
| train-epoch  39 |  1000/ 2983 batches | lr 0.02 | ms/batch 57.81 | loss  3.94 | ppl    51.27
| train-epoch  39 |  1200/ 2983 batches | lr 0.02 | ms/batch 57.85 | loss  3.93 | ppl    51.05
| train-epoch  39 |  1400/ 2983 batches | lr 0.02 | ms/batch 57.81 | loss  3.96 | ppl    52.72
| train-epoch  39 |  1600/ 2983 batches | lr 0.02 | ms/batch 57.78 | loss  4.03 | ppl    56.23
| train-epoch  39 |  1800/ 2983 batches | lr 0.02 | ms/batch 57.83 | loss  3.94 | ppl    51.22
| train-epoch  39 |  2000/ 2983 batches | lr 0.02 | ms/batch 57.85 | loss  3.96 | ppl    52.48
| train-epoch  39 |  2200/ 2983 batches | lr 0.02 | ms/batch 57.82 | loss  3.83 | ppl    45.89
| train-epoch  39 |  2400/ 2983 batches | lr 0.02 | ms/batch 57.81 | loss  3.85 | ppl    47.12
| train-epoch  39 |  2600/ 2983 batches | lr 0.02 | ms/batch 57.82 | loss  3.90 | ppl    49.60
| train-epoch  39 |  2800/ 2983 batches | lr 0.02 | ms/batch 57.72 | loss  3.85 | ppl    47.01
-----------------------------------------------------------------------------------------
| end of train epoch  39 | time: 179.43s | valid loss  4.48 | valid ppl    87.96
-----------------------------------------------------------------------------------------
| train-epoch  40 |   200/ 2983 batches | lr 0.00 | ms/batch 58.02 | loss  4.02 | ppl    55.77
| train-epoch  40 |   400/ 2983 batches | lr 0.00 | ms/batch 57.74 | loss  4.06 | ppl    57.83
| train-epoch  40 |   600/ 2983 batches | lr 0.00 | ms/batch 57.70 | loss  3.86 | ppl    47.30
| train-epoch  40 |   800/ 2983 batches | lr 0.00 | ms/batch 57.61 | loss  3.92 | ppl    50.30
| train-epoch  40 |  1000/ 2983 batches | lr 0.00 | ms/batch 57.71 | loss  3.94 | ppl    51.62
| train-epoch  40 |  1200/ 2983 batches | lr 0.00 | ms/batch 57.71 | loss  3.94 | ppl    51.56
| train-epoch  40 |  1400/ 2983 batches | lr 0.00 | ms/batch 57.72 | loss  3.98 | ppl    53.33
| train-epoch  40 |  1600/ 2983 batches | lr 0.00 | ms/batch 57.72 | loss  4.04 | ppl    56.89
| train-epoch  40 |  1800/ 2983 batches | lr 0.00 | ms/batch 57.69 | loss  3.94 | ppl    51.34
| train-epoch  40 |  2000/ 2983 batches | lr 0.00 | ms/batch 57.65 | loss  3.96 | ppl    52.54
| train-epoch  40 |  2200/ 2983 batches | lr 0.00 | ms/batch 57.74 | loss  3.83 | ppl    46.12
| train-epoch  40 |  2400/ 2983 batches | lr 0.00 | ms/batch 57.71 | loss  3.85 | ppl    47.07
| train-epoch  40 |  2600/ 2983 batches | lr 0.00 | ms/batch 57.75 | loss  3.90 | ppl    49.47
| train-epoch  40 |  2800/ 2983 batches | lr 0.00 | ms/batch 57.71 | loss  3.85 | ppl    46.99
-----------------------------------------------------------------------------------------
| end of train epoch  40 | time: 179.12s | valid loss  4.48 | valid ppl    87.95
-----------------------------------------------------------------------------------------
required epochs  40 | actual epochs  40
pretrain epochs  40 | prune epochs   0 | retrain epochs   0
=========================================================================================
| End of training | test loss  4.43 | test ppl    83.62
=========================================================================================
