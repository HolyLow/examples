python main.py --cuda --epochs 6 --save model/prune/model.pt --prune --retrain --sparsity 0.9
<class 'torch.Tensor'> torch.Size([33278, 200])
<class 'torch.Tensor'> torch.Size([800, 200])
<class 'torch.Tensor'> torch.Size([800, 200])
<class 'torch.Tensor'> torch.Size([800])
<class 'torch.Tensor'> torch.Size([800])
<class 'torch.Tensor'> torch.Size([800, 200])
<class 'torch.Tensor'> torch.Size([800, 200])
<class 'torch.Tensor'> torch.Size([800])
<class 'torch.Tensor'> torch.Size([800])
<class 'torch.Tensor'> torch.Size([33278, 200])
<class 'torch.Tensor'> torch.Size([33278])
RNNModel(
  (drop): Dropout(p=0.2)
  (encoder): Embedding(33278, 200)
  (rnn): LSTM(200, 200, num_layers=2, dropout=0.2)
  (decoder): Linear(in_features=200, out_features=33278, bias=True)
)
Dropout(p=0.2)
Embedding(33278, 200)
LSTM(200, 200, num_layers=2, dropout=0.2)
Linear(in_features=200, out_features=33278, bias=True)
| train-epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 10.55 | loss  7.63 | ppl  2053.44
| train-epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 10.30 | loss  6.86 | ppl   951.17
| train-epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 10.42 | loss  6.48 | ppl   654.89
| train-epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 10.43 | loss  6.31 | ppl   548.52
| train-epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.29 | loss  6.15 | ppl   468.21
| train-epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.30 | loss  6.06 | ppl   426.35
| train-epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.72 | loss  5.94 | ppl   378.68
| train-epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 11.39 | loss  5.93 | ppl   377.77
| train-epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.57 | loss  5.80 | ppl   329.39
| train-epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.95 | loss  5.76 | ppl   318.46
| train-epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.76 | loss  5.66 | ppl   286.06
| train-epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.77 | loss  5.67 | ppl   290.76
| train-epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.73 | loss  5.65 | ppl   285.13
| train-epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.91 | loss  5.54 | ppl   254.12
-----------------------------------------------------------------------------------------
| end of train epoch   1 | time: 33.73s | valid loss  5.56 | valid ppl   259.89
-----------------------------------------------------------------------------------------
| train-epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch 10.39 | loss  5.55 | ppl   256.92
| train-epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch 10.56 | loss  5.54 | ppl   253.46
| train-epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch 10.50 | loss  5.37 | ppl   214.00
| train-epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch 10.87 | loss  5.38 | ppl   217.79
| train-epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.84 | loss  5.35 | ppl   211.20
| train-epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.85 | loss  5.33 | ppl   206.47
| train-epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.82 | loss  5.32 | ppl   205.17
| train-epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 11.33 | loss  5.39 | ppl   218.30
| train-epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.90 | loss  5.27 | ppl   193.58
| train-epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.81 | loss  5.27 | ppl   194.88
| train-epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.89 | loss  5.18 | ppl   178.57
| train-epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch 11.27 | loss  5.22 | ppl   184.31
| train-epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.84 | loss  5.23 | ppl   186.13
| train-epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.83 | loss  5.14 | ppl   171.01
-----------------------------------------------------------------------------------------
| end of train epoch   2 | time: 34.25s | valid loss  5.29 | valid ppl   197.51
-----------------------------------------------------------------------------------------
| train-epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 10.34 | loss  5.20 | ppl   181.09
| train-epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch 10.29 | loss  5.21 | ppl   183.77
| train-epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 10.83 | loss  5.03 | ppl   153.49
| train-epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 10.51 | loss  5.08 | ppl   160.55
| train-epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 11.37 | loss  5.06 | ppl   157.97
| train-epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.57 | loss  5.06 | ppl   157.91
| train-epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.27 | loss  5.08 | ppl   160.61
| train-epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.64 | loss  5.15 | ppl   173.08
| train-epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 11.39 | loss  5.03 | ppl   152.47
| train-epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 11.48 | loss  5.05 | ppl   156.30
| train-epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 11.16 | loss  4.97 | ppl   143.58
| train-epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 11.22 | loss  5.00 | ppl   148.61
| train-epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch 11.01 | loss  5.02 | ppl   150.96
| train-epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 11.08 | loss  4.94 | ppl   139.83
-----------------------------------------------------------------------------------------
| end of train epoch   3 | time: 34.17s | valid loss  5.19 | valid ppl   178.85
-----------------------------------------------------------------------------------------
| train-epoch   4 |   200/ 2983 batches | lr 20.00 | ms/batch 10.52 | loss  5.01 | ppl   149.42
| train-epoch   4 |   400/ 2983 batches | lr 20.00 | ms/batch 11.15 | loss  5.03 | ppl   153.09
| train-epoch   4 |   600/ 2983 batches | lr 20.00 | ms/batch 11.31 | loss  4.84 | ppl   126.98
| train-epoch   4 |   800/ 2983 batches | lr 20.00 | ms/batch 10.98 | loss  4.91 | ppl   135.31
| train-epoch   4 |  1000/ 2983 batches | lr 20.00 | ms/batch 11.37 | loss  4.90 | ppl   133.67
| train-epoch   4 |  1200/ 2983 batches | lr 20.00 | ms/batch 11.24 | loss  4.90 | ppl   133.81
| train-epoch   4 |  1400/ 2983 batches | lr 20.00 | ms/batch 11.26 | loss  4.93 | ppl   137.74
| train-epoch   4 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.96 | loss  5.00 | ppl   149.11
| train-epoch   4 |  1800/ 2983 batches | lr 20.00 | ms/batch 11.35 | loss  4.88 | ppl   131.80
| train-epoch   4 |  2000/ 2983 batches | lr 20.00 | ms/batch 11.01 | loss  4.91 | ppl   135.18
| train-epoch   4 |  2200/ 2983 batches | lr 20.00 | ms/batch 11.18 | loss  4.83 | ppl   124.73
| train-epoch   4 |  2400/ 2983 batches | lr 20.00 | ms/batch 11.29 | loss  4.86 | ppl   129.38
| train-epoch   4 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.97 | loss  4.87 | ppl   130.84
| train-epoch   4 |  2800/ 2983 batches | lr 20.00 | ms/batch 11.40 | loss  4.81 | ppl   122.31
-----------------------------------------------------------------------------------------
| end of train epoch   4 | time: 35.00s | valid loss  5.11 | valid ppl   165.20
-----------------------------------------------------------------------------------------
| train-epoch   5 |   200/ 2983 batches | lr 20.00 | ms/batch 10.55 | loss  4.88 | ppl   131.85
| train-epoch   5 |   400/ 2983 batches | lr 20.00 | ms/batch 10.42 | loss  4.90 | ppl   134.57
| train-epoch   5 |   600/ 2983 batches | lr 20.00 | ms/batch 10.52 | loss  4.72 | ppl   112.05
| train-epoch   5 |   800/ 2983 batches | lr 20.00 | ms/batch 10.39 | loss  4.78 | ppl   119.35
| train-epoch   5 |  1000/ 2983 batches | lr 20.00 | ms/batch 11.26 | loss  4.78 | ppl   118.84
| train-epoch   5 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.85 | loss  4.78 | ppl   119.55
| train-epoch   5 |  1400/ 2983 batches | lr 20.00 | ms/batch 11.20 | loss  4.82 | ppl   123.69
| train-epoch   5 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.73 | loss  4.90 | ppl   133.92
| train-epoch   5 |  1800/ 2983 batches | lr 20.00 | ms/batch 11.18 | loss  4.78 | ppl   118.87
| train-epoch   5 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.98 | loss  4.81 | ppl   122.54
| train-epoch   5 |  2200/ 2983 batches | lr 20.00 | ms/batch 11.09 | loss  4.72 | ppl   112.08
| train-epoch   5 |  2400/ 2983 batches | lr 20.00 | ms/batch 11.20 | loss  4.75 | ppl   116.02
| train-epoch   5 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.82 | loss  4.77 | ppl   118.48
| train-epoch   5 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.92 | loss  4.71 | ppl   110.55
-----------------------------------------------------------------------------------------
| end of train epoch   5 | time: 34.28s | valid loss  5.06 | valid ppl   157.01
-----------------------------------------------------------------------------------------
| train-epoch   6 |   200/ 2983 batches | lr 20.00 | ms/batch 10.66 | loss  4.77 | ppl   118.27
| train-epoch   6 |   400/ 2983 batches | lr 20.00 | ms/batch 11.54 | loss  4.81 | ppl   122.31
| train-epoch   6 |   600/ 2983 batches | lr 20.00 | ms/batch 11.72 | loss  4.63 | ppl   102.21
| train-epoch   6 |   800/ 2983 batches | lr 20.00 | ms/batch 12.21 | loss  4.69 | ppl   108.39
| train-epoch   6 |  1000/ 2983 batches | lr 20.00 | ms/batch 12.41 | loss  4.69 | ppl   109.15
| train-epoch   6 |  1200/ 2983 batches | lr 20.00 | ms/batch 11.67 | loss  4.70 | ppl   109.48
| train-epoch   6 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.48 | loss  4.74 | ppl   113.87
| train-epoch   6 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.66 | loss  4.81 | ppl   122.86
| train-epoch   6 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.65 | loss  4.69 | ppl   108.94
| train-epoch   6 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.69 | loss  4.73 | ppl   113.38
| train-epoch   6 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.96 | loss  4.64 | ppl   103.48
| train-epoch   6 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.96 | loss  4.67 | ppl   107.10
| train-epoch   6 |  2600/ 2983 batches | lr 20.00 | ms/batch 11.10 | loss  4.70 | ppl   109.83
| train-epoch   6 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.80 | loss  4.63 | ppl   102.85
-----------------------------------------------------------------------------------------
| end of train epoch   6 | time: 34.93s | valid loss  5.00 | valid ppl   149.07
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 10.84 | loss  4.71 | ppl   110.88
| prune-epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 10.87 | loss  4.73 | ppl   112.90
| prune-epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 10.41 | loss  4.55 | ppl    94.49
| prune-epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 10.80 | loss  4.61 | ppl   100.47
| prune-epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.74 | loss  4.61 | ppl   100.83
| prune-epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.80 | loss  4.62 | ppl   101.03
| prune-epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 11.29 | loss  4.65 | ppl   104.81
| prune-epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 11.18 | loss  4.73 | ppl   113.47
| prune-epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 11.54 | loss  4.61 | ppl   100.79
| prune-epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 11.50 | loss  4.64 | ppl   103.93
| prune-epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 11.29 | loss  4.55 | ppl    94.49
| prune-epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 11.71 | loss  4.58 | ppl    97.76
| prune-epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 11.64 | loss  4.60 | ppl    99.88
| prune-epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 11.25 | loss  4.54 | ppl    93.55
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
-----------------------------------------------------------------------------------------
| end of prune epoch   1 | time: 35.08s | valid loss  4.98 | valid ppl   145.89
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch 11.16 | loss  4.61 | ppl   100.28
| prune-epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch 11.27 | loss  4.64 | ppl   103.29
| prune-epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch 11.73 | loss  4.47 | ppl    86.94
| prune-epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch 11.15 | loss  4.53 | ppl    92.74
| prune-epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch 11.88 | loss  4.53 | ppl    93.10
| prune-epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 11.30 | loss  4.54 | ppl    93.70
| prune-epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 11.52 | loss  4.58 | ppl    97.54
| prune-epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 11.74 | loss  4.66 | ppl   105.77
| prune-epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch 11.30 | loss  4.54 | ppl    94.11
| prune-epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch 11.74 | loss  4.59 | ppl    98.03
| prune-epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch 11.85 | loss  4.48 | ppl    88.36
| prune-epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch 11.39 | loss  4.51 | ppl    91.38
| prune-epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 11.28 | loss  4.54 | ppl    93.78
| prune-epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 11.81 | loss  4.48 | ppl    88.54
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
-----------------------------------------------------------------------------------------
| end of prune epoch   2 | time: 36.08s | valid loss  4.96 | valid ppl   142.02
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 11.27 | loss  4.55 | ppl    94.84
| prune-epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch 10.82 | loss  4.58 | ppl    97.40
| prune-epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 10.99 | loss  4.41 | ppl    82.25
| prune-epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 10.78 | loss  4.47 | ppl    86.92
| prune-epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.70 | loss  4.48 | ppl    88.51
| prune-epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.67 | loss  4.49 | ppl    89.40
| prune-epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.99 | loss  4.53 | ppl    92.84
| prune-epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.98 | loss  4.61 | ppl   100.09
| prune-epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.98 | loss  4.50 | ppl    89.89
| prune-epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 11.16 | loss  4.53 | ppl    92.43
| prune-epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 11.09 | loss  4.43 | ppl    83.53
| prune-epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 11.13 | loss  4.46 | ppl    86.80
| prune-epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.69 | loss  4.49 | ppl    89.47
| prune-epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.62 | loss  4.43 | ppl    84.31
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
-----------------------------------------------------------------------------------------
| end of prune epoch   3 | time: 34.29s | valid loss  4.97 | valid ppl   144.51
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   4 |   200/ 2983 batches | lr 20.00 | ms/batch 10.80 | loss  4.51 | ppl    90.80
| prune-epoch   4 |   400/ 2983 batches | lr 20.00 | ms/batch 10.49 | loss  4.53 | ppl    92.98
| prune-epoch   4 |   600/ 2983 batches | lr 20.00 | ms/batch 10.89 | loss  4.36 | ppl    78.41
| prune-epoch   4 |   800/ 2983 batches | lr 20.00 | ms/batch 10.64 | loss  4.42 | ppl    82.90
| prune-epoch   4 |  1000/ 2983 batches | lr 20.00 | ms/batch 11.05 | loss  4.44 | ppl    84.52
| prune-epoch   4 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.69 | loss  4.44 | ppl    85.00
| prune-epoch   4 |  1400/ 2983 batches | lr 20.00 | ms/batch 11.37 | loss  4.48 | ppl    88.03
| prune-epoch   4 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.78 | loss  4.56 | ppl    95.37
| prune-epoch   4 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.65 | loss  4.45 | ppl    85.49
| prune-epoch   4 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.94 | loss  4.48 | ppl    88.41
| prune-epoch   4 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.59 | loss  4.38 | ppl    79.72
| prune-epoch   4 |  2400/ 2983 batches | lr 20.00 | ms/batch 11.05 | loss  4.41 | ppl    82.50
| prune-epoch   4 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.58 | loss  4.44 | ppl    84.76
| prune-epoch   4 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.95 | loss  4.39 | ppl    80.45
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
-----------------------------------------------------------------------------------------
| end of prune epoch   4 | time: 33.95s | valid loss  4.95 | valid ppl   141.08
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   5 |   200/ 2983 batches | lr 20.00 | ms/batch 11.13 | loss  4.46 | ppl    86.06
| prune-epoch   5 |   400/ 2983 batches | lr 20.00 | ms/batch 10.98 | loss  4.48 | ppl    88.40
| prune-epoch   5 |   600/ 2983 batches | lr 20.00 | ms/batch 11.74 | loss  4.31 | ppl    74.71
| prune-epoch   5 |   800/ 2983 batches | lr 20.00 | ms/batch 11.22 | loss  4.38 | ppl    79.52
| prune-epoch   5 |  1000/ 2983 batches | lr 20.00 | ms/batch 11.20 | loss  4.39 | ppl    81.02
| prune-epoch   5 |  1200/ 2983 batches | lr 20.00 | ms/batch 11.68 | loss  4.39 | ppl    81.01
| prune-epoch   5 |  1400/ 2983 batches | lr 20.00 | ms/batch 11.01 | loss  4.44 | ppl    84.71
| prune-epoch   5 |  1600/ 2983 batches | lr 20.00 | ms/batch 11.23 | loss  4.51 | ppl    90.88
| prune-epoch   5 |  1800/ 2983 batches | lr 20.00 | ms/batch 11.18 | loss  4.41 | ppl    82.01
| prune-epoch   5 |  2000/ 2983 batches | lr 20.00 | ms/batch 11.62 | loss  4.44 | ppl    84.81
| prune-epoch   5 |  2200/ 2983 batches | lr 20.00 | ms/batch 11.35 | loss  4.33 | ppl    76.03
| prune-epoch   5 |  2400/ 2983 batches | lr 20.00 | ms/batch 11.60 | loss  4.37 | ppl    79.43
| prune-epoch   5 |  2600/ 2983 batches | lr 20.00 | ms/batch 11.27 | loss  4.40 | ppl    81.60
| prune-epoch   5 |  2800/ 2983 batches | lr 20.00 | ms/batch 11.80 | loss  4.34 | ppl    76.94
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
-----------------------------------------------------------------------------------------
| end of prune epoch   5 | time: 35.65s | valid loss  4.93 | valid ppl   138.82
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   6 |   200/ 2983 batches | lr 20.00 | ms/batch 11.16 | loss  4.41 | ppl    82.40
| prune-epoch   6 |   400/ 2983 batches | lr 20.00 | ms/batch 11.19 | loss  4.44 | ppl    85.09
| prune-epoch   6 |   600/ 2983 batches | lr 20.00 | ms/batch 10.73 | loss  4.27 | ppl    71.77
| prune-epoch   6 |   800/ 2983 batches | lr 20.00 | ms/batch 10.73 | loss  4.33 | ppl    76.26
| prune-epoch   6 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.71 | loss  4.36 | ppl    77.90
| prune-epoch   6 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.86 | loss  4.36 | ppl    78.44
| prune-epoch   6 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.87 | loss  4.40 | ppl    81.34
| prune-epoch   6 |  1600/ 2983 batches | lr 20.00 | ms/batch 11.00 | loss  4.47 | ppl    87.75
| prune-epoch   6 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.98 | loss  4.37 | ppl    78.90
| prune-epoch   6 |  2000/ 2983 batches | lr 20.00 | ms/batch 11.32 | loss  4.40 | ppl    81.81
| prune-epoch   6 |  2200/ 2983 batches | lr 20.00 | ms/batch 11.47 | loss  4.30 | ppl    73.75
| prune-epoch   6 |  2400/ 2983 batches | lr 20.00 | ms/batch 11.57 | loss  4.33 | ppl    75.95
| prune-epoch   6 |  2600/ 2983 batches | lr 20.00 | ms/batch 11.56 | loss  4.37 | ppl    78.75
| prune-epoch   6 |  2800/ 2983 batches | lr 20.00 | ms/batch 11.73 | loss  4.31 | ppl    74.46
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
-----------------------------------------------------------------------------------------
| end of prune epoch   6 | time: 35.09s | valid loss  4.94 | valid ppl   140.16
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   7 |   200/ 2983 batches | lr 20.00 | ms/batch 10.57 | loss  4.40 | ppl    81.59
| prune-epoch   7 |   400/ 2983 batches | lr 20.00 | ms/batch 11.43 | loss  4.42 | ppl    83.14
| prune-epoch   7 |   600/ 2983 batches | lr 20.00 | ms/batch 11.19 | loss  4.25 | ppl    70.24
| prune-epoch   7 |   800/ 2983 batches | lr 20.00 | ms/batch 11.25 | loss  4.31 | ppl    74.38
| prune-epoch   7 |  1000/ 2983 batches | lr 20.00 | ms/batch 11.58 | loss  4.33 | ppl    76.30
| prune-epoch   7 |  1200/ 2983 batches | lr 20.00 | ms/batch 11.30 | loss  4.34 | ppl    76.47
| prune-epoch   7 |  1400/ 2983 batches | lr 20.00 | ms/batch 11.26 | loss  4.38 | ppl    79.48
| prune-epoch   7 |  1600/ 2983 batches | lr 20.00 | ms/batch 11.28 | loss  4.45 | ppl    85.24
| prune-epoch   7 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.69 | loss  4.34 | ppl    77.05
| prune-epoch   7 |  2000/ 2983 batches | lr 20.00 | ms/batch 11.13 | loss  4.38 | ppl    79.98
| prune-epoch   7 |  2200/ 2983 batches | lr 20.00 | ms/batch 11.08 | loss  4.27 | ppl    71.52
| prune-epoch   7 |  2400/ 2983 batches | lr 20.00 | ms/batch 11.12 | loss  4.31 | ppl    74.23
| prune-epoch   7 |  2600/ 2983 batches | lr 20.00 | ms/batch 11.24 | loss  4.33 | ppl    76.11
| prune-epoch   7 |  2800/ 2983 batches | lr 20.00 | ms/batch 11.73 | loss  4.28 | ppl    72.13
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
-----------------------------------------------------------------------------------------
| end of prune epoch   7 | time: 35.26s | valid loss  4.94 | valid ppl   139.63
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   8 |   200/ 2983 batches | lr 20.00 | ms/batch 11.10 | loss  4.35 | ppl    77.47
| prune-epoch   8 |   400/ 2983 batches | lr 20.00 | ms/batch 10.58 | loss  4.38 | ppl    79.80
| prune-epoch   8 |   600/ 2983 batches | lr 20.00 | ms/batch 10.64 | loss  4.21 | ppl    67.36
| prune-epoch   8 |   800/ 2983 batches | lr 20.00 | ms/batch 10.77 | loss  4.27 | ppl    71.56
| prune-epoch   8 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.36 | loss  4.29 | ppl    73.12
| prune-epoch   8 |  1200/ 2983 batches | lr 20.00 | ms/batch 11.04 | loss  4.30 | ppl    74.04
| prune-epoch   8 |  1400/ 2983 batches | lr 20.00 | ms/batch 11.09 | loss  4.34 | ppl    76.43
| prune-epoch   8 |  1600/ 2983 batches | lr 20.00 | ms/batch 11.16 | loss  4.40 | ppl    81.83
| prune-epoch   8 |  1800/ 2983 batches | lr 20.00 | ms/batch 11.17 | loss  4.31 | ppl    74.20
| prune-epoch   8 |  2000/ 2983 batches | lr 20.00 | ms/batch 11.81 | loss  4.35 | ppl    77.37
| prune-epoch   8 |  2200/ 2983 batches | lr 20.00 | ms/batch 11.24 | loss  4.24 | ppl    69.42
| prune-epoch   8 |  2400/ 2983 batches | lr 20.00 | ms/batch 11.30 | loss  4.27 | ppl    71.57
| prune-epoch   8 |  2600/ 2983 batches | lr 20.00 | ms/batch 11.25 | loss  4.30 | ppl    73.41
| prune-epoch   8 |  2800/ 2983 batches | lr 20.00 | ms/batch 11.32 | loss  4.25 | ppl    70.01
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
-----------------------------------------------------------------------------------------
| end of prune epoch   8 | time: 34.74s | valid loss  4.91 | valid ppl   136.17
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   9 |   200/ 2983 batches | lr 20.00 | ms/batch 10.28 | loss  4.32 | ppl    74.82
| prune-epoch   9 |   400/ 2983 batches | lr 20.00 | ms/batch 10.64 | loss  4.34 | ppl    76.86
| prune-epoch   9 |   600/ 2983 batches | lr 20.00 | ms/batch 10.14 | loss  4.18 | ppl    65.33
| prune-epoch   9 |   800/ 2983 batches | lr 20.00 | ms/batch 10.31 | loss  4.24 | ppl    69.45
| prune-epoch   9 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.57 | loss  4.26 | ppl    71.12
| prune-epoch   9 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.08 | loss  4.27 | ppl    71.52
| prune-epoch   9 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.72 | loss  4.31 | ppl    74.25
| prune-epoch   9 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.71 | loss  4.38 | ppl    79.62
| prune-epoch   9 |  1800/ 2983 batches | lr 20.00 | ms/batch 11.19 | loss  4.28 | ppl    72.29
| prune-epoch   9 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.70 | loss  4.32 | ppl    75.01
| prune-epoch   9 |  2200/ 2983 batches | lr 20.00 | ms/batch 11.15 | loss  4.20 | ppl    66.85
| prune-epoch   9 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.73 | loss  4.24 | ppl    69.53
| prune-epoch   9 |  2600/ 2983 batches | lr 20.00 | ms/batch 11.22 | loss  4.27 | ppl    71.69
| prune-epoch   9 |  2800/ 2983 batches | lr 20.00 | ms/batch 11.28 | loss  4.23 | ppl    68.46
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
-----------------------------------------------------------------------------------------
| end of prune epoch   9 | time: 33.71s | valid loss  4.93 | valid ppl   138.81
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  10 |   200/ 2983 batches | lr 20.00 | ms/batch 10.30 | loss  4.34 | ppl    76.35
| prune-epoch  10 |   400/ 2983 batches | lr 20.00 | ms/batch 10.62 | loss  4.35 | ppl    77.63
| prune-epoch  10 |   600/ 2983 batches | lr 20.00 | ms/batch 10.53 | loss  4.18 | ppl    65.60
| prune-epoch  10 |   800/ 2983 batches | lr 20.00 | ms/batch 10.21 | loss  4.25 | ppl    70.17
| prune-epoch  10 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.50 | loss  4.27 | ppl    71.45
| prune-epoch  10 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.10 | loss  4.28 | ppl    72.06
| prune-epoch  10 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.50 | loss  4.31 | ppl    74.55
| prune-epoch  10 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.12 | loss  4.38 | ppl    79.75
| prune-epoch  10 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.51 | loss  4.28 | ppl    72.06
| prune-epoch  10 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.27 | loss  4.31 | ppl    74.70
| prune-epoch  10 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.18 | loss  4.20 | ppl    66.69
| prune-epoch  10 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.97 | loss  4.24 | ppl    69.35
| prune-epoch  10 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.50 | loss  4.27 | ppl    71.51
| prune-epoch  10 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.11 | loss  4.21 | ppl    67.61
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
-----------------------------------------------------------------------------------------
| end of prune epoch  10 | time: 32.75s | valid loss  4.93 | valid ppl   137.77
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  11 |   200/ 2983 batches | lr 20.00 | ms/batch 10.71 | loss  4.28 | ppl    72.57
| prune-epoch  11 |   400/ 2983 batches | lr 20.00 | ms/batch 10.83 | loss  4.31 | ppl    74.45
| prune-epoch  11 |   600/ 2983 batches | lr 20.00 | ms/batch 10.81 | loss  4.15 | ppl    63.19
| prune-epoch  11 |   800/ 2983 batches | lr 20.00 | ms/batch 11.06 | loss  4.21 | ppl    67.05
| prune-epoch  11 |  1000/ 2983 batches | lr 20.00 | ms/batch 11.08 | loss  4.23 | ppl    68.68
| prune-epoch  11 |  1200/ 2983 batches | lr 20.00 | ms/batch 11.14 | loss  4.23 | ppl    69.03
| prune-epoch  11 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.70 | loss  4.27 | ppl    71.77
| prune-epoch  11 |  1600/ 2983 batches | lr 20.00 | ms/batch 11.13 | loss  4.34 | ppl    76.56
| prune-epoch  11 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.68 | loss  4.25 | ppl    69.91
| prune-epoch  11 |  2000/ 2983 batches | lr 20.00 | ms/batch 11.27 | loss  4.28 | ppl    72.38
| prune-epoch  11 |  2200/ 2983 batches | lr 20.00 | ms/batch 11.22 | loss  4.17 | ppl    64.65
| prune-epoch  11 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.77 | loss  4.21 | ppl    67.08
| prune-epoch  11 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.66 | loss  4.24 | ppl    69.12
| prune-epoch  11 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.66 | loss  4.18 | ppl    65.65
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
-----------------------------------------------------------------------------------------
| end of prune epoch  11 | time: 34.26s | valid loss  4.92 | valid ppl   137.08
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  12 |   200/ 2983 batches | lr 20.00 | ms/batch 10.56 | loss  4.25 | ppl    70.33
| prune-epoch  12 |   400/ 2983 batches | lr 20.00 | ms/batch 10.50 | loss  4.28 | ppl    72.14
| prune-epoch  12 |   600/ 2983 batches | lr 20.00 | ms/batch 10.11 | loss  4.11 | ppl    61.15
| prune-epoch  12 |   800/ 2983 batches | lr 20.00 | ms/batch 10.87 | loss  4.18 | ppl    65.05
| prune-epoch  12 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.11 | loss  4.21 | ppl    67.18
| prune-epoch  12 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.13 | loss  4.22 | ppl    67.72
| prune-epoch  12 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.46 | loss  4.25 | ppl    70.08
| prune-epoch  12 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.11 | loss  4.31 | ppl    74.28
| prune-epoch  12 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.87 | loss  4.22 | ppl    68.19
| prune-epoch  12 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.43 | loss  4.25 | ppl    70.39
| prune-epoch  12 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.78 | loss  4.14 | ppl    62.98
| prune-epoch  12 |  2400/ 2983 batches | lr 20.00 | ms/batch 11.12 | loss  4.19 | ppl    65.78
| prune-epoch  12 |  2600/ 2983 batches | lr 20.00 | ms/batch 11.78 | loss  4.21 | ppl    67.57
| prune-epoch  12 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.69 | loss  4.16 | ppl    64.32
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
-----------------------------------------------------------------------------------------
| end of prune epoch  12 | time: 33.41s | valid loss  4.93 | valid ppl   138.67
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  13 |   200/ 2983 batches | lr 20.00 | ms/batch 11.08 | loss  4.35 | ppl    77.47
| prune-epoch  13 |   400/ 2983 batches | lr 20.00 | ms/batch 10.60 | loss  4.35 | ppl    77.82
| prune-epoch  13 |   600/ 2983 batches | lr 20.00 | ms/batch 11.19 | loss  4.18 | ppl    65.47
| prune-epoch  13 |   800/ 2983 batches | lr 20.00 | ms/batch 11.12 | loss  4.24 | ppl    69.17
| prune-epoch  13 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.60 | loss  4.26 | ppl    71.07
| prune-epoch  13 |  1200/ 2983 batches | lr 20.00 | ms/batch 11.13 | loss  4.26 | ppl    71.16
| prune-epoch  13 |  1400/ 2983 batches | lr 20.00 | ms/batch 11.10 | loss  4.30 | ppl    73.54
| prune-epoch  13 |  1600/ 2983 batches | lr 20.00 | ms/batch 11.11 | loss  4.35 | ppl    77.84
| prune-epoch  13 |  1800/ 2983 batches | lr 20.00 | ms/batch 11.05 | loss  4.27 | ppl    71.41
| prune-epoch  13 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.64 | loss  4.30 | ppl    73.66
| prune-epoch  13 |  2200/ 2983 batches | lr 20.00 | ms/batch 11.15 | loss  4.19 | ppl    65.94
| prune-epoch  13 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.63 | loss  4.23 | ppl    68.38
| prune-epoch  13 |  2600/ 2983 batches | lr 20.00 | ms/batch 11.19 | loss  4.25 | ppl    69.95
| prune-epoch  13 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.61 | loss  4.20 | ppl    66.77
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
-----------------------------------------------------------------------------------------
| end of prune epoch  13 | time: 34.53s | valid loss  4.93 | valid ppl   138.39
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  14 |   200/ 2983 batches | lr 20.00 | ms/batch 11.02 | loss  4.27 | ppl    71.20
| prune-epoch  14 |   400/ 2983 batches | lr 20.00 | ms/batch 11.10 | loss  4.29 | ppl    73.15
| prune-epoch  14 |   600/ 2983 batches | lr 20.00 | ms/batch 10.63 | loss  4.12 | ppl    61.79
| prune-epoch  14 |   800/ 2983 batches | lr 20.00 | ms/batch 11.17 | loss  4.19 | ppl    66.02
| prune-epoch  14 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.74 | loss  4.22 | ppl    67.78
| prune-epoch  14 |  1200/ 2983 batches | lr 20.00 | ms/batch 11.15 | loss  4.22 | ppl    68.05
| prune-epoch  14 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.67 | loss  4.25 | ppl    70.21
| prune-epoch  14 |  1600/ 2983 batches | lr 20.00 | ms/batch 11.58 | loss  4.31 | ppl    74.70
| prune-epoch  14 |  1800/ 2983 batches | lr 20.00 | ms/batch 11.16 | loss  4.23 | ppl    68.87
| prune-epoch  14 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.64 | loss  4.26 | ppl    70.98
| prune-epoch  14 |  2200/ 2983 batches | lr 20.00 | ms/batch 11.01 | loss  4.15 | ppl    63.57
| prune-epoch  14 |  2400/ 2983 batches | lr 20.00 | ms/batch 11.21 | loss  4.19 | ppl    65.95
| prune-epoch  14 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.63 | loss  4.22 | ppl    68.05
| prune-epoch  14 |  2800/ 2983 batches | lr 20.00 | ms/batch 11.15 | loss  4.17 | ppl    64.59
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
-----------------------------------------------------------------------------------------
| end of prune epoch  14 | time: 34.51s | valid loss  4.93 | valid ppl   138.83
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  15 |   200/ 2983 batches | lr 20.00 | ms/batch 10.20 | loss  4.33 | ppl    76.01
| prune-epoch  15 |   400/ 2983 batches | lr 20.00 | ms/batch 10.41 | loss  4.35 | ppl    77.43
| prune-epoch  15 |   600/ 2983 batches | lr 20.00 | ms/batch 10.64 | loss  4.17 | ppl    64.96
| prune-epoch  15 |   800/ 2983 batches | lr 20.00 | ms/batch 10.66 | loss  4.23 | ppl    68.71
| prune-epoch  15 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  4.27 | ppl    71.19
| prune-epoch  15 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.57 | loss  4.26 | ppl    70.80
| prune-epoch  15 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.46 | loss  4.30 | ppl    73.48
| prune-epoch  15 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.12 | loss  4.35 | ppl    77.64
| prune-epoch  15 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.50 | loss  4.27 | ppl    71.19
| prune-epoch  15 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.89 | loss  4.29 | ppl    73.09
| prune-epoch  15 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.71 | loss  4.19 | ppl    65.80
| prune-epoch  15 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.92 | loss  4.22 | ppl    67.89
| prune-epoch  15 |  2600/ 2983 batches | lr 20.00 | ms/batch 11.07 | loss  4.24 | ppl    69.73
| prune-epoch  15 |  2800/ 2983 batches | lr 20.00 | ms/batch 11.46 | loss  4.20 | ppl    66.66
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
-----------------------------------------------------------------------------------------
| end of prune epoch  15 | time: 33.94s | valid loss  4.94 | valid ppl   139.16
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  16 |   200/ 2983 batches | lr 20.00 | ms/batch 11.91 | loss  4.26 | ppl    71.03
| prune-epoch  16 |   400/ 2983 batches | lr 20.00 | ms/batch 11.77 | loss  4.28 | ppl    72.59
| prune-epoch  16 |   600/ 2983 batches | lr 20.00 | ms/batch 11.79 | loss  4.11 | ppl    61.17
| prune-epoch  16 |   800/ 2983 batches | lr 20.00 | ms/batch 11.46 | loss  4.18 | ppl    65.55
| prune-epoch  16 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.79 | loss  4.22 | ppl    67.99
| prune-epoch  16 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.97 | loss  4.21 | ppl    67.69
| prune-epoch  16 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.66 | loss  4.25 | ppl    70.33
| prune-epoch  16 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.86 | loss  4.31 | ppl    74.40
| prune-epoch  16 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.79 | loss  4.22 | ppl    68.30
| prune-epoch  16 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.78 | loss  4.26 | ppl    70.51
| prune-epoch  16 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.70 | loss  4.14 | ppl    63.02
| prune-epoch  16 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.54 | loss  4.18 | ppl    65.15
| prune-epoch  16 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.83 | loss  4.21 | ppl    67.09
| prune-epoch  16 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.81 | loss  4.16 | ppl    64.17
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
-----------------------------------------------------------------------------------------
| end of prune epoch  16 | time: 34.62s | valid loss  4.93 | valid ppl   138.13
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  17 |   200/ 2983 batches | lr 20.00 | ms/batch 10.91 | loss  4.23 | ppl    68.62
| prune-epoch  17 |   400/ 2983 batches | lr 20.00 | ms/batch 10.48 | loss  4.25 | ppl    70.32
| prune-epoch  17 |   600/ 2983 batches | lr 20.00 | ms/batch 10.68 | loss  4.09 | ppl    59.53
| prune-epoch  17 |   800/ 2983 batches | lr 20.00 | ms/batch 10.73 | loss  4.15 | ppl    63.38
| prune-epoch  17 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.93 | loss  4.19 | ppl    65.77
| prune-epoch  17 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.81 | loss  4.18 | ppl    65.57
| prune-epoch  17 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.92 | loss  4.22 | ppl    67.93
| prune-epoch  17 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.12 | loss  4.28 | ppl    72.05
| prune-epoch  17 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.75 | loss  4.20 | ppl    66.41
| prune-epoch  17 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  4.23 | ppl    68.59
| prune-epoch  17 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.81 | loss  4.11 | ppl    61.01
| prune-epoch  17 |  2400/ 2983 batches | lr 20.00 | ms/batch 11.13 | loss  4.15 | ppl    63.38
| prune-epoch  17 |  2600/ 2983 batches | lr 20.00 | ms/batch 11.06 | loss  4.18 | ppl    65.27
| prune-epoch  17 |  2800/ 2983 batches | lr 20.00 | ms/batch 11.14 | loss  4.14 | ppl    62.70
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
-----------------------------------------------------------------------------------------
| end of prune epoch  17 | time: 34.11s | valid loss  4.93 | valid ppl   138.04
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  18 |   200/ 2983 batches | lr 20.00 | ms/batch 10.57 | loss  4.20 | ppl    66.39
| prune-epoch  18 |   400/ 2983 batches | lr 20.00 | ms/batch 10.56 | loss  4.23 | ppl    68.50
| prune-epoch  18 |   600/ 2983 batches | lr 20.00 | ms/batch 10.41 | loss  4.05 | ppl    57.48
| prune-epoch  18 |   800/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  4.12 | ppl    61.44
| prune-epoch  18 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.47 | loss  4.16 | ppl    64.21
| prune-epoch  18 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.78 | loss  4.16 | ppl    64.00
| prune-epoch  18 |  1400/ 2983 batches | lr 20.00 | ms/batch 11.09 | loss  4.20 | ppl    66.41
| prune-epoch  18 |  1600/ 2983 batches | lr 20.00 | ms/batch 11.09 | loss  4.25 | ppl    70.03
| prune-epoch  18 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.78 | loss  4.17 | ppl    64.53
| prune-epoch  18 |  2000/ 2983 batches | lr 20.00 | ms/batch 11.33 | loss  4.20 | ppl    66.90
| prune-epoch  18 |  2200/ 2983 batches | lr 20.00 | ms/batch 11.49 | loss  4.09 | ppl    59.70
| prune-epoch  18 |  2400/ 2983 batches | lr 20.00 | ms/batch 11.10 | loss  4.12 | ppl    61.80
| prune-epoch  18 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.61 | loss  4.16 | ppl    63.96
| prune-epoch  18 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.83 | loss  4.11 | ppl    60.95
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
-----------------------------------------------------------------------------------------
| end of prune epoch  18 | time: 33.98s | valid loss  4.93 | valid ppl   137.80
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  19 |   200/ 2983 batches | lr 20.00 | ms/batch 11.23 | loss  4.17 | ppl    64.89
| prune-epoch  19 |   400/ 2983 batches | lr 20.00 | ms/batch 11.46 | loss  4.20 | ppl    66.56
| prune-epoch  19 |   600/ 2983 batches | lr 20.00 | ms/batch 11.03 | loss  4.04 | ppl    56.57
| prune-epoch  19 |   800/ 2983 batches | lr 20.00 | ms/batch 11.47 | loss  4.10 | ppl    60.19
| prune-epoch  19 |  1000/ 2983 batches | lr 20.00 | ms/batch 11.46 | loss  4.13 | ppl    62.23
| prune-epoch  19 |  1200/ 2983 batches | lr 20.00 | ms/batch 11.32 | loss  4.13 | ppl    62.49
| prune-epoch  19 |  1400/ 2983 batches | lr 20.00 | ms/batch 11.28 | loss  4.17 | ppl    64.45
| prune-epoch  19 |  1600/ 2983 batches | lr 20.00 | ms/batch 11.51 | loss  4.22 | ppl    68.30
| prune-epoch  19 |  1800/ 2983 batches | lr 20.00 | ms/batch 11.42 | loss  4.15 | ppl    63.18
| prune-epoch  19 |  2000/ 2983 batches | lr 20.00 | ms/batch 11.24 | loss  4.17 | ppl    65.03
| prune-epoch  19 |  2200/ 2983 batches | lr 20.00 | ms/batch 11.56 | loss  4.07 | ppl    58.29
| prune-epoch  19 |  2400/ 2983 batches | lr 20.00 | ms/batch 11.54 | loss  4.10 | ppl    60.04
| prune-epoch  19 |  2600/ 2983 batches | lr 20.00 | ms/batch 11.07 | loss  4.13 | ppl    62.07
| prune-epoch  19 |  2800/ 2983 batches | lr 20.00 | ms/batch 11.55 | loss  4.09 | ppl    59.85
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
-----------------------------------------------------------------------------------------
| end of prune epoch  19 | time: 35.73s | valid loss  4.93 | valid ppl   138.82
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  20 |   200/ 2983 batches | lr 20.00 | ms/batch 10.79 | loss  4.33 | ppl    75.88
| prune-epoch  20 |   400/ 2983 batches | lr 20.00 | ms/batch 11.51 | loss  4.33 | ppl    76.17
| prune-epoch  20 |   600/ 2983 batches | lr 20.00 | ms/batch 11.49 | loss  4.16 | ppl    63.77
| prune-epoch  20 |   800/ 2983 batches | lr 20.00 | ms/batch 11.04 | loss  4.22 | ppl    67.81
| prune-epoch  20 |  1000/ 2983 batches | lr 20.00 | ms/batch 11.16 | loss  4.25 | ppl    69.84
| prune-epoch  20 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.59 | loss  4.24 | ppl    69.38
| prune-epoch  20 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.87 | loss  4.28 | ppl    72.14
| prune-epoch  20 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.88 | loss  4.34 | ppl    76.58
| prune-epoch  20 |  1800/ 2983 batches | lr 20.00 | ms/batch 11.70 | loss  4.25 | ppl    69.82
| prune-epoch  20 |  2000/ 2983 batches | lr 20.00 | ms/batch 11.64 | loss  4.28 | ppl    72.26
| prune-epoch  20 |  2200/ 2983 batches | lr 20.00 | ms/batch 11.60 | loss  4.17 | ppl    64.51
| prune-epoch  20 |  2400/ 2983 batches | lr 20.00 | ms/batch 11.31 | loss  4.19 | ppl    66.25
| prune-epoch  20 |  2600/ 2983 batches | lr 20.00 | ms/batch 11.56 | loss  4.22 | ppl    68.25
| prune-epoch  20 |  2800/ 2983 batches | lr 20.00 | ms/batch 11.44 | loss  4.18 | ppl    65.26
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of prune epoch  20 | time: 35.17s | valid loss  4.95 | valid ppl   141.59
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 10.93 | loss  4.24 | ppl    69.17
| prune-epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 11.12 | loss  4.26 | ppl    71.03
| prune-epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 11.50 | loss  4.09 | ppl    59.92
| prune-epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 11.56 | loss  4.15 | ppl    63.72
| prune-epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 11.57 | loss  4.19 | ppl    66.06
| prune-epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 11.55 | loss  4.20 | ppl    66.37
| prune-epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 11.08 | loss  4.23 | ppl    68.58
| prune-epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 11.45 | loss  4.29 | ppl    72.68
| prune-epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 11.55 | loss  4.20 | ppl    67.00
| prune-epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 11.31 | loss  4.24 | ppl    69.41
| prune-epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 11.31 | loss  4.12 | ppl    61.80
| prune-epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 11.47 | loss  4.15 | ppl    63.59
| prune-epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 11.47 | loss  4.18 | ppl    65.65
| prune-epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 11.33 | loss  4.14 | ppl    62.88
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch   1 | time: 35.80s | valid loss  4.94 | valid ppl   139.08
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch 10.55 | loss  4.20 | ppl    66.84
| prune-epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch 11.37 | loss  4.23 | ppl    68.54
| prune-epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch 11.61 | loss  4.06 | ppl    57.96
| prune-epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch 11.08 | loss  4.13 | ppl    62.09
| prune-epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch 11.56 | loss  4.16 | ppl    64.17
| prune-epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 11.57 | loss  4.16 | ppl    64.27
| prune-epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 11.62 | loss  4.20 | ppl    66.65
| prune-epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 11.14 | loss  4.25 | ppl    70.40
| prune-epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch 11.61 | loss  4.18 | ppl    65.11
| prune-epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch 11.63 | loss  4.21 | ppl    67.08
| prune-epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch 11.25 | loss  4.09 | ppl    59.94
| prune-epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch 11.52 | loss  4.12 | ppl    61.59
| prune-epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 11.59 | loss  4.16 | ppl    63.76
| prune-epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 11.19 | loss  4.12 | ppl    61.29
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch   2 | time: 35.78s | valid loss  4.94 | valid ppl   140.00
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 11.12 | loss  4.17 | ppl    64.69
| prune-epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch 11.51 | loss  4.20 | ppl    66.60
| prune-epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 11.28 | loss  4.03 | ppl    56.41
| prune-epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 10.65 | loss  4.10 | ppl    60.40
| prune-epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.92 | loss  4.14 | ppl    62.52
| prune-epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.97 | loss  4.14 | ppl    62.50
| prune-epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 11.15 | loss  4.17 | ppl    64.73
| prune-epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 11.52 | loss  4.22 | ppl    68.32
| prune-epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 11.27 | loss  4.15 | ppl    63.46
| prune-epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 11.35 | loss  4.18 | ppl    65.65
| prune-epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 11.36 | loss  4.07 | ppl    58.33
| prune-epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.57 | loss  4.10 | ppl    60.18
| prune-epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.88 | loss  4.13 | ppl    62.24
| prune-epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.58 | loss  4.09 | ppl    59.98
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch   3 | time: 34.74s | valid loss  4.94 | valid ppl   139.35
-----------------------------------------------------------------------------------------
required epochs   6 | actual epochs  29
pretrain epochs   6 | prune epochs  20 | retrain epochs   3
=========================================================================================
| End of training | test loss  4.86 | test ppl   128.65
=========================================================================================
python main.py --cuda --epochs 6 --tied --save model/prune/model.pt --prune --retrain --sparsity 0.9
<class 'torch.Tensor'> torch.Size([33278, 200])
<class 'torch.Tensor'> torch.Size([800, 200])
<class 'torch.Tensor'> torch.Size([800, 200])
<class 'torch.Tensor'> torch.Size([800])
<class 'torch.Tensor'> torch.Size([800])
<class 'torch.Tensor'> torch.Size([800, 200])
<class 'torch.Tensor'> torch.Size([800, 200])
<class 'torch.Tensor'> torch.Size([800])
<class 'torch.Tensor'> torch.Size([800])
<class 'torch.Tensor'> torch.Size([33278])
RNNModel(
  (drop): Dropout(p=0.2)
  (encoder): Embedding(33278, 200)
  (rnn): LSTM(200, 200, num_layers=2, dropout=0.2)
  (decoder): Linear(in_features=200, out_features=33278, bias=True)
)
Dropout(p=0.2)
Embedding(33278, 200)
LSTM(200, 200, num_layers=2, dropout=0.2)
Linear(in_features=200, out_features=33278, bias=True)
| train-epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 11.15 | loss  7.60 | ppl  1996.57
| train-epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 10.92 | loss  6.79 | ppl   884.59
| train-epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 10.44 | loss  6.37 | ppl   583.03
| train-epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 10.81 | loss  6.20 | ppl   490.51
| train-epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.44 | loss  6.05 | ppl   426.17
| train-epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.58 | loss  5.96 | ppl   388.70
| train-epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.66 | loss  5.85 | ppl   348.41
| train-epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.68 | loss  5.86 | ppl   348.99
| train-epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.62 | loss  5.70 | ppl   298.04
| train-epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.79 | loss  5.67 | ppl   289.88
| train-epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.41 | loss  5.57 | ppl   261.86
| train-epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.84 | loss  5.58 | ppl   265.83
| train-epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  5.57 | ppl   261.30
| train-epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.76 | loss  5.46 | ppl   233.97
-----------------------------------------------------------------------------------------
| end of train epoch   1 | time: 33.68s | valid loss  5.44 | valid ppl   230.57
-----------------------------------------------------------------------------------------
| train-epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch  9.96 | loss  5.46 | ppl   236.21
| train-epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch  9.97 | loss  5.45 | ppl   233.23
| train-epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch 10.14 | loss  5.28 | ppl   196.31
| train-epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch  9.96 | loss  5.29 | ppl   198.16
| train-epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch  9.94 | loss  5.26 | ppl   192.12
| train-epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.24 | loss  5.25 | ppl   190.83
| train-epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.15 | loss  5.26 | ppl   191.90
| train-epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.43 | loss  5.32 | ppl   203.63
| train-epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.31 | loss  5.19 | ppl   179.80
| train-epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.37 | loss  5.20 | ppl   180.76
| train-epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.66 | loss  5.12 | ppl   166.74
| train-epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.72 | loss  5.14 | ppl   170.90
| train-epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.40 | loss  5.16 | ppl   173.66
| train-epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.71 | loss  5.07 | ppl   159.91
-----------------------------------------------------------------------------------------
| end of train epoch   2 | time: 32.38s | valid loss  5.19 | valid ppl   179.37
-----------------------------------------------------------------------------------------
| train-epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 10.37 | loss  5.12 | ppl   168.12
| train-epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch  9.95 | loss  5.15 | ppl   172.10
| train-epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 10.38 | loss  4.97 | ppl   144.60
| train-epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  5.02 | ppl   151.10
| train-epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.38 | loss  5.01 | ppl   149.40
| train-epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.75 | loss  5.01 | ppl   149.72
| train-epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.66 | loss  5.03 | ppl   152.81
| train-epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.93 | loss  5.10 | ppl   164.52
| train-epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.49 | loss  4.98 | ppl   145.63
| train-epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.84 | loss  5.00 | ppl   148.96
| train-epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.50 | loss  4.92 | ppl   136.63
| train-epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.91 | loss  4.95 | ppl   141.38
| train-epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.54 | loss  4.97 | ppl   144.35
| train-epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.94 | loss  4.90 | ppl   134.54
-----------------------------------------------------------------------------------------
| end of train epoch   3 | time: 33.23s | valid loss  5.09 | valid ppl   161.86
-----------------------------------------------------------------------------------------
| train-epoch   4 |   200/ 2983 batches | lr 20.00 | ms/batch 10.08 | loss  4.96 | ppl   143.14
| train-epoch   4 |   400/ 2983 batches | lr 20.00 | ms/batch 10.27 | loss  4.99 | ppl   146.67
| train-epoch   4 |   600/ 2983 batches | lr 20.00 | ms/batch 10.08 | loss  4.81 | ppl   122.62
| train-epoch   4 |   800/ 2983 batches | lr 20.00 | ms/batch 10.05 | loss  4.87 | ppl   129.81
| train-epoch   4 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.30 | loss  4.86 | ppl   129.64
| train-epoch   4 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.13 | loss  4.87 | ppl   130.67
| train-epoch   4 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.32 | loss  4.91 | ppl   135.05
| train-epoch   4 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.22 | loss  4.98 | ppl   145.14
| train-epoch   4 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.79 | loss  4.86 | ppl   128.85
| train-epoch   4 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.46 | loss  4.89 | ppl   132.30
| train-epoch   4 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.53 | loss  4.80 | ppl   121.25
| train-epoch   4 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.88 | loss  4.84 | ppl   125.98
| train-epoch   4 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.50 | loss  4.86 | ppl   129.40
| train-epoch   4 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.92 | loss  4.79 | ppl   120.84
-----------------------------------------------------------------------------------------
| end of train epoch   4 | time: 32.81s | valid loss  5.01 | valid ppl   150.26
-----------------------------------------------------------------------------------------
| train-epoch   5 |   200/ 2983 batches | lr 20.00 | ms/batch 10.19 | loss  4.85 | ppl   128.02
| train-epoch   5 |   400/ 2983 batches | lr 20.00 | ms/batch 10.52 | loss  4.88 | ppl   132.14
| train-epoch   5 |   600/ 2983 batches | lr 20.00 | ms/batch 10.18 | loss  4.70 | ppl   109.87
| train-epoch   5 |   800/ 2983 batches | lr 20.00 | ms/batch 10.59 | loss  4.77 | ppl   117.47
| train-epoch   5 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.57 | loss  4.77 | ppl   117.93
| train-epoch   5 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.49 | loss  4.78 | ppl   118.83
| train-epoch   5 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.87 | loss  4.81 | ppl   123.27
| train-epoch   5 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.67 | loss  4.89 | ppl   132.36
| train-epoch   5 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.11 | loss  4.78 | ppl   118.59
| train-epoch   5 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.29 | loss  4.80 | ppl   122.12
| train-epoch   5 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.41 | loss  4.71 | ppl   111.20
| train-epoch   5 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.54 | loss  4.76 | ppl   116.44
| train-epoch   5 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.41 | loss  4.78 | ppl   118.73
| train-epoch   5 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.30 | loss  4.72 | ppl   111.89
-----------------------------------------------------------------------------------------
| end of train epoch   5 | time: 32.97s | valid loss  4.97 | valid ppl   143.87
-----------------------------------------------------------------------------------------
| train-epoch   6 |   200/ 2983 batches | lr 20.00 | ms/batch 10.86 | loss  4.78 | ppl   119.24
| train-epoch   6 |   400/ 2983 batches | lr 20.00 | ms/batch 10.46 | loss  4.80 | ppl   121.70
| train-epoch   6 |   600/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  4.63 | ppl   102.63
| train-epoch   6 |   800/ 2983 batches | lr 20.00 | ms/batch 10.69 | loss  4.69 | ppl   109.18
| train-epoch   6 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.63 | loss  4.70 | ppl   110.08
| train-epoch   6 |  1200/ 2983 batches | lr 20.00 | ms/batch 11.11 | loss  4.71 | ppl   110.65
| train-epoch   6 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.97 | loss  4.75 | ppl   115.79
| train-epoch   6 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.56 | loss  4.82 | ppl   123.79
| train-epoch   6 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.94 | loss  4.71 | ppl   111.31
| train-epoch   6 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.68 | loss  4.75 | ppl   115.17
| train-epoch   6 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.40 | loss  4.65 | ppl   104.55
| train-epoch   6 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.51 | loss  4.70 | ppl   109.61
| train-epoch   6 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.84 | loss  4.72 | ppl   112.26
| train-epoch   6 |  2800/ 2983 batches | lr 20.00 | ms/batch 11.73 | loss  4.66 | ppl   105.56
-----------------------------------------------------------------------------------------
| end of train epoch   6 | time: 34.22s | valid loss  4.96 | valid ppl   142.89
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 10.98 | loss  4.73 | ppl   113.45
| prune-epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 10.70 | loss  4.75 | ppl   115.36
| prune-epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 11.25 | loss  4.57 | ppl    96.52
| prune-epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 11.24 | loss  4.63 | ppl   102.43
| prune-epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 11.01 | loss  4.64 | ppl   103.93
| prune-epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 11.40 | loss  4.64 | ppl   103.92
| prune-epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 11.16 | loss  4.68 | ppl   107.99
| prune-epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 11.03 | loss  4.75 | ppl   115.83
| prune-epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 11.12 | loss  4.65 | ppl   104.19
| prune-epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 11.01 | loss  4.68 | ppl   107.60
| prune-epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 11.31 | loss  4.58 | ppl    97.36
| prune-epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.88 | loss  4.63 | ppl   102.19
| prune-epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 11.33 | loss  4.64 | ppl   104.00
| prune-epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.87 | loss  4.59 | ppl    98.23
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
-----------------------------------------------------------------------------------------
| end of prune epoch   1 | time: 34.91s | valid loss  4.92 | valid ppl   136.44
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch 10.99 | loss  4.65 | ppl   104.73
| prune-epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch 10.89 | loss  4.68 | ppl   107.69
| prune-epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch 11.32 | loss  4.50 | ppl    90.34
| prune-epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch 11.00 | loss  4.56 | ppl    95.95
| prune-epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch 11.18 | loss  4.58 | ppl    97.63
| prune-epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 11.24 | loss  4.58 | ppl    97.93
| prune-epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.87 | loss  4.63 | ppl   102.80
| prune-epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.89 | loss  4.70 | ppl   110.01
| prune-epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch  9.82 | loss  4.60 | ppl    99.29
| prune-epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.43 | loss  4.63 | ppl   102.42
| prune-epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.76 | loss  4.53 | ppl    92.36
| prune-epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.96 | loss  4.57 | ppl    96.78
| prune-epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 11.20 | loss  4.60 | ppl    99.21
| prune-epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 11.20 | loss  4.54 | ppl    93.46
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
-----------------------------------------------------------------------------------------
| end of prune epoch   2 | time: 34.39s | valid loss  4.90 | valid ppl   134.08
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 10.89 | loss  4.60 | ppl    99.95
| prune-epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch 10.85 | loss  4.63 | ppl   102.75
| prune-epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 10.67 | loss  4.46 | ppl    86.41
| prune-epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 10.66 | loss  4.52 | ppl    91.51
| prune-epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.36 | loss  4.55 | ppl    94.36
| prune-epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.63 | loss  4.55 | ppl    94.66
| prune-epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.35 | loss  4.59 | ppl    98.53
| prune-epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.69 | loss  4.66 | ppl   105.22
| prune-epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.41 | loss  4.56 | ppl    95.57
| prune-epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 11.43 | loss  4.59 | ppl    98.84
| prune-epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 11.35 | loss  4.49 | ppl    88.87
| prune-epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.91 | loss  4.53 | ppl    93.07
| prune-epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch 11.34 | loss  4.56 | ppl    95.37
| prune-epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.88 | loss  4.50 | ppl    90.32
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
-----------------------------------------------------------------------------------------
| end of prune epoch   3 | time: 34.13s | valid loss  4.89 | valid ppl   132.63
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   4 |   200/ 2983 batches | lr 20.00 | ms/batch 10.68 | loss  4.57 | ppl    96.63
| prune-epoch   4 |   400/ 2983 batches | lr 20.00 | ms/batch 11.68 | loss  4.60 | ppl    99.13
| prune-epoch   4 |   600/ 2983 batches | lr 20.00 | ms/batch 12.19 | loss  4.42 | ppl    83.31
| prune-epoch   4 |   800/ 2983 batches | lr 20.00 | ms/batch 12.07 | loss  4.48 | ppl    88.60
| prune-epoch   4 |  1000/ 2983 batches | lr 20.00 | ms/batch 11.44 | loss  4.51 | ppl    91.10
| prune-epoch   4 |  1200/ 2983 batches | lr 20.00 | ms/batch 11.39 | loss  4.52 | ppl    91.74
| prune-epoch   4 |  1400/ 2983 batches | lr 20.00 | ms/batch 11.02 | loss  4.56 | ppl    95.62
| prune-epoch   4 |  1600/ 2983 batches | lr 20.00 | ms/batch 11.41 | loss  4.63 | ppl   102.12
| prune-epoch   4 |  1800/ 2983 batches | lr 20.00 | ms/batch 11.33 | loss  4.52 | ppl    92.29
| prune-epoch   4 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.94 | loss  4.56 | ppl    95.88
| prune-epoch   4 |  2200/ 2983 batches | lr 20.00 | ms/batch 11.13 | loss  4.45 | ppl    85.82
| prune-epoch   4 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.79 | loss  4.50 | ppl    90.43
| prune-epoch   4 |  2600/ 2983 batches | lr 20.00 | ms/batch 11.23 | loss  4.53 | ppl    92.68
| prune-epoch   4 |  2800/ 2983 batches | lr 20.00 | ms/batch 11.37 | loss  4.48 | ppl    88.41
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
-----------------------------------------------------------------------------------------
| end of prune epoch   4 | time: 35.51s | valid loss  4.89 | valid ppl   132.50
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   5 |   200/ 2983 batches | lr 20.00 | ms/batch 10.80 | loss  4.54 | ppl    93.73
| prune-epoch   5 |   400/ 2983 batches | lr 20.00 | ms/batch 10.41 | loss  4.57 | ppl    96.09
| prune-epoch   5 |   600/ 2983 batches | lr 20.00 | ms/batch 10.70 | loss  4.40 | ppl    81.07
| prune-epoch   5 |   800/ 2983 batches | lr 20.00 | ms/batch 10.31 | loss  4.45 | ppl    85.59
| prune-epoch   5 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.75 | loss  4.48 | ppl    88.33
| prune-epoch   5 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.42 | loss  4.49 | ppl    89.37
| prune-epoch   5 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.71 | loss  4.53 | ppl    92.59
| prune-epoch   5 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.41 | loss  4.60 | ppl    99.63
| prune-epoch   5 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.66 | loss  4.50 | ppl    90.08
| prune-epoch   5 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.05 | loss  4.53 | ppl    93.00
| prune-epoch   5 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.35 | loss  4.43 | ppl    83.58
| prune-epoch   5 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.74 | loss  4.48 | ppl    87.88
| prune-epoch   5 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.82 | loss  4.50 | ppl    90.26
| prune-epoch   5 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.62 | loss  4.45 | ppl    85.49
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
-----------------------------------------------------------------------------------------
| end of prune epoch   5 | time: 33.40s | valid loss  4.89 | valid ppl   132.90
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   6 |   200/ 2983 batches | lr 20.00 | ms/batch 11.28 | loss  4.52 | ppl    91.67
| prune-epoch   6 |   400/ 2983 batches | lr 20.00 | ms/batch 10.86 | loss  4.54 | ppl    93.95
| prune-epoch   6 |   600/ 2983 batches | lr 20.00 | ms/batch 10.80 | loss  4.37 | ppl    79.10
| prune-epoch   6 |   800/ 2983 batches | lr 20.00 | ms/batch 10.30 | loss  4.43 | ppl    83.81
| prune-epoch   6 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.18 | loss  4.46 | ppl    86.18
| prune-epoch   6 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.46 | loss  4.46 | ppl    86.78
| prune-epoch   6 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.14 | loss  4.51 | ppl    90.73
| prune-epoch   6 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.09 | loss  4.57 | ppl    96.92
| prune-epoch   6 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.34 | loss  4.47 | ppl    87.71
| prune-epoch   6 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.33 | loss  4.51 | ppl    90.48
| prune-epoch   6 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.08 | loss  4.40 | ppl    81.16
| prune-epoch   6 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.12 | loss  4.45 | ppl    85.28
| prune-epoch   6 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  4.47 | ppl    87.47
| prune-epoch   6 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.42 | ppl    82.88
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
-----------------------------------------------------------------------------------------
| end of prune epoch   6 | time: 32.65s | valid loss  4.88 | valid ppl   131.68
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   7 |   200/ 2983 batches | lr 20.00 | ms/batch 10.81 | loss  4.49 | ppl    88.85
| prune-epoch   7 |   400/ 2983 batches | lr 20.00 | ms/batch 10.63 | loss  4.51 | ppl    90.91
| prune-epoch   7 |   600/ 2983 batches | lr 20.00 | ms/batch 11.64 | loss  4.34 | ppl    76.45
| prune-epoch   7 |   800/ 2983 batches | lr 20.00 | ms/batch 10.99 | loss  4.40 | ppl    81.41
| prune-epoch   7 |  1000/ 2983 batches | lr 20.00 | ms/batch 11.48 | loss  4.44 | ppl    84.52
| prune-epoch   7 |  1200/ 2983 batches | lr 20.00 | ms/batch 11.02 | loss  4.44 | ppl    84.51
| prune-epoch   7 |  1400/ 2983 batches | lr 20.00 | ms/batch 11.48 | loss  4.48 | ppl    87.93
| prune-epoch   7 |  1600/ 2983 batches | lr 20.00 | ms/batch 11.53 | loss  4.55 | ppl    95.00
| prune-epoch   7 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.55 | loss  4.44 | ppl    85.16
| prune-epoch   7 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.90 | loss  4.49 | ppl    88.80
| prune-epoch   7 |  2200/ 2983 batches | lr 20.00 | ms/batch 11.34 | loss  4.37 | ppl    79.37
| prune-epoch   7 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.94 | loss  4.42 | ppl    82.94
| prune-epoch   7 |  2600/ 2983 batches | lr 20.00 | ms/batch 11.31 | loss  4.45 | ppl    85.41
| prune-epoch   7 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.43 | loss  4.39 | ppl    81.01
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
-----------------------------------------------------------------------------------------
| end of prune epoch   7 | time: 34.77s | valid loss  4.87 | valid ppl   129.87
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   8 |   200/ 2983 batches | lr 20.00 | ms/batch 10.47 | loss  4.46 | ppl    86.47
| prune-epoch   8 |   400/ 2983 batches | lr 20.00 | ms/batch 10.69 | loss  4.48 | ppl    88.54
| prune-epoch   8 |   600/ 2983 batches | lr 20.00 | ms/batch 10.43 | loss  4.32 | ppl    74.88
| prune-epoch   8 |   800/ 2983 batches | lr 20.00 | ms/batch 10.76 | loss  4.37 | ppl    79.25
| prune-epoch   8 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.38 | loss  4.41 | ppl    82.42
| prune-epoch   8 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.69 | loss  4.42 | ppl    83.34
| prune-epoch   8 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.28 | loss  4.45 | ppl    85.97
| prune-epoch   8 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.53 | ppl    92.68
| prune-epoch   8 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.15 | loss  4.43 | ppl    83.85
| prune-epoch   8 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.46 | loss  4.47 | ppl    87.08
| prune-epoch   8 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.47 | loss  4.35 | ppl    77.58
| prune-epoch   8 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.46 | loss  4.40 | ppl    81.27
| prune-epoch   8 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.49 | loss  4.43 | ppl    83.61
| prune-epoch   8 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.49 | loss  4.38 | ppl    79.56
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
-----------------------------------------------------------------------------------------
| end of prune epoch   8 | time: 32.79s | valid loss  4.87 | valid ppl   130.66
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   9 |   200/ 2983 batches | lr 20.00 | ms/batch 10.05 | loss  4.46 | ppl    86.27
| prune-epoch   9 |   400/ 2983 batches | lr 20.00 | ms/batch  9.97 | loss  4.48 | ppl    88.05
| prune-epoch   9 |   600/ 2983 batches | lr 20.00 | ms/batch  9.94 | loss  4.31 | ppl    74.54
| prune-epoch   9 |   800/ 2983 batches | lr 20.00 | ms/batch  9.98 | loss  4.37 | ppl    79.01
| prune-epoch   9 |  1000/ 2983 batches | lr 20.00 | ms/batch  9.98 | loss  4.40 | ppl    81.29
| prune-epoch   9 |  1200/ 2983 batches | lr 20.00 | ms/batch  9.92 | loss  4.41 | ppl    82.55
| prune-epoch   9 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.44 | ppl    84.74
| prune-epoch   9 |  1600/ 2983 batches | lr 20.00 | ms/batch  9.94 | loss  4.51 | ppl    90.96
| prune-epoch   9 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.43 | loss  4.41 | ppl    82.58
| prune-epoch   9 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.47 | loss  4.45 | ppl    85.35
| prune-epoch   9 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.47 | loss  4.34 | ppl    76.64
| prune-epoch   9 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.47 | loss  4.38 | ppl    79.86
| prune-epoch   9 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.49 | loss  4.41 | ppl    82.38
| prune-epoch   9 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.48 | loss  4.36 | ppl    78.16
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
-----------------------------------------------------------------------------------------
| end of prune epoch   9 | time: 32.06s | valid loss  4.87 | valid ppl   129.87
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  10 |   200/ 2983 batches | lr 20.00 | ms/batch 10.06 | loss  4.43 | ppl    83.70
| prune-epoch  10 |   400/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.45 | ppl    85.36
| prune-epoch  10 |   600/ 2983 batches | lr 20.00 | ms/batch 10.46 | loss  4.28 | ppl    72.32
| prune-epoch  10 |   800/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  4.34 | ppl    76.85
| prune-epoch  10 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  4.38 | ppl    79.47
| prune-epoch  10 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.47 | loss  4.39 | ppl    80.44
| prune-epoch  10 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.46 | loss  4.42 | ppl    83.23
| prune-epoch  10 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.97 | loss  4.49 | ppl    89.25
| prune-epoch  10 |  1800/ 2983 batches | lr 20.00 | ms/batch 11.10 | loss  4.39 | ppl    80.84
| prune-epoch  10 |  2000/ 2983 batches | lr 20.00 | ms/batch 11.09 | loss  4.43 | ppl    83.84
| prune-epoch  10 |  2200/ 2983 batches | lr 20.00 | ms/batch 11.10 | loss  4.32 | ppl    75.18
| prune-epoch  10 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.69 | loss  4.36 | ppl    78.38
| prune-epoch  10 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  4.39 | ppl    80.65
| prune-epoch  10 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  4.34 | ppl    76.72
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
-----------------------------------------------------------------------------------------
| end of prune epoch  10 | time: 33.18s | valid loss  4.87 | valid ppl   130.80
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  11 |   200/ 2983 batches | lr 20.00 | ms/batch 10.05 | loss  4.45 | ppl    85.88
| prune-epoch  11 |   400/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.47 | ppl    87.58
| prune-epoch  11 |   600/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.30 | ppl    73.88
| prune-epoch  11 |   800/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.36 | ppl    78.06
| prune-epoch  11 |  1000/ 2983 batches | lr 20.00 | ms/batch  9.98 | loss  4.39 | ppl    80.65
| prune-epoch  11 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.03 | loss  4.40 | ppl    81.35
| prune-epoch  11 |  1400/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.43 | ppl    84.18
| prune-epoch  11 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.50 | ppl    89.83
| prune-epoch  11 |  1800/ 2983 batches | lr 20.00 | ms/batch  9.97 | loss  4.40 | ppl    81.28
| prune-epoch  11 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.43 | ppl    84.02
| prune-epoch  11 |  2200/ 2983 batches | lr 20.00 | ms/batch  9.98 | loss  4.32 | ppl    75.23
| prune-epoch  11 |  2400/ 2983 batches | lr 20.00 | ms/batch  9.98 | loss  4.37 | ppl    78.65
| prune-epoch  11 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.39 | ppl    80.64
| prune-epoch  11 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.34 | ppl    76.89
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
-----------------------------------------------------------------------------------------
| end of prune epoch  11 | time: 31.37s | valid loss  4.85 | valid ppl   127.71
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  12 |   200/ 2983 batches | lr 20.00 | ms/batch 10.05 | loss  4.41 | ppl    82.54
| prune-epoch  12 |   400/ 2983 batches | lr 20.00 | ms/batch  9.97 | loss  4.43 | ppl    84.27
| prune-epoch  12 |   600/ 2983 batches | lr 20.00 | ms/batch  9.94 | loss  4.27 | ppl    71.22
| prune-epoch  12 |   800/ 2983 batches | lr 20.00 | ms/batch  9.96 | loss  4.32 | ppl    75.41
| prune-epoch  12 |  1000/ 2983 batches | lr 20.00 | ms/batch  9.91 | loss  4.36 | ppl    78.13
| prune-epoch  12 |  1200/ 2983 batches | lr 20.00 | ms/batch  9.98 | loss  4.37 | ppl    78.92
| prune-epoch  12 |  1400/ 2983 batches | lr 20.00 | ms/batch  9.95 | loss  4.40 | ppl    81.34
| prune-epoch  12 |  1600/ 2983 batches | lr 20.00 | ms/batch  9.97 | loss  4.47 | ppl    87.55
| prune-epoch  12 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.37 | ppl    79.31
| prune-epoch  12 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.55 | loss  4.41 | ppl    82.48
| prune-epoch  12 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.57 | loss  4.30 | ppl    73.43
| prune-epoch  12 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.44 | loss  4.34 | ppl    76.96
| prune-epoch  12 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  4.37 | ppl    79.02
| prune-epoch  12 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.46 | loss  4.32 | ppl    75.53
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
-----------------------------------------------------------------------------------------
| end of prune epoch  12 | time: 31.97s | valid loss  4.85 | valid ppl   128.06
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  13 |   200/ 2983 batches | lr 20.00 | ms/batch 10.39 | loss  4.50 | ppl    90.12
| prune-epoch  13 |   400/ 2983 batches | lr 20.00 | ms/batch 10.37 | loss  4.50 | ppl    90.30
| prune-epoch  13 |   600/ 2983 batches | lr 20.00 | ms/batch 10.39 | loss  4.33 | ppl    76.01
| prune-epoch  13 |   800/ 2983 batches | lr 20.00 | ms/batch 10.38 | loss  4.39 | ppl    80.27
| prune-epoch  13 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.39 | loss  4.42 | ppl    83.13
| prune-epoch  13 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.38 | loss  4.42 | ppl    83.23
| prune-epoch  13 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.38 | loss  4.45 | ppl    85.56
| prune-epoch  13 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.39 | loss  4.52 | ppl    91.81
| prune-epoch  13 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.40 | loss  4.41 | ppl    82.67
| prune-epoch  13 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.40 | loss  4.46 | ppl    86.42
| prune-epoch  13 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.34 | ppl    77.01
| prune-epoch  13 |  2400/ 2983 batches | lr 20.00 | ms/batch  9.67 | loss  4.39 | ppl    80.34
| prune-epoch  13 |  2600/ 2983 batches | lr 20.00 | ms/batch  9.67 | loss  4.40 | ppl    81.54
| prune-epoch  13 |  2800/ 2983 batches | lr 20.00 | ms/batch  9.67 | loss  4.36 | ppl    78.53
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
-----------------------------------------------------------------------------------------
| end of prune epoch  13 | time: 31.89s | valid loss  4.85 | valid ppl   128.10
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  14 |   200/ 2983 batches | lr 20.00 | ms/batch  9.80 | loss  4.43 | ppl    83.52
| prune-epoch  14 |   400/ 2983 batches | lr 20.00 | ms/batch  9.70 | loss  4.45 | ppl    85.59
| prune-epoch  14 |   600/ 2983 batches | lr 20.00 | ms/batch  9.72 | loss  4.29 | ppl    72.68
| prune-epoch  14 |   800/ 2983 batches | lr 20.00 | ms/batch  9.71 | loss  4.34 | ppl    76.92
| prune-epoch  14 |  1000/ 2983 batches | lr 20.00 | ms/batch  9.72 | loss  4.37 | ppl    79.42
| prune-epoch  14 |  1200/ 2983 batches | lr 20.00 | ms/batch  9.71 | loss  4.39 | ppl    80.52
| prune-epoch  14 |  1400/ 2983 batches | lr 20.00 | ms/batch  9.72 | loss  4.41 | ppl    82.61
| prune-epoch  14 |  1600/ 2983 batches | lr 20.00 | ms/batch  9.73 | loss  4.48 | ppl    88.45
| prune-epoch  14 |  1800/ 2983 batches | lr 20.00 | ms/batch  9.96 | loss  4.38 | ppl    79.99
| prune-epoch  14 |  2000/ 2983 batches | lr 20.00 | ms/batch  9.96 | loss  4.42 | ppl    83.15
| prune-epoch  14 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.22 | loss  4.31 | ppl    74.73
| prune-epoch  14 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.43 | loss  4.36 | ppl    77.91
| prune-epoch  14 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.44 | loss  4.38 | ppl    79.55
| prune-epoch  14 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.43 | loss  4.33 | ppl    75.92
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
-----------------------------------------------------------------------------------------
| end of prune epoch  14 | time: 31.40s | valid loss  4.86 | valid ppl   129.24
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  15 |   200/ 2983 batches | lr 20.00 | ms/batch 10.07 | loss  4.48 | ppl    88.56
| prune-epoch  15 |   400/ 2983 batches | lr 20.00 | ms/batch  9.96 | loss  4.49 | ppl    89.22
| prune-epoch  15 |   600/ 2983 batches | lr 20.00 | ms/batch  9.95 | loss  4.33 | ppl    75.68
| prune-epoch  15 |   800/ 2983 batches | lr 20.00 | ms/batch  9.95 | loss  4.38 | ppl    79.45
| prune-epoch  15 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.27 | loss  4.41 | ppl    82.52
| prune-epoch  15 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.49 | loss  4.42 | ppl    82.97
| prune-epoch  15 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.48 | loss  4.45 | ppl    85.22
| prune-epoch  15 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.49 | loss  4.51 | ppl    91.10
| prune-epoch  15 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.50 | loss  4.41 | ppl    82.49
| prune-epoch  15 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.49 | loss  4.45 | ppl    85.70
| prune-epoch  15 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.50 | loss  4.34 | ppl    76.47
| prune-epoch  15 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.50 | loss  4.38 | ppl    80.00
| prune-epoch  15 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.50 | loss  4.40 | ppl    81.67
| prune-epoch  15 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.49 | loss  4.36 | ppl    78.21
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
-----------------------------------------------------------------------------------------
| end of prune epoch  15 | time: 32.48s | valid loss  4.86 | valid ppl   129.14
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  16 |   200/ 2983 batches | lr 20.00 | ms/batch 10.03 | loss  4.43 | ppl    83.54
| prune-epoch  16 |   400/ 2983 batches | lr 20.00 | ms/batch 10.23 | loss  4.45 | ppl    85.32
| prune-epoch  16 |   600/ 2983 batches | lr 20.00 | ms/batch 10.49 | loss  4.28 | ppl    72.44
| prune-epoch  16 |   800/ 2983 batches | lr 20.00 | ms/batch 10.14 | loss  4.34 | ppl    76.50
| prune-epoch  16 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.37 | ppl    79.07
| prune-epoch  16 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.38 | ppl    79.91
| prune-epoch  16 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.03 | loss  4.41 | ppl    82.59
| prune-epoch  16 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.47 | ppl    87.65
| prune-epoch  16 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.03 | loss  4.37 | ppl    79.37
| prune-epoch  16 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.42 | ppl    82.86
| prune-epoch  16 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.31 | ppl    74.33
| prune-epoch  16 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.03 | loss  4.35 | ppl    77.41
| prune-epoch  16 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.37 | ppl    79.17
| prune-epoch  16 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.33 | ppl    76.27
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
-----------------------------------------------------------------------------------------
| end of prune epoch  16 | time: 31.68s | valid loss  4.86 | valid ppl   128.67
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  17 |   200/ 2983 batches | lr 20.00 | ms/batch 10.16 | loss  4.40 | ppl    81.28
| prune-epoch  17 |   400/ 2983 batches | lr 20.00 | ms/batch 10.05 | loss  4.42 | ppl    82.78
| prune-epoch  17 |   600/ 2983 batches | lr 20.00 | ms/batch  9.97 | loss  4.25 | ppl    70.42
| prune-epoch  17 |   800/ 2983 batches | lr 20.00 | ms/batch  9.96 | loss  4.31 | ppl    74.53
| prune-epoch  17 |  1000/ 2983 batches | lr 20.00 | ms/batch  9.91 | loss  4.34 | ppl    77.09
| prune-epoch  17 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.32 | loss  4.37 | ppl    78.66
| prune-epoch  17 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.39 | ppl    80.66
| prune-epoch  17 |  1600/ 2983 batches | lr 20.00 | ms/batch  9.96 | loss  4.46 | ppl    86.11
| prune-epoch  17 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.35 | ppl    77.54
| prune-epoch  17 |  2000/ 2983 batches | lr 20.00 | ms/batch  9.97 | loss  4.39 | ppl    81.03
| prune-epoch  17 |  2200/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.28 | ppl    72.50
| prune-epoch  17 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.32 | ppl    75.26
| prune-epoch  17 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.04 | loss  4.35 | ppl    77.69
| prune-epoch  17 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.31 | ppl    74.18
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
-----------------------------------------------------------------------------------------
| end of prune epoch  17 | time: 31.47s | valid loss  4.85 | valid ppl   128.04
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  18 |   200/ 2983 batches | lr 20.00 | ms/batch 10.11 | loss  4.38 | ppl    79.59
| prune-epoch  18 |   400/ 2983 batches | lr 20.00 | ms/batch 10.04 | loss  4.39 | ppl    80.92
| prune-epoch  18 |   600/ 2983 batches | lr 20.00 | ms/batch 10.08 | loss  4.23 | ppl    68.92
| prune-epoch  18 |   800/ 2983 batches | lr 20.00 | ms/batch 10.46 | loss  4.29 | ppl    72.90
| prune-epoch  18 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  4.33 | ppl    75.74
| prune-epoch  18 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.48 | loss  4.34 | ppl    76.40
| prune-epoch  18 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.64 | loss  4.37 | ppl    78.84
| prune-epoch  18 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  4.44 | ppl    84.67
| prune-epoch  18 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.43 | loss  4.34 | ppl    76.69
| prune-epoch  18 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.44 | loss  4.38 | ppl    79.55
| prune-epoch  18 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.44 | loss  4.27 | ppl    71.26
| prune-epoch  18 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.43 | loss  4.30 | ppl    73.65
| prune-epoch  18 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.46 | loss  4.33 | ppl    76.06
| prune-epoch  18 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.44 | loss  4.29 | ppl    73.20
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
-----------------------------------------------------------------------------------------
| end of prune epoch  18 | time: 32.61s | valid loss  4.85 | valid ppl   127.73
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  19 |   200/ 2983 batches | lr 20.00 | ms/batch 10.13 | loss  4.36 | ppl    77.97
| prune-epoch  19 |   400/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.37 | ppl    79.43
| prune-epoch  19 |   600/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.22 | ppl    67.73
| prune-epoch  19 |   800/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.27 | ppl    71.68
| prune-epoch  19 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.30 | ppl    74.04
| prune-epoch  19 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.32 | ppl    75.11
| prune-epoch  19 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.35 | ppl    77.32
| prune-epoch  19 |  1600/ 2983 batches | lr 20.00 | ms/batch  9.98 | loss  4.41 | ppl    82.48
| prune-epoch  19 |  1800/ 2983 batches | lr 20.00 | ms/batch  9.98 | loss  4.32 | ppl    74.91
| prune-epoch  19 |  2000/ 2983 batches | lr 20.00 | ms/batch  9.97 | loss  4.36 | ppl    78.55
| prune-epoch  19 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.03 | loss  4.25 | ppl    70.38
| prune-epoch  19 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.04 | loss  4.28 | ppl    72.57
| prune-epoch  19 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.11 | loss  4.31 | ppl    74.68
| prune-epoch  19 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.04 | loss  4.28 | ppl    72.04
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
-----------------------------------------------------------------------------------------
| end of prune epoch  19 | time: 31.52s | valid loss  4.85 | valid ppl   127.59
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  20 |   200/ 2983 batches | lr 20.00 | ms/batch 10.13 | loss  4.34 | ppl    76.90
| prune-epoch  20 |   400/ 2983 batches | lr 20.00 | ms/batch  9.91 | loss  4.36 | ppl    78.05
| prune-epoch  20 |   600/ 2983 batches | lr 20.00 | ms/batch  9.77 | loss  4.20 | ppl    66.48
| prune-epoch  20 |   800/ 2983 batches | lr 20.00 | ms/batch  9.76 | loss  4.26 | ppl    70.61
| prune-epoch  20 |  1000/ 2983 batches | lr 20.00 | ms/batch  9.76 | loss  4.29 | ppl    73.18
| prune-epoch  20 |  1200/ 2983 batches | lr 20.00 | ms/batch  9.80 | loss  4.31 | ppl    74.31
| prune-epoch  20 |  1400/ 2983 batches | lr 20.00 | ms/batch  9.95 | loss  4.33 | ppl    76.25
| prune-epoch  20 |  1600/ 2983 batches | lr 20.00 | ms/batch  9.95 | loss  4.40 | ppl    81.31
| prune-epoch  20 |  1800/ 2983 batches | lr 20.00 | ms/batch  9.95 | loss  4.31 | ppl    74.18
| prune-epoch  20 |  2000/ 2983 batches | lr 20.00 | ms/batch  9.95 | loss  4.35 | ppl    77.10
| prune-epoch  20 |  2200/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.23 | ppl    68.88
| prune-epoch  20 |  2400/ 2983 batches | lr 20.00 | ms/batch  9.98 | loss  4.27 | ppl    71.57
| prune-epoch  20 |  2600/ 2983 batches | lr 20.00 | ms/batch  9.97 | loss  4.30 | ppl    73.88
| prune-epoch  20 |  2800/ 2983 batches | lr 20.00 | ms/batch  9.97 | loss  4.26 | ppl    70.91
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
-----------------------------------------------------------------------------------------
| end of prune epoch  20 | time: 31.17s | valid loss  4.85 | valid ppl   127.52
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  21 |   200/ 2983 batches | lr 20.00 | ms/batch 10.11 | loss  4.33 | ppl    75.73
| prune-epoch  21 |   400/ 2983 batches | lr 20.00 | ms/batch 10.03 | loss  4.35 | ppl    77.29
| prune-epoch  21 |   600/ 2983 batches | lr 20.00 | ms/batch 10.05 | loss  4.19 | ppl    65.82
| prune-epoch  21 |   800/ 2983 batches | lr 20.00 | ms/batch 10.07 | loss  4.24 | ppl    69.62
| prune-epoch  21 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.06 | loss  4.29 | ppl    72.61
| prune-epoch  21 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.06 | loss  4.30 | ppl    73.36
| prune-epoch  21 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.05 | loss  4.32 | ppl    75.35
| prune-epoch  21 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.38 | ppl    80.19
| prune-epoch  21 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.29 | ppl    73.05
| prune-epoch  21 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.05 | loss  4.33 | ppl    76.11
| prune-epoch  21 |  2200/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.22 | ppl    68.29
| prune-epoch  21 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.03 | loss  4.26 | ppl    71.12
| prune-epoch  21 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.29 | ppl    73.01
| prune-epoch  21 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.04 | loss  4.25 | ppl    70.03
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
-----------------------------------------------------------------------------------------
| end of prune epoch  21 | time: 31.55s | valid loss  4.85 | valid ppl   128.32
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  22 |   200/ 2983 batches | lr 20.00 | ms/batch 10.19 | loss  4.46 | ppl    86.77
| prune-epoch  22 |   400/ 2983 batches | lr 20.00 | ms/batch 10.08 | loss  4.46 | ppl    86.26
| prune-epoch  22 |   600/ 2983 batches | lr 20.00 | ms/batch 10.11 | loss  4.29 | ppl    72.91
| prune-epoch  22 |   800/ 2983 batches | lr 20.00 | ms/batch 10.09 | loss  4.35 | ppl    77.17
| prune-epoch  22 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.08 | loss  4.38 | ppl    79.66
| prune-epoch  22 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.09 | loss  4.39 | ppl    80.67
| prune-epoch  22 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.06 | loss  4.41 | ppl    82.30
| prune-epoch  22 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.10 | loss  4.47 | ppl    87.36
| prune-epoch  22 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.25 | loss  4.37 | ppl    79.17
| prune-epoch  22 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.14 | loss  4.42 | ppl    82.94
| prune-epoch  22 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.20 | loss  4.31 | ppl    74.12
| prune-epoch  22 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.50 | loss  4.33 | ppl    76.16
| prune-epoch  22 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.50 | loss  4.36 | ppl    78.42
| prune-epoch  22 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.52 | loss  4.32 | ppl    75.52
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of prune epoch  22 | time: 32.14s | valid loss  4.86 | valid ppl   128.58
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 10.13 | loss  4.39 | ppl    80.52
| prune-epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 10.11 | loss  4.40 | ppl    81.80
| prune-epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 10.48 | loss  4.25 | ppl    69.87
| prune-epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  4.30 | ppl    73.59
| prune-epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  4.34 | ppl    76.97
| prune-epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  4.35 | ppl    77.25
| prune-epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  4.37 | ppl    79.36
| prune-epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  4.44 | ppl    84.73
| prune-epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  4.34 | ppl    76.62
| prune-epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.46 | loss  4.39 | ppl    80.25
| prune-epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.42 | loss  4.28 | ppl    72.07
| prune-epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.42 | loss  4.31 | ppl    74.77
| prune-epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.43 | loss  4.34 | ppl    76.54
| prune-epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.44 | loss  4.30 | ppl    73.54
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch   1 | time: 32.66s | valid loss  4.86 | valid ppl   128.75
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch 10.04 | loss  4.37 | ppl    78.95
| prune-epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch  9.96 | loss  4.38 | ppl    79.80
| prune-epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch  9.92 | loss  4.22 | ppl    68.04
| prune-epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch  9.93 | loss  4.28 | ppl    71.89
| prune-epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.32 | loss  4.32 | ppl    74.86
| prune-epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.37 | loss  4.33 | ppl    75.69
| prune-epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.36 | loss  4.35 | ppl    77.84
| prune-epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.42 | loss  4.42 | ppl    82.80
| prune-epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.42 | loss  4.32 | ppl    75.41
| prune-epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.42 | loss  4.37 | ppl    78.73
| prune-epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.40 | loss  4.25 | ppl    70.35
| prune-epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.41 | loss  4.29 | ppl    72.85
| prune-epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.43 | loss  4.32 | ppl    75.05
| prune-epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.40 | loss  4.28 | ppl    72.49
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch   2 | time: 32.30s | valid loss  4.86 | valid ppl   129.05
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 10.08 | loss  4.35 | ppl    77.22
| prune-epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch 10.03 | loss  4.36 | ppl    78.52
| prune-epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.21 | ppl    67.04
| prune-epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 10.04 | loss  4.26 | ppl    70.98
| prune-epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.05 | loss  4.30 | ppl    73.72
| prune-epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.31 | ppl    74.43
| prune-epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.04 | loss  4.34 | ppl    76.86
| prune-epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.40 | ppl    81.66
| prune-epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.31 | ppl    74.23
| prune-epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.35 | ppl    77.23
| prune-epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.03 | loss  4.24 | ppl    69.27
| prune-epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.06 | loss  4.28 | ppl    71.94
| prune-epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.38 | loss  4.31 | ppl    74.18
| prune-epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.48 | loss  4.26 | ppl    71.01
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch   3 | time: 31.81s | valid loss  4.86 | valid ppl   129.54
-----------------------------------------------------------------------------------------
required epochs   6 | actual epochs  31
pretrain epochs   6 | prune epochs  22 | retrain epochs   3
=========================================================================================
| End of training | test loss  4.79 | test ppl   120.79
=========================================================================================
python main.py --cuda --tied --save model/prune/model.pt --prune --retrain --sparsity 0.9
<class 'torch.Tensor'> torch.Size([33278, 200])
<class 'torch.Tensor'> torch.Size([800, 200])
<class 'torch.Tensor'> torch.Size([800, 200])
<class 'torch.Tensor'> torch.Size([800])
<class 'torch.Tensor'> torch.Size([800])
<class 'torch.Tensor'> torch.Size([800, 200])
<class 'torch.Tensor'> torch.Size([800, 200])
<class 'torch.Tensor'> torch.Size([800])
<class 'torch.Tensor'> torch.Size([800])
<class 'torch.Tensor'> torch.Size([33278])
RNNModel(
  (drop): Dropout(p=0.2)
  (encoder): Embedding(33278, 200)
  (rnn): LSTM(200, 200, num_layers=2, dropout=0.2)
  (decoder): Linear(in_features=200, out_features=33278, bias=True)
)
Dropout(p=0.2)
Embedding(33278, 200)
LSTM(200, 200, num_layers=2, dropout=0.2)
Linear(in_features=200, out_features=33278, bias=True)
| train-epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 10.33 | loss  7.60 | ppl  1996.57
| train-epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 10.19 | loss  6.79 | ppl   884.59
| train-epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 10.19 | loss  6.37 | ppl   583.03
| train-epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 10.19 | loss  6.20 | ppl   490.51
| train-epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.25 | loss  6.05 | ppl   426.17
| train-epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.20 | loss  5.96 | ppl   388.70
| train-epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.18 | loss  5.85 | ppl   348.41
| train-epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.15 | loss  5.86 | ppl   348.99
| train-epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.20 | loss  5.70 | ppl   298.04
| train-epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.16 | loss  5.67 | ppl   289.88
| train-epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.15 | loss  5.57 | ppl   261.86
| train-epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.17 | loss  5.58 | ppl   265.83
| train-epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.21 | loss  5.57 | ppl   261.30
| train-epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.16 | loss  5.46 | ppl   233.97
-----------------------------------------------------------------------------------------
| end of train epoch   1 | time: 32.05s | valid loss  5.44 | valid ppl   230.57
-----------------------------------------------------------------------------------------
| train-epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch  9.69 | loss  5.46 | ppl   236.21
| train-epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch  9.65 | loss  5.45 | ppl   233.23
| train-epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch  9.69 | loss  5.28 | ppl   196.31
| train-epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch  9.57 | loss  5.29 | ppl   198.16
| train-epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch  9.65 | loss  5.26 | ppl   192.12
| train-epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch  9.68 | loss  5.25 | ppl   190.83
| train-epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch  9.66 | loss  5.26 | ppl   191.90
| train-epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch  9.63 | loss  5.32 | ppl   203.63
| train-epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch  9.63 | loss  5.19 | ppl   179.80
| train-epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch  9.72 | loss  5.20 | ppl   180.76
| train-epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch  9.61 | loss  5.12 | ppl   166.74
| train-epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch  9.68 | loss  5.14 | ppl   170.90
| train-epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch  9.72 | loss  5.16 | ppl   173.66
| train-epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch  9.66 | loss  5.07 | ppl   159.91
-----------------------------------------------------------------------------------------
| end of train epoch   2 | time: 30.39s | valid loss  5.19 | valid ppl   179.37
-----------------------------------------------------------------------------------------
| train-epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch  9.78 | loss  5.12 | ppl   168.12
| train-epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch  9.75 | loss  5.15 | ppl   172.10
| train-epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch  9.74 | loss  4.97 | ppl   144.60
| train-epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch  9.64 | loss  5.02 | ppl   151.10
| train-epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch  9.64 | loss  5.01 | ppl   149.40
| train-epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch  9.67 | loss  5.01 | ppl   149.72
| train-epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch  9.75 | loss  5.03 | ppl   152.81
| train-epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch  9.65 | loss  5.10 | ppl   164.52
| train-epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch  9.66 | loss  4.98 | ppl   145.63
| train-epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch  9.70 | loss  5.00 | ppl   148.96
| train-epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch  9.66 | loss  4.92 | ppl   136.63
| train-epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch  9.68 | loss  4.95 | ppl   141.38
| train-epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch  9.75 | loss  4.97 | ppl   144.35
| train-epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch  9.70 | loss  4.90 | ppl   134.54
-----------------------------------------------------------------------------------------
| end of train epoch   3 | time: 30.50s | valid loss  5.09 | valid ppl   161.86
-----------------------------------------------------------------------------------------
| train-epoch   4 |   200/ 2983 batches | lr 20.00 | ms/batch  9.70 | loss  4.96 | ppl   143.14
| train-epoch   4 |   400/ 2983 batches | lr 20.00 | ms/batch  9.72 | loss  4.99 | ppl   146.67
| train-epoch   4 |   600/ 2983 batches | lr 20.00 | ms/batch  9.66 | loss  4.81 | ppl   122.62
| train-epoch   4 |   800/ 2983 batches | lr 20.00 | ms/batch  9.70 | loss  4.87 | ppl   129.81
| train-epoch   4 |  1000/ 2983 batches | lr 20.00 | ms/batch  9.67 | loss  4.86 | ppl   129.64
| train-epoch   4 |  1200/ 2983 batches | lr 20.00 | ms/batch  9.69 | loss  4.87 | ppl   130.67
| train-epoch   4 |  1400/ 2983 batches | lr 20.00 | ms/batch  9.66 | loss  4.91 | ppl   135.05
| train-epoch   4 |  1600/ 2983 batches | lr 20.00 | ms/batch  9.64 | loss  4.98 | ppl   145.14
| train-epoch   4 |  1800/ 2983 batches | lr 20.00 | ms/batch  9.69 | loss  4.86 | ppl   128.85
| train-epoch   4 |  2000/ 2983 batches | lr 20.00 | ms/batch  9.69 | loss  4.89 | ppl   132.30
| train-epoch   4 |  2200/ 2983 batches | lr 20.00 | ms/batch  9.69 | loss  4.80 | ppl   121.25
| train-epoch   4 |  2400/ 2983 batches | lr 20.00 | ms/batch  9.75 | loss  4.84 | ppl   125.98
| train-epoch   4 |  2600/ 2983 batches | lr 20.00 | ms/batch  9.72 | loss  4.86 | ppl   129.40
| train-epoch   4 |  2800/ 2983 batches | lr 20.00 | ms/batch  9.69 | loss  4.79 | ppl   120.84
-----------------------------------------------------------------------------------------
| end of train epoch   4 | time: 30.56s | valid loss  5.01 | valid ppl   150.26
-----------------------------------------------------------------------------------------
| train-epoch   5 |   200/ 2983 batches | lr 20.00 | ms/batch  9.68 | loss  4.85 | ppl   128.02
| train-epoch   5 |   400/ 2983 batches | lr 20.00 | ms/batch  9.69 | loss  4.88 | ppl   132.14
| train-epoch   5 |   600/ 2983 batches | lr 20.00 | ms/batch  9.72 | loss  4.70 | ppl   109.87
| train-epoch   5 |   800/ 2983 batches | lr 20.00 | ms/batch  9.70 | loss  4.77 | ppl   117.47
| train-epoch   5 |  1000/ 2983 batches | lr 20.00 | ms/batch  9.63 | loss  4.77 | ppl   117.93
| train-epoch   5 |  1200/ 2983 batches | lr 20.00 | ms/batch  9.61 | loss  4.78 | ppl   118.83
| train-epoch   5 |  1400/ 2983 batches | lr 20.00 | ms/batch  9.68 | loss  4.81 | ppl   123.27
| train-epoch   5 |  1600/ 2983 batches | lr 20.00 | ms/batch  9.63 | loss  4.89 | ppl   132.36
| train-epoch   5 |  1800/ 2983 batches | lr 20.00 | ms/batch  9.62 | loss  4.78 | ppl   118.59
| train-epoch   5 |  2000/ 2983 batches | lr 20.00 | ms/batch  9.90 | loss  4.80 | ppl   122.12
| train-epoch   5 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.11 | loss  4.71 | ppl   111.20
| train-epoch   5 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.15 | loss  4.76 | ppl   116.44
| train-epoch   5 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.10 | loss  4.78 | ppl   118.73
| train-epoch   5 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.09 | loss  4.72 | ppl   111.89
-----------------------------------------------------------------------------------------
| end of train epoch   5 | time: 31.00s | valid loss  4.97 | valid ppl   143.87
-----------------------------------------------------------------------------------------
| train-epoch   6 |   200/ 2983 batches | lr 20.00 | ms/batch 10.24 | loss  4.78 | ppl   119.24
| train-epoch   6 |   400/ 2983 batches | lr 20.00 | ms/batch 10.16 | loss  4.80 | ppl   121.70
| train-epoch   6 |   600/ 2983 batches | lr 20.00 | ms/batch 10.16 | loss  4.63 | ppl   102.63
| train-epoch   6 |   800/ 2983 batches | lr 20.00 | ms/batch 10.17 | loss  4.69 | ppl   109.18
| train-epoch   6 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.19 | loss  4.70 | ppl   110.08
| train-epoch   6 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.17 | loss  4.71 | ppl   110.65
| train-epoch   6 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.13 | loss  4.75 | ppl   115.79
| train-epoch   6 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.18 | loss  4.82 | ppl   123.79
| train-epoch   6 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.16 | loss  4.71 | ppl   111.31
| train-epoch   6 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.16 | loss  4.75 | ppl   115.17
| train-epoch   6 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.16 | loss  4.65 | ppl   104.55
| train-epoch   6 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.17 | loss  4.70 | ppl   109.61
| train-epoch   6 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.24 | loss  4.72 | ppl   112.26
| train-epoch   6 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.26 | loss  4.66 | ppl   105.56
-----------------------------------------------------------------------------------------
| end of train epoch   6 | time: 32.02s | valid loss  4.96 | valid ppl   142.89
-----------------------------------------------------------------------------------------
| train-epoch   7 |   200/ 2983 batches | lr 20.00 | ms/batch  9.97 | loss  4.72 | ppl   112.34
| train-epoch   7 |   400/ 2983 batches | lr 20.00 | ms/batch  9.92 | loss  4.75 | ppl   115.70
| train-epoch   7 |   600/ 2983 batches | lr 20.00 | ms/batch 10.27 | loss  4.57 | ppl    96.97
| train-epoch   7 |   800/ 2983 batches | lr 20.00 | ms/batch 10.20 | loss  4.63 | ppl   102.65
| train-epoch   7 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.23 | loss  4.65 | ppl   104.70
| train-epoch   7 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.35 | loss  4.65 | ppl   105.09
| train-epoch   7 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.21 | loss  4.70 | ppl   109.41
| train-epoch   7 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.20 | loss  4.77 | ppl   117.65
| train-epoch   7 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.20 | loss  4.67 | ppl   106.17
| train-epoch   7 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.22 | loss  4.70 | ppl   109.88
| train-epoch   7 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.22 | loss  4.60 | ppl    99.24
| train-epoch   7 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.21 | loss  4.65 | ppl   104.42
| train-epoch   7 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.21 | loss  4.67 | ppl   107.11
| train-epoch   7 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.27 | loss  4.61 | ppl   100.77
-----------------------------------------------------------------------------------------
| end of train epoch   7 | time: 32.05s | valid loss  4.94 | valid ppl   139.39
-----------------------------------------------------------------------------------------
| train-epoch   8 |   200/ 2983 batches | lr 20.00 | ms/batch  9.77 | loss  4.67 | ppl   106.80
| train-epoch   8 |   400/ 2983 batches | lr 20.00 | ms/batch  9.76 | loss  4.70 | ppl   110.32
| train-epoch   8 |   600/ 2983 batches | lr 20.00 | ms/batch  9.69 | loss  4.52 | ppl    92.16
| train-epoch   8 |   800/ 2983 batches | lr 20.00 | ms/batch  9.71 | loss  4.59 | ppl    98.03
| train-epoch   8 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.17 | loss  4.61 | ppl   100.20
| train-epoch   8 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.18 | loss  4.61 | ppl   100.83
| train-epoch   8 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.16 | loss  4.66 | ppl   105.49
| train-epoch   8 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.16 | loss  4.73 | ppl   113.36
| train-epoch   8 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.17 | loss  4.62 | ppl   101.89
| train-epoch   8 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.17 | loss  4.66 | ppl   105.61
| train-epoch   8 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.16 | loss  4.56 | ppl    95.65
| train-epoch   8 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.18 | loss  4.61 | ppl   100.33
| train-epoch   8 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.17 | loss  4.63 | ppl   102.81
| train-epoch   8 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.16 | loss  4.57 | ppl    96.83
-----------------------------------------------------------------------------------------
| end of train epoch   8 | time: 31.61s | valid loss  4.93 | valid ppl   138.01
-----------------------------------------------------------------------------------------
| train-epoch   9 |   200/ 2983 batches | lr 20.00 | ms/batch  9.78 | loss  4.64 | ppl   103.24
| train-epoch   9 |   400/ 2983 batches | lr 20.00 | ms/batch  9.70 | loss  4.67 | ppl   106.54
| train-epoch   9 |   600/ 2983 batches | lr 20.00 | ms/batch  9.69 | loss  4.49 | ppl    88.91
| train-epoch   9 |   800/ 2983 batches | lr 20.00 | ms/batch  9.72 | loss  4.55 | ppl    94.61
| train-epoch   9 |  1000/ 2983 batches | lr 20.00 | ms/batch  9.71 | loss  4.57 | ppl    96.82
| train-epoch   9 |  1200/ 2983 batches | lr 20.00 | ms/batch  9.70 | loss  4.58 | ppl    97.54
| train-epoch   9 |  1400/ 2983 batches | lr 20.00 | ms/batch  9.66 | loss  4.62 | ppl   101.79
| train-epoch   9 |  1600/ 2983 batches | lr 20.00 | ms/batch  9.70 | loss  4.70 | ppl   109.46
| train-epoch   9 |  1800/ 2983 batches | lr 20.00 | ms/batch  9.73 | loss  4.59 | ppl    98.85
| train-epoch   9 |  2000/ 2983 batches | lr 20.00 | ms/batch  9.69 | loss  4.63 | ppl   102.15
| train-epoch   9 |  2200/ 2983 batches | lr 20.00 | ms/batch  9.71 | loss  4.52 | ppl    92.07
| train-epoch   9 |  2400/ 2983 batches | lr 20.00 | ms/batch  9.72 | loss  4.58 | ppl    97.07
| train-epoch   9 |  2600/ 2983 batches | lr 20.00 | ms/batch  9.68 | loss  4.60 | ppl    99.77
| train-epoch   9 |  2800/ 2983 batches | lr 20.00 | ms/batch  9.73 | loss  4.54 | ppl    93.77
-----------------------------------------------------------------------------------------
| end of train epoch   9 | time: 30.51s | valid loss  4.91 | valid ppl   135.54
-----------------------------------------------------------------------------------------
| train-epoch  10 |   200/ 2983 batches | lr 20.00 | ms/batch 10.27 | loss  4.60 | ppl    99.97
| train-epoch  10 |   400/ 2983 batches | lr 20.00 | ms/batch 10.20 | loss  4.63 | ppl   102.65
| train-epoch  10 |   600/ 2983 batches | lr 20.00 | ms/batch 10.25 | loss  4.46 | ppl    86.11
| train-epoch  10 |   800/ 2983 batches | lr 20.00 | ms/batch 10.25 | loss  4.51 | ppl    91.25
| train-epoch  10 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.23 | loss  4.54 | ppl    93.84
| train-epoch  10 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.24 | loss  4.55 | ppl    95.00
| train-epoch  10 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.24 | loss  4.59 | ppl    98.88
| train-epoch  10 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.24 | loss  4.66 | ppl   106.07
| train-epoch  10 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.23 | loss  4.56 | ppl    95.86
| train-epoch  10 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.24 | loss  4.60 | ppl    99.77
| train-epoch  10 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.35 | loss  4.49 | ppl    89.32
| train-epoch  10 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.83 | loss  4.55 | ppl    94.44
| train-epoch  10 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.80 | loss  4.57 | ppl    96.82
| train-epoch  10 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.81 | loss  4.52 | ppl    92.12
-----------------------------------------------------------------------------------------
| end of train epoch  10 | time: 32.80s | valid loss  4.91 | valid ppl   135.93
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 10.53 | loss  4.59 | ppl    98.08
| prune-epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 10.39 | loss  4.61 | ppl   100.23
| prune-epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 10.40 | loss  4.43 | ppl    83.77
| prune-epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  4.49 | ppl    88.79
| prune-epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.43 | loss  4.51 | ppl    91.15
| prune-epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.42 | loss  4.52 | ppl    92.03
| prune-epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.48 | loss  4.56 | ppl    95.31
| prune-epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.69 | loss  4.63 | ppl   102.76
| prune-epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.92 | loss  4.53 | ppl    92.48
| prune-epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.56 | loss  4.56 | ppl    95.46
| prune-epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.46 | loss  4.45 | ppl    85.91
| prune-epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.44 | loss  4.50 | ppl    89.97
| prune-epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.22 | loss  4.52 | ppl    92.01
| prune-epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch  9.80 | loss  4.47 | ppl    87.22
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
-----------------------------------------------------------------------------------------
| end of prune epoch   1 | time: 32.60s | valid loss  4.90 | valid ppl   133.87
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch  9.95 | loss  4.54 | ppl    93.23
| prune-epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch  9.79 | loss  4.56 | ppl    95.45
| prune-epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch  9.77 | loss  4.38 | ppl    80.03
| prune-epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch  9.77 | loss  4.44 | ppl    84.95
| prune-epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch  9.77 | loss  4.47 | ppl    87.72
| prune-epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch  9.94 | loss  4.48 | ppl    88.24
| prune-epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch  9.97 | loss  4.52 | ppl    91.93
| prune-epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.60 | ppl    99.07
| prune-epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch  9.96 | loss  4.49 | ppl    89.57
| prune-epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch  9.96 | loss  4.52 | ppl    92.17
| prune-epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch  9.97 | loss  4.41 | ppl    82.61
| prune-epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch  9.95 | loss  4.46 | ppl    86.71
| prune-epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch  9.97 | loss  4.49 | ppl    89.22
| prune-epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.05 | loss  4.44 | ppl    84.69
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
-----------------------------------------------------------------------------------------
| end of prune epoch   2 | time: 31.15s | valid loss  4.87 | valid ppl   130.34
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 10.17 | loss  4.50 | ppl    90.16
| prune-epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.52 | ppl    92.18
| prune-epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.35 | ppl    77.37
| prune-epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 10.33 | loss  4.41 | ppl    82.46
| prune-epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.08 | loss  4.45 | ppl    85.64
| prune-epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.46 | ppl    86.19
| prune-epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.49 | ppl    89.21
| prune-epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch  9.98 | loss  4.57 | ppl    96.45
| prune-epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.47 | ppl    87.05
| prune-epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.50 | ppl    90.01
| prune-epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.39 | ppl    80.81
| prune-epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.44 | ppl    84.39
| prune-epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch  9.98 | loss  4.47 | ppl    87.16
| prune-epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.41 | ppl    82.65
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
-----------------------------------------------------------------------------------------
| end of prune epoch   3 | time: 31.52s | valid loss  4.87 | valid ppl   129.85
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   4 |   200/ 2983 batches | lr 20.00 | ms/batch 10.11 | loss  4.47 | ppl    87.73
| prune-epoch   4 |   400/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.50 | ppl    90.05
| prune-epoch   4 |   600/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.33 | ppl    75.62
| prune-epoch   4 |   800/ 2983 batches | lr 20.00 | ms/batch 10.05 | loss  4.39 | ppl    80.25
| prune-epoch   4 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.42 | ppl    83.26
| prune-epoch   4 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.04 | loss  4.43 | ppl    84.04
| prune-epoch   4 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.47 | ppl    87.14
| prune-epoch   4 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.54 | ppl    93.66
| prune-epoch   4 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.04 | loss  4.44 | ppl    84.97
| prune-epoch   4 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.05 | loss  4.48 | ppl    87.88
| prune-epoch   4 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.36 | ppl    78.62
| prune-epoch   4 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.03 | loss  4.41 | ppl    82.68
| prune-epoch   4 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.03 | loss  4.45 | ppl    85.23
| prune-epoch   4 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.39 | ppl    80.72
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.4  actual sp:  0.395
-----------------------------------------------------------------------------------------
| end of prune epoch   4 | time: 31.51s | valid loss  4.87 | valid ppl   130.85
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   5 |   200/ 2983 batches | lr 20.00 | ms/batch 10.17 | loss  4.46 | ppl    86.84
| prune-epoch   5 |   400/ 2983 batches | lr 20.00 | ms/batch 10.05 | loss  4.49 | ppl    88.77
| prune-epoch   5 |   600/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.31 | ppl    74.71
| prune-epoch   5 |   800/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.37 | ppl    79.24
| prune-epoch   5 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.03 | loss  4.40 | ppl    81.35
| prune-epoch   5 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.04 | loss  4.42 | ppl    82.81
| prune-epoch   5 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.03 | loss  4.45 | ppl    85.64
| prune-epoch   5 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.03 | loss  4.52 | ppl    91.91
| prune-epoch   5 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.42 | ppl    83.43
| prune-epoch   5 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.46 | ppl    86.47
| prune-epoch   5 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.35 | ppl    77.32
| prune-epoch   5 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.40 | ppl    81.08
| prune-epoch   5 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.42 | ppl    83.25
| prune-epoch   5 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.37 | ppl    78.79
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
-----------------------------------------------------------------------------------------
| end of prune epoch   5 | time: 31.54s | valid loss  4.86 | valid ppl   129.47
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   6 |   200/ 2983 batches | lr 20.00 | ms/batch 10.11 | loss  4.44 | ppl    84.63
| prune-epoch   6 |   400/ 2983 batches | lr 20.00 | ms/batch 10.05 | loss  4.45 | ppl    85.86
| prune-epoch   6 |   600/ 2983 batches | lr 20.00 | ms/batch 10.54 | loss  4.29 | ppl    72.81
| prune-epoch   6 |   800/ 2983 batches | lr 20.00 | ms/batch 11.18 | loss  4.35 | ppl    77.17
| prune-epoch   6 |  1000/ 2983 batches | lr 20.00 | ms/batch 11.21 | loss  4.38 | ppl    80.22
| prune-epoch   6 |  1200/ 2983 batches | lr 20.00 | ms/batch 11.25 | loss  4.39 | ppl    80.99
| prune-epoch   6 |  1400/ 2983 batches | lr 20.00 | ms/batch 11.21 | loss  4.43 | ppl    83.76
| prune-epoch   6 |  1600/ 2983 batches | lr 20.00 | ms/batch 11.21 | loss  4.50 | ppl    90.09
| prune-epoch   6 |  1800/ 2983 batches | lr 20.00 | ms/batch 11.20 | loss  4.40 | ppl    81.68
| prune-epoch   6 |  2000/ 2983 batches | lr 20.00 | ms/batch 11.21 | loss  4.43 | ppl    84.34
| prune-epoch   6 |  2200/ 2983 batches | lr 20.00 | ms/batch 11.20 | loss  4.33 | ppl    75.76
| prune-epoch   6 |  2400/ 2983 batches | lr 20.00 | ms/batch 11.10 | loss  4.37 | ppl    79.28
| prune-epoch   6 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.40 | loss  4.40 | ppl    81.15
| prune-epoch   6 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.41 | loss  4.35 | ppl    77.52
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
-----------------------------------------------------------------------------------------
| end of prune epoch   6 | time: 33.99s | valid loss  4.86 | valid ppl   129.33
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   7 |   200/ 2983 batches | lr 20.00 | ms/batch 10.09 | loss  4.42 | ppl    82.83
| prune-epoch   7 |   400/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.44 | ppl    84.47
| prune-epoch   7 |   600/ 2983 batches | lr 20.00 | ms/batch  9.97 | loss  4.27 | ppl    71.64
| prune-epoch   7 |   800/ 2983 batches | lr 20.00 | ms/batch  9.98 | loss  4.33 | ppl    75.78
| prune-epoch   7 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.37 | ppl    78.91
| prune-epoch   7 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.38 | ppl    79.57
| prune-epoch   7 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.03 | loss  4.41 | ppl    82.28
| prune-epoch   7 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.48 | ppl    88.55
| prune-epoch   7 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.38 | ppl    80.12
| prune-epoch   7 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.42 | ppl    82.78
| prune-epoch   7 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.31 | ppl    74.32
| prune-epoch   7 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.12 | loss  4.35 | ppl    77.62
| prune-epoch   7 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.44 | loss  4.38 | ppl    79.91
| prune-epoch   7 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.43 | loss  4.33 | ppl    76.28
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
-----------------------------------------------------------------------------------------
| end of prune epoch   7 | time: 31.78s | valid loss  4.85 | valid ppl   127.44
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   8 |   200/ 2983 batches | lr 20.00 | ms/batch 10.13 | loss  4.40 | ppl    81.62
| prune-epoch   8 |   400/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.42 | ppl    83.35
| prune-epoch   8 |   600/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.25 | ppl    70.40
| prune-epoch   8 |   800/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.31 | ppl    74.48
| prune-epoch   8 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.07 | loss  4.35 | ppl    77.26
| prune-epoch   8 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.36 | ppl    78.28
| prune-epoch   8 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.39 | ppl    80.75
| prune-epoch   8 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.47 | ppl    86.97
| prune-epoch   8 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.37 | ppl    79.11
| prune-epoch   8 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.40 | ppl    81.66
| prune-epoch   8 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.12 | loss  4.29 | ppl    73.17
| prune-epoch   8 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.44 | loss  4.34 | ppl    76.59
| prune-epoch   8 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  4.37 | ppl    78.79
| prune-epoch   8 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.44 | loss  4.32 | ppl    75.18
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.5  actual sp:  0.495
-----------------------------------------------------------------------------------------
| end of prune epoch   8 | time: 31.87s | valid loss  4.86 | valid ppl   128.50
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   9 |   200/ 2983 batches | lr 20.00 | ms/batch 10.08 | loss  4.40 | ppl    81.58
| prune-epoch   9 |   400/ 2983 batches | lr 20.00 | ms/batch  9.95 | loss  4.42 | ppl    83.15
| prune-epoch   9 |   600/ 2983 batches | lr 20.00 | ms/batch  9.96 | loss  4.26 | ppl    70.51
| prune-epoch   9 |   800/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.31 | ppl    74.44
| prune-epoch   9 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.35 | ppl    77.59
| prune-epoch   9 |  1200/ 2983 batches | lr 20.00 | ms/batch  9.98 | loss  4.35 | ppl    77.86
| prune-epoch   9 |  1400/ 2983 batches | lr 20.00 | ms/batch  9.92 | loss  4.39 | ppl    80.41
| prune-epoch   9 |  1600/ 2983 batches | lr 20.00 | ms/batch  9.93 | loss  4.46 | ppl    86.41
| prune-epoch   9 |  1800/ 2983 batches | lr 20.00 | ms/batch  9.98 | loss  4.36 | ppl    78.20
| prune-epoch   9 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.19 | loss  4.39 | ppl    80.86
| prune-epoch   9 |  2200/ 2983 batches | lr 20.00 | ms/batch  9.96 | loss  4.29 | ppl    72.75
| prune-epoch   9 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.33 | ppl    75.94
| prune-epoch   9 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.39 | loss  4.35 | ppl    77.68
| prune-epoch   9 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.38 | loss  4.31 | ppl    74.09
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
-----------------------------------------------------------------------------------------
| end of prune epoch   9 | time: 31.67s | valid loss  4.86 | valid ppl   128.67
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  10 |   200/ 2983 batches | lr 20.00 | ms/batch 10.07 | loss  4.38 | ppl    79.60
| prune-epoch  10 |   400/ 2983 batches | lr 20.00 | ms/batch  9.96 | loss  4.40 | ppl    81.50
| prune-epoch  10 |   600/ 2983 batches | lr 20.00 | ms/batch  9.98 | loss  4.24 | ppl    69.17
| prune-epoch  10 |   800/ 2983 batches | lr 20.00 | ms/batch  9.98 | loss  4.29 | ppl    72.83
| prune-epoch  10 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.17 | loss  4.33 | ppl    75.57
| prune-epoch  10 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.44 | loss  4.34 | ppl    76.86
| prune-epoch  10 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.46 | loss  4.36 | ppl    78.63
| prune-epoch  10 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.47 | loss  4.44 | ppl    84.96
| prune-epoch  10 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.05 | loss  4.34 | ppl    76.78
| prune-epoch  10 |  2000/ 2983 batches | lr 20.00 | ms/batch  9.82 | loss  4.37 | ppl    79.42
| prune-epoch  10 |  2200/ 2983 batches | lr 20.00 | ms/batch  9.81 | loss  4.27 | ppl    71.57
| prune-epoch  10 |  2400/ 2983 batches | lr 20.00 | ms/batch  9.82 | loss  4.31 | ppl    74.74
| prune-epoch  10 |  2600/ 2983 batches | lr 20.00 | ms/batch  9.84 | loss  4.34 | ppl    76.64
| prune-epoch  10 |  2800/ 2983 batches | lr 20.00 | ms/batch  9.81 | loss  4.29 | ppl    73.04
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
-----------------------------------------------------------------------------------------
| end of prune epoch  10 | time: 31.50s | valid loss  4.85 | valid ppl   127.84
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  11 |   200/ 2983 batches | lr 20.00 | ms/batch 10.40 | loss  4.36 | ppl    77.92
| prune-epoch  11 |   400/ 2983 batches | lr 20.00 | ms/batch 10.52 | loss  4.38 | ppl    79.95
| prune-epoch  11 |   600/ 2983 batches | lr 20.00 | ms/batch 10.50 | loss  4.21 | ppl    67.59
| prune-epoch  11 |   800/ 2983 batches | lr 20.00 | ms/batch 10.52 | loss  4.27 | ppl    71.37
| prune-epoch  11 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.52 | loss  4.31 | ppl    74.65
| prune-epoch  11 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.50 | loss  4.32 | ppl    75.11
| prune-epoch  11 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.49 | loss  4.35 | ppl    77.71
| prune-epoch  11 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.50 | loss  4.43 | ppl    83.73
| prune-epoch  11 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.51 | loss  4.32 | ppl    75.56
| prune-epoch  11 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.48 | loss  4.36 | ppl    78.40
| prune-epoch  11 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.49 | loss  4.25 | ppl    70.12
| prune-epoch  11 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.49 | loss  4.30 | ppl    73.50
| prune-epoch  11 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.49 | loss  4.32 | ppl    75.50
| prune-epoch  11 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.49 | loss  4.28 | ppl    72.30
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
-----------------------------------------------------------------------------------------
| end of prune epoch  11 | time: 32.93s | valid loss  4.84 | valid ppl   127.03
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  12 |   200/ 2983 batches | lr 20.00 | ms/batch 10.15 | loss  4.34 | ppl    76.69
| prune-epoch  12 |   400/ 2983 batches | lr 20.00 | ms/batch 10.08 | loss  4.37 | ppl    78.96
| prune-epoch  12 |   600/ 2983 batches | lr 20.00 | ms/batch 10.03 | loss  4.20 | ppl    66.87
| prune-epoch  12 |   800/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.26 | ppl    70.65
| prune-epoch  12 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.30 | ppl    73.49
| prune-epoch  12 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.08 | loss  4.31 | ppl    74.07
| prune-epoch  12 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.08 | loss  4.34 | ppl    76.53
| prune-epoch  12 |  1600/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.41 | ppl    82.10
| prune-epoch  12 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.32 | ppl    74.87
| prune-epoch  12 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.06 | loss  4.35 | ppl    77.29
| prune-epoch  12 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.08 | loss  4.24 | ppl    69.42
| prune-epoch  12 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.07 | loss  4.28 | ppl    72.56
| prune-epoch  12 |  2600/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.31 | ppl    74.69
| prune-epoch  12 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.03 | loss  4.26 | ppl    71.11
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.6  actual sp:  0.595
-----------------------------------------------------------------------------------------
| end of prune epoch  12 | time: 31.56s | valid loss  4.85 | valid ppl   127.26
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  13 |   200/ 2983 batches | lr 20.00 | ms/batch 10.19 | loss  4.38 | ppl    79.71
| prune-epoch  13 |   400/ 2983 batches | lr 20.00 | ms/batch 10.09 | loss  4.40 | ppl    81.45
| prune-epoch  13 |   600/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.23 | ppl    68.50
| prune-epoch  13 |   800/ 2983 batches | lr 20.00 | ms/batch  9.97 | loss  4.29 | ppl    73.07
| prune-epoch  13 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.03 | loss  4.32 | ppl    75.52
| prune-epoch  13 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.10 | loss  4.33 | ppl    76.18
| prune-epoch  13 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.36 | ppl    78.18
| prune-epoch  13 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.08 | loss  4.43 | ppl    84.11
| prune-epoch  13 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.43 | loss  4.33 | ppl    75.90
| prune-epoch  13 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.42 | loss  4.37 | ppl    79.13
| prune-epoch  13 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.42 | loss  4.26 | ppl    70.68
| prune-epoch  13 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.43 | loss  4.30 | ppl    73.40
| prune-epoch  13 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.43 | loss  4.32 | ppl    75.36
| prune-epoch  13 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.42 | loss  4.27 | ppl    71.78
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
-----------------------------------------------------------------------------------------
| end of prune epoch  13 | time: 32.16s | valid loss  4.86 | valid ppl   129.13
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  14 |   200/ 2983 batches | lr 20.00 | ms/batch 10.10 | loss  4.35 | ppl    77.11
| prune-epoch  14 |   400/ 2983 batches | lr 20.00 | ms/batch 10.06 | loss  4.36 | ppl    78.61
| prune-epoch  14 |   600/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.20 | ppl    66.75
| prune-epoch  14 |   800/ 2983 batches | lr 20.00 | ms/batch 10.08 | loss  4.26 | ppl    70.83
| prune-epoch  14 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.39 | loss  4.30 | ppl    73.77
| prune-epoch  14 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.47 | loss  4.30 | ppl    74.06
| prune-epoch  14 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.48 | loss  4.34 | ppl    76.55
| prune-epoch  14 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.46 | loss  4.41 | ppl    82.60
| prune-epoch  14 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  4.32 | ppl    74.82
| prune-epoch  14 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  4.35 | ppl    77.26
| prune-epoch  14 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  4.23 | ppl    68.91
| prune-epoch  14 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  4.27 | ppl    71.75
| prune-epoch  14 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.46 | loss  4.30 | ppl    74.06
| prune-epoch  14 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  4.26 | ppl    70.88
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
-----------------------------------------------------------------------------------------
| end of prune epoch  14 | time: 32.51s | valid loss  4.84 | valid ppl   126.49
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  15 |   200/ 2983 batches | lr 20.00 | ms/batch 10.05 | loss  4.32 | ppl    75.25
| prune-epoch  15 |   400/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.35 | ppl    77.14
| prune-epoch  15 |   600/ 2983 batches | lr 20.00 | ms/batch 10.07 | loss  4.18 | ppl    65.46
| prune-epoch  15 |   800/ 2983 batches | lr 20.00 | ms/batch 10.03 | loss  4.25 | ppl    69.90
| prune-epoch  15 |  1000/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.28 | ppl    72.41
| prune-epoch  15 |  1200/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.29 | ppl    72.77
| prune-epoch  15 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.03 | loss  4.32 | ppl    75.25
| prune-epoch  15 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.39 | ppl    80.64
| prune-epoch  15 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.29 | ppl    73.32
| prune-epoch  15 |  2000/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.34 | ppl    76.33
| prune-epoch  15 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.22 | ppl    68.19
| prune-epoch  15 |  2400/ 2983 batches | lr 20.00 | ms/batch  9.98 | loss  4.26 | ppl    70.86
| prune-epoch  15 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.04 | loss  4.29 | ppl    72.96
| prune-epoch  15 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.05 | loss  4.25 | ppl    69.80
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
-----------------------------------------------------------------------------------------
| end of prune epoch  15 | time: 31.44s | valid loss  4.84 | valid ppl   126.03
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  16 |   200/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.31 | ppl    74.59
| prune-epoch  16 |   400/ 2983 batches | lr 20.00 | ms/batch  9.98 | loss  4.33 | ppl    76.14
| prune-epoch  16 |   600/ 2983 batches | lr 20.00 | ms/batch 10.35 | loss  4.17 | ppl    64.42
| prune-epoch  16 |   800/ 2983 batches | lr 20.00 | ms/batch 10.36 | loss  4.23 | ppl    68.89
| prune-epoch  16 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.38 | loss  4.27 | ppl    71.39
| prune-epoch  16 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.38 | loss  4.28 | ppl    72.17
| prune-epoch  16 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.38 | loss  4.30 | ppl    73.68
| prune-epoch  16 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.39 | loss  4.38 | ppl    79.57
| prune-epoch  16 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.37 | loss  4.28 | ppl    72.08
| prune-epoch  16 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.37 | loss  4.32 | ppl    75.23
| prune-epoch  16 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.38 | loss  4.21 | ppl    67.04
| prune-epoch  16 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.37 | loss  4.25 | ppl    70.04
| prune-epoch  16 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.35 | loss  4.27 | ppl    71.82
| prune-epoch  16 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.36 | loss  4.23 | ppl    68.88
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.7  actual sp:  0.6950000000000001
-----------------------------------------------------------------------------------------
| end of prune epoch  16 | time: 32.41s | valid loss  4.84 | valid ppl   126.70
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  17 |   200/ 2983 batches | lr 20.00 | ms/batch 10.10 | loss  4.42 | ppl    83.14
| prune-epoch  17 |   400/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.43 | ppl    83.58
| prune-epoch  17 |   600/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.25 | ppl    70.33
| prune-epoch  17 |   800/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.30 | ppl    73.98
| prune-epoch  17 |  1000/ 2983 batches | lr 20.00 | ms/batch  9.97 | loss  4.34 | ppl    76.74
| prune-epoch  17 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.35 | ppl    77.20
| prune-epoch  17 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.37 | ppl    79.33
| prune-epoch  17 |  1600/ 2983 batches | lr 20.00 | ms/batch  9.97 | loss  4.44 | ppl    84.85
| prune-epoch  17 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.35 | ppl    77.12
| prune-epoch  17 |  2000/ 2983 batches | lr 20.00 | ms/batch  9.96 | loss  4.38 | ppl    79.86
| prune-epoch  17 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.27 | ppl    71.33
| prune-epoch  17 |  2400/ 2983 batches | lr 20.00 | ms/batch  9.98 | loss  4.31 | ppl    74.30
| prune-epoch  17 |  2600/ 2983 batches | lr 20.00 | ms/batch  9.95 | loss  4.33 | ppl    76.16
| prune-epoch  17 |  2800/ 2983 batches | lr 20.00 | ms/batch  9.98 | loss  4.29 | ppl    72.88
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
-----------------------------------------------------------------------------------------
| end of prune epoch  17 | time: 31.38s | valid loss  4.85 | valid ppl   128.04
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  18 |   200/ 2983 batches | lr 20.00 | ms/batch 10.09 | loss  4.36 | ppl    78.14
| prune-epoch  18 |   400/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.37 | ppl    79.01
| prune-epoch  18 |   600/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.21 | ppl    67.42
| prune-epoch  18 |   800/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.27 | ppl    71.31
| prune-epoch  18 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.31 | ppl    74.44
| prune-epoch  18 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.31 | ppl    74.66
| prune-epoch  18 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.34 | ppl    76.94
| prune-epoch  18 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.41 | ppl    82.03
| prune-epoch  18 |  1800/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.32 | ppl    75.01
| prune-epoch  18 |  2000/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.36 | ppl    77.89
| prune-epoch  18 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.24 | ppl    69.54
| prune-epoch  18 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.28 | ppl    72.09
| prune-epoch  18 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.31 | ppl    74.12
| prune-epoch  18 |  2800/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.26 | ppl    70.99
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
-----------------------------------------------------------------------------------------
| end of prune epoch  18 | time: 31.43s | valid loss  4.84 | valid ppl   126.56
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  19 |   200/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.33 | ppl    76.25
| prune-epoch  19 |   400/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.35 | ppl    77.37
| prune-epoch  19 |   600/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.19 | ppl    66.11
| prune-epoch  19 |   800/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.24 | ppl    69.53
| prune-epoch  19 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.29 | ppl    73.16
| prune-epoch  19 |  1200/ 2983 batches | lr 20.00 | ms/batch  9.98 | loss  4.29 | ppl    73.04
| prune-epoch  19 |  1400/ 2983 batches | lr 20.00 | ms/batch  9.97 | loss  4.32 | ppl    75.37
| prune-epoch  19 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.39 | ppl    80.54
| prune-epoch  19 |  1800/ 2983 batches | lr 20.00 | ms/batch  9.98 | loss  4.30 | ppl    73.48
| prune-epoch  19 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.34 | ppl    76.34
| prune-epoch  19 |  2200/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.22 | ppl    68.19
| prune-epoch  19 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  4.26 | ppl    70.47
| prune-epoch  19 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.47 | loss  4.29 | ppl    72.90
| prune-epoch  19 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.47 | loss  4.24 | ppl    69.73
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
-----------------------------------------------------------------------------------------
| end of prune epoch  19 | time: 31.83s | valid loss  4.84 | valid ppl   126.42
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  20 |   200/ 2983 batches | lr 20.00 | ms/batch 10.09 | loss  4.32 | ppl    75.05
| prune-epoch  20 |   400/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.33 | ppl    75.87
| prune-epoch  20 |   600/ 2983 batches | lr 20.00 | ms/batch 10.04 | loss  4.17 | ppl    64.82
| prune-epoch  20 |   800/ 2983 batches | lr 20.00 | ms/batch 10.06 | loss  4.22 | ppl    68.09
| prune-epoch  20 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.47 | loss  4.27 | ppl    71.52
| prune-epoch  20 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.47 | loss  4.28 | ppl    71.95
| prune-epoch  20 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.47 | loss  4.30 | ppl    73.89
| prune-epoch  20 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.48 | loss  4.37 | ppl    79.03
| prune-epoch  20 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.48 | loss  4.28 | ppl    72.00
| prune-epoch  20 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.49 | loss  4.32 | ppl    74.97
| prune-epoch  20 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.48 | loss  4.20 | ppl    66.81
| prune-epoch  20 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.47 | loss  4.24 | ppl    69.33
| prune-epoch  20 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.48 | loss  4.27 | ppl    71.53
| prune-epoch  20 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.48 | loss  4.23 | ppl    68.71
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
-----------------------------------------------------------------------------------------
| end of prune epoch  20 | time: 32.56s | valid loss  4.84 | valid ppl   125.90
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  21 |   200/ 2983 batches | lr 20.00 | ms/batch 10.17 | loss  4.30 | ppl    73.60
| prune-epoch  21 |   400/ 2983 batches | lr 20.00 | ms/batch 10.05 | loss  4.32 | ppl    75.01
| prune-epoch  21 |   600/ 2983 batches | lr 20.00 | ms/batch 10.05 | loss  4.16 | ppl    63.90
| prune-epoch  21 |   800/ 2983 batches | lr 20.00 | ms/batch 10.04 | loss  4.21 | ppl    67.42
| prune-epoch  21 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.06 | loss  4.25 | ppl    70.45
| prune-epoch  21 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.39 | loss  4.26 | ppl    70.74
| prune-epoch  21 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.51 | loss  4.29 | ppl    73.08
| prune-epoch  21 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.50 | loss  4.36 | ppl    78.56
| prune-epoch  21 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.49 | loss  4.27 | ppl    71.37
| prune-epoch  21 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.50 | loss  4.30 | ppl    73.72
| prune-epoch  21 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.49 | loss  4.19 | ppl    65.92
| prune-epoch  21 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.49 | loss  4.23 | ppl    68.43
| prune-epoch  21 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.51 | loss  4.26 | ppl    70.93
| prune-epoch  21 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.50 | loss  4.21 | ppl    67.50
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.7999999999999999  actual sp:  0.795
-----------------------------------------------------------------------------------------
| end of prune epoch  21 | time: 32.52s | valid loss  4.85 | valid ppl   127.31
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  22 |   200/ 2983 batches | lr 20.00 | ms/batch 10.11 | loss  4.37 | ppl    79.42
| prune-epoch  22 |   400/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.38 | ppl    79.90
| prune-epoch  22 |   600/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.22 | ppl    67.77
| prune-epoch  22 |   800/ 2983 batches | lr 20.00 | ms/batch  9.98 | loss  4.27 | ppl    71.50
| prune-epoch  22 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.31 | ppl    74.44
| prune-epoch  22 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.05 | loss  4.31 | ppl    74.65
| prune-epoch  22 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.34 | ppl    76.60
| prune-epoch  22 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.41 | ppl    82.38
| prune-epoch  22 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.32 | ppl    75.21
| prune-epoch  22 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.35 | ppl    77.48
| prune-epoch  22 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.05 | loss  4.23 | ppl    68.97
| prune-epoch  22 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.04 | loss  4.27 | ppl    71.44
| prune-epoch  22 |  2600/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.31 | ppl    74.12
| prune-epoch  22 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.26 | ppl    71.07
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
-----------------------------------------------------------------------------------------
| end of prune epoch  22 | time: 31.47s | valid loss  4.85 | valid ppl   127.67
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  23 |   200/ 2983 batches | lr 20.00 | ms/batch 10.17 | loss  4.33 | ppl    75.80
| prune-epoch  23 |   400/ 2983 batches | lr 20.00 | ms/batch 10.43 | loss  4.35 | ppl    77.15
| prune-epoch  23 |   600/ 2983 batches | lr 20.00 | ms/batch 10.44 | loss  4.19 | ppl    65.80
| prune-epoch  23 |   800/ 2983 batches | lr 20.00 | ms/batch 10.43 | loss  4.24 | ppl    69.23
| prune-epoch  23 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.43 | loss  4.28 | ppl    72.17
| prune-epoch  23 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.43 | loss  4.29 | ppl    72.74
| prune-epoch  23 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  4.32 | ppl    74.86
| prune-epoch  23 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.43 | loss  4.39 | ppl    80.57
| prune-epoch  23 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.42 | loss  4.29 | ppl    73.01
| prune-epoch  23 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.98 | loss  4.33 | ppl    75.87
| prune-epoch  23 |  2200/ 2983 batches | lr 20.00 | ms/batch 11.09 | loss  4.21 | ppl    67.66
| prune-epoch  23 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.43 | loss  4.25 | ppl    69.87
| prune-epoch  23 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.42 | loss  4.28 | ppl    72.02
| prune-epoch  23 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.44 | loss  4.24 | ppl    69.36
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.85  actual sp:  0.845
-----------------------------------------------------------------------------------------
| end of prune epoch  23 | time: 32.94s | valid loss  4.85 | valid ppl   127.84
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  24 |   200/ 2983 batches | lr 20.00 | ms/batch 10.09 | loss  4.48 | ppl    88.48
| prune-epoch  24 |   400/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.47 | ppl    87.58
| prune-epoch  24 |   600/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.31 | ppl    74.19
| prune-epoch  24 |   800/ 2983 batches | lr 20.00 | ms/batch 10.05 | loss  4.35 | ppl    77.85
| prune-epoch  24 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.09 | loss  4.39 | ppl    80.89
| prune-epoch  24 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.04 | loss  4.40 | ppl    81.19
| prune-epoch  24 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.42 | ppl    83.05
| prune-epoch  24 |  1600/ 2983 batches | lr 20.00 | ms/batch  9.97 | loss  4.48 | ppl    88.62
| prune-epoch  24 |  1800/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.39 | ppl    80.81
| prune-epoch  24 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.42 | ppl    83.38
| prune-epoch  24 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.04 | loss  4.31 | ppl    74.68
| prune-epoch  24 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.35 | ppl    77.17
| prune-epoch  24 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.04 | loss  4.37 | ppl    79.16
| prune-epoch  24 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.33 | ppl    76.31
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of prune epoch  24 | time: 31.46s | valid loss  4.87 | valid ppl   130.78
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 10.12 | loss  4.40 | ppl    81.39
| prune-epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.42 | ppl    82.84
| prune-epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.25 | ppl    70.04
| prune-epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 10.03 | loss  4.31 | ppl    74.33
| prune-epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.44 | loss  4.35 | ppl    77.31
| prune-epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.44 | loss  4.36 | ppl    77.90
| prune-epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  4.39 | ppl    80.41
| prune-epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.44 | loss  4.45 | ppl    85.89
| prune-epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.44 | loss  4.35 | ppl    77.82
| prune-epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.44 | loss  4.39 | ppl    80.92
| prune-epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.44 | loss  4.28 | ppl    72.36
| prune-epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.45 | loss  4.31 | ppl    74.74
| prune-epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.44 | loss  4.34 | ppl    76.74
| prune-epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 10.44 | loss  4.31 | ppl    74.10
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch   1 | time: 32.46s | valid loss  4.85 | valid ppl   127.66
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch 10.12 | loss  4.37 | ppl    79.12
| prune-epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.39 | ppl    80.59
| prune-epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch 10.05 | loss  4.23 | ppl    68.60
| prune-epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch  9.98 | loss  4.29 | ppl    72.70
| prune-epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.32 | ppl    75.32
| prune-epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.33 | ppl    76.30
| prune-epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 10.02 | loss  4.35 | ppl    77.83
| prune-epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.43 | ppl    83.84
| prune-epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.34 | ppl    76.47
| prune-epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.37 | ppl    79.06
| prune-epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch 10.01 | loss  4.26 | ppl    70.58
| prune-epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch 10.07 | loss  4.29 | ppl    73.24
| prune-epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 10.03 | loss  4.32 | ppl    75.28
| prune-epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.28 | ppl    72.50
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch   2 | time: 31.45s | valid loss  4.85 | valid ppl   127.99
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 10.09 | loss  4.35 | ppl    77.25
| prune-epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch  9.98 | loss  4.36 | ppl    78.61
| prune-epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.21 | ppl    67.46
| prune-epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch  9.98 | loss  4.26 | ppl    71.03
| prune-epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.30 | ppl    74.04
| prune-epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.31 | ppl    74.64
| prune-epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch  9.97 | loss  4.34 | ppl    76.81
| prune-epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.41 | ppl    82.10
| prune-epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch  9.97 | loss  4.32 | ppl    74.99
| prune-epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 10.00 | loss  4.36 | ppl    77.91
| prune-epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch  9.98 | loss  4.25 | ppl    69.88
| prune-epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch  9.99 | loss  4.27 | ppl    71.84
| prune-epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch  9.98 | loss  4.31 | ppl    74.22
| prune-epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch  9.97 | loss  4.27 | ppl    71.65
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch   3 | time: 31.37s | valid loss  4.87 | valid ppl   129.85
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   4 |   200/ 2983 batches | lr 10.00 | ms/batch 10.13 | loss  4.33 | ppl    76.16
| prune-epoch   4 |   400/ 2983 batches | lr 10.00 | ms/batch 10.02 | loss  4.33 | ppl    76.01
| prune-epoch   4 |   600/ 2983 batches | lr 10.00 | ms/batch  9.98 | loss  4.17 | ppl    64.86
| prune-epoch   4 |   800/ 2983 batches | lr 10.00 | ms/batch 10.01 | loss  4.23 | ppl    68.41
| prune-epoch   4 |  1000/ 2983 batches | lr 10.00 | ms/batch  9.98 | loss  4.26 | ppl    70.60
| prune-epoch   4 |  1200/ 2983 batches | lr 10.00 | ms/batch 10.21 | loss  4.26 | ppl    70.61
| prune-epoch   4 |  1400/ 2983 batches | lr 10.00 | ms/batch 10.43 | loss  4.28 | ppl    72.54
| prune-epoch   4 |  1600/ 2983 batches | lr 10.00 | ms/batch 10.43 | loss  4.34 | ppl    76.54
| prune-epoch   4 |  1800/ 2983 batches | lr 10.00 | ms/batch 10.44 | loss  4.25 | ppl    70.17
| prune-epoch   4 |  2000/ 2983 batches | lr 10.00 | ms/batch 10.48 | loss  4.28 | ppl    72.16
| prune-epoch   4 |  2200/ 2983 batches | lr 10.00 | ms/batch 10.47 | loss  4.17 | ppl    64.47
| prune-epoch   4 |  2400/ 2983 batches | lr 10.00 | ms/batch 10.47 | loss  4.19 | ppl    65.72
| prune-epoch   4 |  2600/ 2983 batches | lr 10.00 | ms/batch 10.47 | loss  4.21 | ppl    67.57
| prune-epoch   4 |  2800/ 2983 batches | lr 10.00 | ms/batch 10.49 | loss  4.18 | ppl    65.21
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch   4 | time: 32.37s | valid loss  4.81 | valid ppl   123.25
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   5 |   200/ 2983 batches | lr 10.00 | ms/batch 10.12 | loss  4.28 | ppl    72.48
| prune-epoch   5 |   400/ 2983 batches | lr 10.00 | ms/batch 10.02 | loss  4.30 | ppl    73.46
| prune-epoch   5 |   600/ 2983 batches | lr 10.00 | ms/batch 10.05 | loss  4.14 | ppl    62.70
| prune-epoch   5 |   800/ 2983 batches | lr 10.00 | ms/batch 10.03 | loss  4.19 | ppl    66.23
| prune-epoch   5 |  1000/ 2983 batches | lr 10.00 | ms/batch 10.04 | loss  4.23 | ppl    69.02
| prune-epoch   5 |  1200/ 2983 batches | lr 10.00 | ms/batch 10.03 | loss  4.24 | ppl    69.19
| prune-epoch   5 |  1400/ 2983 batches | lr 10.00 | ms/batch 10.01 | loss  4.26 | ppl    71.03
| prune-epoch   5 |  1600/ 2983 batches | lr 10.00 | ms/batch 10.02 | loss  4.32 | ppl    75.03
| prune-epoch   5 |  1800/ 2983 batches | lr 10.00 | ms/batch 10.05 | loss  4.24 | ppl    69.14
| prune-epoch   5 |  2000/ 2983 batches | lr 10.00 | ms/batch 10.06 | loss  4.27 | ppl    71.35
| prune-epoch   5 |  2200/ 2983 batches | lr 10.00 | ms/batch 10.04 | loss  4.15 | ppl    63.60
| prune-epoch   5 |  2400/ 2983 batches | lr 10.00 | ms/batch 10.02 | loss  4.18 | ppl    65.69
| prune-epoch   5 |  2600/ 2983 batches | lr 10.00 | ms/batch 10.04 | loss  4.21 | ppl    67.18
| prune-epoch   5 |  2800/ 2983 batches | lr 10.00 | ms/batch 10.07 | loss  4.17 | ppl    64.94
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch   5 | time: 31.53s | valid loss  4.81 | valid ppl   122.34
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   6 |   200/ 2983 batches | lr 10.00 | ms/batch 10.13 | loss  4.27 | ppl    71.29
| prune-epoch   6 |   400/ 2983 batches | lr 10.00 | ms/batch 10.07 | loss  4.28 | ppl    72.41
| prune-epoch   6 |   600/ 2983 batches | lr 10.00 | ms/batch 10.04 | loss  4.13 | ppl    61.88
| prune-epoch   6 |   800/ 2983 batches | lr 10.00 | ms/batch 10.05 | loss  4.18 | ppl    65.16
| prune-epoch   6 |  1000/ 2983 batches | lr 10.00 | ms/batch 10.01 | loss  4.22 | ppl    68.10
| prune-epoch   6 |  1200/ 2983 batches | lr 10.00 | ms/batch  9.97 | loss  4.22 | ppl    68.11
| prune-epoch   6 |  1400/ 2983 batches | lr 10.00 | ms/batch 10.02 | loss  4.25 | ppl    70.28
| prune-epoch   6 |  1600/ 2983 batches | lr 10.00 | ms/batch  9.99 | loss  4.31 | ppl    74.55
| prune-epoch   6 |  1800/ 2983 batches | lr 10.00 | ms/batch 10.03 | loss  4.22 | ppl    68.31
| prune-epoch   6 |  2000/ 2983 batches | lr 10.00 | ms/batch  9.99 | loss  4.26 | ppl    70.63
| prune-epoch   6 |  2200/ 2983 batches | lr 10.00 | ms/batch  9.97 | loss  4.14 | ppl    62.77
| prune-epoch   6 |  2400/ 2983 batches | lr 10.00 | ms/batch 10.42 | loss  4.17 | ppl    64.75
| prune-epoch   6 |  2600/ 2983 batches | lr 10.00 | ms/batch 10.46 | loss  4.20 | ppl    66.98
| prune-epoch   6 |  2800/ 2983 batches | lr 10.00 | ms/batch 10.47 | loss  4.17 | ppl    64.49
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch   6 | time: 32.16s | valid loss  4.81 | valid ppl   122.99
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   7 |   200/ 2983 batches | lr 10.00 | ms/batch 10.09 | loss  4.25 | ppl    70.30
| prune-epoch   7 |   400/ 2983 batches | lr 10.00 | ms/batch 10.03 | loss  4.26 | ppl    71.11
| prune-epoch   7 |   600/ 2983 batches | lr 10.00 | ms/batch 10.08 | loss  4.11 | ppl    60.93
| prune-epoch   7 |   800/ 2983 batches | lr 10.00 | ms/batch 10.04 | loss  4.16 | ppl    64.30
| prune-epoch   7 |  1000/ 2983 batches | lr 10.00 | ms/batch 10.25 | loss  4.21 | ppl    67.12
| prune-epoch   7 |  1200/ 2983 batches | lr 10.00 | ms/batch 11.07 | loss  4.22 | ppl    67.88
| prune-epoch   7 |  1400/ 2983 batches | lr 10.00 | ms/batch 11.08 | loss  4.24 | ppl    69.48
| prune-epoch   7 |  1600/ 2983 batches | lr 10.00 | ms/batch 11.08 | loss  4.30 | ppl    73.85
| prune-epoch   7 |  1800/ 2983 batches | lr 10.00 | ms/batch 11.07 | loss  4.22 | ppl    67.81
| prune-epoch   7 |  2000/ 2983 batches | lr 10.00 | ms/batch 11.08 | loss  4.25 | ppl    70.06
| prune-epoch   7 |  2200/ 2983 batches | lr 10.00 | ms/batch 11.08 | loss  4.13 | ppl    62.37
| prune-epoch   7 |  2400/ 2983 batches | lr 10.00 | ms/batch 11.08 | loss  4.16 | ppl    64.23
| prune-epoch   7 |  2600/ 2983 batches | lr 10.00 | ms/batch 11.08 | loss  4.20 | ppl    66.40
| prune-epoch   7 |  2800/ 2983 batches | lr 10.00 | ms/batch 11.08 | loss  4.16 | ppl    64.09
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch   7 | time: 33.83s | valid loss  4.81 | valid ppl   123.00
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   8 |   200/ 2983 batches | lr 5.00 | ms/batch 10.50 | loss  4.26 | ppl    70.46
| prune-epoch   8 |   400/ 2983 batches | lr 5.00 | ms/batch 10.46 | loss  4.26 | ppl    70.54
| prune-epoch   8 |   600/ 2983 batches | lr 5.00 | ms/batch 10.45 | loss  4.10 | ppl    60.36
| prune-epoch   8 |   800/ 2983 batches | lr 5.00 | ms/batch 10.45 | loss  4.16 | ppl    64.26
| prune-epoch   8 |  1000/ 2983 batches | lr 5.00 | ms/batch 10.45 | loss  4.19 | ppl    66.21
| prune-epoch   8 |  1200/ 2983 batches | lr 5.00 | ms/batch 10.49 | loss  4.20 | ppl    66.80
| prune-epoch   8 |  1400/ 2983 batches | lr 5.00 | ms/batch 10.43 | loss  4.22 | ppl    67.71
| prune-epoch   8 |  1600/ 2983 batches | lr 5.00 | ms/batch 10.46 | loss  4.27 | ppl    71.45
| prune-epoch   8 |  1800/ 2983 batches | lr 5.00 | ms/batch 10.41 | loss  4.19 | ppl    66.00
| prune-epoch   8 |  2000/ 2983 batches | lr 5.00 | ms/batch 10.48 | loss  4.22 | ppl    68.30
| prune-epoch   8 |  2200/ 2983 batches | lr 5.00 | ms/batch 10.48 | loss  4.10 | ppl    60.35
| prune-epoch   8 |  2400/ 2983 batches | lr 5.00 | ms/batch 10.45 | loss  4.13 | ppl    61.96
| prune-epoch   8 |  2600/ 2983 batches | lr 5.00 | ms/batch 10.46 | loss  4.16 | ppl    64.11
| prune-epoch   8 |  2800/ 2983 batches | lr 5.00 | ms/batch 10.45 | loss  4.13 | ppl    61.87
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch   8 | time: 32.83s | valid loss  4.79 | valid ppl   120.40
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   9 |   200/ 2983 batches | lr 5.00 | ms/batch 10.40 | loss  4.23 | ppl    68.85
| prune-epoch   9 |   400/ 2983 batches | lr 5.00 | ms/batch 10.44 | loss  4.25 | ppl    69.79
| prune-epoch   9 |   600/ 2983 batches | lr 5.00 | ms/batch 10.45 | loss  4.08 | ppl    59.38
| prune-epoch   9 |   800/ 2983 batches | lr 5.00 | ms/batch 10.46 | loss  4.14 | ppl    63.00
| prune-epoch   9 |  1000/ 2983 batches | lr 5.00 | ms/batch 10.43 | loss  4.18 | ppl    65.52
| prune-epoch   9 |  1200/ 2983 batches | lr 5.00 | ms/batch 10.44 | loss  4.19 | ppl    65.70
| prune-epoch   9 |  1400/ 2983 batches | lr 5.00 | ms/batch 10.44 | loss  4.21 | ppl    67.34
| prune-epoch   9 |  1600/ 2983 batches | lr 5.00 | ms/batch 10.44 | loss  4.26 | ppl    71.06
| prune-epoch   9 |  1800/ 2983 batches | lr 5.00 | ms/batch 10.43 | loss  4.18 | ppl    65.29
| prune-epoch   9 |  2000/ 2983 batches | lr 5.00 | ms/batch 10.45 | loss  4.22 | ppl    68.24
| prune-epoch   9 |  2200/ 2983 batches | lr 5.00 | ms/batch 10.44 | loss  4.10 | ppl    60.07
| prune-epoch   9 |  2400/ 2983 batches | lr 5.00 | ms/batch 10.44 | loss  4.12 | ppl    61.78
| prune-epoch   9 |  2600/ 2983 batches | lr 5.00 | ms/batch 10.44 | loss  4.16 | ppl    63.93
| prune-epoch   9 |  2800/ 2983 batches | lr 5.00 | ms/batch 10.43 | loss  4.12 | ppl    61.38
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch   9 | time: 32.75s | valid loss  4.79 | valid ppl   120.27
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  10 |   200/ 2983 batches | lr 5.00 | ms/batch 10.02 | loss  4.21 | ppl    67.56
| prune-epoch  10 |   400/ 2983 batches | lr 5.00 | ms/batch 10.14 | loss  4.23 | ppl    69.06
| prune-epoch  10 |   600/ 2983 batches | lr 5.00 | ms/batch 10.45 | loss  4.08 | ppl    59.06
| prune-epoch  10 |   800/ 2983 batches | lr 5.00 | ms/batch 10.64 | loss  4.14 | ppl    62.52
| prune-epoch  10 |  1000/ 2983 batches | lr 5.00 | ms/batch 10.42 | loss  4.17 | ppl    64.94
| prune-epoch  10 |  1200/ 2983 batches | lr 5.00 | ms/batch 10.43 | loss  4.17 | ppl    65.03
| prune-epoch  10 |  1400/ 2983 batches | lr 5.00 | ms/batch 10.42 | loss  4.20 | ppl    66.70
| prune-epoch  10 |  1600/ 2983 batches | lr 5.00 | ms/batch 10.41 | loss  4.26 | ppl    70.71
| prune-epoch  10 |  1800/ 2983 batches | lr 5.00 | ms/batch 10.42 | loss  4.17 | ppl    64.95
| prune-epoch  10 |  2000/ 2983 batches | lr 5.00 | ms/batch 10.42 | loss  4.21 | ppl    67.27
| prune-epoch  10 |  2200/ 2983 batches | lr 5.00 | ms/batch 10.41 | loss  4.09 | ppl    59.82
| prune-epoch  10 |  2400/ 2983 batches | lr 5.00 | ms/batch 10.41 | loss  4.12 | ppl    61.72
| prune-epoch  10 |  2600/ 2983 batches | lr 5.00 | ms/batch 10.42 | loss  4.15 | ppl    63.64
| prune-epoch  10 |  2800/ 2983 batches | lr 5.00 | ms/batch 10.42 | loss  4.11 | ppl    61.16
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch  10 | time: 32.63s | valid loss  4.79 | valid ppl   120.59
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  11 |   200/ 2983 batches | lr 5.00 | ms/batch 10.12 | loss  4.21 | ppl    67.39
| prune-epoch  11 |   400/ 2983 batches | lr 5.00 | ms/batch 10.05 | loss  4.22 | ppl    68.25
| prune-epoch  11 |   600/ 2983 batches | lr 5.00 | ms/batch 10.07 | loss  4.07 | ppl    58.47
| prune-epoch  11 |   800/ 2983 batches | lr 5.00 | ms/batch 10.09 | loss  4.13 | ppl    62.18
| prune-epoch  11 |  1000/ 2983 batches | lr 5.00 | ms/batch 10.04 | loss  4.16 | ppl    64.13
| prune-epoch  11 |  1200/ 2983 batches | lr 5.00 | ms/batch 10.01 | loss  4.17 | ppl    64.68
| prune-epoch  11 |  1400/ 2983 batches | lr 5.00 | ms/batch 10.42 | loss  4.20 | ppl    66.46
| prune-epoch  11 |  1600/ 2983 batches | lr 5.00 | ms/batch 10.03 | loss  4.25 | ppl    70.28
| prune-epoch  11 |  1800/ 2983 batches | lr 5.00 | ms/batch 10.05 | loss  4.17 | ppl    64.47
| prune-epoch  11 |  2000/ 2983 batches | lr 5.00 | ms/batch 10.05 | loss  4.20 | ppl    66.95
| prune-epoch  11 |  2200/ 2983 batches | lr 5.00 | ms/batch 10.03 | loss  4.09 | ppl    59.48
| prune-epoch  11 |  2400/ 2983 batches | lr 5.00 | ms/batch 10.09 | loss  4.11 | ppl    61.21
| prune-epoch  11 |  2600/ 2983 batches | lr 5.00 | ms/batch 10.07 | loss  4.15 | ppl    63.36
| prune-epoch  11 |  2800/ 2983 batches | lr 5.00 | ms/batch 10.07 | loss  4.11 | ppl    61.08
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch  11 | time: 31.64s | valid loss  4.79 | valid ppl   120.01
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  12 |   200/ 2983 batches | lr 5.00 | ms/batch 10.12 | loss  4.20 | ppl    67.00
| prune-epoch  12 |   400/ 2983 batches | lr 5.00 | ms/batch 10.05 | loss  4.22 | ppl    68.08
| prune-epoch  12 |   600/ 2983 batches | lr 5.00 | ms/batch 10.02 | loss  4.06 | ppl    58.16
| prune-epoch  12 |   800/ 2983 batches | lr 5.00 | ms/batch 10.02 | loss  4.12 | ppl    61.54
| prune-epoch  12 |  1000/ 2983 batches | lr 5.00 | ms/batch  9.99 | loss  4.16 | ppl    64.09
| prune-epoch  12 |  1200/ 2983 batches | lr 5.00 | ms/batch 10.25 | loss  4.17 | ppl    64.61
| prune-epoch  12 |  1400/ 2983 batches | lr 5.00 | ms/batch 10.46 | loss  4.19 | ppl    66.13
| prune-epoch  12 |  1600/ 2983 batches | lr 5.00 | ms/batch 10.48 | loss  4.25 | ppl    69.80
| prune-epoch  12 |  1800/ 2983 batches | lr 5.00 | ms/batch 10.46 | loss  4.16 | ppl    64.31
| prune-epoch  12 |  2000/ 2983 batches | lr 5.00 | ms/batch 10.46 | loss  4.20 | ppl    66.75
| prune-epoch  12 |  2200/ 2983 batches | lr 5.00 | ms/batch 10.45 | loss  4.08 | ppl    59.06
| prune-epoch  12 |  2400/ 2983 batches | lr 5.00 | ms/batch 10.45 | loss  4.11 | ppl    60.92
| prune-epoch  12 |  2600/ 2983 batches | lr 5.00 | ms/batch 10.47 | loss  4.14 | ppl    62.88
| prune-epoch  12 |  2800/ 2983 batches | lr 5.00 | ms/batch 10.45 | loss  4.10 | ppl    60.51
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch  12 | time: 32.40s | valid loss  4.79 | valid ppl   120.35
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  13 |   200/ 2983 batches | lr 2.50 | ms/batch 10.01 | loss  4.21 | ppl    67.66
| prune-epoch  13 |   400/ 2983 batches | lr 2.50 | ms/batch  9.95 | loss  4.23 | ppl    68.41
| prune-epoch  13 |   600/ 2983 batches | lr 2.50 | ms/batch  9.97 | loss  4.06 | ppl    58.12
| prune-epoch  13 |   800/ 2983 batches | lr 2.50 | ms/batch  9.99 | loss  4.13 | ppl    62.12
| prune-epoch  13 |  1000/ 2983 batches | lr 2.50 | ms/batch 10.10 | loss  4.16 | ppl    64.37
| prune-epoch  13 |  1200/ 2983 batches | lr 2.50 | ms/batch 10.59 | loss  4.17 | ppl    64.52
| prune-epoch  13 |  1400/ 2983 batches | lr 2.50 | ms/batch 10.39 | loss  4.19 | ppl    65.97
| prune-epoch  13 |  1600/ 2983 batches | lr 2.50 | ms/batch 10.39 | loss  4.24 | ppl    69.27
| prune-epoch  13 |  1800/ 2983 batches | lr 2.50 | ms/batch 10.40 | loss  4.16 | ppl    63.97
| prune-epoch  13 |  2000/ 2983 batches | lr 2.50 | ms/batch 10.39 | loss  4.19 | ppl    66.24
| prune-epoch  13 |  2200/ 2983 batches | lr 2.50 | ms/batch 10.40 | loss  4.07 | ppl    58.44
| prune-epoch  13 |  2400/ 2983 batches | lr 2.50 | ms/batch 10.40 | loss  4.10 | ppl    60.23
| prune-epoch  13 |  2600/ 2983 batches | lr 2.50 | ms/batch 10.39 | loss  4.13 | ppl    62.36
| prune-epoch  13 |  2800/ 2983 batches | lr 2.50 | ms/batch 10.39 | loss  4.09 | ppl    59.81
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch  13 | time: 32.28s | valid loss  4.78 | valid ppl   118.61
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  14 |   200/ 2983 batches | lr 2.50 | ms/batch 10.09 | loss  4.20 | ppl    66.44
| prune-epoch  14 |   400/ 2983 batches | lr 2.50 | ms/batch 10.52 | loss  4.22 | ppl    67.79
| prune-epoch  14 |   600/ 2983 batches | lr 2.50 | ms/batch 10.45 | loss  4.05 | ppl    57.57
| prune-epoch  14 |   800/ 2983 batches | lr 2.50 | ms/batch 10.46 | loss  4.12 | ppl    61.56
| prune-epoch  14 |  1000/ 2983 batches | lr 2.50 | ms/batch 10.45 | loss  4.16 | ppl    63.75
| prune-epoch  14 |  1200/ 2983 batches | lr 2.50 | ms/batch 10.45 | loss  4.16 | ppl    63.91
| prune-epoch  14 |  1400/ 2983 batches | lr 2.50 | ms/batch 10.44 | loss  4.18 | ppl    65.50
| prune-epoch  14 |  1600/ 2983 batches | lr 2.50 | ms/batch 10.44 | loss  4.23 | ppl    68.68
| prune-epoch  14 |  1800/ 2983 batches | lr 2.50 | ms/batch 10.45 | loss  4.15 | ppl    63.49
| prune-epoch  14 |  2000/ 2983 batches | lr 2.50 | ms/batch 10.44 | loss  4.19 | ppl    66.21
| prune-epoch  14 |  2200/ 2983 batches | lr 2.50 | ms/batch 10.45 | loss  4.07 | ppl    58.42
| prune-epoch  14 |  2400/ 2983 batches | lr 2.50 | ms/batch 10.46 | loss  4.10 | ppl    60.13
| prune-epoch  14 |  2600/ 2983 batches | lr 2.50 | ms/batch 10.45 | loss  4.13 | ppl    62.20
| prune-epoch  14 |  2800/ 2983 batches | lr 2.50 | ms/batch 10.45 | loss  4.09 | ppl    59.90
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch  14 | time: 32.76s | valid loss  4.77 | valid ppl   118.35
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  15 |   200/ 2983 batches | lr 2.50 | ms/batch 10.13 | loss  4.20 | ppl    66.45
| prune-epoch  15 |   400/ 2983 batches | lr 2.50 | ms/batch 10.05 | loss  4.21 | ppl    67.24
| prune-epoch  15 |   600/ 2983 batches | lr 2.50 | ms/batch 10.03 | loss  4.05 | ppl    57.34
| prune-epoch  15 |   800/ 2983 batches | lr 2.50 | ms/batch 10.07 | loss  4.11 | ppl    61.23
| prune-epoch  15 |  1000/ 2983 batches | lr 2.50 | ms/batch 10.05 | loss  4.15 | ppl    63.29
| prune-epoch  15 |  1200/ 2983 batches | lr 2.50 | ms/batch 10.03 | loss  4.15 | ppl    63.52
| prune-epoch  15 |  1400/ 2983 batches | lr 2.50 | ms/batch 10.04 | loss  4.18 | ppl    65.46
| prune-epoch  15 |  1600/ 2983 batches | lr 2.50 | ms/batch 10.04 | loss  4.23 | ppl    68.56
| prune-epoch  15 |  1800/ 2983 batches | lr 2.50 | ms/batch 10.01 | loss  4.15 | ppl    63.37
| prune-epoch  15 |  2000/ 2983 batches | lr 2.50 | ms/batch 10.09 | loss  4.18 | ppl    65.37
| prune-epoch  15 |  2200/ 2983 batches | lr 2.50 | ms/batch 10.04 | loss  4.06 | ppl    58.20
| prune-epoch  15 |  2400/ 2983 batches | lr 2.50 | ms/batch 10.02 | loss  4.09 | ppl    59.86
| prune-epoch  15 |  2600/ 2983 batches | lr 2.50 | ms/batch 10.03 | loss  4.13 | ppl    62.04
| prune-epoch  15 |  2800/ 2983 batches | lr 2.50 | ms/batch 10.05 | loss  4.09 | ppl    59.87
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch  15 | time: 31.54s | valid loss  4.77 | valid ppl   118.47
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  16 |   200/ 2983 batches | lr 2.50 | ms/batch 10.07 | loss  4.19 | ppl    66.17
| prune-epoch  16 |   400/ 2983 batches | lr 2.50 | ms/batch 10.03 | loss  4.20 | ppl    67.00
| prune-epoch  16 |   600/ 2983 batches | lr 2.50 | ms/batch 10.01 | loss  4.05 | ppl    57.14
| prune-epoch  16 |   800/ 2983 batches | lr 2.50 | ms/batch 10.01 | loss  4.11 | ppl    60.86
| prune-epoch  16 |  1000/ 2983 batches | lr 2.50 | ms/batch 10.03 | loss  4.15 | ppl    63.28
| prune-epoch  16 |  1200/ 2983 batches | lr 2.50 | ms/batch  9.98 | loss  4.15 | ppl    63.48
| prune-epoch  16 |  1400/ 2983 batches | lr 2.50 | ms/batch 10.01 | loss  4.17 | ppl    64.93
| prune-epoch  16 |  1600/ 2983 batches | lr 2.50 | ms/batch 10.02 | loss  4.23 | ppl    68.46
| prune-epoch  16 |  1800/ 2983 batches | lr 2.50 | ms/batch 10.01 | loss  4.15 | ppl    63.36
| prune-epoch  16 |  2000/ 2983 batches | lr 2.50 | ms/batch 10.21 | loss  4.19 | ppl    65.84
| prune-epoch  16 |  2200/ 2983 batches | lr 2.50 | ms/batch 10.44 | loss  4.06 | ppl    58.09
| prune-epoch  16 |  2400/ 2983 batches | lr 2.50 | ms/batch 10.43 | loss  4.09 | ppl    59.82
| prune-epoch  16 |  2600/ 2983 batches | lr 2.50 | ms/batch 10.42 | loss  4.13 | ppl    61.99
| prune-epoch  16 |  2800/ 2983 batches | lr 2.50 | ms/batch 10.42 | loss  4.09 | ppl    59.71
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch  16 | time: 31.96s | valid loss  4.77 | valid ppl   118.49
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  17 |   200/ 2983 batches | lr 1.25 | ms/batch 10.10 | loss  4.20 | ppl    66.64
| prune-epoch  17 |   400/ 2983 batches | lr 1.25 | ms/batch  9.95 | loss  4.21 | ppl    67.59
| prune-epoch  17 |   600/ 2983 batches | lr 1.25 | ms/batch 10.00 | loss  4.06 | ppl    57.92
| prune-epoch  17 |   800/ 2983 batches | lr 1.25 | ms/batch 10.00 | loss  4.13 | ppl    61.90
| prune-epoch  17 |  1000/ 2983 batches | lr 1.25 | ms/batch  9.97 | loss  4.15 | ppl    63.53
| prune-epoch  17 |  1200/ 2983 batches | lr 1.25 | ms/batch  9.98 | loss  4.16 | ppl    63.93
| prune-epoch  17 |  1400/ 2983 batches | lr 1.25 | ms/batch 10.01 | loss  4.18 | ppl    65.57
| prune-epoch  17 |  1600/ 2983 batches | lr 1.25 | ms/batch 10.00 | loss  4.23 | ppl    68.52
| prune-epoch  17 |  1800/ 2983 batches | lr 1.25 | ms/batch 10.00 | loss  4.15 | ppl    63.44
| prune-epoch  17 |  2000/ 2983 batches | lr 1.25 | ms/batch  9.99 | loss  4.18 | ppl    65.69
| prune-epoch  17 |  2200/ 2983 batches | lr 1.25 | ms/batch  9.96 | loss  4.05 | ppl    57.63
| prune-epoch  17 |  2400/ 2983 batches | lr 1.25 | ms/batch  9.98 | loss  4.09 | ppl    59.51
| prune-epoch  17 |  2600/ 2983 batches | lr 1.25 | ms/batch 10.42 | loss  4.12 | ppl    61.86
| prune-epoch  17 |  2800/ 2983 batches | lr 1.25 | ms/batch 10.41 | loss  4.09 | ppl    59.59
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch  17 | time: 31.69s | valid loss  4.76 | valid ppl   117.15
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  18 |   200/ 2983 batches | lr 1.25 | ms/batch 10.08 | loss  4.19 | ppl    65.74
| prune-epoch  18 |   400/ 2983 batches | lr 1.25 | ms/batch  9.99 | loss  4.21 | ppl    67.37
| prune-epoch  18 |   600/ 2983 batches | lr 1.25 | ms/batch  9.95 | loss  4.05 | ppl    57.28
| prune-epoch  18 |   800/ 2983 batches | lr 1.25 | ms/batch 10.00 | loss  4.12 | ppl    61.54
| prune-epoch  18 |  1000/ 2983 batches | lr 1.25 | ms/batch 10.03 | loss  4.15 | ppl    63.30
| prune-epoch  18 |  1200/ 2983 batches | lr 1.25 | ms/batch 10.01 | loss  4.15 | ppl    63.62
| prune-epoch  18 |  1400/ 2983 batches | lr 1.25 | ms/batch 10.03 | loss  4.17 | ppl    64.96
| prune-epoch  18 |  1600/ 2983 batches | lr 1.25 | ms/batch 10.02 | loss  4.22 | ppl    68.32
| prune-epoch  18 |  1800/ 2983 batches | lr 1.25 | ms/batch 10.03 | loss  4.15 | ppl    63.22
| prune-epoch  18 |  2000/ 2983 batches | lr 1.25 | ms/batch  9.99 | loss  4.18 | ppl    65.29
| prune-epoch  18 |  2200/ 2983 batches | lr 1.25 | ms/batch 10.02 | loss  4.06 | ppl    57.89
| prune-epoch  18 |  2400/ 2983 batches | lr 1.25 | ms/batch 10.01 | loss  4.09 | ppl    59.64
| prune-epoch  18 |  2600/ 2983 batches | lr 1.25 | ms/batch 10.03 | loss  4.12 | ppl    61.80
| prune-epoch  18 |  2800/ 2983 batches | lr 1.25 | ms/batch 10.04 | loss  4.09 | ppl    59.57
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch  18 | time: 31.43s | valid loss  4.76 | valid ppl   117.06
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  19 |   200/ 2983 batches | lr 1.25 | ms/batch 10.04 | loss  4.19 | ppl    66.05
| prune-epoch  19 |   400/ 2983 batches | lr 1.25 | ms/batch 10.25 | loss  4.20 | ppl    66.83
| prune-epoch  19 |   600/ 2983 batches | lr 1.25 | ms/batch 10.56 | loss  4.05 | ppl    57.21
| prune-epoch  19 |   800/ 2983 batches | lr 1.25 | ms/batch 10.54 | loss  4.11 | ppl    60.93
| prune-epoch  19 |  1000/ 2983 batches | lr 1.25 | ms/batch 10.55 | loss  4.15 | ppl    63.12
| prune-epoch  19 |  1200/ 2983 batches | lr 1.25 | ms/batch 10.56 | loss  4.15 | ppl    63.47
| prune-epoch  19 |  1400/ 2983 batches | lr 1.25 | ms/batch 10.56 | loss  4.17 | ppl    64.99
| prune-epoch  19 |  1600/ 2983 batches | lr 1.25 | ms/batch 10.56 | loss  4.22 | ppl    68.08
| prune-epoch  19 |  1800/ 2983 batches | lr 1.25 | ms/batch 10.54 | loss  4.15 | ppl    63.13
| prune-epoch  19 |  2000/ 2983 batches | lr 1.25 | ms/batch 10.44 | loss  4.19 | ppl    65.88
| prune-epoch  19 |  2200/ 2983 batches | lr 1.25 | ms/batch 10.44 | loss  4.06 | ppl    57.78
| prune-epoch  19 |  2400/ 2983 batches | lr 1.25 | ms/batch 10.43 | loss  4.09 | ppl    59.66
| prune-epoch  19 |  2600/ 2983 batches | lr 1.25 | ms/batch 10.43 | loss  4.13 | ppl    62.08
| prune-epoch  19 |  2800/ 2983 batches | lr 1.25 | ms/batch 10.43 | loss  4.09 | ppl    59.68
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch  19 | time: 32.82s | valid loss  4.76 | valid ppl   117.08
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  20 |   200/ 2983 batches | lr 1.25 | ms/batch 10.57 | loss  4.18 | ppl    65.69
| prune-epoch  20 |   400/ 2983 batches | lr 1.25 | ms/batch 10.40 | loss  4.20 | ppl    66.75
| prune-epoch  20 |   600/ 2983 batches | lr 1.25 | ms/batch 10.42 | loss  4.04 | ppl    56.97
| prune-epoch  20 |   800/ 2983 batches | lr 1.25 | ms/batch 10.42 | loss  4.12 | ppl    61.38
| prune-epoch  20 |  1000/ 2983 batches | lr 1.25 | ms/batch 10.41 | loss  4.14 | ppl    62.84
| prune-epoch  20 |  1200/ 2983 batches | lr 1.25 | ms/batch 10.42 | loss  4.15 | ppl    63.28
| prune-epoch  20 |  1400/ 2983 batches | lr 1.25 | ms/batch 10.41 | loss  4.17 | ppl    64.91
| prune-epoch  20 |  1600/ 2983 batches | lr 1.25 | ms/batch 10.43 | loss  4.22 | ppl    68.15
| prune-epoch  20 |  1800/ 2983 batches | lr 1.25 | ms/batch 10.40 | loss  4.14 | ppl    63.06
| prune-epoch  20 |  2000/ 2983 batches | lr 1.25 | ms/batch 10.41 | loss  4.18 | ppl    65.57
| prune-epoch  20 |  2200/ 2983 batches | lr 1.25 | ms/batch 10.40 | loss  4.06 | ppl    58.03
| prune-epoch  20 |  2400/ 2983 batches | lr 1.25 | ms/batch 10.42 | loss  4.09 | ppl    59.81
| prune-epoch  20 |  2600/ 2983 batches | lr 1.25 | ms/batch 10.42 | loss  4.12 | ppl    61.69
| prune-epoch  20 |  2800/ 2983 batches | lr 1.25 | ms/batch 10.40 | loss  4.09 | ppl    59.48
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch  20 | time: 32.73s | valid loss  4.76 | valid ppl   117.15
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  21 |   200/ 2983 batches | lr 0.62 | ms/batch 10.49 | loss  4.20 | ppl    66.58
| prune-epoch  21 |   400/ 2983 batches | lr 0.62 | ms/batch 10.43 | loss  4.22 | ppl    67.76
| prune-epoch  21 |   600/ 2983 batches | lr 0.62 | ms/batch 10.42 | loss  4.06 | ppl    57.99
| prune-epoch  21 |   800/ 2983 batches | lr 0.62 | ms/batch 10.43 | loss  4.13 | ppl    62.08
| prune-epoch  21 |  1000/ 2983 batches | lr 0.62 | ms/batch 10.43 | loss  4.15 | ppl    63.67
| prune-epoch  21 |  1200/ 2983 batches | lr 0.62 | ms/batch 10.43 | loss  4.16 | ppl    64.09
| prune-epoch  21 |  1400/ 2983 batches | lr 0.62 | ms/batch 10.42 | loss  4.18 | ppl    65.67
| prune-epoch  21 |  1600/ 2983 batches | lr 0.62 | ms/batch 10.43 | loss  4.22 | ppl    68.35
| prune-epoch  21 |  1800/ 2983 batches | lr 0.62 | ms/batch 10.43 | loss  4.15 | ppl    63.56
| prune-epoch  21 |  2000/ 2983 batches | lr 0.62 | ms/batch 10.44 | loss  4.19 | ppl    65.89
| prune-epoch  21 |  2200/ 2983 batches | lr 0.62 | ms/batch 10.55 | loss  4.06 | ppl    57.97
| prune-epoch  21 |  2400/ 2983 batches | lr 0.62 | ms/batch 10.44 | loss  4.09 | ppl    59.85
| prune-epoch  21 |  2600/ 2983 batches | lr 0.62 | ms/batch 10.43 | loss  4.13 | ppl    62.05
| prune-epoch  21 |  2800/ 2983 batches | lr 0.62 | ms/batch 10.44 | loss  4.09 | ppl    59.93
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch  21 | time: 32.78s | valid loss  4.75 | valid ppl   116.02
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  22 |   200/ 2983 batches | lr 0.62 | ms/batch 10.13 | loss  4.19 | ppl    66.17
| prune-epoch  22 |   400/ 2983 batches | lr 0.62 | ms/batch 10.44 | loss  4.21 | ppl    67.29
| prune-epoch  22 |   600/ 2983 batches | lr 0.62 | ms/batch 10.43 | loss  4.06 | ppl    57.93
| prune-epoch  22 |   800/ 2983 batches | lr 0.62 | ms/batch 10.44 | loss  4.12 | ppl    61.73
| prune-epoch  22 |  1000/ 2983 batches | lr 0.62 | ms/batch 10.44 | loss  4.15 | ppl    63.38
| prune-epoch  22 |  1200/ 2983 batches | lr 0.62 | ms/batch 10.44 | loss  4.16 | ppl    63.81
| prune-epoch  22 |  1400/ 2983 batches | lr 0.62 | ms/batch 10.44 | loss  4.18 | ppl    65.45
| prune-epoch  22 |  1600/ 2983 batches | lr 0.62 | ms/batch 10.44 | loss  4.23 | ppl    68.49
| prune-epoch  22 |  1800/ 2983 batches | lr 0.62 | ms/batch 10.43 | loss  4.15 | ppl    63.48
| prune-epoch  22 |  2000/ 2983 batches | lr 0.62 | ms/batch 10.45 | loss  4.19 | ppl    65.90
| prune-epoch  22 |  2200/ 2983 batches | lr 0.62 | ms/batch 10.44 | loss  4.06 | ppl    57.86
| prune-epoch  22 |  2400/ 2983 batches | lr 0.62 | ms/batch 10.44 | loss  4.09 | ppl    59.91
| prune-epoch  22 |  2600/ 2983 batches | lr 0.62 | ms/batch 10.43 | loss  4.13 | ppl    62.01
| prune-epoch  22 |  2800/ 2983 batches | lr 0.62 | ms/batch 10.44 | loss  4.09 | ppl    60.01
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch  22 | time: 32.70s | valid loss  4.75 | valid ppl   116.06
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  23 |   200/ 2983 batches | lr 0.62 | ms/batch 10.04 | loss  4.19 | ppl    66.25
| prune-epoch  23 |   400/ 2983 batches | lr 0.62 | ms/batch 10.04 | loss  4.21 | ppl    67.24
| prune-epoch  23 |   600/ 2983 batches | lr 0.62 | ms/batch 10.02 | loss  4.06 | ppl    57.76
| prune-epoch  23 |   800/ 2983 batches | lr 0.62 | ms/batch 10.01 | loss  4.12 | ppl    61.51
| prune-epoch  23 |  1000/ 2983 batches | lr 0.62 | ms/batch  9.99 | loss  4.15 | ppl    63.64
| prune-epoch  23 |  1200/ 2983 batches | lr 0.62 | ms/batch 10.00 | loss  4.15 | ppl    63.53
| prune-epoch  23 |  1400/ 2983 batches | lr 0.62 | ms/batch 10.01 | loss  4.18 | ppl    65.22
| prune-epoch  23 |  1600/ 2983 batches | lr 0.62 | ms/batch 10.07 | loss  4.22 | ppl    68.17
| prune-epoch  23 |  1800/ 2983 batches | lr 0.62 | ms/batch 10.06 | loss  4.15 | ppl    63.53
| prune-epoch  23 |  2000/ 2983 batches | lr 0.62 | ms/batch  9.99 | loss  4.19 | ppl    65.71
| prune-epoch  23 |  2200/ 2983 batches | lr 0.62 | ms/batch 10.02 | loss  4.06 | ppl    57.78
| prune-epoch  23 |  2400/ 2983 batches | lr 0.62 | ms/batch 10.03 | loss  4.09 | ppl    59.59
| prune-epoch  23 |  2600/ 2983 batches | lr 0.62 | ms/batch 10.00 | loss  4.13 | ppl    62.02
| prune-epoch  23 |  2800/ 2983 batches | lr 0.62 | ms/batch  9.98 | loss  4.09 | ppl    60.00
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch  23 | time: 31.44s | valid loss  4.75 | valid ppl   115.95
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  24 |   200/ 2983 batches | lr 0.62 | ms/batch 10.05 | loss  4.19 | ppl    66.32
| prune-epoch  24 |   400/ 2983 batches | lr 0.62 | ms/batch  9.98 | loss  4.20 | ppl    66.93
| prune-epoch  24 |   600/ 2983 batches | lr 0.62 | ms/batch  9.96 | loss  4.05 | ppl    57.42
| prune-epoch  24 |   800/ 2983 batches | lr 0.62 | ms/batch  9.98 | loss  4.12 | ppl    61.40
| prune-epoch  24 |  1000/ 2983 batches | lr 0.62 | ms/batch  9.99 | loss  4.15 | ppl    63.35
| prune-epoch  24 |  1200/ 2983 batches | lr 0.62 | ms/batch  9.97 | loss  4.15 | ppl    63.50
| prune-epoch  24 |  1400/ 2983 batches | lr 0.62 | ms/batch 10.06 | loss  4.17 | ppl    64.64
| prune-epoch  24 |  1600/ 2983 batches | lr 0.62 | ms/batch 10.00 | loss  4.22 | ppl    67.89
| prune-epoch  24 |  1800/ 2983 batches | lr 0.62 | ms/batch  9.98 | loss  4.15 | ppl    63.35
| prune-epoch  24 |  2000/ 2983 batches | lr 0.62 | ms/batch 10.01 | loss  4.19 | ppl    65.88
| prune-epoch  24 |  2200/ 2983 batches | lr 0.62 | ms/batch  9.95 | loss  4.06 | ppl    57.75
| prune-epoch  24 |  2400/ 2983 batches | lr 0.62 | ms/batch  9.96 | loss  4.09 | ppl    59.51
| prune-epoch  24 |  2600/ 2983 batches | lr 0.62 | ms/batch 10.01 | loss  4.12 | ppl    61.78
| prune-epoch  24 |  2800/ 2983 batches | lr 0.62 | ms/batch  9.99 | loss  4.10 | ppl    60.11
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch  24 | time: 31.52s | valid loss  4.75 | valid ppl   116.10
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  25 |   200/ 2983 batches | lr 0.31 | ms/batch 10.31 | loss  4.20 | ppl    66.88
| prune-epoch  25 |   400/ 2983 batches | lr 0.31 | ms/batch 10.55 | loss  4.22 | ppl    68.06
| prune-epoch  25 |   600/ 2983 batches | lr 0.31 | ms/batch 10.55 | loss  4.07 | ppl    58.58
| prune-epoch  25 |   800/ 2983 batches | lr 0.31 | ms/batch 10.55 | loss  4.13 | ppl    62.35
| prune-epoch  25 |  1000/ 2983 batches | lr 0.31 | ms/batch 10.56 | loss  4.16 | ppl    64.09
| prune-epoch  25 |  1200/ 2983 batches | lr 0.31 | ms/batch 10.56 | loss  4.16 | ppl    64.21
| prune-epoch  25 |  1400/ 2983 batches | lr 0.31 | ms/batch 10.55 | loss  4.18 | ppl    65.68
| prune-epoch  25 |  1600/ 2983 batches | lr 0.31 | ms/batch 10.55 | loss  4.23 | ppl    68.82
| prune-epoch  25 |  1800/ 2983 batches | lr 0.31 | ms/batch 10.47 | loss  4.17 | ppl    64.42
| prune-epoch  25 |  2000/ 2983 batches | lr 0.31 | ms/batch 10.48 | loss  4.20 | ppl    66.69
| prune-epoch  25 |  2200/ 2983 batches | lr 0.31 | ms/batch 10.48 | loss  4.06 | ppl    58.04
| prune-epoch  25 |  2400/ 2983 batches | lr 0.31 | ms/batch 10.48 | loss  4.10 | ppl    60.40
| prune-epoch  25 |  2600/ 2983 batches | lr 0.31 | ms/batch 10.48 | loss  4.13 | ppl    62.42
| prune-epoch  25 |  2800/ 2983 batches | lr 0.31 | ms/batch 10.48 | loss  4.11 | ppl    60.71
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch  25 | time: 33.02s | valid loss  4.75 | valid ppl   115.20
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  26 |   200/ 2983 batches | lr 0.31 | ms/batch 10.09 | loss  4.20 | ppl    66.90
| prune-epoch  26 |   400/ 2983 batches | lr 0.31 | ms/batch 10.10 | loss  4.21 | ppl    67.60
| prune-epoch  26 |   600/ 2983 batches | lr 0.31 | ms/batch 10.06 | loss  4.06 | ppl    58.25
| prune-epoch  26 |   800/ 2983 batches | lr 0.31 | ms/batch 10.04 | loss  4.13 | ppl    62.13
| prune-epoch  26 |  1000/ 2983 batches | lr 0.31 | ms/batch 10.07 | loss  4.16 | ppl    63.83
| prune-epoch  26 |  1200/ 2983 batches | lr 0.31 | ms/batch 10.06 | loss  4.16 | ppl    63.90
| prune-epoch  26 |  1400/ 2983 batches | lr 0.31 | ms/batch 10.04 | loss  4.18 | ppl    65.52
| prune-epoch  26 |  1600/ 2983 batches | lr 0.31 | ms/batch 10.11 | loss  4.23 | ppl    68.79
| prune-epoch  26 |  1800/ 2983 batches | lr 0.31 | ms/batch 10.03 | loss  4.16 | ppl    64.23
| prune-epoch  26 |  2000/ 2983 batches | lr 0.31 | ms/batch 10.04 | loss  4.21 | ppl    67.14
| prune-epoch  26 |  2200/ 2983 batches | lr 0.31 | ms/batch 10.02 | loss  4.06 | ppl    57.75
| prune-epoch  26 |  2400/ 2983 batches | lr 0.31 | ms/batch 10.04 | loss  4.10 | ppl    60.28
| prune-epoch  26 |  2600/ 2983 batches | lr 0.31 | ms/batch 10.11 | loss  4.13 | ppl    62.26
| prune-epoch  26 |  2800/ 2983 batches | lr 0.31 | ms/batch 10.07 | loss  4.10 | ppl    60.56
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch  26 | time: 31.59s | valid loss  4.75 | valid ppl   115.27
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  27 |   200/ 2983 batches | lr 0.31 | ms/batch 10.06 | loss  4.21 | ppl    67.05
| prune-epoch  27 |   400/ 2983 batches | lr 0.31 | ms/batch 10.01 | loss  4.22 | ppl    67.89
| prune-epoch  27 |   600/ 2983 batches | lr 0.31 | ms/batch 10.02 | loss  4.06 | ppl    57.97
| prune-epoch  27 |   800/ 2983 batches | lr 0.31 | ms/batch 10.01 | loss  4.13 | ppl    62.42
| prune-epoch  27 |  1000/ 2983 batches | lr 0.31 | ms/batch 10.02 | loss  4.16 | ppl    63.84
| prune-epoch  27 |  1200/ 2983 batches | lr 0.31 | ms/batch  9.98 | loss  4.16 | ppl    64.14
| prune-epoch  27 |  1400/ 2983 batches | lr 0.31 | ms/batch  9.91 | loss  4.19 | ppl    65.77
| prune-epoch  27 |  1600/ 2983 batches | lr 0.31 | ms/batch  9.81 | loss  4.23 | ppl    68.72
| prune-epoch  27 |  1800/ 2983 batches | lr 0.31 | ms/batch  9.80 | loss  4.16 | ppl    63.77
| prune-epoch  27 |  2000/ 2983 batches | lr 0.31 | ms/batch  9.79 | loss  4.21 | ppl    67.04
| prune-epoch  27 |  2200/ 2983 batches | lr 0.31 | ms/batch  9.97 | loss  4.06 | ppl    58.19
| prune-epoch  27 |  2400/ 2983 batches | lr 0.31 | ms/batch 10.00 | loss  4.09 | ppl    59.96
| prune-epoch  27 |  2600/ 2983 batches | lr 0.31 | ms/batch  9.96 | loss  4.13 | ppl    62.43
| prune-epoch  27 |  2800/ 2983 batches | lr 0.31 | ms/batch 10.04 | loss  4.10 | ppl    60.44
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch  27 | time: 31.28s | valid loss  4.75 | valid ppl   115.16
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  28 |   200/ 2983 batches | lr 0.31 | ms/batch 10.09 | loss  4.20 | ppl    66.55
| prune-epoch  28 |   400/ 2983 batches | lr 0.31 | ms/batch 10.02 | loss  4.21 | ppl    67.64
| prune-epoch  28 |   600/ 2983 batches | lr 0.31 | ms/batch 10.01 | loss  4.06 | ppl    57.86
| prune-epoch  28 |   800/ 2983 batches | lr 0.31 | ms/batch 10.04 | loss  4.13 | ppl    62.07
| prune-epoch  28 |  1000/ 2983 batches | lr 0.31 | ms/batch 10.18 | loss  4.15 | ppl    63.69
| prune-epoch  28 |  1200/ 2983 batches | lr 0.31 | ms/batch 11.10 | loss  4.15 | ppl    63.72
| prune-epoch  28 |  1400/ 2983 batches | lr 0.31 | ms/batch 11.10 | loss  4.18 | ppl    65.49
| prune-epoch  28 |  1600/ 2983 batches | lr 0.31 | ms/batch 11.07 | loss  4.23 | ppl    68.74
| prune-epoch  28 |  1800/ 2983 batches | lr 0.31 | ms/batch 11.06 | loss  4.17 | ppl    64.42
| prune-epoch  28 |  2000/ 2983 batches | lr 0.31 | ms/batch 11.09 | loss  4.20 | ppl    66.85
| prune-epoch  28 |  2200/ 2983 batches | lr 0.31 | ms/batch 11.10 | loss  4.06 | ppl    57.91
| prune-epoch  28 |  2400/ 2983 batches | lr 0.31 | ms/batch 11.09 | loss  4.10 | ppl    60.16
| prune-epoch  28 |  2600/ 2983 batches | lr 0.31 | ms/batch 11.09 | loss  4.13 | ppl    61.90
| prune-epoch  28 |  2800/ 2983 batches | lr 0.31 | ms/batch 11.10 | loss  4.11 | ppl    60.73
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch  28 | time: 33.85s | valid loss  4.75 | valid ppl   115.10
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  29 |   200/ 2983 batches | lr 0.31 | ms/batch 10.50 | loss  4.20 | ppl    66.92
| prune-epoch  29 |   400/ 2983 batches | lr 0.31 | ms/batch 10.43 | loss  4.22 | ppl    67.90
| prune-epoch  29 |   600/ 2983 batches | lr 0.31 | ms/batch 10.42 | loss  4.06 | ppl    57.78
| prune-epoch  29 |   800/ 2983 batches | lr 0.31 | ms/batch 10.47 | loss  4.13 | ppl    62.11
| prune-epoch  29 |  1000/ 2983 batches | lr 0.31 | ms/batch 10.46 | loss  4.15 | ppl    63.67
| prune-epoch  29 |  1200/ 2983 batches | lr 0.31 | ms/batch 10.46 | loss  4.16 | ppl    63.78
| prune-epoch  29 |  1400/ 2983 batches | lr 0.31 | ms/batch 10.48 | loss  4.18 | ppl    65.31
| prune-epoch  29 |  1600/ 2983 batches | lr 0.31 | ms/batch 10.48 | loss  4.23 | ppl    68.65
| prune-epoch  29 |  1800/ 2983 batches | lr 0.31 | ms/batch 10.44 | loss  4.16 | ppl    64.16
| prune-epoch  29 |  2000/ 2983 batches | lr 0.31 | ms/batch 10.46 | loss  4.20 | ppl    66.92
| prune-epoch  29 |  2200/ 2983 batches | lr 0.31 | ms/batch 10.53 | loss  4.06 | ppl    57.93
| prune-epoch  29 |  2400/ 2983 batches | lr 0.31 | ms/batch 10.50 | loss  4.10 | ppl    60.31
| prune-epoch  29 |  2600/ 2983 batches | lr 0.31 | ms/batch 10.42 | loss  4.13 | ppl    62.24
| prune-epoch  29 |  2800/ 2983 batches | lr 0.31 | ms/batch 10.45 | loss  4.11 | ppl    60.76
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch  29 | time: 32.93s | valid loss  4.75 | valid ppl   115.10
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  30 |   200/ 2983 batches | lr 0.16 | ms/batch 10.52 | loss  4.21 | ppl    67.07
| prune-epoch  30 |   400/ 2983 batches | lr 0.16 | ms/batch 10.58 | loss  4.23 | ppl    68.67
| prune-epoch  30 |   600/ 2983 batches | lr 0.16 | ms/batch 10.59 | loss  4.08 | ppl    59.10
| prune-epoch  30 |   800/ 2983 batches | lr 0.16 | ms/batch 10.60 | loss  4.14 | ppl    62.72
| prune-epoch  30 |  1000/ 2983 batches | lr 0.16 | ms/batch 10.59 | loss  4.17 | ppl    65.03
| prune-epoch  30 |  1200/ 2983 batches | lr 0.16 | ms/batch 10.60 | loss  4.17 | ppl    64.62
| prune-epoch  30 |  1400/ 2983 batches | lr 0.16 | ms/batch 10.59 | loss  4.19 | ppl    65.82
| prune-epoch  30 |  1600/ 2983 batches | lr 0.16 | ms/batch 10.59 | loss  4.24 | ppl    69.14
| prune-epoch  30 |  1800/ 2983 batches | lr 0.16 | ms/batch 10.56 | loss  4.17 | ppl    64.67
| prune-epoch  30 |  2000/ 2983 batches | lr 0.16 | ms/batch 10.47 | loss  4.22 | ppl    68.31
| prune-epoch  30 |  2200/ 2983 batches | lr 0.16 | ms/batch 10.46 | loss  4.07 | ppl    58.69
| prune-epoch  30 |  2400/ 2983 batches | lr 0.16 | ms/batch 10.44 | loss  4.11 | ppl    60.69
| prune-epoch  30 |  2600/ 2983 batches | lr 0.16 | ms/batch 10.44 | loss  4.14 | ppl    62.81
| prune-epoch  30 |  2800/ 2983 batches | lr 0.16 | ms/batch 10.42 | loss  4.11 | ppl    60.94
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch  30 | time: 33.02s | valid loss  4.74 | valid ppl   114.49
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  31 |   200/ 2983 batches | lr 0.16 | ms/batch 10.04 | loss  4.22 | ppl    67.74
| prune-epoch  31 |   400/ 2983 batches | lr 0.16 | ms/batch  9.94 | loss  4.23 | ppl    68.53
| prune-epoch  31 |   600/ 2983 batches | lr 0.16 | ms/batch  9.97 | loss  4.07 | ppl    58.71
| prune-epoch  31 |   800/ 2983 batches | lr 0.16 | ms/batch  9.96 | loss  4.14 | ppl    62.59
| prune-epoch  31 |  1000/ 2983 batches | lr 0.16 | ms/batch  9.97 | loss  4.17 | ppl    64.88
| prune-epoch  31 |  1200/ 2983 batches | lr 0.16 | ms/batch  9.96 | loss  4.16 | ppl    64.39
| prune-epoch  31 |  1400/ 2983 batches | lr 0.16 | ms/batch  9.94 | loss  4.19 | ppl    66.03
| prune-epoch  31 |  1600/ 2983 batches | lr 0.16 | ms/batch  9.96 | loss  4.24 | ppl    69.13
| prune-epoch  31 |  1800/ 2983 batches | lr 0.16 | ms/batch 10.26 | loss  4.16 | ppl    64.30
| prune-epoch  31 |  2000/ 2983 batches | lr 0.16 | ms/batch 10.41 | loss  4.22 | ppl    68.37
| prune-epoch  31 |  2200/ 2983 batches | lr 0.16 | ms/batch 10.41 | loss  4.07 | ppl    58.63
| prune-epoch  31 |  2400/ 2983 batches | lr 0.16 | ms/batch 10.50 | loss  4.10 | ppl    60.36
| prune-epoch  31 |  2600/ 2983 batches | lr 0.16 | ms/batch 10.04 | loss  4.14 | ppl    62.63
| prune-epoch  31 |  2800/ 2983 batches | lr 0.16 | ms/batch  9.77 | loss  4.11 | ppl    61.00
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch  31 | time: 31.57s | valid loss  4.74 | valid ppl   114.41
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  32 |   200/ 2983 batches | lr 0.16 | ms/batch  9.89 | loss  4.22 | ppl    68.08
| prune-epoch  32 |   400/ 2983 batches | lr 0.16 | ms/batch  9.80 | loss  4.23 | ppl    68.60
| prune-epoch  32 |   600/ 2983 batches | lr 0.16 | ms/batch  9.90 | loss  4.07 | ppl    58.50
| prune-epoch  32 |   800/ 2983 batches | lr 0.16 | ms/batch 10.06 | loss  4.14 | ppl    62.88
| prune-epoch  32 |  1000/ 2983 batches | lr 0.16 | ms/batch 10.10 | loss  4.17 | ppl    64.61
| prune-epoch  32 |  1200/ 2983 batches | lr 0.16 | ms/batch 10.06 | loss  4.16 | ppl    64.32
| prune-epoch  32 |  1400/ 2983 batches | lr 0.16 | ms/batch 10.01 | loss  4.19 | ppl    65.95
| prune-epoch  32 |  1600/ 2983 batches | lr 0.16 | ms/batch 10.05 | loss  4.24 | ppl    69.37
| prune-epoch  32 |  1800/ 2983 batches | lr 0.16 | ms/batch 10.03 | loss  4.16 | ppl    64.29
| prune-epoch  32 |  2000/ 2983 batches | lr 0.16 | ms/batch 10.00 | loss  4.22 | ppl    68.14
| prune-epoch  32 |  2200/ 2983 batches | lr 0.16 | ms/batch 10.03 | loss  4.07 | ppl    58.79
| prune-epoch  32 |  2400/ 2983 batches | lr 0.16 | ms/batch 10.02 | loss  4.10 | ppl    60.53
| prune-epoch  32 |  2600/ 2983 batches | lr 0.16 | ms/batch 10.06 | loss  4.14 | ppl    62.84
| prune-epoch  32 |  2800/ 2983 batches | lr 0.16 | ms/batch 10.01 | loss  4.11 | ppl    60.76
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch  32 | time: 31.40s | valid loss  4.74 | valid ppl   114.34
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  33 |   200/ 2983 batches | lr 0.16 | ms/batch 10.55 | loss  4.21 | ppl    67.66
| prune-epoch  33 |   400/ 2983 batches | lr 0.16 | ms/batch 10.55 | loss  4.23 | ppl    68.62
| prune-epoch  33 |   600/ 2983 batches | lr 0.16 | ms/batch 10.50 | loss  4.07 | ppl    58.65
| prune-epoch  33 |   800/ 2983 batches | lr 0.16 | ms/batch 10.45 | loss  4.14 | ppl    62.69
| prune-epoch  33 |  1000/ 2983 batches | lr 0.16 | ms/batch 10.45 | loss  4.17 | ppl    64.79
| prune-epoch  33 |  1200/ 2983 batches | lr 0.16 | ms/batch 10.45 | loss  4.16 | ppl    63.95
| prune-epoch  33 |  1400/ 2983 batches | lr 0.16 | ms/batch 10.45 | loss  4.19 | ppl    65.81
| prune-epoch  33 |  1600/ 2983 batches | lr 0.16 | ms/batch 10.44 | loss  4.24 | ppl    69.32
| prune-epoch  33 |  1800/ 2983 batches | lr 0.16 | ms/batch 10.44 | loss  4.16 | ppl    64.20
| prune-epoch  33 |  2000/ 2983 batches | lr 0.16 | ms/batch 10.44 | loss  4.22 | ppl    67.99
| prune-epoch  33 |  2200/ 2983 batches | lr 0.16 | ms/batch 10.44 | loss  4.07 | ppl    58.83
| prune-epoch  33 |  2400/ 2983 batches | lr 0.16 | ms/batch 10.45 | loss  4.10 | ppl    60.62
| prune-epoch  33 |  2600/ 2983 batches | lr 0.16 | ms/batch 10.44 | loss  4.14 | ppl    62.76
| prune-epoch  33 |  2800/ 2983 batches | lr 0.16 | ms/batch 10.48 | loss  4.11 | ppl    60.93
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch  33 | time: 32.85s | valid loss  4.74 | valid ppl   114.44
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  34 |   200/ 2983 batches | lr 0.16 | ms/batch 10.10 | loss  4.22 | ppl    67.79
| prune-epoch  34 |   400/ 2983 batches | lr 0.16 | ms/batch 10.06 | loss  4.23 | ppl    68.40
| prune-epoch  34 |   600/ 2983 batches | lr 0.16 | ms/batch  9.96 | loss  4.07 | ppl    58.60
| prune-epoch  34 |   800/ 2983 batches | lr 0.16 | ms/batch 10.03 | loss  4.14 | ppl    62.60
| prune-epoch  34 |  1000/ 2983 batches | lr 0.16 | ms/batch  9.95 | loss  4.17 | ppl    64.62
| prune-epoch  34 |  1200/ 2983 batches | lr 0.16 | ms/batch 10.07 | loss  4.16 | ppl    64.01
| prune-epoch  34 |  1400/ 2983 batches | lr 0.16 | ms/batch  9.94 | loss  4.18 | ppl    65.64
| prune-epoch  34 |  1600/ 2983 batches | lr 0.16 | ms/batch  9.93 | loss  4.24 | ppl    69.23
| prune-epoch  34 |  1800/ 2983 batches | lr 0.16 | ms/batch 10.01 | loss  4.16 | ppl    64.09
| prune-epoch  34 |  2000/ 2983 batches | lr 0.16 | ms/batch 10.00 | loss  4.22 | ppl    68.07
| prune-epoch  34 |  2200/ 2983 batches | lr 0.16 | ms/batch 10.00 | loss  4.07 | ppl    58.63
| prune-epoch  34 |  2400/ 2983 batches | lr 0.16 | ms/batch  9.95 | loss  4.10 | ppl    60.53
| prune-epoch  34 |  2600/ 2983 batches | lr 0.16 | ms/batch  9.92 | loss  4.14 | ppl    62.62
| prune-epoch  34 |  2800/ 2983 batches | lr 0.16 | ms/batch  9.94 | loss  4.11 | ppl    60.65
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch  34 | time: 31.36s | valid loss  4.74 | valid ppl   114.46
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  35 |   200/ 2983 batches | lr 0.08 | ms/batch 10.09 | loss  4.23 | ppl    68.52
| prune-epoch  35 |   400/ 2983 batches | lr 0.08 | ms/batch 10.02 | loss  4.24 | ppl    69.73
| prune-epoch  35 |   600/ 2983 batches | lr 0.08 | ms/batch 10.01 | loss  4.08 | ppl    59.43
| prune-epoch  35 |   800/ 2983 batches | lr 0.08 | ms/batch 10.03 | loss  4.15 | ppl    63.28
| prune-epoch  35 |  1000/ 2983 batches | lr 0.08 | ms/batch 10.02 | loss  4.19 | ppl    65.99
| prune-epoch  35 |  1200/ 2983 batches | lr 0.08 | ms/batch 10.01 | loss  4.18 | ppl    65.21
| prune-epoch  35 |  1400/ 2983 batches | lr 0.08 | ms/batch 10.00 | loss  4.20 | ppl    66.39
| prune-epoch  35 |  1600/ 2983 batches | lr 0.08 | ms/batch 10.15 | loss  4.25 | ppl    69.96
| prune-epoch  35 |  1800/ 2983 batches | lr 0.08 | ms/batch 10.02 | loss  4.17 | ppl    64.41
| prune-epoch  35 |  2000/ 2983 batches | lr 0.08 | ms/batch 10.02 | loss  4.23 | ppl    68.91
| prune-epoch  35 |  2200/ 2983 batches | lr 0.08 | ms/batch  9.99 | loss  4.09 | ppl    59.66
| prune-epoch  35 |  2400/ 2983 batches | lr 0.08 | ms/batch 10.66 | loss  4.11 | ppl    60.89
| prune-epoch  35 |  2600/ 2983 batches | lr 0.08 | ms/batch 10.89 | loss  4.15 | ppl    63.35
| prune-epoch  35 |  2800/ 2983 batches | lr 0.08 | ms/batch 10.43 | loss  4.11 | ppl    60.74
end prun train
weight_ih_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l0        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_ih_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
weight_hh_l1        shape torch.Size([800, 200])
       expected sp:  0.9  actual sp:  0.895
-----------------------------------------------------------------------------------------
| end of retrain epoch  35 | time: 32.00s | valid loss  4.74 | valid ppl   113.90
-----------------------------------------------------------------------------------------
required epochs  40 | actual epochs  69
pretrain epochs  10 | prune epochs  24 | retrain epochs  35
=========================================================================================
| End of training | test loss  4.68 | test ppl   107.84
=========================================================================================
python main.py --cuda --emsize 650 --nhid 650 --dropout 0.5 --epochs 40 --save model/prune/model.pt --prune --retrain --sparsity 0.9
<class 'torch.Tensor'> torch.Size([33278, 650])
<class 'torch.Tensor'> torch.Size([2600, 650])
<class 'torch.Tensor'> torch.Size([2600, 650])
<class 'torch.Tensor'> torch.Size([2600])
<class 'torch.Tensor'> torch.Size([2600])
<class 'torch.Tensor'> torch.Size([2600, 650])
<class 'torch.Tensor'> torch.Size([2600, 650])
<class 'torch.Tensor'> torch.Size([2600])
<class 'torch.Tensor'> torch.Size([2600])
<class 'torch.Tensor'> torch.Size([33278, 650])
<class 'torch.Tensor'> torch.Size([33278])
RNNModel(
  (drop): Dropout(p=0.5)
  (encoder): Embedding(33278, 650)
  (rnn): LSTM(650, 650, num_layers=2, dropout=0.5)
  (decoder): Linear(in_features=650, out_features=33278, bias=True)
)
Dropout(p=0.5)
Embedding(33278, 650)
LSTM(650, 650, num_layers=2, dropout=0.5)
Linear(in_features=650, out_features=33278, bias=True)
| train-epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 22.39 | loss  7.74 | ppl  2289.44
| train-epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 22.14 | loss  6.83 | ppl   924.74
| train-epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 22.12 | loss  6.45 | ppl   630.61
| train-epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 22.19 | loss  6.28 | ppl   535.41
| train-epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.25 | loss  6.15 | ppl   468.04
| train-epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.29 | loss  6.09 | ppl   441.11
| train-epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.25 | loss  5.99 | ppl   398.26
| train-epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.21 | loss  5.99 | ppl   401.09
| train-epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  5.84 | ppl   344.27
| train-epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  5.82 | ppl   337.40
| train-epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  5.71 | ppl   302.18
| train-epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.34 | loss  5.72 | ppl   303.73
| train-epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  5.70 | ppl   298.17
| train-epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.33 | loss  5.59 | ppl   267.98
-----------------------------------------------------------------------------------------
| end of train epoch   1 | time: 69.28s | valid loss  5.52 | valid ppl   249.79
-----------------------------------------------------------------------------------------
| train-epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch 22.57 | loss  5.59 | ppl   267.17
| train-epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch 22.44 | loss  5.57 | ppl   262.03
| train-epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch 22.49 | loss  5.40 | ppl   221.67
| train-epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  5.41 | ppl   224.50
| train-epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.49 | loss  5.38 | ppl   217.69
| train-epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  5.38 | ppl   216.08
| train-epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.49 | loss  5.36 | ppl   213.47
| train-epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  5.42 | ppl   226.75
| train-epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.49 | loss  5.30 | ppl   199.50
| train-epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.49 | loss  5.31 | ppl   201.80
| train-epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.50 | loss  5.21 | ppl   182.73
| train-epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.50 | loss  5.23 | ppl   187.25
| train-epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.49 | loss  5.24 | ppl   188.62
| train-epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  5.16 | ppl   174.33
-----------------------------------------------------------------------------------------
| end of train epoch   2 | time: 69.87s | valid loss  5.21 | valid ppl   184.00
-----------------------------------------------------------------------------------------
| train-epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 22.51 | loss  5.21 | ppl   183.46
| train-epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch 22.37 | loss  5.22 | ppl   185.26
| train-epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  5.04 | ppl   153.80
| train-epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  5.08 | ppl   161.16
| train-epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  5.07 | ppl   158.83
| train-epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  5.07 | ppl   159.04
| train-epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.37 | loss  5.09 | ppl   162.59
| train-epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.39 | loss  5.15 | ppl   172.79
| train-epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  5.03 | ppl   152.87
| train-epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  5.06 | ppl   157.72
| train-epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  4.96 | ppl   142.54
| train-epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.37 | loss  4.99 | ppl   147.62
| train-epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.37 | loss  5.01 | ppl   149.27
| train-epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.37 | loss  4.94 | ppl   139.43
-----------------------------------------------------------------------------------------
| end of train epoch   3 | time: 69.56s | valid loss  5.05 | valid ppl   156.07
-----------------------------------------------------------------------------------------
| train-epoch   4 |   200/ 2983 batches | lr 20.00 | ms/batch 22.69 | loss  4.99 | ppl   147.59
| train-epoch   4 |   400/ 2983 batches | lr 20.00 | ms/batch 22.57 | loss  5.01 | ppl   150.46
| train-epoch   4 |   600/ 2983 batches | lr 20.00 | ms/batch 22.56 | loss  4.82 | ppl   124.03
| train-epoch   4 |   800/ 2983 batches | lr 20.00 | ms/batch 22.56 | loss  4.88 | ppl   131.69
| train-epoch   4 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.56 | loss  4.87 | ppl   130.51
| train-epoch   4 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.55 | loss  4.88 | ppl   131.66
| train-epoch   4 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.56 | loss  4.91 | ppl   135.65
| train-epoch   4 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.55 | loss  4.98 | ppl   145.86
| train-epoch   4 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.55 | loss  4.85 | ppl   128.25
| train-epoch   4 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.69 | loss  4.89 | ppl   132.68
| train-epoch   4 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.54 | loss  4.78 | ppl   119.62
| train-epoch   4 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.52 | loss  4.82 | ppl   124.31
| train-epoch   4 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.50 | loss  4.84 | ppl   127.07
| train-epoch   4 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.51 | loss  4.78 | ppl   118.73
-----------------------------------------------------------------------------------------
| end of train epoch   4 | time: 70.12s | valid loss  4.95 | valid ppl   141.18
-----------------------------------------------------------------------------------------
| train-epoch   5 |   200/ 2983 batches | lr 20.00 | ms/batch 22.45 | loss  4.84 | ppl   126.60
| train-epoch   5 |   400/ 2983 batches | lr 20.00 | ms/batch 22.32 | loss  4.86 | ppl   128.59
| train-epoch   5 |   600/ 2983 batches | lr 20.00 | ms/batch 22.32 | loss  4.67 | ppl   106.58
| train-epoch   5 |   800/ 2983 batches | lr 20.00 | ms/batch 22.33 | loss  4.73 | ppl   113.67
| train-epoch   5 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.32 | loss  4.72 | ppl   112.65
| train-epoch   5 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.33 | loss  4.74 | ppl   114.13
| train-epoch   5 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.32 | loss  4.78 | ppl   118.94
| train-epoch   5 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.32 | loss  4.85 | ppl   127.48
| train-epoch   5 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.33 | loss  4.73 | ppl   113.11
| train-epoch   5 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.32 | loss  4.76 | ppl   116.97
| train-epoch   5 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.32 | loss  4.66 | ppl   105.62
| train-epoch   5 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.32 | loss  4.70 | ppl   109.69
| train-epoch   5 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.36 | loss  4.71 | ppl   111.53
| train-epoch   5 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.33 | loss  4.66 | ppl   105.59
-----------------------------------------------------------------------------------------
| end of train epoch   5 | time: 69.40s | valid loss  4.90 | valid ppl   134.87
-----------------------------------------------------------------------------------------
| train-epoch   6 |   200/ 2983 batches | lr 20.00 | ms/batch 22.47 | loss  4.71 | ppl   111.54
| train-epoch   6 |   400/ 2983 batches | lr 20.00 | ms/batch 22.33 | loss  4.74 | ppl   114.39
| train-epoch   6 |   600/ 2983 batches | lr 20.00 | ms/batch 22.36 | loss  4.55 | ppl    94.41
| train-epoch   6 |   800/ 2983 batches | lr 20.00 | ms/batch 22.34 | loss  4.61 | ppl   100.35
| train-epoch   6 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.35 | loss  4.61 | ppl   100.94
| train-epoch   6 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.37 | loss  4.63 | ppl   102.35
| train-epoch   6 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.34 | loss  4.67 | ppl   107.05
| train-epoch   6 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.36 | loss  4.74 | ppl   114.27
| train-epoch   6 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.35 | loss  4.62 | ppl   101.89
| train-epoch   6 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.35 | loss  4.66 | ppl   105.40
| train-epoch   6 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.35 | loss  4.55 | ppl    94.98
| train-epoch   6 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.35 | loss  4.59 | ppl    98.77
| train-epoch   6 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.35 | loss  4.62 | ppl   101.36
| train-epoch   6 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.34 | loss  4.56 | ppl    95.45
-----------------------------------------------------------------------------------------
| end of train epoch   6 | time: 69.47s | valid loss  4.86 | valid ppl   128.60
-----------------------------------------------------------------------------------------
| train-epoch   7 |   200/ 2983 batches | lr 20.00 | ms/batch 22.58 | loss  4.61 | ppl   100.84
| train-epoch   7 |   400/ 2983 batches | lr 20.00 | ms/batch 22.47 | loss  4.64 | ppl   103.87
| train-epoch   7 |   600/ 2983 batches | lr 20.00 | ms/batch 22.46 | loss  4.45 | ppl    85.79
| train-epoch   7 |   800/ 2983 batches | lr 20.00 | ms/batch 22.47 | loss  4.51 | ppl    91.10
| train-epoch   7 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.46 | loss  4.53 | ppl    92.52
| train-epoch   7 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.45 | loss  4.54 | ppl    93.80
| train-epoch   7 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.46 | loss  4.58 | ppl    97.89
| train-epoch   7 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.46 | loss  4.66 | ppl   105.19
| train-epoch   7 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.47 | loss  4.54 | ppl    93.91
| train-epoch   7 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.46 | loss  4.58 | ppl    97.21
| train-epoch   7 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.47 | loss  4.47 | ppl    87.29
| train-epoch   7 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.47 | loss  4.51 | ppl    90.80
| train-epoch   7 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.45 | loss  4.54 | ppl    93.25
| train-epoch   7 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.45 | loss  4.48 | ppl    88.67
-----------------------------------------------------------------------------------------
| end of train epoch   7 | time: 69.81s | valid loss  4.85 | valid ppl   127.63
-----------------------------------------------------------------------------------------
| train-epoch   8 |   200/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  4.54 | ppl    93.37
| train-epoch   8 |   400/ 2983 batches | lr 20.00 | ms/batch 22.34 | loss  4.56 | ppl    95.53
| train-epoch   8 |   600/ 2983 batches | lr 20.00 | ms/batch 22.36 | loss  4.38 | ppl    79.73
| train-epoch   8 |   800/ 2983 batches | lr 20.00 | ms/batch 22.37 | loss  4.43 | ppl    84.03
| train-epoch   8 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.37 | loss  4.45 | ppl    85.80
| train-epoch   8 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.36 | loss  4.47 | ppl    87.27
| train-epoch   8 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.36 | loss  4.51 | ppl    90.64
| train-epoch   8 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.36 | loss  4.58 | ppl    97.71
| train-epoch   8 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  4.47 | ppl    87.20
| train-epoch   8 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.50 | loss  4.51 | ppl    90.76
| train-epoch   8 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  4.39 | ppl    80.88
| train-epoch   8 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  4.43 | ppl    84.16
| train-epoch   8 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  4.46 | ppl    86.90
| train-epoch   8 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.45 | loss  4.41 | ppl    82.23
-----------------------------------------------------------------------------------------
| end of train epoch   8 | time: 69.62s | valid loss  4.83 | valid ppl   125.48
-----------------------------------------------------------------------------------------
| train-epoch   9 |   200/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  4.47 | ppl    86.98
| train-epoch   9 |   400/ 2983 batches | lr 20.00 | ms/batch 22.25 | loss  4.49 | ppl    89.13
| train-epoch   9 |   600/ 2983 batches | lr 20.00 | ms/batch 22.30 | loss  4.31 | ppl    74.49
| train-epoch   9 |   800/ 2983 batches | lr 20.00 | ms/batch 22.36 | loss  4.37 | ppl    78.80
| train-epoch   9 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.36 | loss  4.39 | ppl    80.62
| train-epoch   9 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.35 | loss  4.40 | ppl    81.20
| train-epoch   9 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.35 | loss  4.45 | ppl    85.32
| train-epoch   9 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.35 | loss  4.52 | ppl    91.81
| train-epoch   9 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.36 | loss  4.41 | ppl    82.44
| train-epoch   9 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  4.44 | ppl    84.77
| train-epoch   9 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.36 | loss  4.33 | ppl    76.31
| train-epoch   9 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.35 | loss  4.38 | ppl    79.46
| train-epoch   9 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.35 | loss  4.41 | ppl    82.54
| train-epoch   9 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.37 | loss  4.36 | ppl    78.35
-----------------------------------------------------------------------------------------
| end of train epoch   9 | time: 69.45s | valid loss  4.81 | valid ppl   122.22
-----------------------------------------------------------------------------------------
| train-epoch  10 |   200/ 2983 batches | lr 20.00 | ms/batch 22.53 | loss  4.41 | ppl    82.05
| train-epoch  10 |   400/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  4.43 | ppl    83.66
| train-epoch  10 |   600/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  4.26 | ppl    70.53
| train-epoch  10 |   800/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  4.30 | ppl    73.94
| train-epoch  10 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  4.34 | ppl    76.51
| train-epoch  10 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  4.35 | ppl    77.43
| train-epoch  10 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.46 | loss  4.39 | ppl    80.78
| train-epoch  10 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.47 | loss  4.46 | ppl    86.68
| train-epoch  10 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  4.35 | ppl    77.79
| train-epoch  10 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  4.40 | ppl    81.08
| train-epoch  10 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.46 | loss  4.29 | ppl    72.70
| train-epoch  10 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  4.32 | ppl    75.36
| train-epoch  10 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  4.35 | ppl    77.29
| train-epoch  10 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  4.30 | ppl    73.85
-----------------------------------------------------------------------------------------
| end of train epoch  10 | time: 69.75s | valid loss  4.79 | valid ppl   120.02
-----------------------------------------------------------------------------------------
| train-epoch  11 |   200/ 2983 batches | lr 20.00 | ms/batch 22.47 | loss  4.35 | ppl    77.68
| train-epoch  11 |   400/ 2983 batches | lr 20.00 | ms/batch 22.36 | loss  4.38 | ppl    80.17
| train-epoch  11 |   600/ 2983 batches | lr 20.00 | ms/batch 22.36 | loss  4.21 | ppl    67.06
| train-epoch  11 |   800/ 2983 batches | lr 20.00 | ms/batch 22.36 | loss  4.26 | ppl    70.47
| train-epoch  11 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.35 | loss  4.29 | ppl    73.30
| train-epoch  11 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.36 | loss  4.30 | ppl    73.78
| train-epoch  11 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.35 | loss  4.34 | ppl    76.58
| train-epoch  11 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.35 | loss  4.42 | ppl    83.12
| train-epoch  11 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.34 | loss  4.31 | ppl    74.67
| train-epoch  11 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.34 | loss  4.35 | ppl    77.11
| train-epoch  11 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.35 | loss  4.23 | ppl    69.03
| train-epoch  11 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.35 | loss  4.27 | ppl    71.81
| train-epoch  11 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.37 | loss  4.31 | ppl    74.33
| train-epoch  11 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.35 | loss  4.27 | ppl    71.19
-----------------------------------------------------------------------------------------
| end of train epoch  11 | time: 69.47s | valid loss  4.78 | valid ppl   119.49
-----------------------------------------------------------------------------------------
| train-epoch  12 |   200/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  4.31 | ppl    74.56
| train-epoch  12 |   400/ 2983 batches | lr 20.00 | ms/batch 22.34 | loss  4.33 | ppl    76.17
| train-epoch  12 |   600/ 2983 batches | lr 20.00 | ms/batch 22.34 | loss  4.16 | ppl    63.92
| train-epoch  12 |   800/ 2983 batches | lr 20.00 | ms/batch 22.34 | loss  4.21 | ppl    67.09
| train-epoch  12 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.35 | loss  4.25 | ppl    70.20
| train-epoch  12 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.33 | loss  4.26 | ppl    70.70
| train-epoch  12 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.34 | loss  4.30 | ppl    73.71
| train-epoch  12 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.35 | loss  4.38 | ppl    79.59
| train-epoch  12 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.34 | loss  4.27 | ppl    71.40
| train-epoch  12 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.34 | loss  4.30 | ppl    74.06
| train-epoch  12 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.35 | loss  4.19 | ppl    66.25
| train-epoch  12 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.36 | loss  4.23 | ppl    68.79
| train-epoch  12 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  4.27 | ppl    71.34
| train-epoch  12 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.35 | loss  4.23 | ppl    68.45
-----------------------------------------------------------------------------------------
| end of train epoch  12 | time: 69.48s | valid loss  4.78 | valid ppl   119.34
-----------------------------------------------------------------------------------------
| train-epoch  13 |   200/ 2983 batches | lr 20.00 | ms/batch 22.64 | loss  4.27 | ppl    71.83
| train-epoch  13 |   400/ 2983 batches | lr 20.00 | ms/batch 22.50 | loss  4.30 | ppl    73.51
| train-epoch  13 |   600/ 2983 batches | lr 20.00 | ms/batch 22.51 | loss  4.12 | ppl    61.50
| train-epoch  13 |   800/ 2983 batches | lr 20.00 | ms/batch 22.51 | loss  4.17 | ppl    64.53
| train-epoch  13 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.52 | loss  4.21 | ppl    67.37
| train-epoch  13 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.49 | loss  4.22 | ppl    68.29
| train-epoch  13 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.47 | loss  4.26 | ppl    70.68
| train-epoch  13 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.49 | loss  4.34 | ppl    76.85
| train-epoch  13 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.50 | loss  4.23 | ppl    68.70
| train-epoch  13 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.50 | loss  4.27 | ppl    71.79
| train-epoch  13 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.49 | loss  4.17 | ppl    64.44
| train-epoch  13 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.50 | loss  4.19 | ppl    66.34
| train-epoch  13 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.49 | loss  4.23 | ppl    68.62
| train-epoch  13 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.49 | loss  4.19 | ppl    65.79
-----------------------------------------------------------------------------------------
| end of train epoch  13 | time: 69.91s | valid loss  4.78 | valid ppl   119.27
-----------------------------------------------------------------------------------------
| train-epoch  14 |   200/ 2983 batches | lr 20.00 | ms/batch 22.46 | loss  4.24 | ppl    69.10
| train-epoch  14 |   400/ 2983 batches | lr 20.00 | ms/batch 22.33 | loss  4.26 | ppl    70.65
| train-epoch  14 |   600/ 2983 batches | lr 20.00 | ms/batch 22.32 | loss  4.09 | ppl    59.55
| train-epoch  14 |   800/ 2983 batches | lr 20.00 | ms/batch 22.32 | loss  4.13 | ppl    62.10
| train-epoch  14 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.31 | loss  4.18 | ppl    65.66
| train-epoch  14 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.32 | loss  4.19 | ppl    66.03
| train-epoch  14 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.32 | loss  4.22 | ppl    68.29
| train-epoch  14 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.34 | loss  4.31 | ppl    74.28
| train-epoch  14 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.33 | loss  4.20 | ppl    66.70
| train-epoch  14 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.34 | loss  4.24 | ppl    69.17
| train-epoch  14 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.33 | loss  4.13 | ppl    62.36
| train-epoch  14 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.33 | loss  4.16 | ppl    64.25
| train-epoch  14 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.32 | loss  4.20 | ppl    66.99
| train-epoch  14 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.32 | loss  4.16 | ppl    63.92
-----------------------------------------------------------------------------------------
| end of train epoch  14 | time: 69.39s | valid loss  4.78 | valid ppl   118.75
-----------------------------------------------------------------------------------------
| train-epoch  15 |   200/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  4.21 | ppl    67.08
| train-epoch  15 |   400/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  4.23 | ppl    68.38
| train-epoch  15 |   600/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  4.06 | ppl    57.92
| train-epoch  15 |   800/ 2983 batches | lr 20.00 | ms/batch 22.37 | loss  4.10 | ppl    60.46
| train-epoch  15 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.37 | loss  4.15 | ppl    63.72
| train-epoch  15 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.39 | loss  4.16 | ppl    64.33
| train-epoch  15 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.39 | loss  4.19 | ppl    66.34
| train-epoch  15 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  4.28 | ppl    72.29
| train-epoch  15 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  4.17 | ppl    64.81
| train-epoch  15 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  4.21 | ppl    67.14
| train-epoch  15 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.39 | loss  4.09 | ppl    59.96
| train-epoch  15 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  4.14 | ppl    62.60
| train-epoch  15 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  4.17 | ppl    64.58
| train-epoch  15 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  4.13 | ppl    61.95
-----------------------------------------------------------------------------------------
| end of train epoch  15 | time: 69.57s | valid loss  4.80 | valid ppl   121.35
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 23.10 | loss  4.19 | ppl    65.80
| prune-epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 22.55 | loss  4.20 | ppl    66.95
| prune-epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 22.55 | loss  4.04 | ppl    56.55
| prune-epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 22.56 | loss  4.07 | ppl    58.65
| prune-epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.54 | loss  4.12 | ppl    61.35
| prune-epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.55 | loss  4.12 | ppl    61.74
| prune-epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.54 | loss  4.15 | ppl    63.53
| prune-epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.56 | loss  4.23 | ppl    69.02
| prune-epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.55 | loss  4.13 | ppl    62.33
| prune-epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.56 | loss  4.16 | ppl    64.04
| prune-epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.57 | loss  4.05 | ppl    57.49
| prune-epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.58 | loss  4.08 | ppl    59.43
| prune-epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.56 | loss  4.12 | ppl    61.61
| prune-epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.56 | loss  4.08 | ppl    58.88
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.4  actual sp:  0.3984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.4  actual sp:  0.3984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.4  actual sp:  0.3984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.4  actual sp:  0.3984615384615384
-----------------------------------------------------------------------------------------
| end of prune epoch   1 | time: 70.17s | valid loss  4.77 | valid ppl   117.87
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch 22.99 | loss  4.13 | ppl    62.30
| prune-epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch 22.45 | loss  4.16 | ppl    63.78
| prune-epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch 22.44 | loss  3.99 | ppl    53.82
| prune-epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  4.03 | ppl    56.16
| prune-epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  4.08 | ppl    58.95
| prune-epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.44 | loss  4.09 | ppl    59.57
| prune-epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.45 | loss  4.11 | ppl    60.87
| prune-epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  4.20 | ppl    66.38
| prune-epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  4.09 | ppl    59.68
| prune-epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.45 | loss  4.13 | ppl    62.15
| prune-epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.44 | loss  4.01 | ppl    55.13
| prune-epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.60 | loss  4.05 | ppl    57.16
| prune-epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.66 | loss  4.08 | ppl    59.02
| prune-epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.68 | loss  4.04 | ppl    56.86
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.4  actual sp:  0.3984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.4  actual sp:  0.3984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.4  actual sp:  0.3984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.4  actual sp:  0.3984615384615384
-----------------------------------------------------------------------------------------
| end of prune epoch   2 | time: 70.00s | valid loss  4.78 | valid ppl   119.21
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 23.31 | loss  4.11 | ppl    60.96
| prune-epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch 22.95 | loss  4.13 | ppl    62.08
| prune-epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 22.68 | loss  3.96 | ppl    52.40
| prune-epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 22.66 | loss  4.00 | ppl    54.81
| prune-epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.67 | loss  4.05 | ppl    57.44
| prune-epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.65 | loss  4.06 | ppl    57.78
| prune-epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.65 | loss  4.09 | ppl    59.52
| prune-epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.66 | loss  4.17 | ppl    64.86
| prune-epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.61 | loss  4.07 | ppl    58.32
| prune-epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.51 | loss  4.10 | ppl    60.54
| prune-epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.51 | loss  3.99 | ppl    53.87
| prune-epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.51 | loss  4.02 | ppl    55.70
| prune-epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.50 | loss  4.06 | ppl    57.75
| prune-epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.50 | loss  4.01 | ppl    55.09
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.5  actual sp:  0.4984615384615385
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.5  actual sp:  0.4984615384615385
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.5  actual sp:  0.4984615384615385
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.5  actual sp:  0.4984615384615385
-----------------------------------------------------------------------------------------
| end of prune epoch   3 | time: 70.37s | valid loss  4.76 | valid ppl   116.87
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   4 |   200/ 2983 batches | lr 20.00 | ms/batch 22.85 | loss  4.07 | ppl    58.33
| prune-epoch   4 |   400/ 2983 batches | lr 20.00 | ms/batch 22.34 | loss  4.09 | ppl    59.98
| prune-epoch   4 |   600/ 2983 batches | lr 20.00 | ms/batch 22.34 | loss  3.93 | ppl    50.76
| prune-epoch   4 |   800/ 2983 batches | lr 20.00 | ms/batch 22.34 | loss  3.97 | ppl    52.76
| prune-epoch   4 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.34 | loss  4.02 | ppl    55.91
| prune-epoch   4 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.34 | loss  4.02 | ppl    55.92
| prune-epoch   4 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.33 | loss  4.05 | ppl    57.60
| prune-epoch   4 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.33 | loss  4.14 | ppl    62.68
| prune-epoch   4 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.36 | loss  4.03 | ppl    56.40
| prune-epoch   4 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  4.07 | ppl    58.29
| prune-epoch   4 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  3.95 | ppl    51.68
| prune-epoch   4 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  3.98 | ppl    53.77
| prune-epoch   4 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  4.02 | ppl    55.66
| prune-epoch   4 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  3.99 | ppl    53.92
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.5  actual sp:  0.4984615384615385
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.5  actual sp:  0.4984615384615385
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.5  actual sp:  0.4984615384615385
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.5  actual sp:  0.4984615384615385
-----------------------------------------------------------------------------------------
| end of prune epoch   4 | time: 69.56s | valid loss  4.76 | valid ppl   116.91
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   5 |   200/ 2983 batches | lr 20.00 | ms/batch 22.94 | loss  4.07 | ppl    58.30
| prune-epoch   5 |   400/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  4.08 | ppl    59.33
| prune-epoch   5 |   600/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  3.92 | ppl    50.33
| prune-epoch   5 |   800/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  3.96 | ppl    52.27
| prune-epoch   5 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  4.01 | ppl    55.14
| prune-epoch   5 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  4.01 | ppl    55.34
| prune-epoch   5 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  4.04 | ppl    56.57
| prune-epoch   5 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  4.12 | ppl    61.58
| prune-epoch   5 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  4.02 | ppl    55.55
| prune-epoch   5 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.39 | loss  4.05 | ppl    57.56
| prune-epoch   5 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  3.93 | ppl    51.04
| prune-epoch   5 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  3.97 | ppl    53.24
| prune-epoch   5 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  4.01 | ppl    55.00
| prune-epoch   5 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  3.97 | ppl    52.73
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.6  actual sp:  0.5984615384615385
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.6  actual sp:  0.5984615384615385
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.6  actual sp:  0.5984615384615385
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.6  actual sp:  0.5984615384615385
-----------------------------------------------------------------------------------------
| end of prune epoch   5 | time: 69.72s | valid loss  4.77 | valid ppl   117.83
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   6 |   200/ 2983 batches | lr 20.00 | ms/batch 23.01 | loss  4.02 | ppl    55.51
| prune-epoch   6 |   400/ 2983 batches | lr 20.00 | ms/batch 22.53 | loss  4.04 | ppl    57.09
| prune-epoch   6 |   600/ 2983 batches | lr 20.00 | ms/batch 22.53 | loss  3.88 | ppl    48.24
| prune-epoch   6 |   800/ 2983 batches | lr 20.00 | ms/batch 22.51 | loss  3.92 | ppl    50.37
| prune-epoch   6 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.53 | loss  3.97 | ppl    53.21
| prune-epoch   6 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.51 | loss  3.98 | ppl    53.61
| prune-epoch   6 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.53 | loss  4.00 | ppl    54.76
| prune-epoch   6 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.53 | loss  4.09 | ppl    59.51
| prune-epoch   6 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.52 | loss  3.99 | ppl    53.97
| prune-epoch   6 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.53 | loss  4.02 | ppl    55.65
| prune-epoch   6 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.51 | loss  3.90 | ppl    49.64
| prune-epoch   6 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.52 | loss  3.94 | ppl    51.67
| prune-epoch   6 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.52 | loss  3.98 | ppl    53.40
| prune-epoch   6 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.52 | loss  3.93 | ppl    51.09
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.6  actual sp:  0.5984615384615385
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.6  actual sp:  0.5984615384615385
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.6  actual sp:  0.5984615384615385
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.6  actual sp:  0.5984615384615385
-----------------------------------------------------------------------------------------
| end of prune epoch   6 | time: 70.05s | valid loss  4.77 | valid ppl   117.37
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   7 |   200/ 2983 batches | lr 20.00 | ms/batch 22.92 | loss  3.99 | ppl    54.10
| prune-epoch   7 |   400/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  4.01 | ppl    55.32
| prune-epoch   7 |   600/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  3.85 | ppl    46.89
| prune-epoch   7 |   800/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  3.90 | ppl    49.25
| prune-epoch   7 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  3.95 | ppl    51.86
| prune-epoch   7 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  3.95 | ppl    51.96
| prune-epoch   7 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  3.98 | ppl    53.64
| prune-epoch   7 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  4.06 | ppl    58.17
| prune-epoch   7 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  3.96 | ppl    52.58
| prune-epoch   7 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  3.99 | ppl    54.14
| prune-epoch   7 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  3.88 | ppl    48.61
| prune-epoch   7 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  3.91 | ppl    50.13
| prune-epoch   7 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  3.95 | ppl    52.15
| prune-epoch   7 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  3.91 | ppl    49.87
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.6  actual sp:  0.5984615384615385
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.6  actual sp:  0.5984615384615385
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.6  actual sp:  0.5984615384615385
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.6  actual sp:  0.5984615384615385
-----------------------------------------------------------------------------------------
| end of prune epoch   7 | time: 69.75s | valid loss  4.78 | valid ppl   118.70
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   8 |   200/ 2983 batches | lr 20.00 | ms/batch 22.95 | loss  4.02 | ppl    55.51
| prune-epoch   8 |   400/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  4.04 | ppl    56.62
| prune-epoch   8 |   600/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  3.86 | ppl    47.63
| prune-epoch   8 |   800/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  3.90 | ppl    49.54
| prune-epoch   8 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  3.96 | ppl    52.24
| prune-epoch   8 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  3.96 | ppl    52.39
| prune-epoch   8 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  3.98 | ppl    53.74
| prune-epoch   8 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  4.06 | ppl    58.05
| prune-epoch   8 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  3.97 | ppl    52.88
| prune-epoch   8 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  4.00 | ppl    54.54
| prune-epoch   8 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  3.88 | ppl    48.65
| prune-epoch   8 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  3.92 | ppl    50.48
| prune-epoch   8 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  3.95 | ppl    52.10
| prune-epoch   8 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  3.91 | ppl    49.97
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.7  actual sp:  0.696923076923077
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.7  actual sp:  0.696923076923077
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.7  actual sp:  0.696923076923077
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.7  actual sp:  0.696923076923077
-----------------------------------------------------------------------------------------
| end of prune epoch   8 | time: 69.74s | valid loss  4.75 | valid ppl   115.63
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   9 |   200/ 2983 batches | lr 20.00 | ms/batch 22.99 | loss  3.96 | ppl    52.64
| prune-epoch   9 |   400/ 2983 batches | lr 20.00 | ms/batch 22.53 | loss  4.00 | ppl    54.44
| prune-epoch   9 |   600/ 2983 batches | lr 20.00 | ms/batch 22.56 | loss  3.83 | ppl    45.93
| prune-epoch   9 |   800/ 2983 batches | lr 20.00 | ms/batch 22.54 | loss  3.87 | ppl    47.85
| prune-epoch   9 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.55 | loss  3.93 | ppl    50.75
| prune-epoch   9 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.53 | loss  3.93 | ppl    50.90
| prune-epoch   9 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.52 | loss  3.96 | ppl    52.27
| prune-epoch   9 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.54 | loss  4.03 | ppl    56.40
| prune-epoch   9 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.53 | loss  3.94 | ppl    51.20
| prune-epoch   9 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.56 | loss  3.97 | ppl    53.08
| prune-epoch   9 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.53 | loss  3.86 | ppl    47.45
| prune-epoch   9 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.53 | loss  3.89 | ppl    48.94
| prune-epoch   9 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.56 | loss  3.92 | ppl    50.51
| prune-epoch   9 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.54 | loss  3.88 | ppl    48.45
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.7  actual sp:  0.696923076923077
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.7  actual sp:  0.696923076923077
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.7  actual sp:  0.696923076923077
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.7  actual sp:  0.696923076923077
-----------------------------------------------------------------------------------------
| end of prune epoch   9 | time: 70.10s | valid loss  4.76 | valid ppl   116.59
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  10 |   200/ 2983 batches | lr 20.00 | ms/batch 22.93 | loss  4.07 | ppl    58.39
| prune-epoch  10 |   400/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  4.07 | ppl    58.28
| prune-epoch  10 |   600/ 2983 batches | lr 20.00 | ms/batch 22.44 | loss  3.90 | ppl    49.22
| prune-epoch  10 |   800/ 2983 batches | lr 20.00 | ms/batch 22.44 | loss  3.94 | ppl    51.25
| prune-epoch  10 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.45 | loss  3.99 | ppl    53.94
| prune-epoch  10 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.45 | loss  3.99 | ppl    53.88
| prune-epoch  10 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  4.01 | ppl    54.94
| prune-epoch  10 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.45 | loss  4.09 | ppl    59.47
| prune-epoch  10 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.44 | loss  3.99 | ppl    53.99
| prune-epoch  10 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.46 | loss  4.02 | ppl    55.71
| prune-epoch  10 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  3.90 | ppl    49.35
| prune-epoch  10 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.47 | loss  3.93 | ppl    51.07
| prune-epoch  10 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.58 | loss  3.97 | ppl    52.95
| prune-epoch  10 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.60 | loss  3.93 | ppl    50.82
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.7999999999999999  actual sp:  0.7984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.7999999999999999  actual sp:  0.7984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.7999999999999999  actual sp:  0.7984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.7999999999999999  actual sp:  0.7984615384615384
-----------------------------------------------------------------------------------------
| end of prune epoch  10 | time: 69.92s | valid loss  4.79 | valid ppl   120.70
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  11 |   200/ 2983 batches | lr 20.00 | ms/batch 22.84 | loss  3.98 | ppl    53.69
| prune-epoch  11 |   400/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  4.00 | ppl    54.86
| prune-epoch  11 |   600/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  3.84 | ppl    46.58
| prune-epoch  11 |   800/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  3.89 | ppl    48.72
| prune-epoch  11 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  3.94 | ppl    51.59
| prune-epoch  11 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  3.95 | ppl    51.83
| prune-epoch  11 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  3.97 | ppl    52.78
| prune-epoch  11 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  4.04 | ppl    56.74
| prune-epoch  11 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.39 | loss  3.94 | ppl    51.58
| prune-epoch  11 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  3.99 | ppl    53.82
| prune-epoch  11 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  3.87 | ppl    47.80
| prune-epoch  11 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  3.90 | ppl    49.52
| prune-epoch  11 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  3.94 | ppl    51.41
| prune-epoch  11 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  3.90 | ppl    49.18
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.7999999999999999  actual sp:  0.7984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.7999999999999999  actual sp:  0.7984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.7999999999999999  actual sp:  0.7984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.7999999999999999  actual sp:  0.7984615384615384
-----------------------------------------------------------------------------------------
| end of prune epoch  11 | time: 69.69s | valid loss  4.77 | valid ppl   118.22
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  12 |   200/ 2983 batches | lr 20.00 | ms/batch 23.02 | loss  3.96 | ppl    52.25
| prune-epoch  12 |   400/ 2983 batches | lr 20.00 | ms/batch 22.57 | loss  3.98 | ppl    53.36
| prune-epoch  12 |   600/ 2983 batches | lr 20.00 | ms/batch 22.59 | loss  3.82 | ppl    45.40
| prune-epoch  12 |   800/ 2983 batches | lr 20.00 | ms/batch 22.57 | loss  3.86 | ppl    47.38
| prune-epoch  12 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.57 | loss  3.91 | ppl    50.08
| prune-epoch  12 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.58 | loss  3.91 | ppl    49.91
| prune-epoch  12 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.59 | loss  3.94 | ppl    51.55
| prune-epoch  12 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.58 | loss  4.02 | ppl    55.47
| prune-epoch  12 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.58 | loss  3.93 | ppl    50.81
| prune-epoch  12 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.57 | loss  3.95 | ppl    52.15
| prune-epoch  12 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.59 | loss  3.84 | ppl    46.47
| prune-epoch  12 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.58 | loss  3.88 | ppl    48.32
| prune-epoch  12 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.57 | loss  3.91 | ppl    49.93
| prune-epoch  12 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.56 | loss  3.87 | ppl    47.89
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.7999999999999999  actual sp:  0.7984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.7999999999999999  actual sp:  0.7984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.7999999999999999  actual sp:  0.7984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.7999999999999999  actual sp:  0.7984615384615384
-----------------------------------------------------------------------------------------
| end of prune epoch  12 | time: 70.21s | valid loss  4.79 | valid ppl   120.00
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  13 |   200/ 2983 batches | lr 20.00 | ms/batch 22.84 | loss  4.01 | ppl    55.22
| prune-epoch  13 |   400/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  4.02 | ppl    55.73
| prune-epoch  13 |   600/ 2983 batches | lr 20.00 | ms/batch 22.39 | loss  3.87 | ppl    47.79
| prune-epoch  13 |   800/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  3.90 | ppl    49.63
| prune-epoch  13 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  3.95 | ppl    51.98
| prune-epoch  13 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.39 | loss  3.95 | ppl    52.07
| prune-epoch  13 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.39 | loss  3.98 | ppl    53.27
| prune-epoch  13 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.39 | loss  4.05 | ppl    57.31
| prune-epoch  13 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  3.96 | ppl    52.37
| prune-epoch  13 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.37 | loss  3.99 | ppl    53.92
| prune-epoch  13 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  3.87 | ppl    47.80
| prune-epoch  13 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.39 | loss  3.91 | ppl    49.95
| prune-epoch  13 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.39 | loss  3.93 | ppl    51.05
| prune-epoch  13 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.39 | loss  3.90 | ppl    49.23
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.85  actual sp:  0.8476923076923077
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.85  actual sp:  0.8476923076923077
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.85  actual sp:  0.8476923076923077
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.85  actual sp:  0.8476923076923077
-----------------------------------------------------------------------------------------
| end of prune epoch  13 | time: 69.65s | valid loss  4.80 | valid ppl   121.46
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  14 |   200/ 2983 batches | lr 20.00 | ms/batch 22.84 | loss  3.96 | ppl    52.48
| prune-epoch  14 |   400/ 2983 batches | lr 20.00 | ms/batch 22.44 | loss  3.98 | ppl    53.43
| prune-epoch  14 |   600/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  3.82 | ppl    45.54
| prune-epoch  14 |   800/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  3.86 | ppl    47.40
| prune-epoch  14 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.44 | loss  3.91 | ppl    49.89
| prune-epoch  14 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  3.92 | ppl    50.36
| prune-epoch  14 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  3.94 | ppl    51.37
| prune-epoch  14 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  4.01 | ppl    55.22
| prune-epoch  14 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  3.92 | ppl    50.46
| prune-epoch  14 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  3.96 | ppl    52.51
| prune-epoch  14 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  3.84 | ppl    46.59
| prune-epoch  14 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  3.87 | ppl    48.18
| prune-epoch  14 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  3.90 | ppl    49.52
| prune-epoch  14 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  3.87 | ppl    48.14
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.85  actual sp:  0.8476923076923077
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.85  actual sp:  0.8476923076923077
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.85  actual sp:  0.8476923076923077
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.85  actual sp:  0.8476923076923077
-----------------------------------------------------------------------------------------
| end of prune epoch  14 | time: 69.76s | valid loss  4.79 | valid ppl   120.50
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  15 |   200/ 2983 batches | lr 20.00 | ms/batch 22.90 | loss  3.94 | ppl    51.38
| prune-epoch  15 |   400/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  3.95 | ppl    52.11
| prune-epoch  15 |   600/ 2983 batches | lr 20.00 | ms/batch 22.49 | loss  3.79 | ppl    44.45
| prune-epoch  15 |   800/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  3.84 | ppl    46.50
| prune-epoch  15 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  3.88 | ppl    48.38
| prune-epoch  15 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.47 | loss  3.90 | ppl    49.16
| prune-epoch  15 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.47 | loss  3.92 | ppl    50.18
| prune-epoch  15 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.46 | loss  3.99 | ppl    53.91
| prune-epoch  15 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.49 | loss  3.90 | ppl    49.27
| prune-epoch  15 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.47 | loss  3.94 | ppl    51.39
| prune-epoch  15 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.47 | loss  3.82 | ppl    45.63
| prune-epoch  15 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  3.85 | ppl    47.11
| prune-epoch  15 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.47 | loss  3.88 | ppl    48.60
| prune-epoch  15 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  3.85 | ppl    47.14
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.85  actual sp:  0.8476923076923077
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.85  actual sp:  0.8476923076923077
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.85  actual sp:  0.8476923076923077
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.85  actual sp:  0.8476923076923077
-----------------------------------------------------------------------------------------
| end of prune epoch  15 | time: 69.90s | valid loss  4.80 | valid ppl   121.26
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  16 |   200/ 2983 batches | lr 20.00 | ms/batch 22.77 | loss  4.06 | ppl    58.18
| prune-epoch  16 |   400/ 2983 batches | lr 20.00 | ms/batch 22.37 | loss  4.07 | ppl    58.48
| prune-epoch  16 |   600/ 2983 batches | lr 20.00 | ms/batch 22.36 | loss  3.90 | ppl    49.50
| prune-epoch  16 |   800/ 2983 batches | lr 20.00 | ms/batch 22.35 | loss  3.95 | ppl    51.75
| prune-epoch  16 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.35 | loss  3.99 | ppl    53.92
| prune-epoch  16 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.35 | loss  3.99 | ppl    54.12
| prune-epoch  16 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.34 | loss  4.01 | ppl    55.20
| prune-epoch  16 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.34 | loss  4.08 | ppl    59.29
| prune-epoch  16 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.36 | loss  4.00 | ppl    54.37
| prune-epoch  16 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.36 | loss  4.02 | ppl    55.80
| prune-epoch  16 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.34 | loss  3.91 | ppl    50.10
| prune-epoch  16 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.35 | loss  3.94 | ppl    51.21
| prune-epoch  16 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  3.97 | ppl    52.77
| prune-epoch  16 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  3.93 | ppl    50.96
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of prune epoch  16 | time: 69.56s | valid loss  4.79 | valid ppl   120.86
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 22.79 | loss  4.00 | ppl    54.35
| prune-epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 22.37 | loss  4.01 | ppl    55.12
| prune-epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  3.85 | ppl    46.82
| prune-epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  3.89 | ppl    48.97
| prune-epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  3.94 | ppl    51.24
| prune-epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  3.94 | ppl    51.50
| prune-epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.37 | loss  3.97 | ppl    52.96
| prune-epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  4.04 | ppl    56.62
| prune-epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  3.95 | ppl    51.87
| prune-epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  3.98 | ppl    53.73
| prune-epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  3.87 | ppl    47.92
| prune-epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  3.90 | ppl    49.50
| prune-epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.39 | loss  3.93 | ppl    51.08
| prune-epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.37 | loss  3.90 | ppl    49.27
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch   1 | time: 69.61s | valid loss  4.79 | valid ppl   120.49
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch 22.88 | loss  3.96 | ppl    52.51
| prune-epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch 22.46 | loss  3.98 | ppl    53.43
| prune-epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch 22.47 | loss  3.82 | ppl    45.43
| prune-epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  3.86 | ppl    47.59
| prune-epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.46 | loss  3.91 | ppl    50.02
| prune-epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  3.92 | ppl    50.24
| prune-epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.46 | loss  3.94 | ppl    51.20
| prune-epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.48 | loss  4.01 | ppl    55.23
| prune-epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.46 | loss  3.93 | ppl    50.86
| prune-epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.47 | loss  3.96 | ppl    52.32
| prune-epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.52 | loss  3.84 | ppl    46.42
| prune-epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.53 | loss  3.88 | ppl    48.22
| prune-epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.54 | loss  3.91 | ppl    49.93
| prune-epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.53 | loss  3.87 | ppl    48.09
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch   2 | time: 69.94s | valid loss  4.79 | valid ppl   120.41
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 22.83 | loss  3.93 | ppl    50.91
| prune-epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  3.95 | ppl    52.17
| prune-epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  3.79 | ppl    44.43
| prune-epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  3.84 | ppl    46.64
| prune-epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  3.89 | ppl    48.98
| prune-epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.44 | loss  3.89 | ppl    49.14
| prune-epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.57 | loss  3.92 | ppl    50.35
| prune-epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.59 | loss  3.99 | ppl    54.04
| prune-epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.58 | loss  3.90 | ppl    49.53
| prune-epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.58 | loss  3.94 | ppl    51.40
| prune-epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.58 | loss  3.82 | ppl    45.78
| prune-epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.58 | loss  3.85 | ppl    47.14
| prune-epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.59 | loss  3.89 | ppl    48.78
| prune-epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.57 | loss  3.85 | ppl    47.15
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch   3 | time: 70.02s | valid loss  4.79 | valid ppl   120.12
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   4 |   200/ 2983 batches | lr 20.00 | ms/batch 22.91 | loss  3.91 | ppl    49.85
| prune-epoch   4 |   400/ 2983 batches | lr 20.00 | ms/batch 22.52 | loss  3.93 | ppl    51.14
| prune-epoch   4 |   600/ 2983 batches | lr 20.00 | ms/batch 22.52 | loss  3.78 | ppl    43.70
| prune-epoch   4 |   800/ 2983 batches | lr 20.00 | ms/batch 22.52 | loss  3.82 | ppl    45.53
| prune-epoch   4 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.51 | loss  3.87 | ppl    47.94
| prune-epoch   4 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.51 | loss  3.88 | ppl    48.29
| prune-epoch   4 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.51 | loss  3.90 | ppl    49.30
| prune-epoch   4 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.50 | loss  3.97 | ppl    53.02
| prune-epoch   4 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.51 | loss  3.89 | ppl    48.93
| prune-epoch   4 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.50 | loss  3.92 | ppl    50.30
| prune-epoch   4 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.50 | loss  3.80 | ppl    44.75
| prune-epoch   4 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.51 | loss  3.84 | ppl    46.52
| prune-epoch   4 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.51 | loss  3.87 | ppl    47.76
| prune-epoch   4 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.52 | loss  3.84 | ppl    46.34
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch   4 | time: 70.00s | valid loss  4.79 | valid ppl   119.87
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   5 |   200/ 2983 batches | lr 20.00 | ms/batch 22.82 | loss  3.90 | ppl    49.24
| prune-epoch   5 |   400/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  3.91 | ppl    49.97
| prune-epoch   5 |   600/ 2983 batches | lr 20.00 | ms/batch 22.47 | loss  3.76 | ppl    42.91
| prune-epoch   5 |   800/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  3.80 | ppl    44.70
| prune-epoch   5 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  3.85 | ppl    47.22
| prune-epoch   5 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  3.86 | ppl    47.57
| prune-epoch   5 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  3.88 | ppl    48.37
| prune-epoch   5 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  3.95 | ppl    51.98
| prune-epoch   5 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  3.87 | ppl    48.16
| prune-epoch   5 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  3.90 | ppl    49.60
| prune-epoch   5 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.44 | loss  3.79 | ppl    44.05
| prune-epoch   5 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.45 | loss  3.82 | ppl    45.62
| prune-epoch   5 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.43 | loss  3.85 | ppl    47.12
| prune-epoch   5 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.44 | loss  3.82 | ppl    45.77
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch   5 | time: 69.76s | valid loss  4.78 | valid ppl   119.03
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   6 |   200/ 2983 batches | lr 20.00 | ms/batch 22.79 | loss  3.88 | ppl    48.34
| prune-epoch   6 |   400/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  3.90 | ppl    49.53
| prune-epoch   6 |   600/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  3.74 | ppl    42.11
| prune-epoch   6 |   800/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  3.78 | ppl    44.00
| prune-epoch   6 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  3.84 | ppl    46.63
| prune-epoch   6 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.39 | loss  3.84 | ppl    46.58
| prune-epoch   6 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  3.87 | ppl    47.75
| prune-epoch   6 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.39 | loss  3.94 | ppl    51.32
| prune-epoch   6 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.39 | loss  3.85 | ppl    47.11
| prune-epoch   6 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  3.89 | ppl    48.78
| prune-epoch   6 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  3.77 | ppl    43.45
| prune-epoch   6 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.41 | loss  3.81 | ppl    45.18
| prune-epoch   6 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  3.83 | ppl    46.20
| prune-epoch   6 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.42 | loss  3.81 | ppl    45.08
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch   6 | time: 69.67s | valid loss  4.79 | valid ppl   119.96
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   7 |   200/ 2983 batches | lr 20.00 | ms/batch 22.94 | loss  3.86 | ppl    47.49
| prune-epoch   7 |   400/ 2983 batches | lr 20.00 | ms/batch 22.57 | loss  3.88 | ppl    48.43
| prune-epoch   7 |   600/ 2983 batches | lr 20.00 | ms/batch 22.56 | loss  3.73 | ppl    41.55
| prune-epoch   7 |   800/ 2983 batches | lr 20.00 | ms/batch 22.57 | loss  3.77 | ppl    43.40
| prune-epoch   7 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.56 | loss  3.82 | ppl    45.63
| prune-epoch   7 |  1200/ 2983 batches | lr 20.00 | ms/batch 22.56 | loss  3.83 | ppl    46.26
| prune-epoch   7 |  1400/ 2983 batches | lr 20.00 | ms/batch 22.56 | loss  3.85 | ppl    46.91
| prune-epoch   7 |  1600/ 2983 batches | lr 20.00 | ms/batch 22.57 | loss  3.92 | ppl    50.51
| prune-epoch   7 |  1800/ 2983 batches | lr 20.00 | ms/batch 22.59 | loss  3.84 | ppl    46.46
| prune-epoch   7 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.57 | loss  3.87 | ppl    48.00
| prune-epoch   7 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.57 | loss  3.76 | ppl    42.80
| prune-epoch   7 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.57 | loss  3.79 | ppl    44.26
| prune-epoch   7 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.57 | loss  3.82 | ppl    45.50
| prune-epoch   7 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.59 | loss  3.79 | ppl    44.11
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch   7 | time: 70.17s | valid loss  4.79 | valid ppl   120.31
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   8 |   200/ 2983 batches | lr 10.00 | ms/batch 22.82 | loss  3.84 | ppl    46.67
| prune-epoch   8 |   400/ 2983 batches | lr 10.00 | ms/batch 22.44 | loss  3.85 | ppl    46.95
| prune-epoch   8 |   600/ 2983 batches | lr 10.00 | ms/batch 22.43 | loss  3.68 | ppl    39.65
| prune-epoch   8 |   800/ 2983 batches | lr 10.00 | ms/batch 22.43 | loss  3.73 | ppl    41.56
| prune-epoch   8 |  1000/ 2983 batches | lr 10.00 | ms/batch 22.43 | loss  3.76 | ppl    43.02
| prune-epoch   8 |  1200/ 2983 batches | lr 10.00 | ms/batch 22.43 | loss  3.77 | ppl    43.50
| prune-epoch   8 |  1400/ 2983 batches | lr 10.00 | ms/batch 22.44 | loss  3.78 | ppl    43.95
| prune-epoch   8 |  1600/ 2983 batches | lr 10.00 | ms/batch 22.44 | loss  3.85 | ppl    46.84
| prune-epoch   8 |  1800/ 2983 batches | lr 10.00 | ms/batch 22.45 | loss  3.76 | ppl    43.10
| prune-epoch   8 |  2000/ 2983 batches | lr 10.00 | ms/batch 22.44 | loss  3.80 | ppl    44.61
| prune-epoch   8 |  2200/ 2983 batches | lr 10.00 | ms/batch 22.60 | loss  3.66 | ppl    38.95
| prune-epoch   8 |  2400/ 2983 batches | lr 10.00 | ms/batch 22.60 | loss  3.70 | ppl    40.42
| prune-epoch   8 |  2600/ 2983 batches | lr 10.00 | ms/batch 22.61 | loss  3.72 | ppl    41.30
| prune-epoch   8 |  2800/ 2983 batches | lr 10.00 | ms/batch 22.60 | loss  3.69 | ppl    39.97
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch   8 | time: 69.93s | valid loss  4.77 | valid ppl   117.66
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   9 |   200/ 2983 batches | lr 10.00 | ms/batch 22.92 | loss  3.79 | ppl    44.44
| prune-epoch   9 |   400/ 2983 batches | lr 10.00 | ms/batch 22.53 | loss  3.80 | ppl    44.69
| prune-epoch   9 |   600/ 2983 batches | lr 10.00 | ms/batch 22.53 | loss  3.65 | ppl    38.37
| prune-epoch   9 |   800/ 2983 batches | lr 10.00 | ms/batch 22.53 | loss  3.69 | ppl    40.16
| prune-epoch   9 |  1000/ 2983 batches | lr 10.00 | ms/batch 22.53 | loss  3.74 | ppl    42.17
| prune-epoch   9 |  1200/ 2983 batches | lr 10.00 | ms/batch 22.53 | loss  3.75 | ppl    42.41
| prune-epoch   9 |  1400/ 2983 batches | lr 10.00 | ms/batch 22.52 | loss  3.76 | ppl    43.13
| prune-epoch   9 |  1600/ 2983 batches | lr 10.00 | ms/batch 22.53 | loss  3.83 | ppl    45.94
| prune-epoch   9 |  1800/ 2983 batches | lr 10.00 | ms/batch 22.52 | loss  3.74 | ppl    42.15
| prune-epoch   9 |  2000/ 2983 batches | lr 10.00 | ms/batch 22.53 | loss  3.78 | ppl    43.64
| prune-epoch   9 |  2200/ 2983 batches | lr 10.00 | ms/batch 22.55 | loss  3.65 | ppl    38.37
| prune-epoch   9 |  2400/ 2983 batches | lr 10.00 | ms/batch 22.54 | loss  3.67 | ppl    39.42
| prune-epoch   9 |  2600/ 2983 batches | lr 10.00 | ms/batch 22.55 | loss  3.71 | ppl    40.82
| prune-epoch   9 |  2800/ 2983 batches | lr 10.00 | ms/batch 22.53 | loss  3.68 | ppl    39.47
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch   9 | time: 70.06s | valid loss  4.77 | valid ppl   117.56
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  10 |   200/ 2983 batches | lr 10.00 | ms/batch 22.85 | loss  3.77 | ppl    43.53
| prune-epoch  10 |   400/ 2983 batches | lr 10.00 | ms/batch 22.43 | loss  3.79 | ppl    44.12
| prune-epoch  10 |   600/ 2983 batches | lr 10.00 | ms/batch 22.44 | loss  3.63 | ppl    37.85
| prune-epoch  10 |   800/ 2983 batches | lr 10.00 | ms/batch 22.42 | loss  3.68 | ppl    39.50
| prune-epoch  10 |  1000/ 2983 batches | lr 10.00 | ms/batch 22.43 | loss  3.72 | ppl    41.31
| prune-epoch  10 |  1200/ 2983 batches | lr 10.00 | ms/batch 22.45 | loss  3.73 | ppl    41.76
| prune-epoch  10 |  1400/ 2983 batches | lr 10.00 | ms/batch 22.44 | loss  3.75 | ppl    42.36
| prune-epoch  10 |  1600/ 2983 batches | lr 10.00 | ms/batch 22.44 | loss  3.81 | ppl    45.29
| prune-epoch  10 |  1800/ 2983 batches | lr 10.00 | ms/batch 22.43 | loss  3.73 | ppl    41.77
| prune-epoch  10 |  2000/ 2983 batches | lr 10.00 | ms/batch 22.42 | loss  3.77 | ppl    43.24
| prune-epoch  10 |  2200/ 2983 batches | lr 10.00 | ms/batch 22.43 | loss  3.64 | ppl    38.01
| prune-epoch  10 |  2400/ 2983 batches | lr 10.00 | ms/batch 22.43 | loss  3.67 | ppl    39.42
| prune-epoch  10 |  2600/ 2983 batches | lr 10.00 | ms/batch 22.43 | loss  3.70 | ppl    40.63
| prune-epoch  10 |  2800/ 2983 batches | lr 10.00 | ms/batch 22.44 | loss  3.67 | ppl    39.17
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  10 | time: 69.77s | valid loss  4.77 | valid ppl   118.07
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  11 |   200/ 2983 batches | lr 10.00 | ms/batch 22.80 | loss  3.76 | ppl    42.98
| prune-epoch  11 |   400/ 2983 batches | lr 10.00 | ms/batch 22.42 | loss  3.77 | ppl    43.50
| prune-epoch  11 |   600/ 2983 batches | lr 10.00 | ms/batch 22.42 | loss  3.61 | ppl    37.07
| prune-epoch  11 |   800/ 2983 batches | lr 10.00 | ms/batch 22.42 | loss  3.66 | ppl    38.92
| prune-epoch  11 |  1000/ 2983 batches | lr 10.00 | ms/batch 22.42 | loss  3.71 | ppl    41.00
| prune-epoch  11 |  1200/ 2983 batches | lr 10.00 | ms/batch 22.41 | loss  3.72 | ppl    41.14
| prune-epoch  11 |  1400/ 2983 batches | lr 10.00 | ms/batch 22.43 | loss  3.73 | ppl    41.76
| prune-epoch  11 |  1600/ 2983 batches | lr 10.00 | ms/batch 22.41 | loss  3.80 | ppl    44.50
| prune-epoch  11 |  1800/ 2983 batches | lr 10.00 | ms/batch 22.42 | loss  3.71 | ppl    41.05
| prune-epoch  11 |  2000/ 2983 batches | lr 10.00 | ms/batch 22.42 | loss  3.75 | ppl    42.65
| prune-epoch  11 |  2200/ 2983 batches | lr 10.00 | ms/batch 22.43 | loss  3.63 | ppl    37.58
| prune-epoch  11 |  2400/ 2983 batches | lr 10.00 | ms/batch 22.42 | loss  3.66 | ppl    39.04
| prune-epoch  11 |  2600/ 2983 batches | lr 10.00 | ms/batch 22.42 | loss  3.69 | ppl    39.95
| prune-epoch  11 |  2800/ 2983 batches | lr 10.00 | ms/batch 22.42 | loss  3.66 | ppl    38.91
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  11 | time: 69.72s | valid loss  4.79 | valid ppl   120.24
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  12 |   200/ 2983 batches | lr 5.00 | ms/batch 22.96 | loss  3.76 | ppl    43.15
| prune-epoch  12 |   400/ 2983 batches | lr 5.00 | ms/batch 22.58 | loss  3.77 | ppl    43.44
| prune-epoch  12 |   600/ 2983 batches | lr 5.00 | ms/batch 22.58 | loss  3.61 | ppl    36.90
| prune-epoch  12 |   800/ 2983 batches | lr 5.00 | ms/batch 22.58 | loss  3.65 | ppl    38.63
| prune-epoch  12 |  1000/ 2983 batches | lr 5.00 | ms/batch 22.59 | loss  3.70 | ppl    40.32
| prune-epoch  12 |  1200/ 2983 batches | lr 5.00 | ms/batch 22.59 | loss  3.70 | ppl    40.39
| prune-epoch  12 |  1400/ 2983 batches | lr 5.00 | ms/batch 22.59 | loss  3.72 | ppl    41.38
| prune-epoch  12 |  1600/ 2983 batches | lr 5.00 | ms/batch 22.58 | loss  3.77 | ppl    43.19
| prune-epoch  12 |  1800/ 2983 batches | lr 5.00 | ms/batch 22.59 | loss  3.69 | ppl    40.18
| prune-epoch  12 |  2000/ 2983 batches | lr 5.00 | ms/batch 22.58 | loss  3.72 | ppl    41.36
| prune-epoch  12 |  2200/ 2983 batches | lr 5.00 | ms/batch 22.59 | loss  3.59 | ppl    36.14
| prune-epoch  12 |  2400/ 2983 batches | lr 5.00 | ms/batch 22.74 | loss  3.62 | ppl    37.52
| prune-epoch  12 |  2600/ 2983 batches | lr 5.00 | ms/batch 22.71 | loss  3.65 | ppl    38.59
| prune-epoch  12 |  2800/ 2983 batches | lr 5.00 | ms/batch 22.70 | loss  3.61 | ppl    37.13
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  12 | time: 70.37s | valid loss  4.76 | valid ppl   116.47
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  13 |   200/ 2983 batches | lr 5.00 | ms/batch 23.13 | loss  3.75 | ppl    42.42
| prune-epoch  13 |   400/ 2983 batches | lr 5.00 | ms/batch 22.68 | loss  3.74 | ppl    42.17
| prune-epoch  13 |   600/ 2983 batches | lr 5.00 | ms/batch 22.68 | loss  3.59 | ppl    36.07
| prune-epoch  13 |   800/ 2983 batches | lr 5.00 | ms/batch 22.68 | loss  3.63 | ppl    37.75
| prune-epoch  13 |  1000/ 2983 batches | lr 5.00 | ms/batch 22.69 | loss  3.69 | ppl    39.98
| prune-epoch  13 |  1200/ 2983 batches | lr 5.00 | ms/batch 22.69 | loss  3.69 | ppl    40.16
| prune-epoch  13 |  1400/ 2983 batches | lr 5.00 | ms/batch 22.69 | loss  3.70 | ppl    40.52
| prune-epoch  13 |  1600/ 2983 batches | lr 5.00 | ms/batch 22.68 | loss  3.76 | ppl    42.91
| prune-epoch  13 |  1800/ 2983 batches | lr 5.00 | ms/batch 22.70 | loss  3.69 | ppl    39.99
| prune-epoch  13 |  2000/ 2983 batches | lr 5.00 | ms/batch 22.69 | loss  3.72 | ppl    41.14
| prune-epoch  13 |  2200/ 2983 batches | lr 5.00 | ms/batch 22.69 | loss  3.59 | ppl    36.24
| prune-epoch  13 |  2400/ 2983 batches | lr 5.00 | ms/batch 22.68 | loss  3.62 | ppl    37.40
| prune-epoch  13 |  2600/ 2983 batches | lr 5.00 | ms/batch 22.69 | loss  3.65 | ppl    38.31
| prune-epoch  13 |  2800/ 2983 batches | lr 5.00 | ms/batch 22.69 | loss  3.60 | ppl    36.72
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  13 | time: 70.53s | valid loss  4.76 | valid ppl   116.76
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  14 |   200/ 2983 batches | lr 5.00 | ms/batch 23.16 | loss  3.72 | ppl    41.44
| prune-epoch  14 |   400/ 2983 batches | lr 5.00 | ms/batch 22.77 | loss  3.74 | ppl    42.22
| prune-epoch  14 |   600/ 2983 batches | lr 5.00 | ms/batch 22.77 | loss  3.58 | ppl    35.73
| prune-epoch  14 |   800/ 2983 batches | lr 5.00 | ms/batch 22.77 | loss  3.62 | ppl    37.37
| prune-epoch  14 |  1000/ 2983 batches | lr 5.00 | ms/batch 22.78 | loss  3.68 | ppl    39.60
| prune-epoch  14 |  1200/ 2983 batches | lr 5.00 | ms/batch 22.78 | loss  3.68 | ppl    39.59
| prune-epoch  14 |  1400/ 2983 batches | lr 5.00 | ms/batch 22.78 | loss  3.69 | ppl    40.17
| prune-epoch  14 |  1600/ 2983 batches | lr 5.00 | ms/batch 22.76 | loss  3.75 | ppl    42.36
| prune-epoch  14 |  1800/ 2983 batches | lr 5.00 | ms/batch 22.77 | loss  3.67 | ppl    39.43
| prune-epoch  14 |  2000/ 2983 batches | lr 5.00 | ms/batch 22.76 | loss  3.71 | ppl    40.76
| prune-epoch  14 |  2200/ 2983 batches | lr 5.00 | ms/batch 22.77 | loss  3.58 | ppl    35.98
| prune-epoch  14 |  2400/ 2983 batches | lr 5.00 | ms/batch 22.77 | loss  3.61 | ppl    37.12
| prune-epoch  14 |  2600/ 2983 batches | lr 5.00 | ms/batch 22.75 | loss  3.64 | ppl    38.17
| prune-epoch  14 |  2800/ 2983 batches | lr 5.00 | ms/batch 22.56 | loss  3.60 | ppl    36.77
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  14 | time: 70.69s | valid loss  4.76 | valid ppl   116.38
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  15 |   200/ 2983 batches | lr 5.00 | ms/batch 22.83 | loss  3.72 | ppl    41.13
| prune-epoch  15 |   400/ 2983 batches | lr 5.00 | ms/batch 22.47 | loss  3.72 | ppl    41.42
| prune-epoch  15 |   600/ 2983 batches | lr 5.00 | ms/batch 22.49 | loss  3.56 | ppl    35.19
| prune-epoch  15 |   800/ 2983 batches | lr 5.00 | ms/batch 22.45 | loss  3.62 | ppl    37.18
| prune-epoch  15 |  1000/ 2983 batches | lr 5.00 | ms/batch 22.45 | loss  3.67 | ppl    39.07
| prune-epoch  15 |  1200/ 2983 batches | lr 5.00 | ms/batch 22.45 | loss  3.67 | ppl    39.34
| prune-epoch  15 |  1400/ 2983 batches | lr 5.00 | ms/batch 22.43 | loss  3.69 | ppl    39.90
| prune-epoch  15 |  1600/ 2983 batches | lr 5.00 | ms/batch 22.45 | loss  3.74 | ppl    42.29
| prune-epoch  15 |  1800/ 2983 batches | lr 5.00 | ms/batch 22.45 | loss  3.67 | ppl    39.09
| prune-epoch  15 |  2000/ 2983 batches | lr 5.00 | ms/batch 22.46 | loss  3.70 | ppl    40.47
| prune-epoch  15 |  2200/ 2983 batches | lr 5.00 | ms/batch 22.48 | loss  3.58 | ppl    35.74
| prune-epoch  15 |  2400/ 2983 batches | lr 5.00 | ms/batch 22.47 | loss  3.60 | ppl    36.72
| prune-epoch  15 |  2600/ 2983 batches | lr 5.00 | ms/batch 22.46 | loss  3.63 | ppl    37.79
| prune-epoch  15 |  2800/ 2983 batches | lr 5.00 | ms/batch 22.45 | loss  3.60 | ppl    36.55
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  15 | time: 69.84s | valid loss  4.76 | valid ppl   116.44
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  16 |   200/ 2983 batches | lr 2.50 | ms/batch 22.83 | loss  3.73 | ppl    41.80
| prune-epoch  16 |   400/ 2983 batches | lr 2.50 | ms/batch 22.42 | loss  3.74 | ppl    41.96
| prune-epoch  16 |   600/ 2983 batches | lr 2.50 | ms/batch 22.43 | loss  3.58 | ppl    35.84
| prune-epoch  16 |   800/ 2983 batches | lr 2.50 | ms/batch 22.42 | loss  3.62 | ppl    37.33
| prune-epoch  16 |  1000/ 2983 batches | lr 2.50 | ms/batch 22.41 | loss  3.67 | ppl    39.32
| prune-epoch  16 |  1200/ 2983 batches | lr 2.50 | ms/batch 22.41 | loss  3.67 | ppl    39.22
| prune-epoch  16 |  1400/ 2983 batches | lr 2.50 | ms/batch 22.40 | loss  3.70 | ppl    40.51
| prune-epoch  16 |  1600/ 2983 batches | lr 2.50 | ms/batch 22.41 | loss  3.74 | ppl    42.02
| prune-epoch  16 |  1800/ 2983 batches | lr 2.50 | ms/batch 22.40 | loss  3.67 | ppl    39.17
| prune-epoch  16 |  2000/ 2983 batches | lr 2.50 | ms/batch 22.41 | loss  3.70 | ppl    40.50
| prune-epoch  16 |  2200/ 2983 batches | lr 2.50 | ms/batch 22.40 | loss  3.57 | ppl    35.57
| prune-epoch  16 |  2400/ 2983 batches | lr 2.50 | ms/batch 22.41 | loss  3.60 | ppl    36.64
| prune-epoch  16 |  2600/ 2983 batches | lr 2.50 | ms/batch 22.42 | loss  3.64 | ppl    37.94
| prune-epoch  16 |  2800/ 2983 batches | lr 2.50 | ms/batch 22.42 | loss  3.59 | ppl    36.21
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  16 | time: 69.72s | valid loss  4.75 | valid ppl   115.06
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  17 |   200/ 2983 batches | lr 2.50 | ms/batch 22.98 | loss  3.73 | ppl    41.60
| prune-epoch  17 |   400/ 2983 batches | lr 2.50 | ms/batch 22.59 | loss  3.73 | ppl    41.53
| prune-epoch  17 |   600/ 2983 batches | lr 2.50 | ms/batch 22.59 | loss  3.58 | ppl    35.73
| prune-epoch  17 |   800/ 2983 batches | lr 2.50 | ms/batch 22.58 | loss  3.61 | ppl    37.12
| prune-epoch  17 |  1000/ 2983 batches | lr 2.50 | ms/batch 22.58 | loss  3.67 | ppl    39.11
| prune-epoch  17 |  1200/ 2983 batches | lr 2.50 | ms/batch 22.58 | loss  3.66 | ppl    38.77
| prune-epoch  17 |  1400/ 2983 batches | lr 2.50 | ms/batch 22.58 | loss  3.70 | ppl    40.28
| prune-epoch  17 |  1600/ 2983 batches | lr 2.50 | ms/batch 22.58 | loss  3.73 | ppl    41.66
| prune-epoch  17 |  1800/ 2983 batches | lr 2.50 | ms/batch 22.59 | loss  3.66 | ppl    38.84
| prune-epoch  17 |  2000/ 2983 batches | lr 2.50 | ms/batch 22.58 | loss  3.70 | ppl    40.32
| prune-epoch  17 |  2200/ 2983 batches | lr 2.50 | ms/batch 22.59 | loss  3.56 | ppl    35.09
| prune-epoch  17 |  2400/ 2983 batches | lr 2.50 | ms/batch 22.58 | loss  3.61 | ppl    36.91
| prune-epoch  17 |  2600/ 2983 batches | lr 2.50 | ms/batch 22.58 | loss  3.63 | ppl    37.54
| prune-epoch  17 |  2800/ 2983 batches | lr 2.50 | ms/batch 22.58 | loss  3.59 | ppl    36.28
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  17 | time: 70.22s | valid loss  4.75 | valid ppl   115.08
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  18 |   200/ 2983 batches | lr 2.50 | ms/batch 22.78 | loss  3.72 | ppl    41.24
| prune-epoch  18 |   400/ 2983 batches | lr 2.50 | ms/batch 22.40 | loss  3.72 | ppl    41.15
| prune-epoch  18 |   600/ 2983 batches | lr 2.50 | ms/batch 22.42 | loss  3.56 | ppl    35.33
| prune-epoch  18 |   800/ 2983 batches | lr 2.50 | ms/batch 22.42 | loss  3.60 | ppl    36.73
| prune-epoch  18 |  1000/ 2983 batches | lr 2.50 | ms/batch 22.44 | loss  3.66 | ppl    38.76
| prune-epoch  18 |  1200/ 2983 batches | lr 2.50 | ms/batch 22.41 | loss  3.65 | ppl    38.63
| prune-epoch  18 |  1400/ 2983 batches | lr 2.50 | ms/batch 22.40 | loss  3.68 | ppl    39.79
| prune-epoch  18 |  1600/ 2983 batches | lr 2.50 | ms/batch 22.40 | loss  3.73 | ppl    41.74
| prune-epoch  18 |  1800/ 2983 batches | lr 2.50 | ms/batch 22.41 | loss  3.65 | ppl    38.55
| prune-epoch  18 |  2000/ 2983 batches | lr 2.50 | ms/batch 22.41 | loss  3.69 | ppl    40.14
| prune-epoch  18 |  2200/ 2983 batches | lr 2.50 | ms/batch 22.41 | loss  3.56 | ppl    35.21
| prune-epoch  18 |  2400/ 2983 batches | lr 2.50 | ms/batch 22.40 | loss  3.60 | ppl    36.51
| prune-epoch  18 |  2600/ 2983 batches | lr 2.50 | ms/batch 22.39 | loss  3.62 | ppl    37.27
| prune-epoch  18 |  2800/ 2983 batches | lr 2.50 | ms/batch 22.40 | loss  3.58 | ppl    35.99
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  18 | time: 69.69s | valid loss  4.75 | valid ppl   115.58
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  19 |   200/ 2983 batches | lr 1.25 | ms/batch 22.81 | loss  3.74 | ppl    42.21
| prune-epoch  19 |   400/ 2983 batches | lr 1.25 | ms/batch 22.42 | loss  3.75 | ppl    42.50
| prune-epoch  19 |   600/ 2983 batches | lr 1.25 | ms/batch 22.44 | loss  3.59 | ppl    36.36
| prune-epoch  19 |   800/ 2983 batches | lr 1.25 | ms/batch 22.43 | loss  3.65 | ppl    38.34
| prune-epoch  19 |  1000/ 2983 batches | lr 1.25 | ms/batch 22.44 | loss  3.68 | ppl    39.68
| prune-epoch  19 |  1200/ 2983 batches | lr 1.25 | ms/batch 22.44 | loss  3.66 | ppl    38.87
| prune-epoch  19 |  1400/ 2983 batches | lr 1.25 | ms/batch 22.44 | loss  3.72 | ppl    41.07
| prune-epoch  19 |  1600/ 2983 batches | lr 1.25 | ms/batch 22.45 | loss  3.73 | ppl    41.79
| prune-epoch  19 |  1800/ 2983 batches | lr 1.25 | ms/batch 22.45 | loss  3.67 | ppl    39.10
| prune-epoch  19 |  2000/ 2983 batches | lr 1.25 | ms/batch 22.45 | loss  3.70 | ppl    40.49
| prune-epoch  19 |  2200/ 2983 batches | lr 1.25 | ms/batch 22.44 | loss  3.58 | ppl    35.78
| prune-epoch  19 |  2400/ 2983 batches | lr 1.25 | ms/batch 22.45 | loss  3.61 | ppl    36.91
| prune-epoch  19 |  2600/ 2983 batches | lr 1.25 | ms/batch 22.45 | loss  3.64 | ppl    37.99
| prune-epoch  19 |  2800/ 2983 batches | lr 1.25 | ms/batch 22.45 | loss  3.60 | ppl    36.47
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  19 | time: 69.79s | valid loss  4.74 | valid ppl   114.16
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  20 |   200/ 2983 batches | lr 1.25 | ms/batch 22.93 | loss  3.74 | ppl    42.21
| prune-epoch  20 |   400/ 2983 batches | lr 1.25 | ms/batch 22.54 | loss  3.73 | ppl    41.83
| prune-epoch  20 |   600/ 2983 batches | lr 1.25 | ms/batch 22.55 | loss  3.58 | ppl    35.97
| prune-epoch  20 |   800/ 2983 batches | lr 1.25 | ms/batch 22.53 | loss  3.63 | ppl    37.70
| prune-epoch  20 |  1000/ 2983 batches | lr 1.25 | ms/batch 22.52 | loss  3.67 | ppl    39.10
| prune-epoch  20 |  1200/ 2983 batches | lr 1.25 | ms/batch 22.55 | loss  3.66 | ppl    38.84
| prune-epoch  20 |  1400/ 2983 batches | lr 1.25 | ms/batch 22.55 | loss  3.71 | ppl    40.89
| prune-epoch  20 |  1600/ 2983 batches | lr 1.25 | ms/batch 22.55 | loss  3.73 | ppl    41.83
| prune-epoch  20 |  1800/ 2983 batches | lr 1.25 | ms/batch 22.65 | loss  3.66 | ppl    38.95
| prune-epoch  20 |  2000/ 2983 batches | lr 1.25 | ms/batch 22.70 | loss  3.70 | ppl    40.39
| prune-epoch  20 |  2200/ 2983 batches | lr 1.25 | ms/batch 22.70 | loss  3.57 | ppl    35.48
| prune-epoch  20 |  2400/ 2983 batches | lr 1.25 | ms/batch 22.70 | loss  3.61 | ppl    36.91
| prune-epoch  20 |  2600/ 2983 batches | lr 1.25 | ms/batch 22.71 | loss  3.63 | ppl    37.59
| prune-epoch  20 |  2800/ 2983 batches | lr 1.25 | ms/batch 22.72 | loss  3.59 | ppl    36.25
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  20 | time: 70.31s | valid loss  4.74 | valid ppl   114.18
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  21 |   200/ 2983 batches | lr 1.25 | ms/batch 23.18 | loss  3.73 | ppl    41.69
| prune-epoch  21 |   400/ 2983 batches | lr 1.25 | ms/batch 22.79 | loss  3.73 | ppl    41.84
| prune-epoch  21 |   600/ 2983 batches | lr 1.25 | ms/batch 22.79 | loss  3.57 | ppl    35.60
| prune-epoch  21 |   800/ 2983 batches | lr 1.25 | ms/batch 22.80 | loss  3.62 | ppl    37.19
| prune-epoch  21 |  1000/ 2983 batches | lr 1.25 | ms/batch 22.79 | loss  3.66 | ppl    39.02
| prune-epoch  21 |  1200/ 2983 batches | lr 1.25 | ms/batch 22.79 | loss  3.65 | ppl    38.45
| prune-epoch  21 |  1400/ 2983 batches | lr 1.25 | ms/batch 22.61 | loss  3.71 | ppl    40.77
| prune-epoch  21 |  1600/ 2983 batches | lr 1.25 | ms/batch 22.54 | loss  3.72 | ppl    41.47
| prune-epoch  21 |  1800/ 2983 batches | lr 1.25 | ms/batch 22.54 | loss  3.66 | ppl    38.67
| prune-epoch  21 |  2000/ 2983 batches | lr 1.25 | ms/batch 22.75 | loss  3.69 | ppl    40.02
| prune-epoch  21 |  2200/ 2983 batches | lr 1.25 | ms/batch 22.80 | loss  3.57 | ppl    35.57
| prune-epoch  21 |  2400/ 2983 batches | lr 1.25 | ms/batch 22.80 | loss  3.60 | ppl    36.57
| prune-epoch  21 |  2600/ 2983 batches | lr 1.25 | ms/batch 22.79 | loss  3.63 | ppl    37.77
| prune-epoch  21 |  2800/ 2983 batches | lr 1.25 | ms/batch 22.79 | loss  3.59 | ppl    36.21
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  21 | time: 70.69s | valid loss  4.74 | valid ppl   114.19
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  22 |   200/ 2983 batches | lr 0.62 | ms/batch 23.06 | loss  3.75 | ppl    42.51
| prune-epoch  22 |   400/ 2983 batches | lr 0.62 | ms/batch 22.67 | loss  3.77 | ppl    43.49
| prune-epoch  22 |   600/ 2983 batches | lr 0.62 | ms/batch 22.68 | loss  3.59 | ppl    36.38
| prune-epoch  22 |   800/ 2983 batches | lr 0.62 | ms/batch 22.69 | loss  3.66 | ppl    38.79
| prune-epoch  22 |  1000/ 2983 batches | lr 0.62 | ms/batch 22.69 | loss  3.70 | ppl    40.58
| prune-epoch  22 |  1200/ 2983 batches | lr 0.62 | ms/batch 22.68 | loss  3.67 | ppl    39.12
| prune-epoch  22 |  1400/ 2983 batches | lr 0.62 | ms/batch 22.58 | loss  3.74 | ppl    42.18
| prune-epoch  22 |  1600/ 2983 batches | lr 0.62 | ms/batch 22.67 | loss  3.74 | ppl    42.30
| prune-epoch  22 |  1800/ 2983 batches | lr 0.62 | ms/batch 22.59 | loss  3.67 | ppl    39.41
| prune-epoch  22 |  2000/ 2983 batches | lr 0.62 | ms/batch 22.43 | loss  3.72 | ppl    41.39
| prune-epoch  22 |  2200/ 2983 batches | lr 0.62 | ms/batch 22.42 | loss  3.60 | ppl    36.75
| prune-epoch  22 |  2400/ 2983 batches | lr 0.62 | ms/batch 22.42 | loss  3.63 | ppl    37.61
| prune-epoch  22 |  2600/ 2983 batches | lr 0.62 | ms/batch 22.44 | loss  3.65 | ppl    38.63
| prune-epoch  22 |  2800/ 2983 batches | lr 0.62 | ms/batch 22.43 | loss  3.60 | ppl    36.43
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  22 | time: 70.17s | valid loss  4.73 | valid ppl   113.58
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  23 |   200/ 2983 batches | lr 0.62 | ms/batch 22.88 | loss  3.75 | ppl    42.56
| prune-epoch  23 |   400/ 2983 batches | lr 0.62 | ms/batch 22.52 | loss  3.76 | ppl    42.82
| prune-epoch  23 |   600/ 2983 batches | lr 0.62 | ms/batch 22.51 | loss  3.58 | ppl    35.97
| prune-epoch  23 |   800/ 2983 batches | lr 0.62 | ms/batch 22.51 | loss  3.65 | ppl    38.41
| prune-epoch  23 |  1000/ 2983 batches | lr 0.62 | ms/batch 22.53 | loss  3.69 | ppl    40.10
| prune-epoch  23 |  1200/ 2983 batches | lr 0.62 | ms/batch 22.52 | loss  3.67 | ppl    39.20
| prune-epoch  23 |  1400/ 2983 batches | lr 0.62 | ms/batch 22.55 | loss  3.73 | ppl    41.75
| prune-epoch  23 |  1600/ 2983 batches | lr 0.62 | ms/batch 22.56 | loss  3.74 | ppl    42.15
| prune-epoch  23 |  1800/ 2983 batches | lr 0.62 | ms/batch 22.55 | loss  3.68 | ppl    39.56
| prune-epoch  23 |  2000/ 2983 batches | lr 0.62 | ms/batch 22.54 | loss  3.71 | ppl    40.89
| prune-epoch  23 |  2200/ 2983 batches | lr 0.62 | ms/batch 22.53 | loss  3.60 | ppl    36.76
| prune-epoch  23 |  2400/ 2983 batches | lr 0.62 | ms/batch 22.53 | loss  3.61 | ppl    37.02
| prune-epoch  23 |  2600/ 2983 batches | lr 0.62 | ms/batch 22.55 | loss  3.66 | ppl    38.79
| prune-epoch  23 |  2800/ 2983 batches | lr 0.62 | ms/batch 22.54 | loss  3.60 | ppl    36.45
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  23 | time: 70.06s | valid loss  4.73 | valid ppl   113.57
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  24 |   200/ 2983 batches | lr 0.62 | ms/batch 22.81 | loss  3.75 | ppl    42.36
| prune-epoch  24 |   400/ 2983 batches | lr 0.62 | ms/batch 22.42 | loss  3.76 | ppl    42.94
| prune-epoch  24 |   600/ 2983 batches | lr 0.62 | ms/batch 22.42 | loss  3.59 | ppl    36.08
| prune-epoch  24 |   800/ 2983 batches | lr 0.62 | ms/batch 22.50 | loss  3.65 | ppl    38.43
| prune-epoch  24 |  1000/ 2983 batches | lr 0.62 | ms/batch 22.56 | loss  3.70 | ppl    40.25
| prune-epoch  24 |  1200/ 2983 batches | lr 0.62 | ms/batch 22.57 | loss  3.66 | ppl    39.02
| prune-epoch  24 |  1400/ 2983 batches | lr 0.62 | ms/batch 22.56 | loss  3.73 | ppl    41.80
| prune-epoch  24 |  1600/ 2983 batches | lr 0.62 | ms/batch 22.56 | loss  3.75 | ppl    42.45
| prune-epoch  24 |  1800/ 2983 batches | lr 0.62 | ms/batch 22.56 | loss  3.68 | ppl    39.60
| prune-epoch  24 |  2000/ 2983 batches | lr 0.62 | ms/batch 22.56 | loss  3.72 | ppl    41.10
| prune-epoch  24 |  2200/ 2983 batches | lr 0.62 | ms/batch 22.56 | loss  3.60 | ppl    36.59
| prune-epoch  24 |  2400/ 2983 batches | lr 0.62 | ms/batch 22.57 | loss  3.62 | ppl    37.30
| prune-epoch  24 |  2600/ 2983 batches | lr 0.62 | ms/batch 22.73 | loss  3.66 | ppl    38.78
| prune-epoch  24 |  2800/ 2983 batches | lr 0.62 | ms/batch 22.77 | loss  3.59 | ppl    36.22
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  24 | time: 70.17s | valid loss  4.73 | valid ppl   113.47
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  25 |   200/ 2983 batches | lr 0.62 | ms/batch 23.12 | loss  3.74 | ppl    42.21
| prune-epoch  25 |   400/ 2983 batches | lr 0.62 | ms/batch 22.72 | loss  3.75 | ppl    42.71
| prune-epoch  25 |   600/ 2983 batches | lr 0.62 | ms/batch 22.73 | loss  3.58 | ppl    35.99
| prune-epoch  25 |   800/ 2983 batches | lr 0.62 | ms/batch 22.73 | loss  3.65 | ppl    38.42
| prune-epoch  25 |  1000/ 2983 batches | lr 0.62 | ms/batch 22.74 | loss  3.68 | ppl    39.79
| prune-epoch  25 |  1200/ 2983 batches | lr 0.62 | ms/batch 22.74 | loss  3.66 | ppl    38.94
| prune-epoch  25 |  1400/ 2983 batches | lr 0.62 | ms/batch 22.73 | loss  3.72 | ppl    41.43
| prune-epoch  25 |  1600/ 2983 batches | lr 0.62 | ms/batch 22.74 | loss  3.74 | ppl    42.01
| prune-epoch  25 |  1800/ 2983 batches | lr 0.62 | ms/batch 22.72 | loss  3.66 | ppl    39.02
| prune-epoch  25 |  2000/ 2983 batches | lr 0.62 | ms/batch 22.72 | loss  3.71 | ppl    40.76
| prune-epoch  25 |  2200/ 2983 batches | lr 0.62 | ms/batch 22.74 | loss  3.60 | ppl    36.62
| prune-epoch  25 |  2400/ 2983 batches | lr 0.62 | ms/batch 22.73 | loss  3.62 | ppl    37.27
| prune-epoch  25 |  2600/ 2983 batches | lr 0.62 | ms/batch 22.73 | loss  3.65 | ppl    38.49
| prune-epoch  25 |  2800/ 2983 batches | lr 0.62 | ms/batch 22.72 | loss  3.60 | ppl    36.49
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  25 | time: 70.65s | valid loss  4.73 | valid ppl   113.56
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  26 |   200/ 2983 batches | lr 0.62 | ms/batch 23.11 | loss  3.74 | ppl    42.01
| prune-epoch  26 |   400/ 2983 batches | lr 0.62 | ms/batch 22.80 | loss  3.75 | ppl    42.62
| prune-epoch  26 |   600/ 2983 batches | lr 0.62 | ms/batch 22.76 | loss  3.58 | ppl    35.70
| prune-epoch  26 |   800/ 2983 batches | lr 0.62 | ms/batch 22.75 | loss  3.64 | ppl    38.18
| prune-epoch  26 |  1000/ 2983 batches | lr 0.62 | ms/batch 22.76 | loss  3.68 | ppl    39.65
| prune-epoch  26 |  1200/ 2983 batches | lr 0.62 | ms/batch 22.76 | loss  3.66 | ppl    39.02
| prune-epoch  26 |  1400/ 2983 batches | lr 0.62 | ms/batch 22.75 | loss  3.72 | ppl    41.34
| prune-epoch  26 |  1600/ 2983 batches | lr 0.62 | ms/batch 22.73 | loss  3.74 | ppl    42.21
| prune-epoch  26 |  1800/ 2983 batches | lr 0.62 | ms/batch 22.75 | loss  3.67 | ppl    39.12
| prune-epoch  26 |  2000/ 2983 batches | lr 0.62 | ms/batch 22.73 | loss  3.70 | ppl    40.51
| prune-epoch  26 |  2200/ 2983 batches | lr 0.62 | ms/batch 22.74 | loss  3.60 | ppl    36.58
| prune-epoch  26 |  2400/ 2983 batches | lr 0.62 | ms/batch 22.74 | loss  3.62 | ppl    37.18
| prune-epoch  26 |  2600/ 2983 batches | lr 0.62 | ms/batch 22.74 | loss  3.65 | ppl    38.57
| prune-epoch  26 |  2800/ 2983 batches | lr 0.62 | ms/batch 22.74 | loss  3.59 | ppl    36.30
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  26 | time: 70.70s | valid loss  4.73 | valid ppl   113.57
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  27 |   200/ 2983 batches | lr 0.31 | ms/batch 23.04 | loss  3.76 | ppl    42.90
| prune-epoch  27 |   400/ 2983 batches | lr 0.31 | ms/batch 22.66 | loss  3.80 | ppl    44.58
| prune-epoch  27 |   600/ 2983 batches | lr 0.31 | ms/batch 22.66 | loss  3.61 | ppl    36.85
| prune-epoch  27 |   800/ 2983 batches | lr 0.31 | ms/batch 22.66 | loss  3.67 | ppl    39.27
| prune-epoch  27 |  1000/ 2983 batches | lr 0.31 | ms/batch 22.66 | loss  3.72 | ppl    41.43
| prune-epoch  27 |  1200/ 2983 batches | lr 0.31 | ms/batch 22.66 | loss  3.70 | ppl    40.30
| prune-epoch  27 |  1400/ 2983 batches | lr 0.31 | ms/batch 22.66 | loss  3.74 | ppl    41.98
| prune-epoch  27 |  1600/ 2983 batches | lr 0.31 | ms/batch 22.65 | loss  3.78 | ppl    43.74
| prune-epoch  27 |  1800/ 2983 batches | lr 0.31 | ms/batch 22.67 | loss  3.68 | ppl    39.82
| prune-epoch  27 |  2000/ 2983 batches | lr 0.31 | ms/batch 22.66 | loss  3.71 | ppl    40.84
| prune-epoch  27 |  2200/ 2983 batches | lr 0.31 | ms/batch 22.67 | loss  3.63 | ppl    37.54
| prune-epoch  27 |  2400/ 2983 batches | lr 0.31 | ms/batch 22.66 | loss  3.65 | ppl    38.37
| prune-epoch  27 |  2600/ 2983 batches | lr 0.31 | ms/batch 22.66 | loss  3.68 | ppl    39.68
| prune-epoch  27 |  2800/ 2983 batches | lr 0.31 | ms/batch 22.67 | loss  3.62 | ppl    37.22
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  27 | time: 70.44s | valid loss  4.72 | valid ppl   112.26
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  28 |   200/ 2983 batches | lr 0.31 | ms/batch 23.20 | loss  3.74 | ppl    42.26
| prune-epoch  28 |   400/ 2983 batches | lr 0.31 | ms/batch 22.80 | loss  3.78 | ppl    43.89
| prune-epoch  28 |   600/ 2983 batches | lr 0.31 | ms/batch 22.80 | loss  3.60 | ppl    36.56
| prune-epoch  28 |   800/ 2983 batches | lr 0.31 | ms/batch 22.81 | loss  3.66 | ppl    38.86
| prune-epoch  28 |  1000/ 2983 batches | lr 0.31 | ms/batch 22.80 | loss  3.71 | ppl    40.94
| prune-epoch  28 |  1200/ 2983 batches | lr 0.31 | ms/batch 22.79 | loss  3.69 | ppl    40.01
| prune-epoch  28 |  1400/ 2983 batches | lr 0.31 | ms/batch 22.79 | loss  3.74 | ppl    41.96
| prune-epoch  28 |  1600/ 2983 batches | lr 0.31 | ms/batch 22.79 | loss  3.78 | ppl    43.76
| prune-epoch  28 |  1800/ 2983 batches | lr 0.31 | ms/batch 22.79 | loss  3.68 | ppl    39.68
| prune-epoch  28 |  2000/ 2983 batches | lr 0.31 | ms/batch 22.78 | loss  3.72 | ppl    41.16
| prune-epoch  28 |  2200/ 2983 batches | lr 0.31 | ms/batch 22.82 | loss  3.62 | ppl    37.52
| prune-epoch  28 |  2400/ 2983 batches | lr 0.31 | ms/batch 22.83 | loss  3.64 | ppl    38.17
| prune-epoch  28 |  2600/ 2983 batches | lr 0.31 | ms/batch 22.79 | loss  3.68 | ppl    39.53
| prune-epoch  28 |  2800/ 2983 batches | lr 0.31 | ms/batch 22.79 | loss  3.61 | ppl    36.96
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  28 | time: 70.85s | valid loss  4.72 | valid ppl   112.39
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  29 |   200/ 2983 batches | lr 0.31 | ms/batch 23.12 | loss  3.74 | ppl    42.29
| prune-epoch  29 |   400/ 2983 batches | lr 0.31 | ms/batch 22.73 | loss  3.78 | ppl    43.70
| prune-epoch  29 |   600/ 2983 batches | lr 0.31 | ms/batch 22.74 | loss  3.60 | ppl    36.51
| prune-epoch  29 |   800/ 2983 batches | lr 0.31 | ms/batch 22.74 | loss  3.65 | ppl    38.65
| prune-epoch  29 |  1000/ 2983 batches | lr 0.31 | ms/batch 22.63 | loss  3.70 | ppl    40.65
| prune-epoch  29 |  1200/ 2983 batches | lr 0.31 | ms/batch 22.60 | loss  3.69 | ppl    39.92
| prune-epoch  29 |  1400/ 2983 batches | lr 0.31 | ms/batch 22.60 | loss  3.74 | ppl    41.94
| prune-epoch  29 |  1600/ 2983 batches | lr 0.31 | ms/batch 22.56 | loss  3.78 | ppl    43.75
| prune-epoch  29 |  1800/ 2983 batches | lr 0.31 | ms/batch 22.49 | loss  3.69 | ppl    39.85
| prune-epoch  29 |  2000/ 2983 batches | lr 0.31 | ms/batch 22.53 | loss  3.71 | ppl    40.95
| prune-epoch  29 |  2200/ 2983 batches | lr 0.31 | ms/batch 22.57 | loss  3.62 | ppl    37.40
| prune-epoch  29 |  2400/ 2983 batches | lr 0.31 | ms/batch 22.57 | loss  3.65 | ppl    38.49
| prune-epoch  29 |  2600/ 2983 batches | lr 0.31 | ms/batch 22.58 | loss  3.68 | ppl    39.46
| prune-epoch  29 |  2800/ 2983 batches | lr 0.31 | ms/batch 22.72 | loss  3.61 | ppl    37.01
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  29 | time: 70.37s | valid loss  4.72 | valid ppl   111.99
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  30 |   200/ 2983 batches | lr 0.31 | ms/batch 23.13 | loss  3.74 | ppl    42.22
| prune-epoch  30 |   400/ 2983 batches | lr 0.31 | ms/batch 22.74 | loss  3.77 | ppl    43.59
| prune-epoch  30 |   600/ 2983 batches | lr 0.31 | ms/batch 22.74 | loss  3.60 | ppl    36.44
| prune-epoch  30 |   800/ 2983 batches | lr 0.31 | ms/batch 22.74 | loss  3.65 | ppl    38.56
| prune-epoch  30 |  1000/ 2983 batches | lr 0.31 | ms/batch 22.74 | loss  3.70 | ppl    40.35
| prune-epoch  30 |  1200/ 2983 batches | lr 0.31 | ms/batch 22.73 | loss  3.69 | ppl    40.09
| prune-epoch  30 |  1400/ 2983 batches | lr 0.31 | ms/batch 22.74 | loss  3.74 | ppl    42.06
| prune-epoch  30 |  1600/ 2983 batches | lr 0.31 | ms/batch 22.74 | loss  3.78 | ppl    43.66
| prune-epoch  30 |  1800/ 2983 batches | lr 0.31 | ms/batch 22.75 | loss  3.68 | ppl    39.68
| prune-epoch  30 |  2000/ 2983 batches | lr 0.31 | ms/batch 22.74 | loss  3.71 | ppl    41.03
| prune-epoch  30 |  2200/ 2983 batches | lr 0.31 | ms/batch 22.74 | loss  3.62 | ppl    37.32
| prune-epoch  30 |  2400/ 2983 batches | lr 0.31 | ms/batch 22.74 | loss  3.64 | ppl    38.12
| prune-epoch  30 |  2600/ 2983 batches | lr 0.31 | ms/batch 22.74 | loss  3.68 | ppl    39.51
| prune-epoch  30 |  2800/ 2983 batches | lr 0.31 | ms/batch 22.73 | loss  3.61 | ppl    36.96
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  30 | time: 70.68s | valid loss  4.72 | valid ppl   112.22
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  31 |   200/ 2983 batches | lr 0.16 | ms/batch 23.15 | loss  3.76 | ppl    42.76
| prune-epoch  31 |   400/ 2983 batches | lr 0.16 | ms/batch 22.76 | loss  3.83 | ppl    46.22
| prune-epoch  31 |   600/ 2983 batches | lr 0.16 | ms/batch 22.76 | loss  3.64 | ppl    38.12
| prune-epoch  31 |   800/ 2983 batches | lr 0.16 | ms/batch 22.77 | loss  3.68 | ppl    39.72
| prune-epoch  31 |  1000/ 2983 batches | lr 0.16 | ms/batch 22.84 | loss  3.73 | ppl    41.69
| prune-epoch  31 |  1200/ 2983 batches | lr 0.16 | ms/batch 22.78 | loss  3.72 | ppl    41.42
| prune-epoch  31 |  1400/ 2983 batches | lr 0.16 | ms/batch 22.76 | loss  3.75 | ppl    42.54
| prune-epoch  31 |  1600/ 2983 batches | lr 0.16 | ms/batch 22.78 | loss  3.80 | ppl    44.77
| prune-epoch  31 |  1800/ 2983 batches | lr 0.16 | ms/batch 22.76 | loss  3.71 | ppl    40.87
| prune-epoch  31 |  2000/ 2983 batches | lr 0.16 | ms/batch 22.78 | loss  3.73 | ppl    41.69
| prune-epoch  31 |  2200/ 2983 batches | lr 0.16 | ms/batch 22.77 | loss  3.62 | ppl    37.35
| prune-epoch  31 |  2400/ 2983 batches | lr 0.16 | ms/batch 22.78 | loss  3.65 | ppl    38.53
| prune-epoch  31 |  2600/ 2983 batches | lr 0.16 | ms/batch 22.77 | loss  3.69 | ppl    39.97
| prune-epoch  31 |  2800/ 2983 batches | lr 0.16 | ms/batch 22.76 | loss  3.64 | ppl    38.12
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  31 | time: 70.79s | valid loss  4.71 | valid ppl   110.55
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  32 |   200/ 2983 batches | lr 0.16 | ms/batch 23.11 | loss  3.77 | ppl    43.27
| prune-epoch  32 |   400/ 2983 batches | lr 0.16 | ms/batch 22.71 | loss  3.80 | ppl    44.63
| prune-epoch  32 |   600/ 2983 batches | lr 0.16 | ms/batch 22.70 | loss  3.63 | ppl    37.53
| prune-epoch  32 |   800/ 2983 batches | lr 0.16 | ms/batch 22.70 | loss  3.67 | ppl    39.27
| prune-epoch  32 |  1000/ 2983 batches | lr 0.16 | ms/batch 22.70 | loss  3.73 | ppl    41.49
| prune-epoch  32 |  1200/ 2983 batches | lr 0.16 | ms/batch 22.69 | loss  3.72 | ppl    41.10
| prune-epoch  32 |  1400/ 2983 batches | lr 0.16 | ms/batch 22.70 | loss  3.75 | ppl    42.42
| prune-epoch  32 |  1600/ 2983 batches | lr 0.16 | ms/batch 22.70 | loss  3.80 | ppl    44.75
| prune-epoch  32 |  1800/ 2983 batches | lr 0.16 | ms/batch 22.71 | loss  3.71 | ppl    40.66
| prune-epoch  32 |  2000/ 2983 batches | lr 0.16 | ms/batch 22.70 | loss  3.72 | ppl    41.45
| prune-epoch  32 |  2200/ 2983 batches | lr 0.16 | ms/batch 22.71 | loss  3.63 | ppl    37.69
| prune-epoch  32 |  2400/ 2983 batches | lr 0.16 | ms/batch 22.71 | loss  3.65 | ppl    38.59
| prune-epoch  32 |  2600/ 2983 batches | lr 0.16 | ms/batch 22.69 | loss  3.69 | ppl    40.24
| prune-epoch  32 |  2800/ 2983 batches | lr 0.16 | ms/batch 22.70 | loss  3.64 | ppl    38.20
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  32 | time: 70.57s | valid loss  4.71 | valid ppl   110.53
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  33 |   200/ 2983 batches | lr 0.16 | ms/batch 23.14 | loss  3.76 | ppl    42.95
| prune-epoch  33 |   400/ 2983 batches | lr 0.16 | ms/batch 22.73 | loss  3.79 | ppl    44.42
| prune-epoch  33 |   600/ 2983 batches | lr 0.16 | ms/batch 22.73 | loss  3.62 | ppl    37.45
| prune-epoch  33 |   800/ 2983 batches | lr 0.16 | ms/batch 22.72 | loss  3.67 | ppl    39.23
| prune-epoch  33 |  1000/ 2983 batches | lr 0.16 | ms/batch 22.74 | loss  3.72 | ppl    41.28
| prune-epoch  33 |  1200/ 2983 batches | lr 0.16 | ms/batch 22.73 | loss  3.72 | ppl    41.10
| prune-epoch  33 |  1400/ 2983 batches | lr 0.16 | ms/batch 22.74 | loss  3.75 | ppl    42.45
| prune-epoch  33 |  1600/ 2983 batches | lr 0.16 | ms/batch 22.73 | loss  3.80 | ppl    44.75
| prune-epoch  33 |  1800/ 2983 batches | lr 0.16 | ms/batch 22.73 | loss  3.71 | ppl    40.91
| prune-epoch  33 |  2000/ 2983 batches | lr 0.16 | ms/batch 22.74 | loss  3.73 | ppl    41.65
| prune-epoch  33 |  2200/ 2983 batches | lr 0.16 | ms/batch 22.72 | loss  3.63 | ppl    37.63
| prune-epoch  33 |  2400/ 2983 batches | lr 0.16 | ms/batch 22.72 | loss  3.65 | ppl    38.41
| prune-epoch  33 |  2600/ 2983 batches | lr 0.16 | ms/batch 22.74 | loss  3.68 | ppl    39.70
| prune-epoch  33 |  2800/ 2983 batches | lr 0.16 | ms/batch 22.64 | loss  3.63 | ppl    37.82
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  33 | time: 70.62s | valid loss  4.71 | valid ppl   110.55
-----------------------------------------------------------------------------------------
required epochs  40 | actual epochs  64
pretrain epochs  15 | prune epochs  16 | retrain epochs  33
=========================================================================================
| End of training | test loss  4.64 | test ppl   103.69
=========================================================================================
python main.py --cuda --emsize 650 --nhid 650 --dropout 0.5 --epochs 40 --tied --save model/prune/model.pt --prune --retrain --sparsity 0.9
<class 'torch.Tensor'> torch.Size([33278, 650])
<class 'torch.Tensor'> torch.Size([2600, 650])
<class 'torch.Tensor'> torch.Size([2600, 650])
<class 'torch.Tensor'> torch.Size([2600])
<class 'torch.Tensor'> torch.Size([2600])
<class 'torch.Tensor'> torch.Size([2600, 650])
<class 'torch.Tensor'> torch.Size([2600, 650])
<class 'torch.Tensor'> torch.Size([2600])
<class 'torch.Tensor'> torch.Size([2600])
<class 'torch.Tensor'> torch.Size([33278])
RNNModel(
  (drop): Dropout(p=0.5)
  (encoder): Embedding(33278, 650)
  (rnn): LSTM(650, 650, num_layers=2, dropout=0.5)
  (decoder): Linear(in_features=650, out_features=33278, bias=True)
)
Dropout(p=0.5)
Embedding(33278, 650)
LSTM(650, 650, num_layers=2, dropout=0.5)
Linear(in_features=650, out_features=33278, bias=True)
| train-epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 21.77 | loss  7.74 | ppl  2297.39
| train-epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 21.49 | loss  6.78 | ppl   880.76
| train-epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 21.59 | loss  6.39 | ppl   594.52
| train-epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 21.58 | loss  6.24 | ppl   510.38
| train-epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.60 | loss  6.11 | ppl   450.04
| train-epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.62 | loss  6.04 | ppl   420.21
| train-epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  5.93 | ppl   377.78
| train-epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.60 | loss  5.94 | ppl   380.68
| train-epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  5.79 | ppl   326.74
| train-epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  5.75 | ppl   315.38
| train-epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.65 | loss  5.65 | ppl   284.08
| train-epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.65 | loss  5.65 | ppl   283.66
| train-epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.65 | loss  5.64 | ppl   281.90
| train-epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.65 | loss  5.53 | ppl   252.41
-----------------------------------------------------------------------------------------
| end of train epoch   1 | time: 67.29s | valid loss  5.42 | valid ppl   226.46
-----------------------------------------------------------------------------------------
| train-epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch 21.85 | loss  5.54 | ppl   254.04
| train-epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  5.52 | ppl   248.65
| train-epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  5.34 | ppl   208.78
| train-epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  5.36 | ppl   213.67
| train-epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  5.34 | ppl   208.20
| train-epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  5.33 | ppl   205.83
| train-epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  5.32 | ppl   204.94
| train-epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  5.38 | ppl   216.98
| train-epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.72 | loss  5.25 | ppl   190.33
| train-epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  5.27 | ppl   193.77
| train-epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  5.18 | ppl   176.81
| train-epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  5.19 | ppl   179.73
| train-epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  5.20 | ppl   182.16
| train-epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  5.13 | ppl   168.66
-----------------------------------------------------------------------------------------
| end of train epoch   2 | time: 67.66s | valid loss  5.11 | valid ppl   165.62
-----------------------------------------------------------------------------------------
| train-epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 21.76 | loss  5.17 | ppl   175.86
| train-epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch 21.65 | loss  5.19 | ppl   179.03
| train-epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 21.64 | loss  5.01 | ppl   149.52
| train-epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 21.70 | loss  5.06 | ppl   157.73
| train-epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.66 | loss  5.04 | ppl   155.22
| train-epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.62 | loss  5.05 | ppl   155.58
| train-epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  5.07 | ppl   159.35
| train-epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  5.14 | ppl   170.24
| train-epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.80 | loss  5.00 | ppl   149.12
| train-epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.80 | loss  5.04 | ppl   153.87
| train-epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.66 | loss  4.94 | ppl   139.40
| train-epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.62 | loss  4.97 | ppl   144.13
| train-epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.62 | loss  4.99 | ppl   146.75
| train-epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.61 | loss  4.92 | ppl   137.24
-----------------------------------------------------------------------------------------
| end of train epoch   3 | time: 67.44s | valid loss  4.96 | valid ppl   143.31
-----------------------------------------------------------------------------------------
| train-epoch   4 |   200/ 2983 batches | lr 20.00 | ms/batch 21.92 | loss  4.97 | ppl   144.44
| train-epoch   4 |   400/ 2983 batches | lr 20.00 | ms/batch 21.80 | loss  4.99 | ppl   146.72
| train-epoch   4 |   600/ 2983 batches | lr 20.00 | ms/batch 21.80 | loss  4.82 | ppl   123.37
| train-epoch   4 |   800/ 2983 batches | lr 20.00 | ms/batch 21.80 | loss  4.88 | ppl   131.21
| train-epoch   4 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.81 | loss  4.87 | ppl   130.36
| train-epoch   4 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.78 | loss  4.87 | ppl   130.95
| train-epoch   4 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.80 | loss  4.91 | ppl   135.32
| train-epoch   4 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.79 | loss  4.98 | ppl   145.16
| train-epoch   4 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.80 | loss  4.85 | ppl   128.15
| train-epoch   4 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.80 | loss  4.89 | ppl   132.86
| train-epoch   4 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.77 | loss  4.79 | ppl   120.21
| train-epoch   4 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.80 | loss  4.83 | ppl   124.90
| train-epoch   4 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.80 | loss  4.85 | ppl   127.57
| train-epoch   4 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.80 | loss  4.78 | ppl   119.54
-----------------------------------------------------------------------------------------
| end of train epoch   4 | time: 67.83s | valid loss  4.87 | valid ppl   130.15
-----------------------------------------------------------------------------------------
| train-epoch   5 |   200/ 2983 batches | lr 20.00 | ms/batch 21.72 | loss  4.84 | ppl   125.84
| train-epoch   5 |   400/ 2983 batches | lr 20.00 | ms/batch 21.64 | loss  4.86 | ppl   129.60
| train-epoch   5 |   600/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  4.69 | ppl   108.35
| train-epoch   5 |   800/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  4.74 | ppl   114.90
| train-epoch   5 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.75 | ppl   115.61
| train-epoch   5 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  4.75 | ppl   116.13
| train-epoch   5 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  4.80 | ppl   121.35
| train-epoch   5 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  4.86 | ppl   128.86
| train-epoch   5 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  4.74 | ppl   114.97
| train-epoch   5 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  4.78 | ppl   119.34
| train-epoch   5 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  4.68 | ppl   107.38
| train-epoch   5 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.72 | loss  4.72 | ppl   111.95
| train-epoch   5 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  4.74 | ppl   114.76
| train-epoch   5 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  4.68 | ppl   108.12
-----------------------------------------------------------------------------------------
| end of train epoch   5 | time: 67.61s | valid loss  4.82 | valid ppl   124.22
-----------------------------------------------------------------------------------------
| train-epoch   6 |   200/ 2983 batches | lr 20.00 | ms/batch 21.87 | loss  4.74 | ppl   113.93
| train-epoch   6 |   400/ 2983 batches | lr 20.00 | ms/batch 21.77 | loss  4.76 | ppl   116.87
| train-epoch   6 |   600/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.58 | ppl    97.76
| train-epoch   6 |   800/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.64 | ppl   103.71
| train-epoch   6 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.76 | loss  4.65 | ppl   104.90
| train-epoch   6 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  4.67 | ppl   106.23
| train-epoch   6 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  4.71 | ppl   110.67
| train-epoch   6 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.77 | ppl   118.15
| train-epoch   6 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.76 | loss  4.65 | ppl   104.98
| train-epoch   6 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.76 | loss  4.70 | ppl   110.36
| train-epoch   6 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.59 | ppl    98.89
| train-epoch   6 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.63 | ppl   102.68
| train-epoch   6 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.66 | ppl   105.35
| train-epoch   6 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  4.60 | ppl    99.83
-----------------------------------------------------------------------------------------
| end of train epoch   6 | time: 67.69s | valid loss  4.78 | valid ppl   119.55
-----------------------------------------------------------------------------------------
| train-epoch   7 |   200/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  4.65 | ppl   104.90
| train-epoch   7 |   400/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  4.68 | ppl   108.00
| train-epoch   7 |   600/ 2983 batches | lr 20.00 | ms/batch 21.64 | loss  4.51 | ppl    90.49
| train-epoch   7 |   800/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  4.56 | ppl    95.95
| train-epoch   7 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  4.58 | ppl    97.33
| train-epoch   7 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.62 | loss  4.59 | ppl    98.35
| train-epoch   7 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.61 | loss  4.63 | ppl   103.02
| train-epoch   7 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  4.70 | ppl   109.47
| train-epoch   7 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  4.59 | ppl    98.34
| train-epoch   7 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.62 | loss  4.63 | ppl   102.57
| train-epoch   7 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.61 | loss  4.52 | ppl    92.15
| train-epoch   7 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.60 | loss  4.57 | ppl    96.19
| train-epoch   7 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  4.59 | ppl    98.31
| train-epoch   7 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.61 | loss  4.54 | ppl    93.65
-----------------------------------------------------------------------------------------
| end of train epoch   7 | time: 67.33s | valid loss  4.76 | valid ppl   116.95
-----------------------------------------------------------------------------------------
| train-epoch   8 |   200/ 2983 batches | lr 20.00 | ms/batch 21.78 | loss  4.59 | ppl    98.06
| train-epoch   8 |   400/ 2983 batches | lr 20.00 | ms/batch 21.68 | loss  4.62 | ppl   101.01
| train-epoch   8 |   600/ 2983 batches | lr 20.00 | ms/batch 21.69 | loss  4.44 | ppl    84.53
| train-epoch   8 |   800/ 2983 batches | lr 20.00 | ms/batch 21.68 | loss  4.50 | ppl    89.94
| train-epoch   8 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.68 | loss  4.52 | ppl    91.94
| train-epoch   8 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.67 | loss  4.53 | ppl    93.16
| train-epoch   8 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.71 | loss  4.57 | ppl    96.99
| train-epoch   8 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.66 | loss  4.64 | ppl   103.77
| train-epoch   8 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.66 | loss  4.54 | ppl    93.32
| train-epoch   8 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  4.58 | ppl    97.05
| train-epoch   8 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.93 | loss  4.47 | ppl    87.13
| train-epoch   8 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.91 | loss  4.50 | ppl    90.44
| train-epoch   8 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.92 | loss  4.53 | ppl    93.02
| train-epoch   8 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.90 | loss  4.49 | ppl    89.05
-----------------------------------------------------------------------------------------
| end of train epoch   8 | time: 67.71s | valid loss  4.73 | valid ppl   113.67
-----------------------------------------------------------------------------------------
| train-epoch   9 |   200/ 2983 batches | lr 20.00 | ms/batch 22.05 | loss  4.53 | ppl    93.22
| train-epoch   9 |   400/ 2983 batches | lr 20.00 | ms/batch 21.91 | loss  4.56 | ppl    95.64
| train-epoch   9 |   600/ 2983 batches | lr 20.00 | ms/batch 21.94 | loss  4.38 | ppl    80.10
| train-epoch   9 |   800/ 2983 batches | lr 20.00 | ms/batch 21.94 | loss  4.44 | ppl    85.13
| train-epoch   9 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.94 | loss  4.46 | ppl    86.74
| train-epoch   9 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.93 | loss  4.48 | ppl    88.21
| train-epoch   9 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.94 | loss  4.52 | ppl    91.77
| train-epoch   9 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.94 | loss  4.59 | ppl    98.88
| train-epoch   9 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.93 | loss  4.49 | ppl    88.80
| train-epoch   9 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.93 | loss  4.52 | ppl    92.10
| train-epoch   9 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.94 | loss  4.41 | ppl    82.65
| train-epoch   9 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.78 | loss  4.46 | ppl    86.28
| train-epoch   9 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.76 | loss  4.48 | ppl    88.63
| train-epoch   9 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.76 | loss  4.44 | ppl    84.85
-----------------------------------------------------------------------------------------
| end of train epoch   9 | time: 68.10s | valid loss  4.72 | valid ppl   112.34
-----------------------------------------------------------------------------------------
| train-epoch  10 |   200/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.49 | ppl    89.24
| train-epoch  10 |   400/ 2983 batches | lr 20.00 | ms/batch 21.61 | loss  4.51 | ppl    90.97
| train-epoch  10 |   600/ 2983 batches | lr 20.00 | ms/batch 21.64 | loss  4.34 | ppl    76.77
| train-epoch  10 |   800/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  4.39 | ppl    80.78
| train-epoch  10 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.65 | loss  4.43 | ppl    83.76
| train-epoch  10 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  4.44 | ppl    84.74
| train-epoch  10 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.62 | loss  4.48 | ppl    87.93
| train-epoch  10 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  4.55 | ppl    94.59
| train-epoch  10 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.88 | loss  4.44 | ppl    85.17
| train-epoch  10 |  2000/ 2983 batches | lr 20.00 | ms/batch 22.01 | loss  4.49 | ppl    88.68
| train-epoch  10 |  2200/ 2983 batches | lr 20.00 | ms/batch 22.02 | loss  4.37 | ppl    78.92
| train-epoch  10 |  2400/ 2983 batches | lr 20.00 | ms/batch 22.04 | loss  4.41 | ppl    82.61
| train-epoch  10 |  2600/ 2983 batches | lr 20.00 | ms/batch 22.02 | loss  4.45 | ppl    85.44
| train-epoch  10 |  2800/ 2983 batches | lr 20.00 | ms/batch 22.00 | loss  4.39 | ppl    80.77
-----------------------------------------------------------------------------------------
| end of train epoch  10 | time: 67.83s | valid loss  4.71 | valid ppl   110.82
-----------------------------------------------------------------------------------------
| train-epoch  11 |   200/ 2983 batches | lr 20.00 | ms/batch 21.90 | loss  4.45 | ppl    85.54
| train-epoch  11 |   400/ 2983 batches | lr 20.00 | ms/batch 21.80 | loss  4.47 | ppl    87.63
| train-epoch  11 |   600/ 2983 batches | lr 20.00 | ms/batch 21.81 | loss  4.30 | ppl    73.61
| train-epoch  11 |   800/ 2983 batches | lr 20.00 | ms/batch 21.80 | loss  4.35 | ppl    77.85
| train-epoch  11 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.79 | loss  4.39 | ppl    80.55
| train-epoch  11 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.80 | loss  4.40 | ppl    81.36
| train-epoch  11 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.80 | loss  4.44 | ppl    84.68
| train-epoch  11 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.79 | loss  4.51 | ppl    90.97
| train-epoch  11 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.82 | loss  4.40 | ppl    81.86
| train-epoch  11 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.81 | loss  4.44 | ppl    85.14
| train-epoch  11 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.83 | loss  4.34 | ppl    76.41
| train-epoch  11 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.80 | loss  4.38 | ppl    79.61
| train-epoch  11 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.78 | loss  4.41 | ppl    82.06
| train-epoch  11 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.82 | loss  4.37 | ppl    78.67
-----------------------------------------------------------------------------------------
| end of train epoch  11 | time: 67.85s | valid loss  4.70 | valid ppl   110.19
-----------------------------------------------------------------------------------------
| train-epoch  12 |   200/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  4.41 | ppl    82.40
| train-epoch  12 |   400/ 2983 batches | lr 20.00 | ms/batch 21.62 | loss  4.44 | ppl    84.36
| train-epoch  12 |   600/ 2983 batches | lr 20.00 | ms/batch 21.62 | loss  4.26 | ppl    71.01
| train-epoch  12 |   800/ 2983 batches | lr 20.00 | ms/batch 21.64 | loss  4.32 | ppl    75.00
| train-epoch  12 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.64 | loss  4.35 | ppl    77.85
| train-epoch  12 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.65 | loss  4.37 | ppl    79.02
| train-epoch  12 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.65 | loss  4.41 | ppl    81.91
| train-epoch  12 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.63 | loss  4.48 | ppl    88.43
| train-epoch  12 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.64 | loss  4.37 | ppl    79.42
| train-epoch  12 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.66 | loss  4.41 | ppl    82.56
| train-epoch  12 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.66 | loss  4.30 | ppl    73.73
| train-epoch  12 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.65 | loss  4.34 | ppl    76.92
| train-epoch  12 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.65 | loss  4.38 | ppl    79.61
| train-epoch  12 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.65 | loss  4.33 | ppl    75.87
-----------------------------------------------------------------------------------------
| end of train epoch  12 | time: 67.36s | valid loss  4.69 | valid ppl   108.78
-----------------------------------------------------------------------------------------
| train-epoch  13 |   200/ 2983 batches | lr 20.00 | ms/batch 21.76 | loss  4.38 | ppl    79.61
| train-epoch  13 |   400/ 2983 batches | lr 20.00 | ms/batch 21.66 | loss  4.41 | ppl    82.11
| train-epoch  13 |   600/ 2983 batches | lr 20.00 | ms/batch 21.67 | loss  4.23 | ppl    68.71
| train-epoch  13 |   800/ 2983 batches | lr 20.00 | ms/batch 21.65 | loss  4.29 | ppl    72.75
| train-epoch  13 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.67 | loss  4.32 | ppl    75.06
| train-epoch  13 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.64 | loss  4.34 | ppl    76.36
| train-epoch  13 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.66 | loss  4.38 | ppl    79.53
| train-epoch  13 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.66 | loss  4.45 | ppl    85.48
| train-epoch  13 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.65 | loss  4.35 | ppl    77.60
| train-epoch  13 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.65 | loss  4.39 | ppl    80.36
| train-epoch  13 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.65 | loss  4.27 | ppl    71.55
| train-epoch  13 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.65 | loss  4.31 | ppl    74.69
| train-epoch  13 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.65 | loss  4.34 | ppl    76.85
| train-epoch  13 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.65 | loss  4.31 | ppl    74.21
-----------------------------------------------------------------------------------------
| end of train epoch  13 | time: 67.40s | valid loss  4.69 | valid ppl   108.36
-----------------------------------------------------------------------------------------
| train-epoch  14 |   200/ 2983 batches | lr 20.00 | ms/batch 21.86 | loss  4.35 | ppl    77.39
| train-epoch  14 |   400/ 2983 batches | lr 20.00 | ms/batch 21.79 | loss  4.38 | ppl    79.57
| train-epoch  14 |   600/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  4.21 | ppl    67.18
| train-epoch  14 |   800/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  4.27 | ppl    71.17
| train-epoch  14 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  4.30 | ppl    73.40
| train-epoch  14 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.31 | ppl    74.60
| train-epoch  14 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.70 | loss  4.35 | ppl    77.63
| train-epoch  14 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.43 | ppl    83.78
| train-epoch  14 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  4.32 | ppl    75.16
| train-epoch  14 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.36 | ppl    78.64
| train-epoch  14 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.25 | ppl    70.07
| train-epoch  14 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.29 | ppl    72.88
| train-epoch  14 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.32 | ppl    75.41
| train-epoch  14 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.28 | ppl    72.03
-----------------------------------------------------------------------------------------
| end of train epoch  14 | time: 67.67s | valid loss  4.68 | valid ppl   107.67
-----------------------------------------------------------------------------------------
| train-epoch  15 |   200/ 2983 batches | lr 20.00 | ms/batch 21.76 | loss  4.33 | ppl    75.63
| train-epoch  15 |   400/ 2983 batches | lr 20.00 | ms/batch 21.65 | loss  4.35 | ppl    77.67
| train-epoch  15 |   600/ 2983 batches | lr 20.00 | ms/batch 21.64 | loss  4.18 | ppl    65.11
| train-epoch  15 |   800/ 2983 batches | lr 20.00 | ms/batch 21.66 | loss  4.24 | ppl    69.35
| train-epoch  15 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.64 | loss  4.27 | ppl    71.75
| train-epoch  15 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.66 | loss  4.29 | ppl    72.69
| train-epoch  15 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.66 | loss  4.32 | ppl    75.37
| train-epoch  15 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.65 | loss  4.40 | ppl    81.37
| train-epoch  15 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.65 | loss  4.30 | ppl    73.98
| train-epoch  15 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.66 | loss  4.34 | ppl    76.86
| train-epoch  15 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.66 | loss  4.22 | ppl    68.27
| train-epoch  15 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.66 | loss  4.26 | ppl    70.94
| train-epoch  15 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.66 | loss  4.30 | ppl    73.55
| train-epoch  15 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.65 | loss  4.26 | ppl    71.01
-----------------------------------------------------------------------------------------
| end of train epoch  15 | time: 67.40s | valid loss  4.69 | valid ppl   108.36
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 22.26 | loss  4.31 | ppl    74.52
| prune-epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  4.33 | ppl    75.86
| prune-epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 21.72 | loss  4.16 | ppl    64.19
| prune-epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 21.72 | loss  4.21 | ppl    67.69
| prune-epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.72 | loss  4.25 | ppl    70.06
| prune-epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.72 | loss  4.26 | ppl    70.49
| prune-epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  4.29 | ppl    73.00
| prune-epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.69 | loss  4.36 | ppl    78.51
| prune-epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.72 | loss  4.26 | ppl    71.12
| prune-epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  4.30 | ppl    73.77
| prune-epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.72 | loss  4.18 | ppl    65.39
| prune-epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  4.22 | ppl    68.14
| prune-epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.25 | ppl    70.22
| prune-epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  4.21 | ppl    67.46
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.4  actual sp:  0.3984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.4  actual sp:  0.3984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.4  actual sp:  0.3984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.4  actual sp:  0.3984615384615384
-----------------------------------------------------------------------------------------
| end of prune epoch   1 | time: 67.68s | valid loss  4.68 | valid ppl   107.25
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch 22.38 | loss  4.26 | ppl    70.74
| prune-epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch 21.87 | loss  4.29 | ppl    72.63
| prune-epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch 21.85 | loss  4.12 | ppl    61.59
| prune-epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch 21.85 | loss  4.17 | ppl    64.98
| prune-epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.85 | loss  4.21 | ppl    67.16
| prune-epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.86 | loss  4.23 | ppl    68.47
| prune-epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.87 | loss  4.26 | ppl    70.64
| prune-epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.89 | loss  4.33 | ppl    75.98
| prune-epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.88 | loss  4.23 | ppl    68.58
| prune-epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.89 | loss  4.27 | ppl    71.43
| prune-epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.88 | loss  4.15 | ppl    63.53
| prune-epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.88 | loss  4.19 | ppl    65.98
| prune-epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.88 | loss  4.23 | ppl    68.44
| prune-epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.88 | loss  4.19 | ppl    65.90
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.4  actual sp:  0.3984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.4  actual sp:  0.3984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.4  actual sp:  0.3984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.4  actual sp:  0.3984615384615384
-----------------------------------------------------------------------------------------
| end of prune epoch   2 | time: 68.12s | valid loss  4.68 | valid ppl   107.54
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 22.30 | loss  4.25 | ppl    70.13
| prune-epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch 21.77 | loss  4.27 | ppl    71.21
| prune-epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.09 | ppl    59.83
| prune-epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.15 | ppl    63.32
| prune-epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.77 | loss  4.18 | ppl    65.49
| prune-epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.77 | loss  4.20 | ppl    66.92
| prune-epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.23 | ppl    69.00
| prune-epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.77 | loss  4.30 | ppl    73.94
| prune-epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.76 | loss  4.21 | ppl    67.40
| prune-epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.76 | loss  4.24 | ppl    69.65
| prune-epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.76 | loss  4.13 | ppl    61.99
| prune-epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.16 | ppl    64.01
| prune-epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.76 | loss  4.20 | ppl    66.62
| prune-epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.77 | loss  4.16 | ppl    63.97
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.5  actual sp:  0.4984615384615385
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.5  actual sp:  0.4984609467455622
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.5  actual sp:  0.4984615384615385
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.5  actual sp:  0.4984615384615385
-----------------------------------------------------------------------------------------
| end of prune epoch   3 | time: 67.80s | valid loss  4.67 | valid ppl   106.50
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   4 |   200/ 2983 batches | lr 20.00 | ms/batch 22.25 | loss  4.21 | ppl    67.33
| prune-epoch   4 |   400/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  4.23 | ppl    68.88
| prune-epoch   4 |   600/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  4.07 | ppl    58.29
| prune-epoch   4 |   800/ 2983 batches | lr 20.00 | ms/batch 21.72 | loss  4.12 | ppl    61.47
| prune-epoch   4 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  4.15 | ppl    63.64
| prune-epoch   4 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  4.17 | ppl    64.99
| prune-epoch   4 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  4.21 | ppl    67.12
| prune-epoch   4 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  4.27 | ppl    71.53
| prune-epoch   4 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.72 | loss  4.18 | ppl    65.67
| prune-epoch   4 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.22 | ppl    67.83
| prune-epoch   4 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  4.10 | ppl    60.17
| prune-epoch   4 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.72 | loss  4.14 | ppl    62.57
| prune-epoch   4 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  4.17 | ppl    64.78
| prune-epoch   4 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.68 | loss  4.13 | ppl    62.23
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.5  actual sp:  0.4984615384615385
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.5  actual sp:  0.4984615384615385
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.5  actual sp:  0.4984615384615385
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.5  actual sp:  0.4984615384615385
-----------------------------------------------------------------------------------------
| end of prune epoch   4 | time: 67.69s | valid loss  4.67 | valid ppl   107.06
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   5 |   200/ 2983 batches | lr 20.00 | ms/batch 22.39 | loss  4.21 | ppl    67.27
| prune-epoch   5 |   400/ 2983 batches | lr 20.00 | ms/batch 21.87 | loss  4.23 | ppl    68.78
| prune-epoch   5 |   600/ 2983 batches | lr 20.00 | ms/batch 21.86 | loss  4.05 | ppl    57.59
| prune-epoch   5 |   800/ 2983 batches | lr 20.00 | ms/batch 21.86 | loss  4.11 | ppl    60.76
| prune-epoch   5 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.87 | loss  4.14 | ppl    62.92
| prune-epoch   5 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.85 | loss  4.16 | ppl    64.02
| prune-epoch   5 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.85 | loss  4.19 | ppl    66.35
| prune-epoch   5 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.86 | loss  4.26 | ppl    71.01
| prune-epoch   5 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.87 | loss  4.17 | ppl    64.59
| prune-epoch   5 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.86 | loss  4.20 | ppl    66.87
| prune-epoch   5 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.86 | loss  4.08 | ppl    59.29
| prune-epoch   5 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.86 | loss  4.12 | ppl    61.34
| prune-epoch   5 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.86 | loss  4.16 | ppl    63.92
| prune-epoch   5 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.85 | loss  4.11 | ppl    61.08
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.6  actual sp:  0.5984615384615385
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.6  actual sp:  0.5984615384615385
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.6  actual sp:  0.5984615384615385
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.6  actual sp:  0.5984615384615385
-----------------------------------------------------------------------------------------
| end of prune epoch   5 | time: 68.09s | valid loss  4.68 | valid ppl   107.45
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   6 |   200/ 2983 batches | lr 20.00 | ms/batch 22.21 | loss  4.17 | ppl    64.86
| prune-epoch   6 |   400/ 2983 batches | lr 20.00 | ms/batch 21.72 | loss  4.20 | ppl    66.60
| prune-epoch   6 |   600/ 2983 batches | lr 20.00 | ms/batch 21.72 | loss  4.03 | ppl    56.15
| prune-epoch   6 |   800/ 2983 batches | lr 20.00 | ms/batch 21.72 | loss  4.08 | ppl    59.13
| prune-epoch   6 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  4.12 | ppl    61.39
| prune-epoch   6 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.78 | loss  4.13 | ppl    62.42
| prune-epoch   6 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.84 | loss  4.17 | ppl    64.39
| prune-epoch   6 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.83 | loss  4.23 | ppl    68.81
| prune-epoch   6 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.83 | loss  4.14 | ppl    62.77
| prune-epoch   6 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.82 | loss  4.18 | ppl    65.12
| prune-epoch   6 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.81 | loss  4.06 | ppl    57.75
| prune-epoch   6 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.80 | loss  4.10 | ppl    60.33
| prune-epoch   6 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.81 | loss  4.12 | ppl    61.84
| prune-epoch   6 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.82 | loss  4.09 | ppl    59.74
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.6  actual sp:  0.5984615384615385
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.6  actual sp:  0.5984615384615385
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.6  actual sp:  0.5984615384615385
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.6  actual sp:  0.5984615384615385
-----------------------------------------------------------------------------------------
| end of prune epoch   6 | time: 67.86s | valid loss  4.67 | valid ppl   106.63
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   7 |   200/ 2983 batches | lr 20.00 | ms/batch 22.35 | loss  4.14 | ppl    62.96
| prune-epoch   7 |   400/ 2983 batches | lr 20.00 | ms/batch 21.84 | loss  4.17 | ppl    64.81
| prune-epoch   7 |   600/ 2983 batches | lr 20.00 | ms/batch 21.86 | loss  4.01 | ppl    55.00
| prune-epoch   7 |   800/ 2983 batches | lr 20.00 | ms/batch 21.88 | loss  4.06 | ppl    57.86
| prune-epoch   7 |  1000/ 2983 batches | lr 20.00 | ms/batch 22.05 | loss  4.10 | ppl    60.19
| prune-epoch   7 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.88 | loss  4.11 | ppl    60.77
| prune-epoch   7 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.88 | loss  4.14 | ppl    62.76
| prune-epoch   7 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.88 | loss  4.21 | ppl    67.29
| prune-epoch   7 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.87 | loss  4.12 | ppl    61.69
| prune-epoch   7 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.88 | loss  4.15 | ppl    63.72
| prune-epoch   7 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.89 | loss  4.04 | ppl    56.76
| prune-epoch   7 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.89 | loss  4.08 | ppl    59.12
| prune-epoch   7 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.88 | loss  4.11 | ppl    60.75
| prune-epoch   7 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.85 | loss  4.08 | ppl    58.90
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.6  actual sp:  0.5984615384615385
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.6  actual sp:  0.5984615384615385
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.6  actual sp:  0.5984615384615385
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.6  actual sp:  0.5984615384615385
-----------------------------------------------------------------------------------------
| end of prune epoch   7 | time: 68.16s | valid loss  4.67 | valid ppl   106.83
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   8 |   200/ 2983 batches | lr 20.00 | ms/batch 22.22 | loss  4.16 | ppl    63.89
| prune-epoch   8 |   400/ 2983 batches | lr 20.00 | ms/batch 21.70 | loss  4.19 | ppl    65.89
| prune-epoch   8 |   600/ 2983 batches | lr 20.00 | ms/batch 21.69 | loss  4.01 | ppl    55.37
| prune-epoch   8 |   800/ 2983 batches | lr 20.00 | ms/batch 21.70 | loss  4.07 | ppl    58.28
| prune-epoch   8 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.70 | loss  4.11 | ppl    61.16
| prune-epoch   8 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.76 | loss  4.12 | ppl    61.77
| prune-epoch   8 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  4.15 | ppl    63.44
| prune-epoch   8 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.71 | loss  4.22 | ppl    67.73
| prune-epoch   8 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.72 | loss  4.12 | ppl    61.73
| prune-epoch   8 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.71 | loss  4.16 | ppl    63.84
| prune-epoch   8 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.71 | loss  4.04 | ppl    56.78
| prune-epoch   8 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.71 | loss  4.08 | ppl    58.86
| prune-epoch   8 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.69 | loss  4.11 | ppl    60.91
| prune-epoch   8 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.69 | loss  4.07 | ppl    58.51
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.7  actual sp:  0.696923076923077
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.7  actual sp:  0.696923076923077
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.7  actual sp:  0.696923076923077
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.7  actual sp:  0.696923076923077
-----------------------------------------------------------------------------------------
| end of prune epoch   8 | time: 67.65s | valid loss  4.66 | valid ppl   106.02
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   9 |   200/ 2983 batches | lr 20.00 | ms/batch 22.21 | loss  4.12 | ppl    61.54
| prune-epoch   9 |   400/ 2983 batches | lr 20.00 | ms/batch 21.72 | loss  4.15 | ppl    63.61
| prune-epoch   9 |   600/ 2983 batches | lr 20.00 | ms/batch 21.71 | loss  3.98 | ppl    53.52
| prune-epoch   9 |   800/ 2983 batches | lr 20.00 | ms/batch 21.72 | loss  4.03 | ppl    56.37
| prune-epoch   9 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.92 | loss  4.08 | ppl    58.94
| prune-epoch   9 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.90 | loss  4.10 | ppl    60.08
| prune-epoch   9 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.91 | loss  4.13 | ppl    61.90
| prune-epoch   9 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.92 | loss  4.19 | ppl    66.07
| prune-epoch   9 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.92 | loss  4.09 | ppl    60.04
| prune-epoch   9 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.92 | loss  4.13 | ppl    62.27
| prune-epoch   9 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.86 | loss  4.01 | ppl    55.35
| prune-epoch   9 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  4.05 | ppl    57.22
| prune-epoch   9 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.72 | loss  4.07 | ppl    58.82
| prune-epoch   9 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.72 | loss  4.04 | ppl    57.10
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.7  actual sp:  0.696923076923077
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.7  actual sp:  0.696923076923077
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.7  actual sp:  0.696923076923077
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.7  actual sp:  0.696923076923077
-----------------------------------------------------------------------------------------
| end of prune epoch   9 | time: 67.95s | valid loss  4.67 | valid ppl   107.22
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  10 |   200/ 2983 batches | lr 20.00 | ms/batch 22.40 | loss  4.20 | ppl    66.62
| prune-epoch  10 |   400/ 2983 batches | lr 20.00 | ms/batch 21.91 | loss  4.22 | ppl    67.82
| prune-epoch  10 |   600/ 2983 batches | lr 20.00 | ms/batch 21.92 | loss  4.04 | ppl    56.89
| prune-epoch  10 |   800/ 2983 batches | lr 20.00 | ms/batch 21.90 | loss  4.09 | ppl    59.79
| prune-epoch  10 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.92 | loss  4.14 | ppl    62.70
| prune-epoch  10 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.91 | loss  4.14 | ppl    62.87
| prune-epoch  10 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.91 | loss  4.17 | ppl    64.43
| prune-epoch  10 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.92 | loss  4.23 | ppl    68.86
| prune-epoch  10 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.91 | loss  4.14 | ppl    62.52
| prune-epoch  10 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.91 | loss  4.18 | ppl    65.17
| prune-epoch  10 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.93 | loss  4.05 | ppl    57.56
| prune-epoch  10 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.91 | loss  4.09 | ppl    59.64
| prune-epoch  10 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.91 | loss  4.12 | ppl    61.47
| prune-epoch  10 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.91 | loss  4.09 | ppl    59.87
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.7999999999999999  actual sp:  0.7984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.7999999999999999  actual sp:  0.7984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.7999999999999999  actual sp:  0.7984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.7999999999999999  actual sp:  0.7984615384615384
-----------------------------------------------------------------------------------------
| end of prune epoch  10 | time: 68.24s | valid loss  4.66 | valid ppl   105.89
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  11 |   200/ 2983 batches | lr 20.00 | ms/batch 22.12 | loss  4.14 | ppl    62.90
| prune-epoch  11 |   400/ 2983 batches | lr 20.00 | ms/batch 21.71 | loss  4.16 | ppl    64.32
| prune-epoch  11 |   600/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  4.00 | ppl    54.39
| prune-epoch  11 |   800/ 2983 batches | lr 20.00 | ms/batch 21.70 | loss  4.05 | ppl    57.18
| prune-epoch  11 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.70 | loss  4.09 | ppl    59.72
| prune-epoch  11 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.68 | loss  4.10 | ppl    60.29
| prune-epoch  11 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.70 | loss  4.14 | ppl    62.49
| prune-epoch  11 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.69 | loss  4.19 | ppl    66.33
| prune-epoch  11 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.71 | loss  4.11 | ppl    60.92
| prune-epoch  11 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  4.15 | ppl    63.40
| prune-epoch  11 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  4.02 | ppl    55.75
| prune-epoch  11 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  4.06 | ppl    58.04
| prune-epoch  11 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  4.09 | ppl    59.75
| prune-epoch  11 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.72 | loss  4.06 | ppl    58.17
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.7999999999999999  actual sp:  0.7984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.7999999999999999  actual sp:  0.7984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.7999999999999999  actual sp:  0.7984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.7999999999999999  actual sp:  0.7984615384615384
-----------------------------------------------------------------------------------------
| end of prune epoch  11 | time: 67.65s | valid loss  4.66 | valid ppl   106.01
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  12 |   200/ 2983 batches | lr 20.00 | ms/batch 22.20 | loss  4.19 | ppl    65.88
| prune-epoch  12 |   400/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.21 | ppl    67.20
| prune-epoch  12 |   600/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.04 | ppl    56.60
| prune-epoch  12 |   800/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.09 | ppl    59.50
| prune-epoch  12 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.13 | ppl    62.12
| prune-epoch  12 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.76 | loss  4.14 | ppl    62.60
| prune-epoch  12 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.76 | loss  4.16 | ppl    64.31
| prune-epoch  12 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.76 | loss  4.22 | ppl    68.20
| prune-epoch  12 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  4.13 | ppl    62.32
| prune-epoch  12 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.76 | loss  4.17 | ppl    65.01
| prune-epoch  12 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.81 | loss  4.05 | ppl    57.33
| prune-epoch  12 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.79 | loss  4.09 | ppl    59.53
| prune-epoch  12 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.12 | ppl    61.27
| prune-epoch  12 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.76 | loss  4.09 | ppl    59.58
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.85  actual sp:  0.8476923076923077
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.85  actual sp:  0.8476923076923077
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.85  actual sp:  0.8476923076923077
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.85  actual sp:  0.8476923076923077
-----------------------------------------------------------------------------------------
| end of prune epoch  12 | time: 67.78s | valid loss  4.67 | valid ppl   106.56
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  13 |   200/ 2983 batches | lr 20.00 | ms/batch 22.28 | loss  4.14 | ppl    62.54
| prune-epoch  13 |   400/ 2983 batches | lr 20.00 | ms/batch 21.87 | loss  4.16 | ppl    64.15
| prune-epoch  13 |   600/ 2983 batches | lr 20.00 | ms/batch 21.87 | loss  4.00 | ppl    54.43
| prune-epoch  13 |   800/ 2983 batches | lr 20.00 | ms/batch 21.86 | loss  4.05 | ppl    57.11
| prune-epoch  13 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.85 | loss  4.09 | ppl    59.54
| prune-epoch  13 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.87 | loss  4.11 | ppl    60.82
| prune-epoch  13 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.87 | loss  4.13 | ppl    62.18
| prune-epoch  13 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.86 | loss  4.19 | ppl    66.34
| prune-epoch  13 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.87 | loss  4.11 | ppl    60.76
| prune-epoch  13 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.87 | loss  4.15 | ppl    63.39
| prune-epoch  13 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.83 | loss  4.02 | ppl    55.83
| prune-epoch  13 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.82 | loss  4.06 | ppl    57.99
| prune-epoch  13 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.81 | loss  4.09 | ppl    59.83
| prune-epoch  13 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.81 | loss  4.06 | ppl    58.24
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.85  actual sp:  0.8476923076923077
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.85  actual sp:  0.8476923076923077
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.85  actual sp:  0.8476923076923077
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.85  actual sp:  0.8476923076923077
-----------------------------------------------------------------------------------------
| end of prune epoch  13 | time: 68.04s | valid loss  4.67 | valid ppl   106.62
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  14 |   200/ 2983 batches | lr 20.00 | ms/batch 22.16 | loss  4.26 | ppl    70.58
| prune-epoch  14 |   400/ 2983 batches | lr 20.00 | ms/batch 21.75 | loss  4.26 | ppl    70.71
| prune-epoch  14 |   600/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  4.09 | ppl    59.80
| prune-epoch  14 |   800/ 2983 batches | lr 20.00 | ms/batch 21.74 | loss  4.14 | ppl    62.88
| prune-epoch  14 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  4.18 | ppl    65.05
| prune-epoch  14 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  4.19 | ppl    66.03
| prune-epoch  14 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  4.21 | ppl    67.48
| prune-epoch  14 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  4.28 | ppl    71.89
| prune-epoch  14 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.82 | loss  4.18 | ppl    65.59
| prune-epoch  14 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.87 | loss  4.22 | ppl    67.71
| prune-epoch  14 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.88 | loss  4.10 | ppl    60.45
| prune-epoch  14 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.88 | loss  4.13 | ppl    62.01
| prune-epoch  14 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.88 | loss  4.17 | ppl    64.42
| prune-epoch  14 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.87 | loss  4.13 | ppl    62.29
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of prune epoch  14 | time: 67.89s | valid loss  4.69 | valid ppl   109.11
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 22.09 | loss  4.18 | ppl    65.51
| prune-epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 21.69 | loss  4.20 | ppl    66.85
| prune-epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 21.71 | loss  4.04 | ppl    56.98
| prune-epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 21.70 | loss  4.09 | ppl    59.81
| prune-epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.70 | loss  4.13 | ppl    62.32
| prune-epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.72 | loss  4.16 | ppl    63.76
| prune-epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.72 | loss  4.18 | ppl    65.28
| prune-epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.69 | loss  4.24 | ppl    69.15
| prune-epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.69 | loss  4.15 | ppl    63.45
| prune-epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.79 | loss  4.19 | ppl    65.81
| prune-epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.85 | loss  4.07 | ppl    58.42
| prune-epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.84 | loss  4.09 | ppl    59.86
| prune-epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.84 | loss  4.13 | ppl    62.10
| prune-epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.84 | loss  4.10 | ppl    60.29
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch   1 | time: 67.73s | valid loss  4.68 | valid ppl   107.54
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch 22.23 | loss  4.15 | ppl    63.55
| prune-epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch 21.85 | loss  4.18 | ppl    65.18
| prune-epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch 21.86 | loss  4.01 | ppl    55.22
| prune-epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch 21.85 | loss  4.07 | ppl    58.37
| prune-epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.85 | loss  4.11 | ppl    60.83
| prune-epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.84 | loss  4.12 | ppl    61.80
| prune-epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.85 | loss  4.15 | ppl    63.61
| prune-epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.84 | loss  4.21 | ppl    67.29
| prune-epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.85 | loss  4.13 | ppl    62.23
| prune-epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.86 | loss  4.16 | ppl    64.37
| prune-epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.86 | loss  4.04 | ppl    57.09
| prune-epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.84 | loss  4.08 | ppl    58.94
| prune-epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.85 | loss  4.11 | ppl    60.99
| prune-epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.86 | loss  4.08 | ppl    59.20
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch   2 | time: 68.04s | valid loss  4.67 | valid ppl   107.02
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 22.12 | loss  4.14 | ppl    62.56
| prune-epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  4.15 | ppl    63.72
| prune-epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 21.72 | loss  3.99 | ppl    54.28
| prune-epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 21.73 | loss  4.05 | ppl    57.51
| prune-epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.78 | loss  4.09 | ppl    59.87
| prune-epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.86 | loss  4.11 | ppl    60.65
| prune-epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.85 | loss  4.13 | ppl    62.16
| prune-epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.87 | loss  4.19 | ppl    66.18
| prune-epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.88 | loss  4.11 | ppl    60.93
| prune-epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.87 | loss  4.15 | ppl    63.25
| prune-epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.87 | loss  4.03 | ppl    55.98
| prune-epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.89 | loss  4.06 | ppl    57.95
| prune-epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.89 | loss  4.10 | ppl    60.22
| prune-epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.92 | loss  4.06 | ppl    58.16
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch   3 | time: 67.98s | valid loss  4.69 | valid ppl   108.60
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   4 |   200/ 2983 batches | lr 20.00 | ms/batch 22.23 | loss  4.12 | ppl    61.36
| prune-epoch   4 |   400/ 2983 batches | lr 20.00 | ms/batch 21.82 | loss  4.14 | ppl    62.90
| prune-epoch   4 |   600/ 2983 batches | lr 20.00 | ms/batch 21.83 | loss  3.97 | ppl    53.11
| prune-epoch   4 |   800/ 2983 batches | lr 20.00 | ms/batch 21.83 | loss  4.03 | ppl    56.23
| prune-epoch   4 |  1000/ 2983 batches | lr 20.00 | ms/batch 21.83 | loss  4.08 | ppl    58.87
| prune-epoch   4 |  1200/ 2983 batches | lr 20.00 | ms/batch 21.84 | loss  4.09 | ppl    59.98
| prune-epoch   4 |  1400/ 2983 batches | lr 20.00 | ms/batch 21.82 | loss  4.11 | ppl    61.15
| prune-epoch   4 |  1600/ 2983 batches | lr 20.00 | ms/batch 21.82 | loss  4.18 | ppl    65.19
| prune-epoch   4 |  1800/ 2983 batches | lr 20.00 | ms/batch 21.79 | loss  4.10 | ppl    60.12
| prune-epoch   4 |  2000/ 2983 batches | lr 20.00 | ms/batch 21.82 | loss  4.13 | ppl    62.27
| prune-epoch   4 |  2200/ 2983 batches | lr 20.00 | ms/batch 21.81 | loss  4.01 | ppl    55.09
| prune-epoch   4 |  2400/ 2983 batches | lr 20.00 | ms/batch 21.81 | loss  4.04 | ppl    56.85
| prune-epoch   4 |  2600/ 2983 batches | lr 20.00 | ms/batch 21.81 | loss  4.08 | ppl    59.36
| prune-epoch   4 |  2800/ 2983 batches | lr 20.00 | ms/batch 21.79 | loss  4.06 | ppl    57.78
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch   4 | time: 67.95s | valid loss  4.70 | valid ppl   110.01
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   5 |   200/ 2983 batches | lr 10.00 | ms/batch 22.08 | loss  4.10 | ppl    60.48
| prune-epoch   5 |   400/ 2983 batches | lr 10.00 | ms/batch 21.70 | loss  4.11 | ppl    61.19
| prune-epoch   5 |   600/ 2983 batches | lr 10.00 | ms/batch 21.69 | loss  3.94 | ppl    51.51
| prune-epoch   5 |   800/ 2983 batches | lr 10.00 | ms/batch 21.70 | loss  3.99 | ppl    54.01
| prune-epoch   5 |  1000/ 2983 batches | lr 10.00 | ms/batch 21.70 | loss  4.03 | ppl    56.09
| prune-epoch   5 |  1200/ 2983 batches | lr 10.00 | ms/batch 21.71 | loss  4.03 | ppl    56.35
| prune-epoch   5 |  1400/ 2983 batches | lr 10.00 | ms/batch 21.70 | loss  4.05 | ppl    57.32
| prune-epoch   5 |  1600/ 2983 batches | lr 10.00 | ms/batch 21.70 | loss  4.10 | ppl    60.50
| prune-epoch   5 |  1800/ 2983 batches | lr 10.00 | ms/batch 21.71 | loss  4.02 | ppl    55.94
| prune-epoch   5 |  2000/ 2983 batches | lr 10.00 | ms/batch 21.71 | loss  4.06 | ppl    57.85
| prune-epoch   5 |  2200/ 2983 batches | lr 10.00 | ms/batch 21.72 | loss  3.93 | ppl    50.81
| prune-epoch   5 |  2400/ 2983 batches | lr 10.00 | ms/batch 21.69 | loss  3.95 | ppl    51.94
| prune-epoch   5 |  2600/ 2983 batches | lr 10.00 | ms/batch 21.71 | loss  3.99 | ppl    54.21
| prune-epoch   5 |  2800/ 2983 batches | lr 10.00 | ms/batch 21.71 | loss  3.96 | ppl    52.24
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch   5 | time: 67.60s | valid loss  4.65 | valid ppl   104.69
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   6 |   200/ 2983 batches | lr 10.00 | ms/batch 22.11 | loss  4.05 | ppl    57.27
| prune-epoch   6 |   400/ 2983 batches | lr 10.00 | ms/batch 21.71 | loss  4.07 | ppl    58.71
| prune-epoch   6 |   600/ 2983 batches | lr 10.00 | ms/batch 21.72 | loss  3.90 | ppl    49.63
| prune-epoch   6 |   800/ 2983 batches | lr 10.00 | ms/batch 21.71 | loss  3.95 | ppl    51.91
| prune-epoch   6 |  1000/ 2983 batches | lr 10.00 | ms/batch 21.72 | loss  3.99 | ppl    54.18
| prune-epoch   6 |  1200/ 2983 batches | lr 10.00 | ms/batch 21.73 | loss  4.01 | ppl    54.97
| prune-epoch   6 |  1400/ 2983 batches | lr 10.00 | ms/batch 21.70 | loss  4.03 | ppl    56.32
| prune-epoch   6 |  1600/ 2983 batches | lr 10.00 | ms/batch 21.71 | loss  4.09 | ppl    59.52
| prune-epoch   6 |  1800/ 2983 batches | lr 10.00 | ms/batch 21.70 | loss  4.00 | ppl    54.85
| prune-epoch   6 |  2000/ 2983 batches | lr 10.00 | ms/batch 21.71 | loss  4.04 | ppl    56.58
| prune-epoch   6 |  2200/ 2983 batches | lr 10.00 | ms/batch 21.70 | loss  3.91 | ppl    50.08
| prune-epoch   6 |  2400/ 2983 batches | lr 10.00 | ms/batch 21.71 | loss  3.94 | ppl    51.63
| prune-epoch   6 |  2600/ 2983 batches | lr 10.00 | ms/batch 21.78 | loss  3.97 | ppl    53.04
| prune-epoch   6 |  2800/ 2983 batches | lr 10.00 | ms/batch 21.72 | loss  3.95 | ppl    51.81
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch   6 | time: 67.64s | valid loss  4.65 | valid ppl   104.84
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   7 |   200/ 2983 batches | lr 10.00 | ms/batch 22.26 | loss  4.03 | ppl    56.21
| prune-epoch   7 |   400/ 2983 batches | lr 10.00 | ms/batch 21.88 | loss  4.05 | ppl    57.30
| prune-epoch   7 |   600/ 2983 batches | lr 10.00 | ms/batch 21.88 | loss  3.88 | ppl    48.48
| prune-epoch   7 |   800/ 2983 batches | lr 10.00 | ms/batch 21.86 | loss  3.93 | ppl    51.04
| prune-epoch   7 |  1000/ 2983 batches | lr 10.00 | ms/batch 21.85 | loss  3.98 | ppl    53.75
| prune-epoch   7 |  1200/ 2983 batches | lr 10.00 | ms/batch 21.88 | loss  3.99 | ppl    54.22
| prune-epoch   7 |  1400/ 2983 batches | lr 10.00 | ms/batch 21.87 | loss  4.01 | ppl    55.24
| prune-epoch   7 |  1600/ 2983 batches | lr 10.00 | ms/batch 21.87 | loss  4.07 | ppl    58.58
| prune-epoch   7 |  1800/ 2983 batches | lr 10.00 | ms/batch 21.86 | loss  3.99 | ppl    54.05
| prune-epoch   7 |  2000/ 2983 batches | lr 10.00 | ms/batch 21.86 | loss  4.03 | ppl    56.13
| prune-epoch   7 |  2200/ 2983 batches | lr 10.00 | ms/batch 21.88 | loss  3.90 | ppl    49.37
| prune-epoch   7 |  2400/ 2983 batches | lr 10.00 | ms/batch 21.87 | loss  3.93 | ppl    50.74
| prune-epoch   7 |  2600/ 2983 batches | lr 10.00 | ms/batch 21.87 | loss  3.97 | ppl    52.81
| prune-epoch   7 |  2800/ 2983 batches | lr 10.00 | ms/batch 21.85 | loss  3.94 | ppl    51.24
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch   7 | time: 68.09s | valid loss  4.64 | valid ppl   104.04
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   8 |   200/ 2983 batches | lr 10.00 | ms/batch 22.05 | loss  4.01 | ppl    55.18
| prune-epoch   8 |   400/ 2983 batches | lr 10.00 | ms/batch 21.67 | loss  4.04 | ppl    56.67
| prune-epoch   8 |   600/ 2983 batches | lr 10.00 | ms/batch 21.66 | loss  3.87 | ppl    48.09
| prune-epoch   8 |   800/ 2983 batches | lr 10.00 | ms/batch 21.66 | loss  3.92 | ppl    50.43
| prune-epoch   8 |  1000/ 2983 batches | lr 10.00 | ms/batch 21.65 | loss  3.97 | ppl    52.87
| prune-epoch   8 |  1200/ 2983 batches | lr 10.00 | ms/batch 21.66 | loss  3.98 | ppl    53.55
| prune-epoch   8 |  1400/ 2983 batches | lr 10.00 | ms/batch 21.69 | loss  4.00 | ppl    54.84
| prune-epoch   8 |  1600/ 2983 batches | lr 10.00 | ms/batch 21.68 | loss  4.06 | ppl    57.99
| prune-epoch   8 |  1800/ 2983 batches | lr 10.00 | ms/batch 21.63 | loss  3.98 | ppl    53.59
| prune-epoch   8 |  2000/ 2983 batches | lr 10.00 | ms/batch 21.62 | loss  4.01 | ppl    55.40
| prune-epoch   8 |  2200/ 2983 batches | lr 10.00 | ms/batch 21.80 | loss  3.89 | ppl    48.76
| prune-epoch   8 |  2400/ 2983 batches | lr 10.00 | ms/batch 21.69 | loss  3.92 | ppl    50.37
| prune-epoch   8 |  2600/ 2983 batches | lr 10.00 | ms/batch 21.65 | loss  3.96 | ppl    52.21
| prune-epoch   8 |  2800/ 2983 batches | lr 10.00 | ms/batch 21.66 | loss  3.93 | ppl    50.94
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch   8 | time: 67.49s | valid loss  4.65 | valid ppl   104.64
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   9 |   200/ 2983 batches | lr 5.00 | ms/batch 22.09 | loss  4.01 | ppl    55.31
| prune-epoch   9 |   400/ 2983 batches | lr 5.00 | ms/batch 21.70 | loss  4.03 | ppl    56.04
| prune-epoch   9 |   600/ 2983 batches | lr 5.00 | ms/batch 21.70 | loss  3.87 | ppl    47.77
| prune-epoch   9 |   800/ 2983 batches | lr 5.00 | ms/batch 21.69 | loss  3.91 | ppl    49.73
| prune-epoch   9 |  1000/ 2983 batches | lr 5.00 | ms/batch 21.70 | loss  3.95 | ppl    51.91
| prune-epoch   9 |  1200/ 2983 batches | lr 5.00 | ms/batch 21.70 | loss  3.95 | ppl    52.04
| prune-epoch   9 |  1400/ 2983 batches | lr 5.00 | ms/batch 21.71 | loss  3.98 | ppl    53.58
| prune-epoch   9 |  1600/ 2983 batches | lr 5.00 | ms/batch 21.74 | loss  4.03 | ppl    56.06
| prune-epoch   9 |  1800/ 2983 batches | lr 5.00 | ms/batch 21.71 | loss  3.95 | ppl    52.08
| prune-epoch   9 |  2000/ 2983 batches | lr 5.00 | ms/batch 21.70 | loss  3.98 | ppl    53.74
| prune-epoch   9 |  2200/ 2983 batches | lr 5.00 | ms/batch 21.69 | loss  3.86 | ppl    47.36
| prune-epoch   9 |  2400/ 2983 batches | lr 5.00 | ms/batch 21.69 | loss  3.89 | ppl    48.69
| prune-epoch   9 |  2600/ 2983 batches | lr 5.00 | ms/batch 21.69 | loss  3.92 | ppl    50.23
| prune-epoch   9 |  2800/ 2983 batches | lr 5.00 | ms/batch 21.68 | loss  3.89 | ppl    48.89
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch   9 | time: 67.58s | valid loss  4.62 | valid ppl   101.71
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  10 |   200/ 2983 batches | lr 5.00 | ms/batch 22.26 | loss  3.98 | ppl    53.67
| prune-epoch  10 |   400/ 2983 batches | lr 5.00 | ms/batch 21.87 | loss  4.01 | ppl    54.98
| prune-epoch  10 |   600/ 2983 batches | lr 5.00 | ms/batch 21.85 | loss  3.84 | ppl    46.71
| prune-epoch  10 |   800/ 2983 batches | lr 5.00 | ms/batch 21.87 | loss  3.88 | ppl    48.58
| prune-epoch  10 |  1000/ 2983 batches | lr 5.00 | ms/batch 21.87 | loss  3.94 | ppl    51.47
| prune-epoch  10 |  1200/ 2983 batches | lr 5.00 | ms/batch 21.87 | loss  3.94 | ppl    51.40
| prune-epoch  10 |  1400/ 2983 batches | lr 5.00 | ms/batch 21.87 | loss  3.97 | ppl    52.89
| prune-epoch  10 |  1600/ 2983 batches | lr 5.00 | ms/batch 21.87 | loss  4.02 | ppl    55.53
| prune-epoch  10 |  1800/ 2983 batches | lr 5.00 | ms/batch 21.87 | loss  3.94 | ppl    51.49
| prune-epoch  10 |  2000/ 2983 batches | lr 5.00 | ms/batch 21.84 | loss  3.98 | ppl    53.46
| prune-epoch  10 |  2200/ 2983 batches | lr 5.00 | ms/batch 21.87 | loss  3.85 | ppl    46.82
| prune-epoch  10 |  2400/ 2983 batches | lr 5.00 | ms/batch 21.85 | loss  3.88 | ppl    48.42
| prune-epoch  10 |  2600/ 2983 batches | lr 5.00 | ms/batch 21.86 | loss  3.91 | ppl    49.89
| prune-epoch  10 |  2800/ 2983 batches | lr 5.00 | ms/batch 21.88 | loss  3.88 | ppl    48.51
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  10 | time: 68.08s | valid loss  4.62 | valid ppl   101.94
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  11 |   200/ 2983 batches | lr 5.00 | ms/batch 22.06 | loss  3.98 | ppl    53.37
| prune-epoch  11 |   400/ 2983 batches | lr 5.00 | ms/batch 21.67 | loss  3.99 | ppl    54.29
| prune-epoch  11 |   600/ 2983 batches | lr 5.00 | ms/batch 21.76 | loss  3.83 | ppl    45.98
| prune-epoch  11 |   800/ 2983 batches | lr 5.00 | ms/batch 21.79 | loss  3.88 | ppl    48.46
| prune-epoch  11 |  1000/ 2983 batches | lr 5.00 | ms/batch 21.80 | loss  3.93 | ppl    50.81
| prune-epoch  11 |  1200/ 2983 batches | lr 5.00 | ms/batch 21.79 | loss  3.93 | ppl    51.14
| prune-epoch  11 |  1400/ 2983 batches | lr 5.00 | ms/batch 21.80 | loss  3.96 | ppl    52.32
| prune-epoch  11 |  1600/ 2983 batches | lr 5.00 | ms/batch 21.80 | loss  4.01 | ppl    54.91
| prune-epoch  11 |  1800/ 2983 batches | lr 5.00 | ms/batch 21.79 | loss  3.94 | ppl    51.18
| prune-epoch  11 |  2000/ 2983 batches | lr 5.00 | ms/batch 21.78 | loss  3.97 | ppl    52.99
| prune-epoch  11 |  2200/ 2983 batches | lr 5.00 | ms/batch 21.80 | loss  3.84 | ppl    46.67
| prune-epoch  11 |  2400/ 2983 batches | lr 5.00 | ms/batch 21.81 | loss  3.87 | ppl    47.98
| prune-epoch  11 |  2600/ 2983 batches | lr 5.00 | ms/batch 21.80 | loss  3.91 | ppl    49.90
| prune-epoch  11 |  2800/ 2983 batches | lr 5.00 | ms/batch 21.79 | loss  3.88 | ppl    48.44
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  11 | time: 67.81s | valid loss  4.62 | valid ppl   101.64
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  12 |   200/ 2983 batches | lr 5.00 | ms/batch 22.09 | loss  3.97 | ppl    52.79
| prune-epoch  12 |   400/ 2983 batches | lr 5.00 | ms/batch 21.67 | loss  3.98 | ppl    53.77
| prune-epoch  12 |   600/ 2983 batches | lr 5.00 | ms/batch 21.70 | loss  3.83 | ppl    45.95
| prune-epoch  12 |   800/ 2983 batches | lr 5.00 | ms/batch 21.68 | loss  3.87 | ppl    48.13
| prune-epoch  12 |  1000/ 2983 batches | lr 5.00 | ms/batch 21.68 | loss  3.92 | ppl    50.33
| prune-epoch  12 |  1200/ 2983 batches | lr 5.00 | ms/batch 21.69 | loss  3.93 | ppl    50.93
| prune-epoch  12 |  1400/ 2983 batches | lr 5.00 | ms/batch 21.67 | loss  3.95 | ppl    52.19
| prune-epoch  12 |  1600/ 2983 batches | lr 5.00 | ms/batch 21.68 | loss  4.00 | ppl    54.51
| prune-epoch  12 |  1800/ 2983 batches | lr 5.00 | ms/batch 21.69 | loss  3.92 | ppl    50.62
| prune-epoch  12 |  2000/ 2983 batches | lr 5.00 | ms/batch 21.68 | loss  3.96 | ppl    52.70
| prune-epoch  12 |  2200/ 2983 batches | lr 5.00 | ms/batch 21.68 | loss  3.84 | ppl    46.37
| prune-epoch  12 |  2400/ 2983 batches | lr 5.00 | ms/batch 21.84 | loss  3.86 | ppl    47.48
| prune-epoch  12 |  2600/ 2983 batches | lr 5.00 | ms/batch 21.69 | loss  3.90 | ppl    49.51
| prune-epoch  12 |  2800/ 2983 batches | lr 5.00 | ms/batch 21.69 | loss  3.87 | ppl    48.11
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  12 | time: 67.57s | valid loss  4.62 | valid ppl   101.76
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  13 |   200/ 2983 batches | lr 2.50 | ms/batch 22.19 | loss  3.98 | ppl    53.36
| prune-epoch  13 |   400/ 2983 batches | lr 2.50 | ms/batch 21.80 | loss  4.00 | ppl    54.42
| prune-epoch  13 |   600/ 2983 batches | lr 2.50 | ms/batch 21.81 | loss  3.84 | ppl    46.41
| prune-epoch  13 |   800/ 2983 batches | lr 2.50 | ms/batch 21.82 | loss  3.88 | ppl    48.36
| prune-epoch  13 |  1000/ 2983 batches | lr 2.50 | ms/batch 21.81 | loss  3.92 | ppl    50.40
| prune-epoch  13 |  1200/ 2983 batches | lr 2.50 | ms/batch 21.82 | loss  3.93 | ppl    50.96
| prune-epoch  13 |  1400/ 2983 batches | lr 2.50 | ms/batch 21.82 | loss  3.95 | ppl    51.96
| prune-epoch  13 |  1600/ 2983 batches | lr 2.50 | ms/batch 21.82 | loss  4.00 | ppl    54.47
| prune-epoch  13 |  1800/ 2983 batches | lr 2.50 | ms/batch 21.81 | loss  3.92 | ppl    50.53
| prune-epoch  13 |  2000/ 2983 batches | lr 2.50 | ms/batch 21.81 | loss  3.96 | ppl    52.52
| prune-epoch  13 |  2200/ 2983 batches | lr 2.50 | ms/batch 21.98 | loss  3.83 | ppl    46.07
| prune-epoch  13 |  2400/ 2983 batches | lr 2.50 | ms/batch 22.02 | loss  3.85 | ppl    47.09
| prune-epoch  13 |  2600/ 2983 batches | lr 2.50 | ms/batch 22.03 | loss  3.89 | ppl    48.87
| prune-epoch  13 |  2800/ 2983 batches | lr 2.50 | ms/batch 22.03 | loss  3.86 | ppl    47.56
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  13 | time: 68.13s | valid loss  4.61 | valid ppl   100.95
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  14 |   200/ 2983 batches | lr 2.50 | ms/batch 22.41 | loss  3.96 | ppl    52.53
| prune-epoch  14 |   400/ 2983 batches | lr 2.50 | ms/batch 22.03 | loss  3.98 | ppl    53.57
| prune-epoch  14 |   600/ 2983 batches | lr 2.50 | ms/batch 22.03 | loss  3.82 | ppl    45.64
| prune-epoch  14 |   800/ 2983 batches | lr 2.50 | ms/batch 22.02 | loss  3.86 | ppl    47.62
| prune-epoch  14 |  1000/ 2983 batches | lr 2.50 | ms/batch 22.02 | loss  3.91 | ppl    50.11
| prune-epoch  14 |  1200/ 2983 batches | lr 2.50 | ms/batch 22.01 | loss  3.92 | ppl    50.38
| prune-epoch  14 |  1400/ 2983 batches | lr 2.50 | ms/batch 22.01 | loss  3.95 | ppl    51.72
| prune-epoch  14 |  1600/ 2983 batches | lr 2.50 | ms/batch 22.03 | loss  3.99 | ppl    54.10
| prune-epoch  14 |  1800/ 2983 batches | lr 2.50 | ms/batch 22.04 | loss  3.92 | ppl    50.45
| prune-epoch  14 |  2000/ 2983 batches | lr 2.50 | ms/batch 22.02 | loss  3.96 | ppl    52.21
| prune-epoch  14 |  2200/ 2983 batches | lr 2.50 | ms/batch 22.03 | loss  3.83 | ppl    46.07
| prune-epoch  14 |  2400/ 2983 batches | lr 2.50 | ms/batch 22.02 | loss  3.85 | ppl    47.12
| prune-epoch  14 |  2600/ 2983 batches | lr 2.50 | ms/batch 22.04 | loss  3.89 | ppl    48.85
| prune-epoch  14 |  2800/ 2983 batches | lr 2.50 | ms/batch 22.04 | loss  3.86 | ppl    47.40
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  14 | time: 68.58s | valid loss  4.61 | valid ppl   100.82
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  15 |   200/ 2983 batches | lr 2.50 | ms/batch 22.36 | loss  3.95 | ppl    52.01
| prune-epoch  15 |   400/ 2983 batches | lr 2.50 | ms/batch 21.98 | loss  3.98 | ppl    53.38
| prune-epoch  15 |   600/ 2983 batches | lr 2.50 | ms/batch 21.81 | loss  3.81 | ppl    45.10
| prune-epoch  15 |   800/ 2983 batches | lr 2.50 | ms/batch 21.80 | loss  3.86 | ppl    47.64
| prune-epoch  15 |  1000/ 2983 batches | lr 2.50 | ms/batch 21.81 | loss  3.91 | ppl    49.88
| prune-epoch  15 |  1200/ 2983 batches | lr 2.50 | ms/batch 21.81 | loss  3.92 | ppl    50.26
| prune-epoch  15 |  1400/ 2983 batches | lr 2.50 | ms/batch 21.81 | loss  3.94 | ppl    51.50
| prune-epoch  15 |  1600/ 2983 batches | lr 2.50 | ms/batch 21.80 | loss  3.99 | ppl    53.81
| prune-epoch  15 |  1800/ 2983 batches | lr 2.50 | ms/batch 21.81 | loss  3.91 | ppl    49.73
| prune-epoch  15 |  2000/ 2983 batches | lr 2.50 | ms/batch 21.80 | loss  3.95 | ppl    52.07
| prune-epoch  15 |  2200/ 2983 batches | lr 2.50 | ms/batch 21.79 | loss  3.82 | ppl    45.71
| prune-epoch  15 |  2400/ 2983 batches | lr 2.50 | ms/batch 21.79 | loss  3.85 | ppl    46.90
| prune-epoch  15 |  2600/ 2983 batches | lr 2.50 | ms/batch 21.81 | loss  3.89 | ppl    48.78
| prune-epoch  15 |  2800/ 2983 batches | lr 2.50 | ms/batch 21.82 | loss  3.85 | ppl    47.18
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  15 | time: 67.97s | valid loss  4.61 | valid ppl   100.54
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  16 |   200/ 2983 batches | lr 2.50 | ms/batch 22.07 | loss  3.95 | ppl    51.87
| prune-epoch  16 |   400/ 2983 batches | lr 2.50 | ms/batch 21.68 | loss  3.98 | ppl    53.29
| prune-epoch  16 |   600/ 2983 batches | lr 2.50 | ms/batch 21.68 | loss  3.81 | ppl    45.12
| prune-epoch  16 |   800/ 2983 batches | lr 2.50 | ms/batch 21.74 | loss  3.86 | ppl    47.46
| prune-epoch  16 |  1000/ 2983 batches | lr 2.50 | ms/batch 21.84 | loss  3.91 | ppl    49.73
| prune-epoch  16 |  1200/ 2983 batches | lr 2.50 | ms/batch 21.82 | loss  3.91 | ppl    49.85
| prune-epoch  16 |  1400/ 2983 batches | lr 2.50 | ms/batch 21.83 | loss  3.94 | ppl    51.20
| prune-epoch  16 |  1600/ 2983 batches | lr 2.50 | ms/batch 21.83 | loss  3.99 | ppl    53.84
| prune-epoch  16 |  1800/ 2983 batches | lr 2.50 | ms/batch 21.83 | loss  3.91 | ppl    49.75
| prune-epoch  16 |  2000/ 2983 batches | lr 2.50 | ms/batch 21.83 | loss  3.95 | ppl    51.97
| prune-epoch  16 |  2200/ 2983 batches | lr 2.50 | ms/batch 21.83 | loss  3.82 | ppl    45.65
| prune-epoch  16 |  2400/ 2983 batches | lr 2.50 | ms/batch 21.84 | loss  3.84 | ppl    46.72
| prune-epoch  16 |  2600/ 2983 batches | lr 2.50 | ms/batch 21.85 | loss  3.88 | ppl    48.41
| prune-epoch  16 |  2800/ 2983 batches | lr 2.50 | ms/batch 21.84 | loss  3.85 | ppl    47.13
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  16 | time: 67.88s | valid loss  4.61 | valid ppl   100.73
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  17 |   200/ 2983 batches | lr 2.50 | ms/batch 22.10 | loss  3.94 | ppl    51.59
| prune-epoch  17 |   400/ 2983 batches | lr 2.50 | ms/batch 21.70 | loss  3.97 | ppl    52.98
| prune-epoch  17 |   600/ 2983 batches | lr 2.50 | ms/batch 21.72 | loss  3.80 | ppl    44.76
| prune-epoch  17 |   800/ 2983 batches | lr 2.50 | ms/batch 21.72 | loss  3.85 | ppl    47.08
| prune-epoch  17 |  1000/ 2983 batches | lr 2.50 | ms/batch 21.72 | loss  3.90 | ppl    49.52
| prune-epoch  17 |  1200/ 2983 batches | lr 2.50 | ms/batch 21.71 | loss  3.91 | ppl    49.66
| prune-epoch  17 |  1400/ 2983 batches | lr 2.50 | ms/batch 21.73 | loss  3.93 | ppl    50.83
| prune-epoch  17 |  1600/ 2983 batches | lr 2.50 | ms/batch 21.71 | loss  3.98 | ppl    53.54
| prune-epoch  17 |  1800/ 2983 batches | lr 2.50 | ms/batch 21.72 | loss  3.90 | ppl    49.57
| prune-epoch  17 |  2000/ 2983 batches | lr 2.50 | ms/batch 21.73 | loss  3.95 | ppl    51.94
| prune-epoch  17 |  2200/ 2983 batches | lr 2.50 | ms/batch 21.71 | loss  3.81 | ppl    45.30
| prune-epoch  17 |  2400/ 2983 batches | lr 2.50 | ms/batch 21.72 | loss  3.85 | ppl    46.77
| prune-epoch  17 |  2600/ 2983 batches | lr 2.50 | ms/batch 21.70 | loss  3.88 | ppl    48.65
| prune-epoch  17 |  2800/ 2983 batches | lr 2.50 | ms/batch 21.69 | loss  3.86 | ppl    47.24
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  17 | time: 67.62s | valid loss  4.61 | valid ppl   100.87
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  18 |   200/ 2983 batches | lr 1.25 | ms/batch 22.22 | loss  3.96 | ppl    52.33
| prune-epoch  18 |   400/ 2983 batches | lr 1.25 | ms/batch 21.87 | loss  3.98 | ppl    53.73
| prune-epoch  18 |   600/ 2983 batches | lr 1.25 | ms/batch 21.89 | loss  3.81 | ppl    45.27
| prune-epoch  18 |   800/ 2983 batches | lr 1.25 | ms/batch 21.87 | loss  3.87 | ppl    47.79
| prune-epoch  18 |  1000/ 2983 batches | lr 1.25 | ms/batch 21.86 | loss  3.93 | ppl    50.81
| prune-epoch  18 |  1200/ 2983 batches | lr 1.25 | ms/batch 21.87 | loss  3.92 | ppl    50.30
| prune-epoch  18 |  1400/ 2983 batches | lr 1.25 | ms/batch 21.85 | loss  3.94 | ppl    51.50
| prune-epoch  18 |  1600/ 2983 batches | lr 1.25 | ms/batch 21.88 | loss  4.00 | ppl    54.65
| prune-epoch  18 |  1800/ 2983 batches | lr 1.25 | ms/batch 21.86 | loss  3.90 | ppl    49.51
| prune-epoch  18 |  2000/ 2983 batches | lr 1.25 | ms/batch 21.87 | loss  3.96 | ppl    52.48
| prune-epoch  18 |  2200/ 2983 batches | lr 1.25 | ms/batch 21.87 | loss  3.82 | ppl    45.69
| prune-epoch  18 |  2400/ 2983 batches | lr 1.25 | ms/batch 21.87 | loss  3.84 | ppl    46.58
| prune-epoch  18 |  2600/ 2983 batches | lr 1.25 | ms/batch 21.88 | loss  3.88 | ppl    48.59
| prune-epoch  18 |  2800/ 2983 batches | lr 1.25 | ms/batch 21.87 | loss  3.86 | ppl    47.36
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  18 | time: 68.09s | valid loss  4.60 | valid ppl    99.33
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  19 |   200/ 2983 batches | lr 1.25 | ms/batch 22.28 | loss  3.96 | ppl    52.26
| prune-epoch  19 |   400/ 2983 batches | lr 1.25 | ms/batch 21.92 | loss  3.98 | ppl    53.54
| prune-epoch  19 |   600/ 2983 batches | lr 1.25 | ms/batch 21.91 | loss  3.80 | ppl    44.77
| prune-epoch  19 |   800/ 2983 batches | lr 1.25 | ms/batch 21.91 | loss  3.86 | ppl    47.55
| prune-epoch  19 |  1000/ 2983 batches | lr 1.25 | ms/batch 21.86 | loss  3.91 | ppl    50.03
| prune-epoch  19 |  1200/ 2983 batches | lr 1.25 | ms/batch 21.85 | loss  3.92 | ppl    50.23
| prune-epoch  19 |  1400/ 2983 batches | lr 1.25 | ms/batch 21.83 | loss  3.94 | ppl    51.53
| prune-epoch  19 |  1600/ 2983 batches | lr 1.25 | ms/batch 21.84 | loss  3.99 | ppl    54.25
| prune-epoch  19 |  1800/ 2983 batches | lr 1.25 | ms/batch 21.82 | loss  3.89 | ppl    49.11
| prune-epoch  19 |  2000/ 2983 batches | lr 1.25 | ms/batch 21.83 | loss  3.95 | ppl    51.91
| prune-epoch  19 |  2200/ 2983 batches | lr 1.25 | ms/batch 21.83 | loss  3.82 | ppl    45.46
| prune-epoch  19 |  2400/ 2983 batches | lr 1.25 | ms/batch 21.82 | loss  3.84 | ppl    46.73
| prune-epoch  19 |  2600/ 2983 batches | lr 1.25 | ms/batch 21.82 | loss  3.88 | ppl    48.60
| prune-epoch  19 |  2800/ 2983 batches | lr 1.25 | ms/batch 21.83 | loss  3.85 | ppl    47.21
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  19 | time: 68.04s | valid loss  4.60 | valid ppl    99.12
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  20 |   200/ 2983 batches | lr 1.25 | ms/batch 22.19 | loss  3.95 | ppl    52.10
| prune-epoch  20 |   400/ 2983 batches | lr 1.25 | ms/batch 21.83 | loss  3.98 | ppl    53.47
| prune-epoch  20 |   600/ 2983 batches | lr 1.25 | ms/batch 21.82 | loss  3.80 | ppl    44.89
| prune-epoch  20 |   800/ 2983 batches | lr 1.25 | ms/batch 21.82 | loss  3.85 | ppl    47.22
| prune-epoch  20 |  1000/ 2983 batches | lr 1.25 | ms/batch 21.84 | loss  3.91 | ppl    49.84
| prune-epoch  20 |  1200/ 2983 batches | lr 1.25 | ms/batch 21.83 | loss  3.91 | ppl    50.14
| prune-epoch  20 |  1400/ 2983 batches | lr 1.25 | ms/batch 21.83 | loss  3.93 | ppl    51.06
| prune-epoch  20 |  1600/ 2983 batches | lr 1.25 | ms/batch 21.82 | loss  3.99 | ppl    54.01
| prune-epoch  20 |  1800/ 2983 batches | lr 1.25 | ms/batch 21.81 | loss  3.90 | ppl    49.47
| prune-epoch  20 |  2000/ 2983 batches | lr 1.25 | ms/batch 21.80 | loss  3.95 | ppl    52.01
| prune-epoch  20 |  2200/ 2983 batches | lr 1.25 | ms/batch 21.80 | loss  3.82 | ppl    45.42
| prune-epoch  20 |  2400/ 2983 batches | lr 1.25 | ms/batch 21.80 | loss  3.84 | ppl    46.69
| prune-epoch  20 |  2600/ 2983 batches | lr 1.25 | ms/batch 21.80 | loss  3.88 | ppl    48.54
| prune-epoch  20 |  2800/ 2983 batches | lr 1.25 | ms/batch 21.80 | loss  3.86 | ppl    47.27
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  20 | time: 67.93s | valid loss  4.60 | valid ppl    99.25
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  21 |   200/ 2983 batches | lr 1.25 | ms/batch 22.09 | loss  3.95 | ppl    52.02
| prune-epoch  21 |   400/ 2983 batches | lr 1.25 | ms/batch 21.71 | loss  3.98 | ppl    53.25
| prune-epoch  21 |   600/ 2983 batches | lr 1.25 | ms/batch 21.70 | loss  3.80 | ppl    44.61
| prune-epoch  21 |   800/ 2983 batches | lr 1.25 | ms/batch 21.71 | loss  3.85 | ppl    47.22
| prune-epoch  21 |  1000/ 2983 batches | lr 1.25 | ms/batch 21.71 | loss  3.91 | ppl    49.75
| prune-epoch  21 |  1200/ 2983 batches | lr 1.25 | ms/batch 21.70 | loss  3.91 | ppl    49.82
| prune-epoch  21 |  1400/ 2983 batches | lr 1.25 | ms/batch 21.71 | loss  3.93 | ppl    51.06
| prune-epoch  21 |  1600/ 2983 batches | lr 1.25 | ms/batch 21.74 | loss  3.99 | ppl    53.99
| prune-epoch  21 |  1800/ 2983 batches | lr 1.25 | ms/batch 21.85 | loss  3.90 | ppl    49.18
| prune-epoch  21 |  2000/ 2983 batches | lr 1.25 | ms/batch 21.85 | loss  3.95 | ppl    52.04
| prune-epoch  21 |  2200/ 2983 batches | lr 1.25 | ms/batch 21.84 | loss  3.81 | ppl    45.20
| prune-epoch  21 |  2400/ 2983 batches | lr 1.25 | ms/batch 21.85 | loss  3.84 | ppl    46.40
| prune-epoch  21 |  2600/ 2983 batches | lr 1.25 | ms/batch 21.85 | loss  3.88 | ppl    48.44
| prune-epoch  21 |  2800/ 2983 batches | lr 1.25 | ms/batch 21.86 | loss  3.86 | ppl    47.26
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  21 | time: 67.81s | valid loss  4.60 | valid ppl    99.13
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  22 |   200/ 2983 batches | lr 1.25 | ms/batch 22.07 | loss  3.94 | ppl    51.59
| prune-epoch  22 |   400/ 2983 batches | lr 1.25 | ms/batch 21.65 | loss  3.97 | ppl    52.75
| prune-epoch  22 |   600/ 2983 batches | lr 1.25 | ms/batch 21.61 | loss  3.80 | ppl    44.48
| prune-epoch  22 |   800/ 2983 batches | lr 1.25 | ms/batch 21.61 | loss  3.85 | ppl    47.21
| prune-epoch  22 |  1000/ 2983 batches | lr 1.25 | ms/batch 21.62 | loss  3.91 | ppl    49.69
| prune-epoch  22 |  1200/ 2983 batches | lr 1.25 | ms/batch 21.61 | loss  3.91 | ppl    49.75
| prune-epoch  22 |  1400/ 2983 batches | lr 1.25 | ms/batch 21.61 | loss  3.93 | ppl    51.06
| prune-epoch  22 |  1600/ 2983 batches | lr 1.25 | ms/batch 21.62 | loss  3.99 | ppl    54.08
| prune-epoch  22 |  1800/ 2983 batches | lr 1.25 | ms/batch 21.65 | loss  3.90 | ppl    49.20
| prune-epoch  22 |  2000/ 2983 batches | lr 1.25 | ms/batch 21.63 | loss  3.95 | ppl    51.86
| prune-epoch  22 |  2200/ 2983 batches | lr 1.25 | ms/batch 21.61 | loss  3.81 | ppl    45.35
| prune-epoch  22 |  2400/ 2983 batches | lr 1.25 | ms/batch 21.61 | loss  3.84 | ppl    46.58
| prune-epoch  22 |  2600/ 2983 batches | lr 1.25 | ms/batch 21.62 | loss  3.88 | ppl    48.32
| prune-epoch  22 |  2800/ 2983 batches | lr 1.25 | ms/batch 21.63 | loss  3.85 | ppl    46.99
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  22 | time: 67.36s | valid loss  4.60 | valid ppl    99.10
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  23 |   200/ 2983 batches | lr 1.25 | ms/batch 22.19 | loss  3.94 | ppl    51.58
| prune-epoch  23 |   400/ 2983 batches | lr 1.25 | ms/batch 21.79 | loss  3.96 | ppl    52.57
| prune-epoch  23 |   600/ 2983 batches | lr 1.25 | ms/batch 21.76 | loss  3.80 | ppl    44.55
| prune-epoch  23 |   800/ 2983 batches | lr 1.25 | ms/batch 21.78 | loss  3.85 | ppl    47.00
| prune-epoch  23 |  1000/ 2983 batches | lr 1.25 | ms/batch 21.77 | loss  3.91 | ppl    49.88
| prune-epoch  23 |  1200/ 2983 batches | lr 1.25 | ms/batch 21.79 | loss  3.90 | ppl    49.53
| prune-epoch  23 |  1400/ 2983 batches | lr 1.25 | ms/batch 21.76 | loss  3.93 | ppl    50.93
| prune-epoch  23 |  1600/ 2983 batches | lr 1.25 | ms/batch 21.81 | loss  3.99 | ppl    54.07
| prune-epoch  23 |  1800/ 2983 batches | lr 1.25 | ms/batch 21.83 | loss  3.89 | ppl    48.99
| prune-epoch  23 |  2000/ 2983 batches | lr 1.25 | ms/batch 21.83 | loss  3.95 | ppl    51.98
| prune-epoch  23 |  2200/ 2983 batches | lr 1.25 | ms/batch 21.84 | loss  3.82 | ppl    45.44
| prune-epoch  23 |  2400/ 2983 batches | lr 1.25 | ms/batch 21.83 | loss  3.83 | ppl    46.26
| prune-epoch  23 |  2600/ 2983 batches | lr 1.25 | ms/batch 21.83 | loss  3.87 | ppl    47.97
| prune-epoch  23 |  2800/ 2983 batches | lr 1.25 | ms/batch 21.84 | loss  3.85 | ppl    47.13
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  23 | time: 67.91s | valid loss  4.60 | valid ppl    99.12
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  24 |   200/ 2983 batches | lr 0.62 | ms/batch 22.10 | loss  3.96 | ppl    52.26
| prune-epoch  24 |   400/ 2983 batches | lr 0.62 | ms/batch 21.72 | loss  3.99 | ppl    54.16
| prune-epoch  24 |   600/ 2983 batches | lr 0.62 | ms/batch 21.85 | loss  3.82 | ppl    45.66
| prune-epoch  24 |   800/ 2983 batches | lr 0.62 | ms/batch 21.86 | loss  3.85 | ppl    47.10
| prune-epoch  24 |  1000/ 2983 batches | lr 0.62 | ms/batch 21.86 | loss  3.93 | ppl    50.68
| prune-epoch  24 |  1200/ 2983 batches | lr 0.62 | ms/batch 21.87 | loss  3.93 | ppl    50.73
| prune-epoch  24 |  1400/ 2983 batches | lr 0.62 | ms/batch 21.86 | loss  3.95 | ppl    51.79
| prune-epoch  24 |  1600/ 2983 batches | lr 0.62 | ms/batch 21.87 | loss  4.01 | ppl    55.28
| prune-epoch  24 |  1800/ 2983 batches | lr 0.62 | ms/batch 21.87 | loss  3.91 | ppl    49.79
| prune-epoch  24 |  2000/ 2983 batches | lr 0.62 | ms/batch 21.86 | loss  3.96 | ppl    52.21
| prune-epoch  24 |  2200/ 2983 batches | lr 0.62 | ms/batch 21.86 | loss  3.82 | ppl    45.81
| prune-epoch  24 |  2400/ 2983 batches | lr 0.62 | ms/batch 21.85 | loss  3.85 | ppl    46.85
| prune-epoch  24 |  2600/ 2983 batches | lr 0.62 | ms/batch 21.87 | loss  3.88 | ppl    48.25
| prune-epoch  24 |  2800/ 2983 batches | lr 0.62 | ms/batch 21.87 | loss  3.86 | ppl    47.26
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  24 | time: 68.02s | valid loss  4.58 | valid ppl    97.82
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  25 |   200/ 2983 batches | lr 0.62 | ms/batch 22.19 | loss  3.96 | ppl    52.56
| prune-epoch  25 |   400/ 2983 batches | lr 0.62 | ms/batch 21.82 | loss  3.99 | ppl    53.91
| prune-epoch  25 |   600/ 2983 batches | lr 0.62 | ms/batch 21.82 | loss  3.82 | ppl    45.43
| prune-epoch  25 |   800/ 2983 batches | lr 0.62 | ms/batch 21.82 | loss  3.85 | ppl    46.88
| prune-epoch  25 |  1000/ 2983 batches | lr 0.62 | ms/batch 21.83 | loss  3.91 | ppl    50.09
| prune-epoch  25 |  1200/ 2983 batches | lr 0.62 | ms/batch 21.83 | loss  3.92 | ppl    50.39
| prune-epoch  25 |  1400/ 2983 batches | lr 0.62 | ms/batch 21.83 | loss  3.94 | ppl    51.66
| prune-epoch  25 |  1600/ 2983 batches | lr 0.62 | ms/batch 21.82 | loss  4.01 | ppl    54.97
| prune-epoch  25 |  1800/ 2983 batches | lr 0.62 | ms/batch 21.81 | loss  3.90 | ppl    49.40
| prune-epoch  25 |  2000/ 2983 batches | lr 0.62 | ms/batch 21.81 | loss  3.96 | ppl    52.36
| prune-epoch  25 |  2200/ 2983 batches | lr 0.62 | ms/batch 21.82 | loss  3.82 | ppl    45.77
| prune-epoch  25 |  2400/ 2983 batches | lr 0.62 | ms/batch 21.82 | loss  3.84 | ppl    46.64
| prune-epoch  25 |  2600/ 2983 batches | lr 0.62 | ms/batch 21.82 | loss  3.88 | ppl    48.31
| prune-epoch  25 |  2800/ 2983 batches | lr 0.62 | ms/batch 21.82 | loss  3.86 | ppl    47.26
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  25 | time: 67.94s | valid loss  4.58 | valid ppl    97.87
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  26 |   200/ 2983 batches | lr 0.62 | ms/batch 22.11 | loss  3.96 | ppl    52.60
| prune-epoch  26 |   400/ 2983 batches | lr 0.62 | ms/batch 21.87 | loss  3.99 | ppl    53.85
| prune-epoch  26 |   600/ 2983 batches | lr 0.62 | ms/batch 21.86 | loss  3.81 | ppl    45.31
| prune-epoch  26 |   800/ 2983 batches | lr 0.62 | ms/batch 21.86 | loss  3.84 | ppl    46.74
| prune-epoch  26 |  1000/ 2983 batches | lr 0.62 | ms/batch 21.86 | loss  3.91 | ppl    49.78
| prune-epoch  26 |  1200/ 2983 batches | lr 0.62 | ms/batch 21.87 | loss  3.92 | ppl    50.28
| prune-epoch  26 |  1400/ 2983 batches | lr 0.62 | ms/batch 21.86 | loss  3.94 | ppl    51.45
| prune-epoch  26 |  1600/ 2983 batches | lr 0.62 | ms/batch 21.88 | loss  4.00 | ppl    54.71
| prune-epoch  26 |  1800/ 2983 batches | lr 0.62 | ms/batch 21.86 | loss  3.90 | ppl    49.47
| prune-epoch  26 |  2000/ 2983 batches | lr 0.62 | ms/batch 21.85 | loss  3.95 | ppl    52.14
| prune-epoch  26 |  2200/ 2983 batches | lr 0.62 | ms/batch 21.87 | loss  3.82 | ppl    45.70
| prune-epoch  26 |  2400/ 2983 batches | lr 0.62 | ms/batch 21.86 | loss  3.85 | ppl    46.83
| prune-epoch  26 |  2600/ 2983 batches | lr 0.62 | ms/batch 21.86 | loss  3.88 | ppl    48.47
| prune-epoch  26 |  2800/ 2983 batches | lr 0.62 | ms/batch 21.85 | loss  3.85 | ppl    47.10
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  26 | time: 68.05s | valid loss  4.58 | valid ppl    97.73
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  27 |   200/ 2983 batches | lr 0.62 | ms/batch 22.13 | loss  3.96 | ppl    52.30
| prune-epoch  27 |   400/ 2983 batches | lr 0.62 | ms/batch 21.74 | loss  3.98 | ppl    53.38
| prune-epoch  27 |   600/ 2983 batches | lr 0.62 | ms/batch 21.73 | loss  3.81 | ppl    45.31
| prune-epoch  27 |   800/ 2983 batches | lr 0.62 | ms/batch 21.72 | loss  3.84 | ppl    46.72
| prune-epoch  27 |  1000/ 2983 batches | lr 0.62 | ms/batch 21.72 | loss  3.91 | ppl    49.89
| prune-epoch  27 |  1200/ 2983 batches | lr 0.62 | ms/batch 21.72 | loss  3.91 | ppl    50.07
| prune-epoch  27 |  1400/ 2983 batches | lr 0.62 | ms/batch 21.72 | loss  3.94 | ppl    51.36
| prune-epoch  27 |  1600/ 2983 batches | lr 0.62 | ms/batch 21.75 | loss  4.01 | ppl    54.91
| prune-epoch  27 |  1800/ 2983 batches | lr 0.62 | ms/batch 21.72 | loss  3.90 | ppl    49.33
| prune-epoch  27 |  2000/ 2983 batches | lr 0.62 | ms/batch 21.71 | loss  3.95 | ppl    52.02
| prune-epoch  27 |  2200/ 2983 batches | lr 0.62 | ms/batch 21.72 | loss  3.82 | ppl    45.57
| prune-epoch  27 |  2400/ 2983 batches | lr 0.62 | ms/batch 21.72 | loss  3.85 | ppl    46.83
| prune-epoch  27 |  2600/ 2983 batches | lr 0.62 | ms/batch 21.76 | loss  3.88 | ppl    48.26
| prune-epoch  27 |  2800/ 2983 batches | lr 0.62 | ms/batch 21.72 | loss  3.85 | ppl    47.05
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  27 | time: 67.67s | valid loss  4.58 | valid ppl    97.77
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  28 |   200/ 2983 batches | lr 0.31 | ms/batch 22.26 | loss  3.97 | ppl    52.86
| prune-epoch  28 |   400/ 2983 batches | lr 0.31 | ms/batch 21.85 | loss  4.01 | ppl    55.23
| prune-epoch  28 |   600/ 2983 batches | lr 0.31 | ms/batch 21.86 | loss  3.84 | ppl    46.53
| prune-epoch  28 |   800/ 2983 batches | lr 0.31 | ms/batch 21.88 | loss  3.88 | ppl    48.22
| prune-epoch  28 |  1000/ 2983 batches | lr 0.31 | ms/batch 21.87 | loss  3.91 | ppl    49.96
| prune-epoch  28 |  1200/ 2983 batches | lr 0.31 | ms/batch 21.84 | loss  3.92 | ppl    50.58
| prune-epoch  28 |  1400/ 2983 batches | lr 0.31 | ms/batch 21.87 | loss  3.96 | ppl    52.31
| prune-epoch  28 |  1600/ 2983 batches | lr 0.31 | ms/batch 21.89 | loss  4.02 | ppl    55.66
| prune-epoch  28 |  1800/ 2983 batches | lr 0.31 | ms/batch 21.90 | loss  3.93 | ppl    50.97
| prune-epoch  28 |  2000/ 2983 batches | lr 0.31 | ms/batch 21.88 | loss  3.97 | ppl    52.86
| prune-epoch  28 |  2200/ 2983 batches | lr 0.31 | ms/batch 21.84 | loss  3.83 | ppl    46.23
| prune-epoch  28 |  2400/ 2983 batches | lr 0.31 | ms/batch 21.88 | loss  3.86 | ppl    47.58
| prune-epoch  28 |  2600/ 2983 batches | lr 0.31 | ms/batch 21.87 | loss  3.90 | ppl    49.36
| prune-epoch  28 |  2800/ 2983 batches | lr 0.31 | ms/batch 21.88 | loss  3.85 | ppl    47.18
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  28 | time: 68.10s | valid loss  4.58 | valid ppl    97.56
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  29 |   200/ 2983 batches | lr 0.31 | ms/batch 22.08 | loss  3.98 | ppl    53.65
| prune-epoch  29 |   400/ 2983 batches | lr 0.31 | ms/batch 21.67 | loss  4.00 | ppl    54.60
| prune-epoch  29 |   600/ 2983 batches | lr 0.31 | ms/batch 21.67 | loss  3.84 | ppl    46.44
| prune-epoch  29 |   800/ 2983 batches | lr 0.31 | ms/batch 21.67 | loss  3.87 | ppl    47.88
| prune-epoch  29 |  1000/ 2983 batches | lr 0.31 | ms/batch 21.65 | loss  3.91 | ppl    50.00
| prune-epoch  29 |  1200/ 2983 batches | lr 0.31 | ms/batch 21.75 | loss  3.93 | ppl    50.68
| prune-epoch  29 |  1400/ 2983 batches | lr 0.31 | ms/batch 21.90 | loss  3.96 | ppl    52.45
| prune-epoch  29 |  1600/ 2983 batches | lr 0.31 | ms/batch 21.89 | loss  4.01 | ppl    55.30
| prune-epoch  29 |  1800/ 2983 batches | lr 0.31 | ms/batch 21.89 | loss  3.93 | ppl    50.76
| prune-epoch  29 |  2000/ 2983 batches | lr 0.31 | ms/batch 21.89 | loss  3.97 | ppl    52.80
| prune-epoch  29 |  2200/ 2983 batches | lr 0.31 | ms/batch 21.88 | loss  3.84 | ppl    46.34
| prune-epoch  29 |  2400/ 2983 batches | lr 0.31 | ms/batch 21.89 | loss  3.86 | ppl    47.38
| prune-epoch  29 |  2600/ 2983 batches | lr 0.31 | ms/batch 21.90 | loss  3.90 | ppl    49.58
| prune-epoch  29 |  2800/ 2983 batches | lr 0.31 | ms/batch 21.88 | loss  3.85 | ppl    47.18
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  29 | time: 67.92s | valid loss  4.58 | valid ppl    97.55
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  30 |   200/ 2983 batches | lr 0.31 | ms/batch 22.11 | loss  3.98 | ppl    53.52
| prune-epoch  30 |   400/ 2983 batches | lr 0.31 | ms/batch 21.65 | loss  4.00 | ppl    54.82
| prune-epoch  30 |   600/ 2983 batches | lr 0.31 | ms/batch 21.64 | loss  3.84 | ppl    46.31
| prune-epoch  30 |   800/ 2983 batches | lr 0.31 | ms/batch 21.65 | loss  3.86 | ppl    47.64
| prune-epoch  30 |  1000/ 2983 batches | lr 0.31 | ms/batch 21.79 | loss  3.91 | ppl    49.83
| prune-epoch  30 |  1200/ 2983 batches | lr 0.31 | ms/batch 21.72 | loss  3.92 | ppl    50.62
| prune-epoch  30 |  1400/ 2983 batches | lr 0.31 | ms/batch 21.73 | loss  3.95 | ppl    52.11
| prune-epoch  30 |  1600/ 2983 batches | lr 0.31 | ms/batch 21.69 | loss  4.01 | ppl    55.04
| prune-epoch  30 |  1800/ 2983 batches | lr 0.31 | ms/batch 21.70 | loss  3.92 | ppl    50.31
| prune-epoch  30 |  2000/ 2983 batches | lr 0.31 | ms/batch 21.74 | loss  3.96 | ppl    52.61
| prune-epoch  30 |  2200/ 2983 batches | lr 0.31 | ms/batch 21.72 | loss  3.83 | ppl    46.24
| prune-epoch  30 |  2400/ 2983 batches | lr 0.31 | ms/batch 21.69 | loss  3.85 | ppl    47.22
| prune-epoch  30 |  2600/ 2983 batches | lr 0.31 | ms/batch 21.71 | loss  3.90 | ppl    49.64
| prune-epoch  30 |  2800/ 2983 batches | lr 0.31 | ms/batch 21.70 | loss  3.85 | ppl    47.12
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  30 | time: 67.60s | valid loss  4.58 | valid ppl    97.66
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  31 |   200/ 2983 batches | lr 0.31 | ms/batch 22.25 | loss  3.98 | ppl    53.50
| prune-epoch  31 |   400/ 2983 batches | lr 0.31 | ms/batch 21.86 | loss  4.00 | ppl    54.39
| prune-epoch  31 |   600/ 2983 batches | lr 0.31 | ms/batch 21.88 | loss  3.84 | ppl    46.39
| prune-epoch  31 |   800/ 2983 batches | lr 0.31 | ms/batch 21.86 | loss  3.87 | ppl    47.73
| prune-epoch  31 |  1000/ 2983 batches | lr 0.31 | ms/batch 21.88 | loss  3.90 | ppl    49.60
| prune-epoch  31 |  1200/ 2983 batches | lr 0.31 | ms/batch 21.88 | loss  3.92 | ppl    50.49
| prune-epoch  31 |  1400/ 2983 batches | lr 0.31 | ms/batch 21.89 | loss  3.95 | ppl    52.11
| prune-epoch  31 |  1600/ 2983 batches | lr 0.31 | ms/batch 21.88 | loss  4.01 | ppl    55.10
| prune-epoch  31 |  1800/ 2983 batches | lr 0.31 | ms/batch 21.87 | loss  3.92 | ppl    50.39
| prune-epoch  31 |  2000/ 2983 batches | lr 0.31 | ms/batch 21.88 | loss  3.96 | ppl    52.52
| prune-epoch  31 |  2200/ 2983 batches | lr 0.31 | ms/batch 21.86 | loss  3.83 | ppl    46.11
| prune-epoch  31 |  2400/ 2983 batches | lr 0.31 | ms/batch 21.88 | loss  3.86 | ppl    47.34
| prune-epoch  31 |  2600/ 2983 batches | lr 0.31 | ms/batch 21.87 | loss  3.90 | ppl    49.34
| prune-epoch  31 |  2800/ 2983 batches | lr 0.31 | ms/batch 21.86 | loss  3.86 | ppl    47.25
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  31 | time: 68.10s | valid loss  4.58 | valid ppl    97.61
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  32 |   200/ 2983 batches | lr 0.31 | ms/batch 22.07 | loss  3.98 | ppl    53.33
| prune-epoch  32 |   400/ 2983 batches | lr 0.31 | ms/batch 21.68 | loss  4.00 | ppl    54.54
| prune-epoch  32 |   600/ 2983 batches | lr 0.31 | ms/batch 21.68 | loss  3.83 | ppl    46.24
| prune-epoch  32 |   800/ 2983 batches | lr 0.31 | ms/batch 21.66 | loss  3.86 | ppl    47.44
| prune-epoch  32 |  1000/ 2983 batches | lr 0.31 | ms/batch 21.68 | loss  3.90 | ppl    49.62
| prune-epoch  32 |  1200/ 2983 batches | lr 0.31 | ms/batch 21.67 | loss  3.92 | ppl    50.47
| prune-epoch  32 |  1400/ 2983 batches | lr 0.31 | ms/batch 21.68 | loss  3.95 | ppl    52.03
| prune-epoch  32 |  1600/ 2983 batches | lr 0.31 | ms/batch 21.69 | loss  4.01 | ppl    54.95
| prune-epoch  32 |  1800/ 2983 batches | lr 0.31 | ms/batch 21.69 | loss  3.93 | ppl    50.76
| prune-epoch  32 |  2000/ 2983 batches | lr 0.31 | ms/batch 21.68 | loss  3.97 | ppl    52.76
| prune-epoch  32 |  2200/ 2983 batches | lr 0.31 | ms/batch 21.69 | loss  3.83 | ppl    46.11
| prune-epoch  32 |  2400/ 2983 batches | lr 0.31 | ms/batch 21.69 | loss  3.86 | ppl    47.26
| prune-epoch  32 |  2600/ 2983 batches | lr 0.31 | ms/batch 21.69 | loss  3.90 | ppl    49.26
| prune-epoch  32 |  2800/ 2983 batches | lr 0.31 | ms/batch 21.69 | loss  3.86 | ppl    47.36
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  32 | time: 67.54s | valid loss  4.58 | valid ppl    97.58
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  33 |   200/ 2983 batches | lr 0.31 | ms/batch 22.10 | loss  3.98 | ppl    53.44
| prune-epoch  33 |   400/ 2983 batches | lr 0.31 | ms/batch 22.00 | loss  4.00 | ppl    54.37
| prune-epoch  33 |   600/ 2983 batches | lr 0.31 | ms/batch 22.00 | loss  3.83 | ppl    46.04
| prune-epoch  33 |   800/ 2983 batches | lr 0.31 | ms/batch 22.00 | loss  3.87 | ppl    47.75
| prune-epoch  33 |  1000/ 2983 batches | lr 0.31 | ms/batch 21.99 | loss  3.91 | ppl    49.77
| prune-epoch  33 |  1200/ 2983 batches | lr 0.31 | ms/batch 22.00 | loss  3.93 | ppl    50.69
| prune-epoch  33 |  1400/ 2983 batches | lr 0.31 | ms/batch 22.01 | loss  3.95 | ppl    52.16
| prune-epoch  33 |  1600/ 2983 batches | lr 0.31 | ms/batch 22.00 | loss  4.01 | ppl    55.22
| prune-epoch  33 |  1800/ 2983 batches | lr 0.31 | ms/batch 21.98 | loss  3.92 | ppl    50.38
| prune-epoch  33 |  2000/ 2983 batches | lr 0.31 | ms/batch 22.00 | loss  3.96 | ppl    52.48
| prune-epoch  33 |  2200/ 2983 batches | lr 0.31 | ms/batch 22.00 | loss  3.83 | ppl    45.98
| prune-epoch  33 |  2400/ 2983 batches | lr 0.31 | ms/batch 22.00 | loss  3.86 | ppl    47.40
| prune-epoch  33 |  2600/ 2983 batches | lr 0.31 | ms/batch 22.00 | loss  3.89 | ppl    49.08
| prune-epoch  33 |  2800/ 2983 batches | lr 0.31 | ms/batch 22.00 | loss  3.85 | ppl    47.12
end prun train
weight_ih_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l0        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_ih_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
weight_hh_l1        shape torch.Size([2600, 650])
       expected sp:  0.9  actual sp:  0.8984615384615384
-----------------------------------------------------------------------------------------
| end of retrain epoch  33 | time: 68.42s | valid loss  4.58 | valid ppl    97.69
-----------------------------------------------------------------------------------------
required epochs  40 | actual epochs  62
pretrain epochs  15 | prune epochs  14 | retrain epochs  33
=========================================================================================
| End of training | test loss  4.52 | test ppl    92.28
=========================================================================================
python main.py --cuda --emsize 1500 --nhid 1500 --dropout 0.65 --epochs 40 --save model/prune/model.pt --prune --retrain --sparsity 0.9
<class 'torch.Tensor'> torch.Size([33278, 1500])
<class 'torch.Tensor'> torch.Size([6000, 1500])
<class 'torch.Tensor'> torch.Size([6000, 1500])
<class 'torch.Tensor'> torch.Size([6000])
<class 'torch.Tensor'> torch.Size([6000])
<class 'torch.Tensor'> torch.Size([6000, 1500])
<class 'torch.Tensor'> torch.Size([6000, 1500])
<class 'torch.Tensor'> torch.Size([6000])
<class 'torch.Tensor'> torch.Size([6000])
<class 'torch.Tensor'> torch.Size([33278, 1500])
<class 'torch.Tensor'> torch.Size([33278])
RNNModel(
  (drop): Dropout(p=0.65)
  (encoder): Embedding(33278, 1500)
  (rnn): LSTM(1500, 1500, num_layers=2, dropout=0.65)
  (decoder): Linear(in_features=1500, out_features=33278, bias=True)
)
Dropout(p=0.65)
Embedding(33278, 1500)
LSTM(1500, 1500, num_layers=2, dropout=0.65)
Linear(in_features=1500, out_features=33278, bias=True)
| train-epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 58.74 | loss  7.87 | ppl  2611.10
| train-epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 58.37 | loss  6.80 | ppl   893.96
| train-epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 58.36 | loss  6.44 | ppl   628.43
| train-epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 58.37 | loss  6.29 | ppl   540.87
| train-epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.37 | loss  6.18 | ppl   484.87
| train-epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.38 | loss  6.13 | ppl   458.85
| train-epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.36 | loss  6.03 | ppl   417.29
| train-epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.35 | loss  6.05 | ppl   423.83
| train-epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.39 | loss  5.91 | ppl   367.46
| train-epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.37 | loss  5.89 | ppl   362.49
| train-epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.39 | loss  5.79 | ppl   326.17
| train-epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.37 | loss  5.79 | ppl   327.80
| train-epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.39 | loss  5.78 | ppl   325.07
| train-epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.39 | loss  5.68 | ppl   291.94
-----------------------------------------------------------------------------------------
| end of train epoch   1 | time: 180.97s | valid loss  5.53 | valid ppl   251.50
-----------------------------------------------------------------------------------------
| train-epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch 58.31 | loss  5.66 | ppl   287.07
| train-epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch 57.99 | loss  5.64 | ppl   280.31
| train-epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch 57.98 | loss  5.47 | ppl   237.13
| train-epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch 58.00 | loss  5.49 | ppl   241.83
| train-epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.00 | loss  5.46 | ppl   235.64
| train-epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.98 | loss  5.45 | ppl   233.85
| train-epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.99 | loss  5.45 | ppl   231.74
| train-epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.00 | loss  5.50 | ppl   245.14
| train-epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.99 | loss  5.38 | ppl   216.35
| train-epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.99 | loss  5.40 | ppl   220.43
| train-epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.99 | loss  5.30 | ppl   200.53
| train-epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.99 | loss  5.33 | ppl   205.65
| train-epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.99 | loss  5.34 | ppl   207.57
| train-epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.02 | loss  5.26 | ppl   191.79
-----------------------------------------------------------------------------------------
| end of train epoch   2 | time: 179.84s | valid loss  5.23 | valid ppl   187.67
-----------------------------------------------------------------------------------------
| train-epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 59.01 | loss  5.30 | ppl   200.24
| train-epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch 58.69 | loss  5.30 | ppl   201.28
| train-epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 58.68 | loss  5.13 | ppl   168.19
| train-epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 58.70 | loss  5.17 | ppl   175.37
| train-epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.69 | loss  5.15 | ppl   173.18
| train-epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.69 | loss  5.15 | ppl   172.98
| train-epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.68 | loss  5.18 | ppl   177.47
| train-epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.69 | loss  5.24 | ppl   188.43
| train-epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.68 | loss  5.11 | ppl   165.84
| train-epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.77 | loss  5.14 | ppl   171.30
| train-epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.76 | loss  5.05 | ppl   155.78
| train-epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.75 | loss  5.07 | ppl   159.94
| train-epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.66 | loss  5.09 | ppl   162.65
| train-epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.67 | loss  5.02 | ppl   151.55
-----------------------------------------------------------------------------------------
| end of train epoch   3 | time: 181.93s | valid loss  5.06 | valid ppl   158.24
-----------------------------------------------------------------------------------------
| train-epoch   4 |   200/ 2983 batches | lr 20.00 | ms/batch 58.86 | loss  5.07 | ppl   159.94
| train-epoch   4 |   400/ 2983 batches | lr 20.00 | ms/batch 58.57 | loss  5.09 | ppl   162.33
| train-epoch   4 |   600/ 2983 batches | lr 20.00 | ms/batch 58.54 | loss  4.91 | ppl   134.99
| train-epoch   4 |   800/ 2983 batches | lr 20.00 | ms/batch 58.59 | loss  4.96 | ppl   142.46
| train-epoch   4 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.61 | loss  4.96 | ppl   141.99
| train-epoch   4 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.54 | loss  4.96 | ppl   142.11
| train-epoch   4 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.55 | loss  4.99 | ppl   146.29
| train-epoch   4 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.59 | loss  5.05 | ppl   156.80
| train-epoch   4 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.58 | loss  4.93 | ppl   138.30
| train-epoch   4 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.47 | loss  4.96 | ppl   142.80
| train-epoch   4 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.50 | loss  4.86 | ppl   129.35
| train-epoch   4 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.46 | loss  4.90 | ppl   133.82
| train-epoch   4 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.43 | loss  4.92 | ppl   136.66
| train-epoch   4 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.42 | loss  4.85 | ppl   127.68
-----------------------------------------------------------------------------------------
| end of train epoch   4 | time: 181.39s | valid loss  4.96 | valid ppl   142.13
-----------------------------------------------------------------------------------------
| train-epoch   5 |   200/ 2983 batches | lr 20.00 | ms/batch 58.80 | loss  4.91 | ppl   135.11
| train-epoch   5 |   400/ 2983 batches | lr 20.00 | ms/batch 58.36 | loss  4.93 | ppl   138.48
| train-epoch   5 |   600/ 2983 batches | lr 20.00 | ms/batch 58.33 | loss  4.74 | ppl   114.60
| train-epoch   5 |   800/ 2983 batches | lr 20.00 | ms/batch 58.32 | loss  4.80 | ppl   121.50
| train-epoch   5 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.36 | loss  4.80 | ppl   121.24
| train-epoch   5 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.36 | loss  4.80 | ppl   121.96
| train-epoch   5 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.35 | loss  4.84 | ppl   126.88
| train-epoch   5 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.36 | loss  4.91 | ppl   135.70
| train-epoch   5 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.34 | loss  4.78 | ppl   119.70
| train-epoch   5 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.35 | loss  4.82 | ppl   124.37
| train-epoch   5 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.38 | loss  4.72 | ppl   111.78
| train-epoch   5 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.36 | loss  4.75 | ppl   115.83
| train-epoch   5 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.35 | loss  4.78 | ppl   118.72
| train-epoch   5 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.38 | loss  4.71 | ppl   111.52
-----------------------------------------------------------------------------------------
| end of train epoch   5 | time: 180.90s | valid loss  4.89 | valid ppl   132.79
-----------------------------------------------------------------------------------------
| train-epoch   6 |   200/ 2983 batches | lr 20.00 | ms/batch 58.73 | loss  4.77 | ppl   118.32
| train-epoch   6 |   400/ 2983 batches | lr 20.00 | ms/batch 58.45 | loss  4.79 | ppl   120.32
| train-epoch   6 |   600/ 2983 batches | lr 20.00 | ms/batch 58.48 | loss  4.61 | ppl   100.52
| train-epoch   6 |   800/ 2983 batches | lr 20.00 | ms/batch 58.44 | loss  4.67 | ppl   106.72
| train-epoch   6 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.44 | loss  4.67 | ppl   106.74
| train-epoch   6 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.45 | loss  4.68 | ppl   107.78
| train-epoch   6 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.43 | loss  4.72 | ppl   112.25
| train-epoch   6 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.42 | loss  4.79 | ppl   120.81
| train-epoch   6 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.43 | loss  4.67 | ppl   106.35
| train-epoch   6 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.44 | loss  4.70 | ppl   110.22
| train-epoch   6 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.44 | loss  4.60 | ppl    99.18
| train-epoch   6 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.43 | loss  4.63 | ppl   102.81
| train-epoch   6 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.44 | loss  4.66 | ppl   106.03
| train-epoch   6 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.43 | loss  4.60 | ppl    99.45
-----------------------------------------------------------------------------------------
| end of train epoch   6 | time: 181.13s | valid loss  4.83 | valid ppl   125.60
-----------------------------------------------------------------------------------------
| train-epoch   7 |   200/ 2983 batches | lr 20.00 | ms/batch 58.69 | loss  4.66 | ppl   105.24
| train-epoch   7 |   400/ 2983 batches | lr 20.00 | ms/batch 58.41 | loss  4.68 | ppl   107.34
| train-epoch   7 |   600/ 2983 batches | lr 20.00 | ms/batch 58.41 | loss  4.50 | ppl    89.84
| train-epoch   7 |   800/ 2983 batches | lr 20.00 | ms/batch 58.42 | loss  4.55 | ppl    94.62
| train-epoch   7 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.40 | loss  4.56 | ppl    96.04
| train-epoch   7 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.40 | loss  4.58 | ppl    97.07
| train-epoch   7 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.40 | loss  4.62 | ppl   101.62
| train-epoch   7 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.40 | loss  4.69 | ppl   108.62
| train-epoch   7 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.39 | loss  4.57 | ppl    96.12
| train-epoch   7 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.40 | loss  4.60 | ppl    99.82
| train-epoch   7 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.40 | loss  4.50 | ppl    89.75
| train-epoch   7 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.38 | loss  4.53 | ppl    92.57
| train-epoch   7 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.42 | loss  4.57 | ppl    96.19
| train-epoch   7 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.43 | loss  4.51 | ppl    90.90
-----------------------------------------------------------------------------------------
| end of train epoch   7 | time: 181.01s | valid loss  4.80 | valid ppl   121.35
-----------------------------------------------------------------------------------------
| train-epoch   8 |   200/ 2983 batches | lr 20.00 | ms/batch 58.87 | loss  4.56 | ppl    95.37
| train-epoch   8 |   400/ 2983 batches | lr 20.00 | ms/batch 58.58 | loss  4.58 | ppl    97.46
| train-epoch   8 |   600/ 2983 batches | lr 20.00 | ms/batch 58.56 | loss  4.40 | ppl    81.17
| train-epoch   8 |   800/ 2983 batches | lr 20.00 | ms/batch 58.56 | loss  4.46 | ppl    86.36
| train-epoch   8 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.57 | loss  4.47 | ppl    87.17
| train-epoch   8 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.58 | loss  4.48 | ppl    88.61
| train-epoch   8 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.57 | loss  4.53 | ppl    92.99
| train-epoch   8 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.54 | loss  4.60 | ppl    99.50
| train-epoch   8 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.56 | loss  4.48 | ppl    88.00
| train-epoch   8 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.52 | loss  4.51 | ppl    91.26
| train-epoch   8 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.55 | loss  4.40 | ppl    81.70
| train-epoch   8 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.49 | loss  4.44 | ppl    85.02
| train-epoch   8 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.49 | loss  4.48 | ppl    88.20
| train-epoch   8 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.50 | loss  4.42 | ppl    82.80
-----------------------------------------------------------------------------------------
| end of train epoch   8 | time: 181.43s | valid loss  4.76 | valid ppl   116.19
-----------------------------------------------------------------------------------------
| train-epoch   9 |   200/ 2983 batches | lr 20.00 | ms/batch 58.28 | loss  4.47 | ppl    87.17
| train-epoch   9 |   400/ 2983 batches | lr 20.00 | ms/batch 58.00 | loss  4.49 | ppl    89.27
| train-epoch   9 |   600/ 2983 batches | lr 20.00 | ms/batch 57.97 | loss  4.32 | ppl    75.02
| train-epoch   9 |   800/ 2983 batches | lr 20.00 | ms/batch 57.99 | loss  4.37 | ppl    78.70
| train-epoch   9 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.97 | loss  4.39 | ppl    80.57
| train-epoch   9 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.99 | loss  4.40 | ppl    81.67
| train-epoch   9 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.97 | loss  4.44 | ppl    84.90
| train-epoch   9 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.98 | loss  4.52 | ppl    92.18
| train-epoch   9 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.96 | loss  4.40 | ppl    81.58
| train-epoch   9 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.97 | loss  4.44 | ppl    84.67
| train-epoch   9 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.98 | loss  4.33 | ppl    75.59
| train-epoch   9 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.97 | loss  4.37 | ppl    78.66
| train-epoch   9 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.98 | loss  4.40 | ppl    81.30
| train-epoch   9 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.97 | loss  4.34 | ppl    77.03
-----------------------------------------------------------------------------------------
| end of train epoch   9 | time: 179.76s | valid loss  4.75 | valid ppl   115.66
-----------------------------------------------------------------------------------------
| train-epoch  10 |   200/ 2983 batches | lr 20.00 | ms/batch 58.98 | loss  4.40 | ppl    81.24
| train-epoch  10 |   400/ 2983 batches | lr 20.00 | ms/batch 58.64 | loss  4.42 | ppl    82.89
| train-epoch  10 |   600/ 2983 batches | lr 20.00 | ms/batch 58.65 | loss  4.24 | ppl    69.25
| train-epoch  10 |   800/ 2983 batches | lr 20.00 | ms/batch 58.65 | loss  4.29 | ppl    72.86
| train-epoch  10 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.65 | loss  4.32 | ppl    74.84
| train-epoch  10 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.64 | loss  4.33 | ppl    75.91
| train-epoch  10 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.65 | loss  4.37 | ppl    79.33
| train-epoch  10 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.64 | loss  4.45 | ppl    85.31
| train-epoch  10 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.66 | loss  4.33 | ppl    76.27
| train-epoch  10 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.65 | loss  4.37 | ppl    78.92
| train-epoch  10 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.64 | loss  4.25 | ppl    70.20
| train-epoch  10 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.65 | loss  4.29 | ppl    73.09
| train-epoch  10 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.67 | loss  4.33 | ppl    75.99
| train-epoch  10 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.65 | loss  4.28 | ppl    72.19
-----------------------------------------------------------------------------------------
| end of train epoch  10 | time: 181.75s | valid loss  4.73 | valid ppl   113.53
-----------------------------------------------------------------------------------------
| train-epoch  11 |   200/ 2983 batches | lr 20.00 | ms/batch 58.74 | loss  4.33 | ppl    75.69
| train-epoch  11 |   400/ 2983 batches | lr 20.00 | ms/batch 58.43 | loss  4.35 | ppl    77.37
| train-epoch  11 |   600/ 2983 batches | lr 20.00 | ms/batch 58.41 | loss  4.17 | ppl    64.59
| train-epoch  11 |   800/ 2983 batches | lr 20.00 | ms/batch 58.43 | loss  4.22 | ppl    67.83
| train-epoch  11 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.42 | loss  4.25 | ppl    70.19
| train-epoch  11 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.45 | loss  4.26 | ppl    70.79
| train-epoch  11 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.43 | loss  4.30 | ppl    73.75
| train-epoch  11 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.43 | loss  4.38 | ppl    79.91
| train-epoch  11 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.44 | loss  4.27 | ppl    71.28
| train-epoch  11 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.44 | loss  4.30 | ppl    73.59
| train-epoch  11 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.44 | loss  4.18 | ppl    65.59
| train-epoch  11 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.44 | loss  4.23 | ppl    68.56
| train-epoch  11 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.43 | loss  4.27 | ppl    71.65
| train-epoch  11 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.43 | loss  4.21 | ppl    67.60
-----------------------------------------------------------------------------------------
| end of train epoch  11 | time: 182.20s | valid loss  4.73 | valid ppl   113.23
-----------------------------------------------------------------------------------------
| train-epoch  12 |   200/ 2983 batches | lr 20.00 | ms/batch 58.71 | loss  4.26 | ppl    70.85
| train-epoch  12 |   400/ 2983 batches | lr 20.00 | ms/batch 58.32 | loss  4.28 | ppl    72.45
| train-epoch  12 |   600/ 2983 batches | lr 20.00 | ms/batch 58.38 | loss  4.11 | ppl    60.70
| train-epoch  12 |   800/ 2983 batches | lr 20.00 | ms/batch 58.34 | loss  4.16 | ppl    63.81
| train-epoch  12 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.32 | loss  4.18 | ppl    65.67
| train-epoch  12 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.34 | loss  4.20 | ppl    66.85
| train-epoch  12 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.35 | loss  4.24 | ppl    69.54
| train-epoch  12 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.32 | loss  4.32 | ppl    75.18
| train-epoch  12 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.31 | loss  4.21 | ppl    67.25
| train-epoch  12 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.35 | loss  4.24 | ppl    69.71
| train-epoch  12 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.33 | loss  4.13 | ppl    61.99
| train-epoch  12 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.47 | loss  4.16 | ppl    64.34
| train-epoch  12 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.38 | loss  4.21 | ppl    67.28
| train-epoch  12 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.39 | loss  4.16 | ppl    63.86
-----------------------------------------------------------------------------------------
| end of train epoch  12 | time: 180.90s | valid loss  4.76 | valid ppl   117.07
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 61.74 | loss  4.21 | ppl    67.04
| prune-epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 58.98 | loss  4.23 | ppl    68.45
| prune-epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 58.89 | loss  4.05 | ppl    57.43
| prune-epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 58.85 | loss  4.09 | ppl    59.78
| prune-epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.86 | loss  4.12 | ppl    61.72
| prune-epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.85 | loss  4.14 | ppl    62.76
| prune-epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.95 | loss  4.18 | ppl    65.24
| prune-epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.86 | loss  4.25 | ppl    70.35
| prune-epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.86 | loss  4.14 | ppl    62.70
| prune-epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.86 | loss  4.17 | ppl    64.87
| prune-epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.85 | loss  4.06 | ppl    57.74
| prune-epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.85 | loss  4.09 | ppl    59.76
| prune-epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.87 | loss  4.13 | ppl    62.09
| prune-epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.86 | loss  4.08 | ppl    59.15
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.3993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.3993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.3993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.3993333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch   1 | time: 182.92s | valid loss  4.72 | valid ppl   112.55
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch 61.48 | loss  4.13 | ppl    62.44
| prune-epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch 58.80 | loss  4.16 | ppl    63.93
| prune-epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch 58.97 | loss  3.98 | ppl    53.72
| prune-epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch 58.83 | loss  4.03 | ppl    56.15
| prune-epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.83 | loss  4.06 | ppl    58.18
| prune-epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.83 | loss  4.08 | ppl    59.02
| prune-epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.81 | loss  4.12 | ppl    61.29
| prune-epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.82 | loss  4.19 | ppl    66.23
| prune-epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.82 | loss  4.09 | ppl    59.57
| prune-epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.82 | loss  4.12 | ppl    61.76
| prune-epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.82 | loss  4.00 | ppl    54.63
| prune-epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.82 | loss  4.04 | ppl    56.74
| prune-epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.82 | loss  4.07 | ppl    58.66
| prune-epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.84 | loss  4.03 | ppl    56.31
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.3993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.3993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.3993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.3993333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch   2 | time: 182.75s | valid loss  4.71 | valid ppl   111.27
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 61.80 | loss  4.08 | ppl    59.14
| prune-epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch 58.96 | loss  4.11 | ppl    60.83
| prune-epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 58.97 | loss  3.93 | ppl    50.82
| prune-epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 58.98 | loss  3.97 | ppl    53.18
| prune-epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.99 | loss  4.01 | ppl    55.23
| prune-epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.99 | loss  4.02 | ppl    55.76
| prune-epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.96 | loss  4.06 | ppl    58.08
| prune-epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.99 | loss  4.14 | ppl    63.00
| prune-epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.96 | loss  4.04 | ppl    56.75
| prune-epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 59.10 | loss  4.07 | ppl    58.67
| prune-epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 59.18 | loss  3.95 | ppl    51.85
| prune-epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.96 | loss  3.98 | ppl    53.69
| prune-epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch 59.08 | loss  4.02 | ppl    55.95
| prune-epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.96 | loss  3.98 | ppl    53.73
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.3993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.3993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.3993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.3993333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch   3 | time: 183.29s | valid loss  4.72 | valid ppl   112.09
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   4 |   200/ 2983 batches | lr 20.00 | ms/batch 62.04 | loss  4.04 | ppl    56.63
| prune-epoch   4 |   400/ 2983 batches | lr 20.00 | ms/batch 58.62 | loss  4.05 | ppl    57.65
| prune-epoch   4 |   600/ 2983 batches | lr 20.00 | ms/batch 58.74 | loss  3.88 | ppl    48.58
| prune-epoch   4 |   800/ 2983 batches | lr 20.00 | ms/batch 58.64 | loss  3.92 | ppl    50.51
| prune-epoch   4 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.64 | loss  3.97 | ppl    52.78
| prune-epoch   4 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.68 | loss  3.98 | ppl    53.50
| prune-epoch   4 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.70 | loss  4.01 | ppl    55.30
| prune-epoch   4 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.67 | loss  4.10 | ppl    60.28
| prune-epoch   4 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.69 | loss  3.98 | ppl    53.72
| prune-epoch   4 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.65 | loss  4.02 | ppl    55.68
| prune-epoch   4 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.70 | loss  3.90 | ppl    49.30
| prune-epoch   4 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.70 | loss  3.93 | ppl    50.97
| prune-epoch   4 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.67 | loss  3.97 | ppl    53.16
| prune-epoch   4 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.66 | loss  3.93 | ppl    50.91
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993332222222222
-----------------------------------------------------------------------------------------
| end of prune epoch   4 | time: 182.44s | valid loss  4.73 | valid ppl   113.58
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   5 |   200/ 2983 batches | lr 20.00 | ms/batch 62.57 | loss  3.98 | ppl    53.59
| prune-epoch   5 |   400/ 2983 batches | lr 20.00 | ms/batch 59.24 | loss  4.01 | ppl    55.22
| prune-epoch   5 |   600/ 2983 batches | lr 20.00 | ms/batch 59.27 | loss  3.83 | ppl    46.04
| prune-epoch   5 |   800/ 2983 batches | lr 20.00 | ms/batch 59.24 | loss  3.88 | ppl    48.38
| prune-epoch   5 |  1000/ 2983 batches | lr 20.00 | ms/batch 59.34 | loss  3.91 | ppl    50.12
| prune-epoch   5 |  1200/ 2983 batches | lr 20.00 | ms/batch 59.30 | loss  3.93 | ppl    50.90
| prune-epoch   5 |  1400/ 2983 batches | lr 20.00 | ms/batch 59.27 | loss  3.96 | ppl    52.68
| prune-epoch   5 |  1600/ 2983 batches | lr 20.00 | ms/batch 59.27 | loss  4.05 | ppl    57.53
| prune-epoch   5 |  1800/ 2983 batches | lr 20.00 | ms/batch 59.27 | loss  3.94 | ppl    51.66
| prune-epoch   5 |  2000/ 2983 batches | lr 20.00 | ms/batch 59.30 | loss  3.98 | ppl    53.51
| prune-epoch   5 |  2200/ 2983 batches | lr 20.00 | ms/batch 59.28 | loss  3.85 | ppl    47.08
| prune-epoch   5 |  2400/ 2983 batches | lr 20.00 | ms/batch 59.25 | loss  3.89 | ppl    48.83
| prune-epoch   5 |  2600/ 2983 batches | lr 20.00 | ms/batch 59.27 | loss  3.93 | ppl    50.78
| prune-epoch   5 |  2800/ 2983 batches | lr 20.00 | ms/batch 59.42 | loss  3.89 | ppl    49.08
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch   5 | time: 184.18s | valid loss  4.73 | valid ppl   113.64
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   6 |   200/ 2983 batches | lr 20.00 | ms/batch 61.76 | loss  3.96 | ppl    52.69
| prune-epoch   6 |   400/ 2983 batches | lr 20.00 | ms/batch 58.87 | loss  3.98 | ppl    53.40
| prune-epoch   6 |   600/ 2983 batches | lr 20.00 | ms/batch 58.86 | loss  3.80 | ppl    44.90
| prune-epoch   6 |   800/ 2983 batches | lr 20.00 | ms/batch 58.87 | loss  3.85 | ppl    46.89
| prune-epoch   6 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.87 | loss  3.89 | ppl    48.88
| prune-epoch   6 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.85 | loss  3.89 | ppl    49.01
| prune-epoch   6 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.86 | loss  3.93 | ppl    50.93
| prune-epoch   6 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.85 | loss  4.01 | ppl    55.17
| prune-epoch   6 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.86 | loss  3.91 | ppl    49.96
| prune-epoch   6 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.87 | loss  3.94 | ppl    51.52
| prune-epoch   6 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.86 | loss  3.82 | ppl    45.49
| prune-epoch   6 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.85 | loss  3.86 | ppl    47.29
| prune-epoch   6 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.86 | loss  3.89 | ppl    48.88
| prune-epoch   6 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.87 | loss  3.85 | ppl    46.88
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.6  actual sp:  0.5993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.6  actual sp:  0.5993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.6  actual sp:  0.5993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.6  actual sp:  0.5993333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch   6 | time: 182.86s | valid loss  4.73 | valid ppl   113.10
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   7 |   200/ 2983 batches | lr 20.00 | ms/batch 61.32 | loss  3.90 | ppl    49.46
| prune-epoch   7 |   400/ 2983 batches | lr 20.00 | ms/batch 58.75 | loss  3.93 | ppl    50.87
| prune-epoch   7 |   600/ 2983 batches | lr 20.00 | ms/batch 58.76 | loss  3.76 | ppl    42.88
| prune-epoch   7 |   800/ 2983 batches | lr 20.00 | ms/batch 58.77 | loss  3.79 | ppl    44.41
| prune-epoch   7 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.79 | loss  3.84 | ppl    46.44
| prune-epoch   7 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.79 | loss  3.85 | ppl    47.16
| prune-epoch   7 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.76 | loss  3.88 | ppl    48.44
| prune-epoch   7 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.78 | loss  3.97 | ppl    52.82
| prune-epoch   7 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.78 | loss  3.87 | ppl    48.03
| prune-epoch   7 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.80 | loss  3.90 | ppl    49.45
| prune-epoch   7 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.78 | loss  3.78 | ppl    43.71
| prune-epoch   7 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.75 | loss  3.81 | ppl    45.15
| prune-epoch   7 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.78 | loss  3.85 | ppl    47.13
| prune-epoch   7 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.78 | loss  3.81 | ppl    45.11
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.6  actual sp:  0.5993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.6  actual sp:  0.5993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.6  actual sp:  0.5993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.6  actual sp:  0.5993333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch   7 | time: 182.53s | valid loss  4.73 | valid ppl   113.34
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   8 |   200/ 2983 batches | lr 20.00 | ms/batch 61.54 | loss  3.90 | ppl    49.63
| prune-epoch   8 |   400/ 2983 batches | lr 20.00 | ms/batch 58.90 | loss  3.93 | ppl    50.70
| prune-epoch   8 |   600/ 2983 batches | lr 20.00 | ms/batch 58.90 | loss  3.75 | ppl    42.37
| prune-epoch   8 |   800/ 2983 batches | lr 20.00 | ms/batch 58.89 | loss  3.79 | ppl    44.15
| prune-epoch   8 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.90 | loss  3.83 | ppl    46.18
| prune-epoch   8 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.89 | loss  3.83 | ppl    46.16
| prune-epoch   8 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.88 | loss  3.86 | ppl    47.69
| prune-epoch   8 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.88 | loss  3.95 | ppl    51.73
| prune-epoch   8 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.88 | loss  3.86 | ppl    47.27
| prune-epoch   8 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.87 | loss  3.88 | ppl    48.57
| prune-epoch   8 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.88 | loss  3.76 | ppl    43.05
| prune-epoch   8 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.88 | loss  3.79 | ppl    44.23
| prune-epoch   8 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.88 | loss  3.82 | ppl    45.72
| prune-epoch   8 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.89 | loss  3.79 | ppl    44.38
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7  actual sp:  0.6993333333333334
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7  actual sp:  0.6993333333333334
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7  actual sp:  0.6993333333333334
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7  actual sp:  0.6993333333333334
-----------------------------------------------------------------------------------------
| end of prune epoch   8 | time: 182.86s | valid loss  4.74 | valid ppl   114.07
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   9 |   200/ 2983 batches | lr 20.00 | ms/batch 61.23 | loss  3.85 | ppl    46.80
| prune-epoch   9 |   400/ 2983 batches | lr 20.00 | ms/batch 58.82 | loss  3.86 | ppl    47.49
| prune-epoch   9 |   600/ 2983 batches | lr 20.00 | ms/batch 58.83 | loss  3.70 | ppl    40.30
| prune-epoch   9 |   800/ 2983 batches | lr 20.00 | ms/batch 58.82 | loss  3.73 | ppl    41.71
| prune-epoch   9 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.82 | loss  3.79 | ppl    44.13
| prune-epoch   9 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.83 | loss  3.80 | ppl    44.52
| prune-epoch   9 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.83 | loss  3.82 | ppl    45.68
| prune-epoch   9 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.83 | loss  3.90 | ppl    49.55
| prune-epoch   9 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.82 | loss  3.81 | ppl    45.05
| prune-epoch   9 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.82 | loss  3.84 | ppl    46.40
| prune-epoch   9 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.82 | loss  3.72 | ppl    41.34
| prune-epoch   9 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.82 | loss  3.75 | ppl    42.60
| prune-epoch   9 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.82 | loss  3.80 | ppl    44.56
| prune-epoch   9 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.82 | loss  3.75 | ppl    42.50
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7  actual sp:  0.6993333333333334
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7  actual sp:  0.6993333333333334
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7  actual sp:  0.6993333333333334
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7  actual sp:  0.6993333333333334
-----------------------------------------------------------------------------------------
| end of prune epoch   9 | time: 182.62s | valid loss  4.76 | valid ppl   116.38
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  10 |   200/ 2983 batches | lr 20.00 | ms/batch 61.56 | loss  3.91 | ppl    49.77
| prune-epoch  10 |   400/ 2983 batches | lr 20.00 | ms/batch 58.97 | loss  3.91 | ppl    49.85
| prune-epoch  10 |   600/ 2983 batches | lr 20.00 | ms/batch 58.98 | loss  3.73 | ppl    41.76
| prune-epoch  10 |   800/ 2983 batches | lr 20.00 | ms/batch 58.96 | loss  3.78 | ppl    43.67
| prune-epoch  10 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.97 | loss  3.82 | ppl    45.57
| prune-epoch  10 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.95 | loss  3.83 | ppl    45.90
| prune-epoch  10 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.96 | loss  3.85 | ppl    46.95
| prune-epoch  10 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.94 | loss  3.92 | ppl    50.60
| prune-epoch  10 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.98 | loss  3.83 | ppl    46.25
| prune-epoch  10 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.93 | loss  3.87 | ppl    47.76
| prune-epoch  10 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.96 | loss  3.74 | ppl    42.08
| prune-epoch  10 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.94 | loss  3.77 | ppl    43.35
| prune-epoch  10 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.97 | loss  3.81 | ppl    45.07
| prune-epoch  10 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.99 | loss  3.77 | ppl    43.52
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch  10 | time: 183.05s | valid loss  4.74 | valid ppl   114.40
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  11 |   200/ 2983 batches | lr 20.00 | ms/batch 60.56 | loss  3.83 | ppl    45.99
| prune-epoch  11 |   400/ 2983 batches | lr 20.00 | ms/batch 58.37 | loss  3.84 | ppl    46.63
| prune-epoch  11 |   600/ 2983 batches | lr 20.00 | ms/batch 58.38 | loss  3.68 | ppl    39.49
| prune-epoch  11 |   800/ 2983 batches | lr 20.00 | ms/batch 58.38 | loss  3.72 | ppl    41.14
| prune-epoch  11 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.38 | loss  3.77 | ppl    43.23
| prune-epoch  11 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.39 | loss  3.77 | ppl    43.56
| prune-epoch  11 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.39 | loss  3.80 | ppl    44.93
| prune-epoch  11 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.37 | loss  3.88 | ppl    48.54
| prune-epoch  11 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.37 | loss  3.79 | ppl    44.18
| prune-epoch  11 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.38 | loss  3.82 | ppl    45.76
| prune-epoch  11 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.38 | loss  3.70 | ppl    40.37
| prune-epoch  11 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.38 | loss  3.72 | ppl    41.38
| prune-epoch  11 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.39 | loss  3.77 | ppl    43.29
| prune-epoch  11 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.39 | loss  3.73 | ppl    41.77
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch  11 | time: 181.24s | valid loss  4.77 | valid ppl   118.20
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  12 |   200/ 2983 batches | lr 20.00 | ms/batch 61.22 | loss  3.88 | ppl    48.22
| prune-epoch  12 |   400/ 2983 batches | lr 20.00 | ms/batch 59.01 | loss  3.88 | ppl    48.19
| prune-epoch  12 |   600/ 2983 batches | lr 20.00 | ms/batch 59.00 | loss  3.71 | ppl    40.95
| prune-epoch  12 |   800/ 2983 batches | lr 20.00 | ms/batch 58.99 | loss  3.75 | ppl    42.42
| prune-epoch  12 |  1000/ 2983 batches | lr 20.00 | ms/batch 59.01 | loss  3.80 | ppl    44.55
| prune-epoch  12 |  1200/ 2983 batches | lr 20.00 | ms/batch 59.00 | loss  3.80 | ppl    44.88
| prune-epoch  12 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.99 | loss  3.82 | ppl    45.55
| prune-epoch  12 |  1600/ 2983 batches | lr 20.00 | ms/batch 59.01 | loss  3.90 | ppl    49.63
| prune-epoch  12 |  1800/ 2983 batches | lr 20.00 | ms/batch 59.04 | loss  3.81 | ppl    45.05
| prune-epoch  12 |  2000/ 2983 batches | lr 20.00 | ms/batch 59.06 | loss  3.85 | ppl    46.85
| prune-epoch  12 |  2200/ 2983 batches | lr 20.00 | ms/batch 59.02 | loss  3.72 | ppl    41.23
| prune-epoch  12 |  2400/ 2983 batches | lr 20.00 | ms/batch 59.00 | loss  3.75 | ppl    42.37
| prune-epoch  12 |  2600/ 2983 batches | lr 20.00 | ms/batch 59.01 | loss  3.78 | ppl    43.99
| prune-epoch  12 |  2800/ 2983 batches | lr 20.00 | ms/batch 59.02 | loss  3.75 | ppl    42.43
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch  12 | time: 183.12s | valid loss  4.76 | valid ppl   116.76
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  13 |   200/ 2983 batches | lr 20.00 | ms/batch 60.90 | loss  3.80 | ppl    44.85
| prune-epoch  13 |   400/ 2983 batches | lr 20.00 | ms/batch 58.83 | loss  3.82 | ppl    45.63
| prune-epoch  13 |   600/ 2983 batches | lr 20.00 | ms/batch 58.83 | loss  3.65 | ppl    38.66
| prune-epoch  13 |   800/ 2983 batches | lr 20.00 | ms/batch 58.81 | loss  3.69 | ppl    40.13
| prune-epoch  13 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.80 | loss  3.75 | ppl    42.48
| prune-epoch  13 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.80 | loss  3.76 | ppl    42.79
| prune-epoch  13 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.81 | loss  3.78 | ppl    43.61
| prune-epoch  13 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.81 | loss  3.85 | ppl    47.18
| prune-epoch  13 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.81 | loss  3.77 | ppl    43.36
| prune-epoch  13 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.80 | loss  3.80 | ppl    44.74
| prune-epoch  13 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.82 | loss  3.67 | ppl    39.41
| prune-epoch  13 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.81 | loss  3.70 | ppl    40.52
| prune-epoch  13 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.81 | loss  3.75 | ppl    42.49
| prune-epoch  13 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.82 | loss  3.71 | ppl    40.92
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch  13 | time: 182.49s | valid loss  4.77 | valid ppl   118.28
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  14 |   200/ 2983 batches | lr 20.00 | ms/batch 60.78 | loss  3.92 | ppl    50.32
| prune-epoch  14 |   400/ 2983 batches | lr 20.00 | ms/batch 58.68 | loss  3.92 | ppl    50.45
| prune-epoch  14 |   600/ 2983 batches | lr 20.00 | ms/batch 58.66 | loss  3.74 | ppl    42.14
| prune-epoch  14 |   800/ 2983 batches | lr 20.00 | ms/batch 58.65 | loss  3.78 | ppl    43.84
| prune-epoch  14 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.67 | loss  3.83 | ppl    45.86
| prune-epoch  14 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.66 | loss  3.83 | ppl    46.00
| prune-epoch  14 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.66 | loss  3.86 | ppl    47.40
| prune-epoch  14 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.68 | loss  3.93 | ppl    51.11
| prune-epoch  14 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.70 | loss  3.84 | ppl    46.63
| prune-epoch  14 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.68 | loss  3.87 | ppl    48.03
| prune-epoch  14 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.69 | loss  3.75 | ppl    42.59
| prune-epoch  14 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.70 | loss  3.78 | ppl    43.63
| prune-epoch  14 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.73 | loss  3.81 | ppl    45.09
| prune-epoch  14 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.72 | loss  3.78 | ppl    43.95
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch  14 | time: 182.10s | valid loss  4.77 | valid ppl   117.40
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 60.71 | loss  3.83 | ppl    46.11
| prune-epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 58.76 | loss  3.84 | ppl    46.61
| prune-epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 58.76 | loss  3.68 | ppl    39.46
| prune-epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 58.75 | loss  3.72 | ppl    41.39
| prune-epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.76 | loss  3.77 | ppl    43.48
| prune-epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.77 | loss  3.78 | ppl    43.62
| prune-epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.74 | loss  3.80 | ppl    44.80
| prune-epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.76 | loss  3.88 | ppl    48.34
| prune-epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.75 | loss  3.80 | ppl    44.61
| prune-epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.77 | loss  3.83 | ppl    45.98
| prune-epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.76 | loss  3.70 | ppl    40.48
| prune-epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.76 | loss  3.73 | ppl    41.56
| prune-epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.76 | loss  3.77 | ppl    43.48
| prune-epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.76 | loss  3.74 | ppl    42.11
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch   1 | time: 182.29s | valid loss  4.80 | valid ppl   121.03
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch 60.72 | loss  3.79 | ppl    44.20
| prune-epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch 58.77 | loss  3.81 | ppl    45.04
| prune-epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch 58.78 | loss  3.64 | ppl    38.19
| prune-epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch 58.76 | loss  3.69 | ppl    40.02
| prune-epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.77 | loss  3.74 | ppl    42.04
| prune-epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.77 | loss  3.74 | ppl    42.30
| prune-epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.78 | loss  3.77 | ppl    43.41
| prune-epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.78 | loss  3.84 | ppl    46.58
| prune-epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.78 | loss  3.76 | ppl    42.93
| prune-epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.78 | loss  3.80 | ppl    44.57
| prune-epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.78 | loss  3.66 | ppl    38.98
| prune-epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.83 | loss  3.69 | ppl    40.24
| prune-epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.76 | loss  3.74 | ppl    41.93
| prune-epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.76 | loss  3.70 | ppl    40.59
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch   2 | time: 182.34s | valid loss  4.78 | valid ppl   119.22
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 60.88 | loss  3.76 | ppl    42.83
| prune-epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch 58.91 | loss  3.77 | ppl    43.47
| prune-epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 58.91 | loss  3.62 | ppl    37.23
| prune-epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 58.89 | loss  3.65 | ppl    38.46
| prune-epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.88 | loss  3.71 | ppl    40.79
| prune-epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.93 | loss  3.71 | ppl    40.75
| prune-epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.92 | loss  3.73 | ppl    41.82
| prune-epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.90 | loss  3.81 | ppl    45.19
| prune-epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.88 | loss  3.73 | ppl    41.76
| prune-epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.91 | loss  3.77 | ppl    43.27
| prune-epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.95 | loss  3.64 | ppl    38.13
| prune-epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.91 | loss  3.66 | ppl    38.98
| prune-epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.89 | loss  3.71 | ppl    40.78
| prune-epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.95 | loss  3.68 | ppl    39.71
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch   3 | time: 182.75s | valid loss  4.79 | valid ppl   120.77
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   4 |   200/ 2983 batches | lr 20.00 | ms/batch 60.26 | loss  3.74 | ppl    41.93
| prune-epoch   4 |   400/ 2983 batches | lr 20.00 | ms/batch 58.36 | loss  3.75 | ppl    42.47
| prune-epoch   4 |   600/ 2983 batches | lr 20.00 | ms/batch 58.36 | loss  3.58 | ppl    36.02
| prune-epoch   4 |   800/ 2983 batches | lr 20.00 | ms/batch 58.38 | loss  3.63 | ppl    37.81
| prune-epoch   4 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.37 | loss  3.68 | ppl    39.75
| prune-epoch   4 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.37 | loss  3.69 | ppl    39.95
| prune-epoch   4 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.37 | loss  3.71 | ppl    40.85
| prune-epoch   4 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.37 | loss  3.79 | ppl    44.34
| prune-epoch   4 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.38 | loss  3.70 | ppl    40.49
| prune-epoch   4 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.38 | loss  3.74 | ppl    42.12
| prune-epoch   4 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.40 | loss  3.61 | ppl    36.98
| prune-epoch   4 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.38 | loss  3.65 | ppl    38.29
| prune-epoch   4 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.38 | loss  3.68 | ppl    39.56
| prune-epoch   4 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.38 | loss  3.65 | ppl    38.66
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch   4 | time: 181.13s | valid loss  4.80 | valid ppl   121.64
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   5 |   200/ 2983 batches | lr 5.00 | ms/batch 60.95 | loss  3.73 | ppl    41.50
| prune-epoch   5 |   400/ 2983 batches | lr 5.00 | ms/batch 59.05 | loss  3.71 | ppl    40.71
| prune-epoch   5 |   600/ 2983 batches | lr 5.00 | ms/batch 59.08 | loss  3.53 | ppl    34.21
| prune-epoch   5 |   800/ 2983 batches | lr 5.00 | ms/batch 59.11 | loss  3.56 | ppl    35.32
| prune-epoch   5 |  1000/ 2983 batches | lr 5.00 | ms/batch 59.10 | loss  3.61 | ppl    37.10
| prune-epoch   5 |  1200/ 2983 batches | lr 5.00 | ms/batch 59.10 | loss  3.60 | ppl    36.73
| prune-epoch   5 |  1400/ 2983 batches | lr 5.00 | ms/batch 59.12 | loss  3.61 | ppl    36.94
| prune-epoch   5 |  1600/ 2983 batches | lr 5.00 | ms/batch 59.11 | loss  3.68 | ppl    39.77
| prune-epoch   5 |  1800/ 2983 batches | lr 5.00 | ms/batch 59.12 | loss  3.59 | ppl    36.13
| prune-epoch   5 |  2000/ 2983 batches | lr 5.00 | ms/batch 59.11 | loss  3.62 | ppl    37.47
| prune-epoch   5 |  2200/ 2983 batches | lr 5.00 | ms/batch 59.14 | loss  3.48 | ppl    32.42
| prune-epoch   5 |  2400/ 2983 batches | lr 5.00 | ms/batch 59.12 | loss  3.50 | ppl    33.15
| prune-epoch   5 |  2600/ 2983 batches | lr 5.00 | ms/batch 59.10 | loss  3.53 | ppl    34.09
| prune-epoch   5 |  2800/ 2983 batches | lr 5.00 | ms/batch 59.10 | loss  3.50 | ppl    33.15
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch   5 | time: 183.31s | valid loss  4.76 | valid ppl   117.30
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   6 |   200/ 2983 batches | lr 5.00 | ms/batch 60.81 | loss  3.65 | ppl    38.45
| prune-epoch   6 |   400/ 2983 batches | lr 5.00 | ms/batch 58.82 | loss  3.65 | ppl    38.28
| prune-epoch   6 |   600/ 2983 batches | lr 5.00 | ms/batch 58.82 | loss  3.48 | ppl    32.51
| prune-epoch   6 |   800/ 2983 batches | lr 5.00 | ms/batch 58.85 | loss  3.51 | ppl    33.40
| prune-epoch   6 |  1000/ 2983 batches | lr 5.00 | ms/batch 58.82 | loss  3.57 | ppl    35.59
| prune-epoch   6 |  1200/ 2983 batches | lr 5.00 | ms/batch 58.83 | loss  3.56 | ppl    35.23
| prune-epoch   6 |  1400/ 2983 batches | lr 5.00 | ms/batch 58.83 | loss  3.57 | ppl    35.52
| prune-epoch   6 |  1600/ 2983 batches | lr 5.00 | ms/batch 58.83 | loss  3.65 | ppl    38.55
| prune-epoch   6 |  1800/ 2983 batches | lr 5.00 | ms/batch 58.82 | loss  3.56 | ppl    35.28
| prune-epoch   6 |  2000/ 2983 batches | lr 5.00 | ms/batch 58.84 | loss  3.60 | ppl    36.55
| prune-epoch   6 |  2200/ 2983 batches | lr 5.00 | ms/batch 58.83 | loss  3.47 | ppl    32.02
| prune-epoch   6 |  2400/ 2983 batches | lr 5.00 | ms/batch 58.81 | loss  3.48 | ppl    32.34
| prune-epoch   6 |  2600/ 2983 batches | lr 5.00 | ms/batch 58.81 | loss  3.51 | ppl    33.55
| prune-epoch   6 |  2800/ 2983 batches | lr 5.00 | ms/batch 58.82 | loss  3.49 | ppl    32.74
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch   6 | time: 182.50s | valid loss  4.77 | valid ppl   118.31
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   7 |   200/ 2983 batches | lr 5.00 | ms/batch 60.77 | loss  3.62 | ppl    37.33
| prune-epoch   7 |   400/ 2983 batches | lr 5.00 | ms/batch 58.83 | loss  3.62 | ppl    37.25
| prune-epoch   7 |   600/ 2983 batches | lr 5.00 | ms/batch 58.83 | loss  3.46 | ppl    31.68
| prune-epoch   7 |   800/ 2983 batches | lr 5.00 | ms/batch 59.00 | loss  3.49 | ppl    32.70
| prune-epoch   7 |  1000/ 2983 batches | lr 5.00 | ms/batch 58.84 | loss  3.56 | ppl    35.00
| prune-epoch   7 |  1200/ 2983 batches | lr 5.00 | ms/batch 58.84 | loss  3.55 | ppl    34.69
| prune-epoch   7 |  1400/ 2983 batches | lr 5.00 | ms/batch 58.86 | loss  3.55 | ppl    34.79
| prune-epoch   7 |  1600/ 2983 batches | lr 5.00 | ms/batch 58.84 | loss  3.64 | ppl    37.94
| prune-epoch   7 |  1800/ 2983 batches | lr 5.00 | ms/batch 58.85 | loss  3.54 | ppl    34.60
| prune-epoch   7 |  2000/ 2983 batches | lr 5.00 | ms/batch 58.87 | loss  3.57 | ppl    35.59
| prune-epoch   7 |  2200/ 2983 batches | lr 5.00 | ms/batch 58.87 | loss  3.45 | ppl    31.36
| prune-epoch   7 |  2400/ 2983 batches | lr 5.00 | ms/batch 58.89 | loss  3.47 | ppl    32.08
| prune-epoch   7 |  2600/ 2983 batches | lr 5.00 | ms/batch 58.85 | loss  3.50 | ppl    33.03
| prune-epoch   7 |  2800/ 2983 batches | lr 5.00 | ms/batch 58.85 | loss  3.46 | ppl    31.91
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch   7 | time: 182.60s | valid loss  4.78 | valid ppl   118.65
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   8 |   200/ 2983 batches | lr 1.25 | ms/batch 60.89 | loss  3.66 | ppl    38.75
| prune-epoch   8 |   400/ 2983 batches | lr 1.25 | ms/batch 58.97 | loss  3.68 | ppl    39.56
| prune-epoch   8 |   600/ 2983 batches | lr 1.25 | ms/batch 58.98 | loss  3.50 | ppl    33.04
| prune-epoch   8 |   800/ 2983 batches | lr 1.25 | ms/batch 58.99 | loss  3.52 | ppl    33.69
| prune-epoch   8 |  1000/ 2983 batches | lr 1.25 | ms/batch 59.00 | loss  3.58 | ppl    35.87
| prune-epoch   8 |  1200/ 2983 batches | lr 1.25 | ms/batch 58.98 | loss  3.64 | ppl    38.00
| prune-epoch   8 |  1400/ 2983 batches | lr 1.25 | ms/batch 58.98 | loss  3.55 | ppl    34.84
| prune-epoch   8 |  1600/ 2983 batches | lr 1.25 | ms/batch 58.99 | loss  3.66 | ppl    38.84
| prune-epoch   8 |  1800/ 2983 batches | lr 1.25 | ms/batch 58.99 | loss  3.58 | ppl    35.80
| prune-epoch   8 |  2000/ 2983 batches | lr 1.25 | ms/batch 58.99 | loss  3.61 | ppl    36.80
| prune-epoch   8 |  2200/ 2983 batches | lr 1.25 | ms/batch 58.98 | loss  3.46 | ppl    31.66
| prune-epoch   8 |  2400/ 2983 batches | lr 1.25 | ms/batch 58.97 | loss  3.48 | ppl    32.41
| prune-epoch   8 |  2600/ 2983 batches | lr 1.25 | ms/batch 58.98 | loss  3.52 | ppl    33.72
| prune-epoch   8 |  2800/ 2983 batches | lr 1.25 | ms/batch 58.98 | loss  3.49 | ppl    32.76
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch   8 | time: 182.96s | valid loss  4.74 | valid ppl   114.76
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   9 |   200/ 2983 batches | lr 1.25 | ms/batch 60.74 | loss  3.64 | ppl    38.09
| prune-epoch   9 |   400/ 2983 batches | lr 1.25 | ms/batch 58.79 | loss  3.65 | ppl    38.45
| prune-epoch   9 |   600/ 2983 batches | lr 1.25 | ms/batch 58.80 | loss  3.46 | ppl    31.95
| prune-epoch   9 |   800/ 2983 batches | lr 1.25 | ms/batch 58.80 | loss  3.50 | ppl    33.17
| prune-epoch   9 |  1000/ 2983 batches | lr 1.25 | ms/batch 58.80 | loss  3.55 | ppl    34.82
| prune-epoch   9 |  1200/ 2983 batches | lr 1.25 | ms/batch 58.80 | loss  3.63 | ppl    37.63
| prune-epoch   9 |  1400/ 2983 batches | lr 1.25 | ms/batch 58.80 | loss  3.54 | ppl    34.53
| prune-epoch   9 |  1600/ 2983 batches | lr 1.25 | ms/batch 58.81 | loss  3.65 | ppl    38.28
| prune-epoch   9 |  1800/ 2983 batches | lr 1.25 | ms/batch 58.79 | loss  3.55 | ppl    34.90
| prune-epoch   9 |  2000/ 2983 batches | lr 1.25 | ms/batch 58.80 | loss  3.59 | ppl    36.05
| prune-epoch   9 |  2200/ 2983 batches | lr 1.25 | ms/batch 58.79 | loss  3.45 | ppl    31.43
| prune-epoch   9 |  2400/ 2983 batches | lr 1.25 | ms/batch 58.81 | loss  3.48 | ppl    32.30
| prune-epoch   9 |  2600/ 2983 batches | lr 1.25 | ms/batch 58.79 | loss  3.51 | ppl    33.51
| prune-epoch   9 |  2800/ 2983 batches | lr 1.25 | ms/batch 58.80 | loss  3.48 | ppl    32.32
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch   9 | time: 182.41s | valid loss  4.74 | valid ppl   114.81
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  10 |   200/ 2983 batches | lr 1.25 | ms/batch 60.84 | loss  3.63 | ppl    37.59
| prune-epoch  10 |   400/ 2983 batches | lr 1.25 | ms/batch 58.88 | loss  3.64 | ppl    38.02
| prune-epoch  10 |   600/ 2983 batches | lr 1.25 | ms/batch 58.87 | loss  3.45 | ppl    31.53
| prune-epoch  10 |   800/ 2983 batches | lr 1.25 | ms/batch 58.88 | loss  3.50 | ppl    33.13
| prune-epoch  10 |  1000/ 2983 batches | lr 1.25 | ms/batch 58.89 | loss  3.54 | ppl    34.45
| prune-epoch  10 |  1200/ 2983 batches | lr 1.25 | ms/batch 58.88 | loss  3.61 | ppl    36.93
| prune-epoch  10 |  1400/ 2983 batches | lr 1.25 | ms/batch 58.89 | loss  3.54 | ppl    34.34
| prune-epoch  10 |  1600/ 2983 batches | lr 1.25 | ms/batch 58.88 | loss  3.65 | ppl    38.37
| prune-epoch  10 |  1800/ 2983 batches | lr 1.25 | ms/batch 58.91 | loss  3.55 | ppl    34.72
| prune-epoch  10 |  2000/ 2983 batches | lr 1.25 | ms/batch 58.89 | loss  3.58 | ppl    36.03
| prune-epoch  10 |  2200/ 2983 batches | lr 1.25 | ms/batch 58.90 | loss  3.45 | ppl    31.35
| prune-epoch  10 |  2400/ 2983 batches | lr 1.25 | ms/batch 58.93 | loss  3.47 | ppl    32.18
| prune-epoch  10 |  2600/ 2983 batches | lr 1.25 | ms/batch 58.92 | loss  3.50 | ppl    33.18
| prune-epoch  10 |  2800/ 2983 batches | lr 1.25 | ms/batch 58.89 | loss  3.47 | ppl    32.04
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  10 | time: 182.70s | valid loss  4.74 | valid ppl   114.53
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  11 |   200/ 2983 batches | lr 1.25 | ms/batch 60.34 | loss  3.61 | ppl    37.13
| prune-epoch  11 |   400/ 2983 batches | lr 1.25 | ms/batch 58.33 | loss  3.63 | ppl    37.85
| prune-epoch  11 |   600/ 2983 batches | lr 1.25 | ms/batch 58.34 | loss  3.45 | ppl    31.47
| prune-epoch  11 |   800/ 2983 batches | lr 1.25 | ms/batch 58.33 | loss  3.50 | ppl    32.99
| prune-epoch  11 |  1000/ 2983 batches | lr 1.25 | ms/batch 58.34 | loss  3.53 | ppl    33.98
| prune-epoch  11 |  1200/ 2983 batches | lr 1.25 | ms/batch 58.34 | loss  3.59 | ppl    36.25
| prune-epoch  11 |  1400/ 2983 batches | lr 1.25 | ms/batch 58.34 | loss  3.54 | ppl    34.45
| prune-epoch  11 |  1600/ 2983 batches | lr 1.25 | ms/batch 58.34 | loss  3.63 | ppl    37.88
| prune-epoch  11 |  1800/ 2983 batches | lr 1.25 | ms/batch 58.35 | loss  3.55 | ppl    34.64
| prune-epoch  11 |  2000/ 2983 batches | lr 1.25 | ms/batch 58.36 | loss  3.58 | ppl    35.72
| prune-epoch  11 |  2200/ 2983 batches | lr 1.25 | ms/batch 58.33 | loss  3.43 | ppl    30.95
| prune-epoch  11 |  2400/ 2983 batches | lr 1.25 | ms/batch 58.36 | loss  3.47 | ppl    31.98
| prune-epoch  11 |  2600/ 2983 batches | lr 1.25 | ms/batch 58.34 | loss  3.50 | ppl    33.05
| prune-epoch  11 |  2800/ 2983 batches | lr 1.25 | ms/batch 58.33 | loss  3.46 | ppl    31.87
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  11 | time: 181.06s | valid loss  4.74 | valid ppl   114.25
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  12 |   200/ 2983 batches | lr 1.25 | ms/batch 61.04 | loss  3.61 | ppl    36.85
| prune-epoch  12 |   400/ 2983 batches | lr 1.25 | ms/batch 59.01 | loss  3.62 | ppl    37.46
| prune-epoch  12 |   600/ 2983 batches | lr 1.25 | ms/batch 59.00 | loss  3.43 | ppl    30.95
| prune-epoch  12 |   800/ 2983 batches | lr 1.25 | ms/batch 59.00 | loss  3.49 | ppl    32.71
| prune-epoch  12 |  1000/ 2983 batches | lr 1.25 | ms/batch 59.00 | loss  3.52 | ppl    33.93
| prune-epoch  12 |  1200/ 2983 batches | lr 1.25 | ms/batch 59.00 | loss  3.60 | ppl    36.57
| prune-epoch  12 |  1400/ 2983 batches | lr 1.25 | ms/batch 59.00 | loss  3.53 | ppl    34.23
| prune-epoch  12 |  1600/ 2983 batches | lr 1.25 | ms/batch 59.00 | loss  3.63 | ppl    37.69
| prune-epoch  12 |  1800/ 2983 batches | lr 1.25 | ms/batch 59.00 | loss  3.54 | ppl    34.50
| prune-epoch  12 |  2000/ 2983 batches | lr 1.25 | ms/batch 59.05 | loss  3.58 | ppl    35.89
| prune-epoch  12 |  2200/ 2983 batches | lr 1.25 | ms/batch 58.98 | loss  3.43 | ppl    30.74
| prune-epoch  12 |  2400/ 2983 batches | lr 1.25 | ms/batch 58.96 | loss  3.46 | ppl    31.96
| prune-epoch  12 |  2600/ 2983 batches | lr 1.25 | ms/batch 58.99 | loss  3.49 | ppl    32.88
| prune-epoch  12 |  2800/ 2983 batches | lr 1.25 | ms/batch 58.98 | loss  3.45 | ppl    31.64
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  12 | time: 183.03s | valid loss  4.73 | valid ppl   113.24
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  13 |   200/ 2983 batches | lr 1.25 | ms/batch 60.88 | loss  3.60 | ppl    36.50
| prune-epoch  13 |   400/ 2983 batches | lr 1.25 | ms/batch 58.84 | loss  3.62 | ppl    37.42
| prune-epoch  13 |   600/ 2983 batches | lr 1.25 | ms/batch 58.85 | loss  3.43 | ppl    30.79
| prune-epoch  13 |   800/ 2983 batches | lr 1.25 | ms/batch 58.83 | loss  3.49 | ppl    32.85
| prune-epoch  13 |  1000/ 2983 batches | lr 1.25 | ms/batch 58.84 | loss  3.52 | ppl    33.82
| prune-epoch  13 |  1200/ 2983 batches | lr 1.25 | ms/batch 58.82 | loss  3.58 | ppl    35.99
| prune-epoch  13 |  1400/ 2983 batches | lr 1.25 | ms/batch 58.85 | loss  3.53 | ppl    34.00
| prune-epoch  13 |  1600/ 2983 batches | lr 1.25 | ms/batch 58.84 | loss  3.62 | ppl    37.39
| prune-epoch  13 |  1800/ 2983 batches | lr 1.25 | ms/batch 58.85 | loss  3.54 | ppl    34.45
| prune-epoch  13 |  2000/ 2983 batches | lr 1.25 | ms/batch 58.86 | loss  3.57 | ppl    35.50
| prune-epoch  13 |  2200/ 2983 batches | lr 1.25 | ms/batch 58.86 | loss  3.43 | ppl    30.82
| prune-epoch  13 |  2400/ 2983 batches | lr 1.25 | ms/batch 58.84 | loss  3.46 | ppl    31.74
| prune-epoch  13 |  2600/ 2983 batches | lr 1.25 | ms/batch 58.85 | loss  3.49 | ppl    32.86
| prune-epoch  13 |  2800/ 2983 batches | lr 1.25 | ms/batch 58.84 | loss  3.45 | ppl    31.41
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  13 | time: 182.57s | valid loss  4.73 | valid ppl   113.75
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  14 |   200/ 2983 batches | lr 0.31 | ms/batch 60.77 | loss  3.64 | ppl    38.27
| prune-epoch  14 |   400/ 2983 batches | lr 0.31 | ms/batch 58.87 | loss  3.78 | ppl    43.69
| prune-epoch  14 |   600/ 2983 batches | lr 0.31 | ms/batch 58.90 | loss  3.56 | ppl    35.11
| prune-epoch  14 |   800/ 2983 batches | lr 0.31 | ms/batch 58.88 | loss  3.58 | ppl    35.87
| prune-epoch  14 |  1000/ 2983 batches | lr 0.31 | ms/batch 58.89 | loss  3.64 | ppl    37.98
| prune-epoch  14 |  1200/ 2983 batches | lr 0.31 | ms/batch 58.85 | loss  3.63 | ppl    37.65
| prune-epoch  14 |  1400/ 2983 batches | lr 0.31 | ms/batch 58.86 | loss  3.67 | ppl    39.15
| prune-epoch  14 |  1600/ 2983 batches | lr 0.31 | ms/batch 58.87 | loss  3.72 | ppl    41.21
| prune-epoch  14 |  1800/ 2983 batches | lr 0.31 | ms/batch 58.90 | loss  3.58 | ppl    35.77
| prune-epoch  14 |  2000/ 2983 batches | lr 0.31 | ms/batch 58.87 | loss  3.63 | ppl    37.58
| prune-epoch  14 |  2200/ 2983 batches | lr 0.31 | ms/batch 58.90 | loss  3.49 | ppl    32.82
| prune-epoch  14 |  2400/ 2983 batches | lr 0.31 | ms/batch 58.87 | loss  3.49 | ppl    32.81
| prune-epoch  14 |  2600/ 2983 batches | lr 0.31 | ms/batch 58.85 | loss  3.57 | ppl    35.51
| prune-epoch  14 |  2800/ 2983 batches | lr 0.31 | ms/batch 58.88 | loss  3.53 | ppl    33.97
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  14 | time: 182.63s | valid loss  4.68 | valid ppl   107.91
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  15 |   200/ 2983 batches | lr 0.31 | ms/batch 60.82 | loss  3.65 | ppl    38.35
| prune-epoch  15 |   400/ 2983 batches | lr 0.31 | ms/batch 58.86 | loss  3.71 | ppl    41.03
| prune-epoch  15 |   600/ 2983 batches | lr 0.31 | ms/batch 58.88 | loss  3.52 | ppl    33.95
| prune-epoch  15 |   800/ 2983 batches | lr 0.31 | ms/batch 58.87 | loss  3.57 | ppl    35.35
| prune-epoch  15 |  1000/ 2983 batches | lr 0.31 | ms/batch 58.88 | loss  3.60 | ppl    36.74
| prune-epoch  15 |  1200/ 2983 batches | lr 0.31 | ms/batch 58.87 | loss  3.62 | ppl    37.34
| prune-epoch  15 |  1400/ 2983 batches | lr 0.31 | ms/batch 58.85 | loss  3.64 | ppl    38.09
| prune-epoch  15 |  1600/ 2983 batches | lr 0.31 | ms/batch 58.86 | loss  3.70 | ppl    40.44
| prune-epoch  15 |  1800/ 2983 batches | lr 0.31 | ms/batch 58.86 | loss  3.58 | ppl    36.03
| prune-epoch  15 |  2000/ 2983 batches | lr 0.31 | ms/batch 58.86 | loss  3.61 | ppl    36.85
| prune-epoch  15 |  2200/ 2983 batches | lr 0.31 | ms/batch 58.85 | loss  3.48 | ppl    32.46
| prune-epoch  15 |  2400/ 2983 batches | lr 0.31 | ms/batch 58.88 | loss  3.48 | ppl    32.49
| prune-epoch  15 |  2600/ 2983 batches | lr 0.31 | ms/batch 58.89 | loss  3.56 | ppl    35.18
| prune-epoch  15 |  2800/ 2983 batches | lr 0.31 | ms/batch 58.86 | loss  3.52 | ppl    33.87
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  15 | time: 182.62s | valid loss  4.68 | valid ppl   107.75
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  16 |   200/ 2983 batches | lr 0.31 | ms/batch 60.75 | loss  3.64 | ppl    37.93
| prune-epoch  16 |   400/ 2983 batches | lr 0.31 | ms/batch 58.80 | loss  3.71 | ppl    40.92
| prune-epoch  16 |   600/ 2983 batches | lr 0.31 | ms/batch 58.81 | loss  3.52 | ppl    33.73
| prune-epoch  16 |   800/ 2983 batches | lr 0.31 | ms/batch 58.80 | loss  3.55 | ppl    34.96
| prune-epoch  16 |  1000/ 2983 batches | lr 0.31 | ms/batch 58.80 | loss  3.59 | ppl    36.39
| prune-epoch  16 |  1200/ 2983 batches | lr 0.31 | ms/batch 58.80 | loss  3.61 | ppl    37.00
| prune-epoch  16 |  1400/ 2983 batches | lr 0.31 | ms/batch 58.80 | loss  3.62 | ppl    37.51
| prune-epoch  16 |  1600/ 2983 batches | lr 0.31 | ms/batch 58.81 | loss  3.70 | ppl    40.27
| prune-epoch  16 |  1800/ 2983 batches | lr 0.31 | ms/batch 58.82 | loss  3.59 | ppl    36.17
| prune-epoch  16 |  2000/ 2983 batches | lr 0.31 | ms/batch 58.81 | loss  3.61 | ppl    37.09
| prune-epoch  16 |  2200/ 2983 batches | lr 0.31 | ms/batch 58.80 | loss  3.47 | ppl    32.15
| prune-epoch  16 |  2400/ 2983 batches | lr 0.31 | ms/batch 58.80 | loss  3.48 | ppl    32.35
| prune-epoch  16 |  2600/ 2983 batches | lr 0.31 | ms/batch 58.82 | loss  3.55 | ppl    34.68
| prune-epoch  16 |  2800/ 2983 batches | lr 0.31 | ms/batch 58.81 | loss  3.52 | ppl    33.70
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  16 | time: 182.44s | valid loss  4.68 | valid ppl   107.56
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  17 |   200/ 2983 batches | lr 0.31 | ms/batch 60.89 | loss  3.64 | ppl    37.93
| prune-epoch  17 |   400/ 2983 batches | lr 0.31 | ms/batch 58.84 | loss  3.70 | ppl    40.61
| prune-epoch  17 |   600/ 2983 batches | lr 0.31 | ms/batch 58.82 | loss  3.51 | ppl    33.44
| prune-epoch  17 |   800/ 2983 batches | lr 0.31 | ms/batch 58.84 | loss  3.56 | ppl    35.03
| prune-epoch  17 |  1000/ 2983 batches | lr 0.31 | ms/batch 58.91 | loss  3.60 | ppl    36.49
| prune-epoch  17 |  1200/ 2983 batches | lr 0.31 | ms/batch 58.87 | loss  3.62 | ppl    37.26
| prune-epoch  17 |  1400/ 2983 batches | lr 0.31 | ms/batch 58.84 | loss  3.63 | ppl    37.69
| prune-epoch  17 |  1600/ 2983 batches | lr 0.31 | ms/batch 58.88 | loss  3.68 | ppl    39.78
| prune-epoch  17 |  1800/ 2983 batches | lr 0.31 | ms/batch 58.84 | loss  3.58 | ppl    35.98
| prune-epoch  17 |  2000/ 2983 batches | lr 0.31 | ms/batch 58.85 | loss  3.61 | ppl    36.91
| prune-epoch  17 |  2200/ 2983 batches | lr 0.31 | ms/batch 58.84 | loss  3.47 | ppl    32.20
| prune-epoch  17 |  2400/ 2983 batches | lr 0.31 | ms/batch 58.83 | loss  3.48 | ppl    32.59
| prune-epoch  17 |  2600/ 2983 batches | lr 0.31 | ms/batch 58.85 | loss  3.55 | ppl    34.92
| prune-epoch  17 |  2800/ 2983 batches | lr 0.31 | ms/batch 58.85 | loss  3.53 | ppl    33.99
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  17 | time: 182.59s | valid loss  4.68 | valid ppl   107.47
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  18 |   200/ 2983 batches | lr 0.31 | ms/batch 60.52 | loss  3.64 | ppl    38.11
| prune-epoch  18 |   400/ 2983 batches | lr 0.31 | ms/batch 58.51 | loss  3.69 | ppl    40.15
| prune-epoch  18 |   600/ 2983 batches | lr 0.31 | ms/batch 58.50 | loss  3.50 | ppl    33.21
| prune-epoch  18 |   800/ 2983 batches | lr 0.31 | ms/batch 58.52 | loss  3.55 | ppl    34.98
| prune-epoch  18 |  1000/ 2983 batches | lr 0.31 | ms/batch 58.51 | loss  3.59 | ppl    36.26
| prune-epoch  18 |  1200/ 2983 batches | lr 0.31 | ms/batch 58.52 | loss  3.61 | ppl    37.03
| prune-epoch  18 |  1400/ 2983 batches | lr 0.31 | ms/batch 58.50 | loss  3.63 | ppl    37.59
| prune-epoch  18 |  1600/ 2983 batches | lr 0.31 | ms/batch 58.52 | loss  3.68 | ppl    39.48
| prune-epoch  18 |  1800/ 2983 batches | lr 0.31 | ms/batch 58.52 | loss  3.58 | ppl    35.77
| prune-epoch  18 |  2000/ 2983 batches | lr 0.31 | ms/batch 58.51 | loss  3.62 | ppl    37.30
| prune-epoch  18 |  2200/ 2983 batches | lr 0.31 | ms/batch 58.52 | loss  3.48 | ppl    32.31
| prune-epoch  18 |  2400/ 2983 batches | lr 0.31 | ms/batch 58.52 | loss  3.48 | ppl    32.44
| prune-epoch  18 |  2600/ 2983 batches | lr 0.31 | ms/batch 58.52 | loss  3.55 | ppl    34.92
| prune-epoch  18 |  2800/ 2983 batches | lr 0.31 | ms/batch 58.51 | loss  3.52 | ppl    33.84
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  18 | time: 181.57s | valid loss  4.67 | valid ppl   107.21
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  19 |   200/ 2983 batches | lr 0.31 | ms/batch 61.15 | loss  3.64 | ppl    37.91
| prune-epoch  19 |   400/ 2983 batches | lr 0.31 | ms/batch 59.14 | loss  3.68 | ppl    39.84
| prune-epoch  19 |   600/ 2983 batches | lr 0.31 | ms/batch 59.16 | loss  3.50 | ppl    32.99
| prune-epoch  19 |   800/ 2983 batches | lr 0.31 | ms/batch 59.16 | loss  3.56 | ppl    35.03
| prune-epoch  19 |  1000/ 2983 batches | lr 0.31 | ms/batch 59.14 | loss  3.57 | ppl    35.43
| prune-epoch  19 |  1200/ 2983 batches | lr 0.31 | ms/batch 59.12 | loss  3.61 | ppl    36.83
| prune-epoch  19 |  1400/ 2983 batches | lr 0.31 | ms/batch 59.13 | loss  3.63 | ppl    37.67
| prune-epoch  19 |  1600/ 2983 batches | lr 0.31 | ms/batch 59.16 | loss  3.68 | ppl    39.58
| prune-epoch  19 |  1800/ 2983 batches | lr 0.31 | ms/batch 59.15 | loss  3.58 | ppl    35.93
| prune-epoch  19 |  2000/ 2983 batches | lr 0.31 | ms/batch 59.12 | loss  3.61 | ppl    36.95
| prune-epoch  19 |  2200/ 2983 batches | lr 0.31 | ms/batch 59.15 | loss  3.47 | ppl    32.15
| prune-epoch  19 |  2400/ 2983 batches | lr 0.31 | ms/batch 59.12 | loss  3.47 | ppl    32.28
| prune-epoch  19 |  2600/ 2983 batches | lr 0.31 | ms/batch 59.15 | loss  3.54 | ppl    34.52
| prune-epoch  19 |  2800/ 2983 batches | lr 0.31 | ms/batch 59.12 | loss  3.51 | ppl    33.59
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  19 | time: 183.44s | valid loss  4.67 | valid ppl   107.12
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  20 |   200/ 2983 batches | lr 0.31 | ms/batch 60.93 | loss  3.64 | ppl    38.13
| prune-epoch  20 |   400/ 2983 batches | lr 0.31 | ms/batch 58.84 | loss  3.68 | ppl    39.63
| prune-epoch  20 |   600/ 2983 batches | lr 0.31 | ms/batch 58.83 | loss  3.50 | ppl    32.99
| prune-epoch  20 |   800/ 2983 batches | lr 0.31 | ms/batch 58.82 | loss  3.56 | ppl    35.11
| prune-epoch  20 |  1000/ 2983 batches | lr 0.31 | ms/batch 58.84 | loss  3.58 | ppl    35.74
| prune-epoch  20 |  1200/ 2983 batches | lr 0.31 | ms/batch 58.85 | loss  3.62 | ppl    37.16
| prune-epoch  20 |  1400/ 2983 batches | lr 0.31 | ms/batch 58.84 | loss  3.63 | ppl    37.58
| prune-epoch  20 |  1600/ 2983 batches | lr 0.31 | ms/batch 58.84 | loss  3.68 | ppl    39.69
| prune-epoch  20 |  1800/ 2983 batches | lr 0.31 | ms/batch 58.84 | loss  3.58 | ppl    35.88
| prune-epoch  20 |  2000/ 2983 batches | lr 0.31 | ms/batch 58.84 | loss  3.61 | ppl    36.81
| prune-epoch  20 |  2200/ 2983 batches | lr 0.31 | ms/batch 58.83 | loss  3.46 | ppl    31.96
| prune-epoch  20 |  2400/ 2983 batches | lr 0.31 | ms/batch 58.84 | loss  3.47 | ppl    32.05
| prune-epoch  20 |  2600/ 2983 batches | lr 0.31 | ms/batch 58.83 | loss  3.55 | ppl    34.77
| prune-epoch  20 |  2800/ 2983 batches | lr 0.31 | ms/batch 58.83 | loss  3.52 | ppl    33.73
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  20 | time: 182.55s | valid loss  4.67 | valid ppl   106.93
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  21 |   200/ 2983 batches | lr 0.31 | ms/batch 60.76 | loss  3.63 | ppl    37.59
| prune-epoch  21 |   400/ 2983 batches | lr 0.31 | ms/batch 58.81 | loss  3.68 | ppl    39.73
| prune-epoch  21 |   600/ 2983 batches | lr 0.31 | ms/batch 58.75 | loss  3.49 | ppl    32.85
| prune-epoch  21 |   800/ 2983 batches | lr 0.31 | ms/batch 58.77 | loss  3.55 | ppl    34.72
| prune-epoch  21 |  1000/ 2983 batches | lr 0.31 | ms/batch 58.76 | loss  3.57 | ppl    35.59
| prune-epoch  21 |  1200/ 2983 batches | lr 0.31 | ms/batch 58.76 | loss  3.61 | ppl    36.84
| prune-epoch  21 |  1400/ 2983 batches | lr 0.31 | ms/batch 58.80 | loss  3.62 | ppl    37.45
| prune-epoch  21 |  1600/ 2983 batches | lr 0.31 | ms/batch 58.79 | loss  3.68 | ppl    39.49
| prune-epoch  21 |  1800/ 2983 batches | lr 0.31 | ms/batch 58.74 | loss  3.58 | ppl    35.94
| prune-epoch  21 |  2000/ 2983 batches | lr 0.31 | ms/batch 58.73 | loss  3.61 | ppl    36.79
| prune-epoch  21 |  2200/ 2983 batches | lr 0.31 | ms/batch 58.75 | loss  3.47 | ppl    32.18
| prune-epoch  21 |  2400/ 2983 batches | lr 0.31 | ms/batch 58.72 | loss  3.47 | ppl    32.09
| prune-epoch  21 |  2600/ 2983 batches | lr 0.31 | ms/batch 58.76 | loss  3.55 | ppl    34.76
| prune-epoch  21 |  2800/ 2983 batches | lr 0.31 | ms/batch 58.79 | loss  3.52 | ppl    33.69
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  21 | time: 182.32s | valid loss  4.67 | valid ppl   106.98
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  22 |   200/ 2983 batches | lr 0.31 | ms/batch 60.87 | loss  3.63 | ppl    37.53
| prune-epoch  22 |   400/ 2983 batches | lr 0.31 | ms/batch 58.98 | loss  3.67 | ppl    39.13
| prune-epoch  22 |   600/ 2983 batches | lr 0.31 | ms/batch 58.95 | loss  3.48 | ppl    32.47
| prune-epoch  22 |   800/ 2983 batches | lr 0.31 | ms/batch 58.98 | loss  3.54 | ppl    34.39
| prune-epoch  22 |  1000/ 2983 batches | lr 0.31 | ms/batch 58.97 | loss  3.56 | ppl    35.34
| prune-epoch  22 |  1200/ 2983 batches | lr 0.31 | ms/batch 58.97 | loss  3.61 | ppl    36.87
| prune-epoch  22 |  1400/ 2983 batches | lr 0.31 | ms/batch 58.98 | loss  3.63 | ppl    37.70
| prune-epoch  22 |  1600/ 2983 batches | lr 0.31 | ms/batch 58.99 | loss  3.67 | ppl    39.32
| prune-epoch  22 |  1800/ 2983 batches | lr 0.31 | ms/batch 58.98 | loss  3.58 | ppl    35.93
| prune-epoch  22 |  2000/ 2983 batches | lr 0.31 | ms/batch 59.01 | loss  3.60 | ppl    36.76
| prune-epoch  22 |  2200/ 2983 batches | lr 0.31 | ms/batch 59.00 | loss  3.46 | ppl    31.90
| prune-epoch  22 |  2400/ 2983 batches | lr 0.31 | ms/batch 58.98 | loss  3.47 | ppl    32.10
| prune-epoch  22 |  2600/ 2983 batches | lr 0.31 | ms/batch 58.98 | loss  3.55 | ppl    34.91
| prune-epoch  22 |  2800/ 2983 batches | lr 0.31 | ms/batch 58.98 | loss  3.52 | ppl    33.68
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  22 | time: 182.95s | valid loss  4.67 | valid ppl   106.93
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  23 |   200/ 2983 batches | lr 0.31 | ms/batch 60.93 | loss  3.62 | ppl    37.34
| prune-epoch  23 |   400/ 2983 batches | lr 0.31 | ms/batch 58.94 | loss  3.67 | ppl    39.34
| prune-epoch  23 |   600/ 2983 batches | lr 0.31 | ms/batch 58.93 | loss  3.47 | ppl    32.12
| prune-epoch  23 |   800/ 2983 batches | lr 0.31 | ms/batch 58.92 | loss  3.54 | ppl    34.46
| prune-epoch  23 |  1000/ 2983 batches | lr 0.31 | ms/batch 58.93 | loss  3.56 | ppl    35.21
| prune-epoch  23 |  1200/ 2983 batches | lr 0.31 | ms/batch 58.94 | loss  3.60 | ppl    36.59
| prune-epoch  23 |  1400/ 2983 batches | lr 0.31 | ms/batch 58.95 | loss  3.62 | ppl    37.22
| prune-epoch  23 |  1600/ 2983 batches | lr 0.31 | ms/batch 58.93 | loss  3.67 | ppl    39.31
| prune-epoch  23 |  1800/ 2983 batches | lr 0.31 | ms/batch 58.94 | loss  3.59 | ppl    36.08
| prune-epoch  23 |  2000/ 2983 batches | lr 0.31 | ms/batch 58.94 | loss  3.61 | ppl    36.87
| prune-epoch  23 |  2200/ 2983 batches | lr 0.31 | ms/batch 58.94 | loss  3.46 | ppl    31.68
| prune-epoch  23 |  2400/ 2983 batches | lr 0.31 | ms/batch 58.95 | loss  3.46 | ppl    31.88
| prune-epoch  23 |  2600/ 2983 batches | lr 0.31 | ms/batch 58.94 | loss  3.54 | ppl    34.44
| prune-epoch  23 |  2800/ 2983 batches | lr 0.31 | ms/batch 58.93 | loss  3.51 | ppl    33.42
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  23 | time: 182.83s | valid loss  4.67 | valid ppl   106.83
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  24 |   200/ 2983 batches | lr 0.31 | ms/batch 60.99 | loss  3.62 | ppl    37.48
| prune-epoch  24 |   400/ 2983 batches | lr 0.31 | ms/batch 58.96 | loss  3.65 | ppl    38.56
| prune-epoch  24 |   600/ 2983 batches | lr 0.31 | ms/batch 58.93 | loss  3.47 | ppl    32.25
| prune-epoch  24 |   800/ 2983 batches | lr 0.31 | ms/batch 58.96 | loss  3.54 | ppl    34.30
| prune-epoch  24 |  1000/ 2983 batches | lr 0.31 | ms/batch 58.97 | loss  3.55 | ppl    34.97
| prune-epoch  24 |  1200/ 2983 batches | lr 0.31 | ms/batch 58.97 | loss  3.60 | ppl    36.71
| prune-epoch  24 |  1400/ 2983 batches | lr 0.31 | ms/batch 58.97 | loss  3.62 | ppl    37.21
| prune-epoch  24 |  1600/ 2983 batches | lr 0.31 | ms/batch 58.97 | loss  3.67 | ppl    39.17
| prune-epoch  24 |  1800/ 2983 batches | lr 0.31 | ms/batch 58.99 | loss  3.58 | ppl    35.88
| prune-epoch  24 |  2000/ 2983 batches | lr 0.31 | ms/batch 58.95 | loss  3.60 | ppl    36.59
| prune-epoch  24 |  2200/ 2983 batches | lr 0.31 | ms/batch 58.97 | loss  3.46 | ppl    31.93
| prune-epoch  24 |  2400/ 2983 batches | lr 0.31 | ms/batch 58.96 | loss  3.47 | ppl    32.07
| prune-epoch  24 |  2600/ 2983 batches | lr 0.31 | ms/batch 58.95 | loss  3.55 | ppl    34.65
| prune-epoch  24 |  2800/ 2983 batches | lr 0.31 | ms/batch 58.95 | loss  3.51 | ppl    33.35
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  24 | time: 182.91s | valid loss  4.67 | valid ppl   106.87
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  25 |   200/ 2983 batches | lr 0.08 | ms/batch 60.44 | loss  3.64 | ppl    38.25
| prune-epoch  25 |   400/ 2983 batches | lr 0.08 | ms/batch 58.53 | loss  3.72 | ppl    41.19
| prune-epoch  25 |   600/ 2983 batches | lr 0.08 | ms/batch 58.53 | loss  3.56 | ppl    35.21
| prune-epoch  25 |   800/ 2983 batches | lr 0.08 | ms/batch 58.53 | loss  3.64 | ppl    38.05
| prune-epoch  25 |  1000/ 2983 batches | lr 0.08 | ms/batch 58.52 | loss  3.64 | ppl    38.19
| prune-epoch  25 |  1200/ 2983 batches | lr 0.08 | ms/batch 58.52 | loss  3.64 | ppl    38.16
| prune-epoch  25 |  1400/ 2983 batches | lr 0.08 | ms/batch 58.53 | loss  3.67 | ppl    39.08
| prune-epoch  25 |  1600/ 2983 batches | lr 0.08 | ms/batch 58.53 | loss  3.75 | ppl    42.39
| prune-epoch  25 |  1800/ 2983 batches | lr 0.08 | ms/batch 58.51 | loss  3.67 | ppl    39.11
| prune-epoch  25 |  2000/ 2983 batches | lr 0.08 | ms/batch 58.55 | loss  3.68 | ppl    39.50
| prune-epoch  25 |  2200/ 2983 batches | lr 0.08 | ms/batch 58.52 | loss  3.57 | ppl    35.46
| prune-epoch  25 |  2400/ 2983 batches | lr 0.08 | ms/batch 58.54 | loss  3.55 | ppl    34.88
| prune-epoch  25 |  2600/ 2983 batches | lr 0.08 | ms/batch 58.53 | loss  3.56 | ppl    35.18
| prune-epoch  25 |  2800/ 2983 batches | lr 0.08 | ms/batch 58.53 | loss  3.50 | ppl    33.15
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  25 | time: 181.60s | valid loss  4.65 | valid ppl   105.09
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  26 |   200/ 2983 batches | lr 0.08 | ms/batch 61.21 | loss  3.71 | ppl    40.95
| prune-epoch  26 |   400/ 2983 batches | lr 0.08 | ms/batch 59.18 | loss  3.74 | ppl    41.99
| prune-epoch  26 |   600/ 2983 batches | lr 0.08 | ms/batch 59.16 | loss  3.60 | ppl    36.42
| prune-epoch  26 |   800/ 2983 batches | lr 0.08 | ms/batch 59.18 | loss  3.64 | ppl    38.12
| prune-epoch  26 |  1000/ 2983 batches | lr 0.08 | ms/batch 59.20 | loss  3.63 | ppl    37.88
| prune-epoch  26 |  1200/ 2983 batches | lr 0.08 | ms/batch 59.20 | loss  3.64 | ppl    38.07
| prune-epoch  26 |  1400/ 2983 batches | lr 0.08 | ms/batch 59.19 | loss  3.67 | ppl    39.19
| prune-epoch  26 |  1600/ 2983 batches | lr 0.08 | ms/batch 59.16 | loss  3.73 | ppl    41.60
| prune-epoch  26 |  1800/ 2983 batches | lr 0.08 | ms/batch 59.18 | loss  3.63 | ppl    37.74
| prune-epoch  26 |  2000/ 2983 batches | lr 0.08 | ms/batch 59.15 | loss  3.67 | ppl    39.07
| prune-epoch  26 |  2200/ 2983 batches | lr 0.08 | ms/batch 59.13 | loss  3.52 | ppl    33.76
| prune-epoch  26 |  2400/ 2983 batches | lr 0.08 | ms/batch 59.14 | loss  3.52 | ppl    33.89
| prune-epoch  26 |  2600/ 2983 batches | lr 0.08 | ms/batch 59.17 | loss  3.56 | ppl    35.12
| prune-epoch  26 |  2800/ 2983 batches | lr 0.08 | ms/batch 59.17 | loss  3.54 | ppl    34.53
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  26 | time: 183.54s | valid loss  4.65 | valid ppl   104.70
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  27 |   200/ 2983 batches | lr 0.08 | ms/batch 60.88 | loss  3.72 | ppl    41.13
| prune-epoch  27 |   400/ 2983 batches | lr 0.08 | ms/batch 58.89 | loss  3.74 | ppl    41.94
| prune-epoch  27 |   600/ 2983 batches | lr 0.08 | ms/batch 58.94 | loss  3.56 | ppl    35.12
| prune-epoch  27 |   800/ 2983 batches | lr 0.08 | ms/batch 58.87 | loss  3.62 | ppl    37.33
| prune-epoch  27 |  1000/ 2983 batches | lr 0.08 | ms/batch 58.85 | loss  3.62 | ppl    37.42
| prune-epoch  27 |  1200/ 2983 batches | lr 0.08 | ms/batch 58.86 | loss  3.61 | ppl    37.10
| prune-epoch  27 |  1400/ 2983 batches | lr 0.08 | ms/batch 58.86 | loss  3.66 | ppl    38.86
| prune-epoch  27 |  1600/ 2983 batches | lr 0.08 | ms/batch 58.85 | loss  3.72 | ppl    41.40
| prune-epoch  27 |  1800/ 2983 batches | lr 0.08 | ms/batch 58.85 | loss  3.63 | ppl    37.60
| prune-epoch  27 |  2000/ 2983 batches | lr 0.08 | ms/batch 58.85 | loss  3.63 | ppl    37.89
| prune-epoch  27 |  2200/ 2983 batches | lr 0.08 | ms/batch 58.86 | loss  3.51 | ppl    33.61
| prune-epoch  27 |  2400/ 2983 batches | lr 0.08 | ms/batch 58.86 | loss  3.54 | ppl    34.53
| prune-epoch  27 |  2600/ 2983 batches | lr 0.08 | ms/batch 58.86 | loss  3.58 | ppl    35.84
| prune-epoch  27 |  2800/ 2983 batches | lr 0.08 | ms/batch 58.84 | loss  3.54 | ppl    34.64
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  27 | time: 182.61s | valid loss  4.65 | valid ppl   104.37
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  28 |   200/ 2983 batches | lr 0.08 | ms/batch 60.75 | loss  3.71 | ppl    40.69
| prune-epoch  28 |   400/ 2983 batches | lr 0.08 | ms/batch 58.81 | loss  3.71 | ppl    40.82
| prune-epoch  28 |   600/ 2983 batches | lr 0.08 | ms/batch 58.81 | loss  3.56 | ppl    35.00
| prune-epoch  28 |   800/ 2983 batches | lr 0.08 | ms/batch 58.95 | loss  3.61 | ppl    36.83
| prune-epoch  28 |  1000/ 2983 batches | lr 0.08 | ms/batch 58.82 | loss  3.61 | ppl    36.94
| prune-epoch  28 |  1200/ 2983 batches | lr 0.08 | ms/batch 58.88 | loss  3.62 | ppl    37.30
| prune-epoch  28 |  1400/ 2983 batches | lr 0.08 | ms/batch 58.82 | loss  3.65 | ppl    38.51
| prune-epoch  28 |  1600/ 2983 batches | lr 0.08 | ms/batch 58.82 | loss  3.71 | ppl    40.84
| prune-epoch  28 |  1800/ 2983 batches | lr 0.08 | ms/batch 58.80 | loss  3.62 | ppl    37.40
| prune-epoch  28 |  2000/ 2983 batches | lr 0.08 | ms/batch 58.82 | loss  3.64 | ppl    38.23
| prune-epoch  28 |  2200/ 2983 batches | lr 0.08 | ms/batch 58.97 | loss  3.53 | ppl    34.25
| prune-epoch  28 |  2400/ 2983 batches | lr 0.08 | ms/batch 59.11 | loss  3.54 | ppl    34.33
| prune-epoch  28 |  2600/ 2983 batches | lr 0.08 | ms/batch 59.09 | loss  3.59 | ppl    36.10
| prune-epoch  28 |  2800/ 2983 batches | lr 0.08 | ms/batch 59.09 | loss  3.56 | ppl    34.99
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  28 | time: 182.80s | valid loss  4.65 | valid ppl   104.19
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  29 |   200/ 2983 batches | lr 0.08 | ms/batch 61.32 | loss  3.70 | ppl    40.37
| prune-epoch  29 |   400/ 2983 batches | lr 0.08 | ms/batch 59.27 | loss  3.71 | ppl    40.86
| prune-epoch  29 |   600/ 2983 batches | lr 0.08 | ms/batch 59.40 | loss  3.55 | ppl    34.74
| prune-epoch  29 |   800/ 2983 batches | lr 0.08 | ms/batch 59.21 | loss  3.60 | ppl    36.51
| prune-epoch  29 |  1000/ 2983 batches | lr 0.08 | ms/batch 59.36 | loss  3.61 | ppl    37.10
| prune-epoch  29 |  1200/ 2983 batches | lr 0.08 | ms/batch 59.30 | loss  3.62 | ppl    37.35
| prune-epoch  29 |  1400/ 2983 batches | lr 0.08 | ms/batch 59.31 | loss  3.65 | ppl    38.47
| prune-epoch  29 |  1600/ 2983 batches | lr 0.08 | ms/batch 59.17 | loss  3.71 | ppl    40.94
| prune-epoch  29 |  1800/ 2983 batches | lr 0.08 | ms/batch 59.28 | loss  3.62 | ppl    37.41
| prune-epoch  29 |  2000/ 2983 batches | lr 0.08 | ms/batch 59.16 | loss  3.64 | ppl    38.22
| prune-epoch  29 |  2200/ 2983 batches | lr 0.08 | ms/batch 59.19 | loss  3.52 | ppl    33.65
| prune-epoch  29 |  2400/ 2983 batches | lr 0.08 | ms/batch 59.13 | loss  3.55 | ppl    34.74
| prune-epoch  29 |  2600/ 2983 batches | lr 0.08 | ms/batch 59.25 | loss  3.57 | ppl    35.62
| prune-epoch  29 |  2800/ 2983 batches | lr 0.08 | ms/batch 59.16 | loss  3.54 | ppl    34.51
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  29 | time: 183.81s | valid loss  4.65 | valid ppl   104.13
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  30 |   200/ 2983 batches | lr 0.08 | ms/batch 61.36 | loss  3.70 | ppl    40.57
| prune-epoch  30 |   400/ 2983 batches | lr 0.08 | ms/batch 59.08 | loss  3.71 | ppl    40.91
| prune-epoch  30 |   600/ 2983 batches | lr 0.08 | ms/batch 59.19 | loss  3.53 | ppl    34.25
| prune-epoch  30 |   800/ 2983 batches | lr 0.08 | ms/batch 59.06 | loss  3.61 | ppl    37.09
| prune-epoch  30 |  1000/ 2983 batches | lr 0.08 | ms/batch 59.11 | loss  3.63 | ppl    37.56
| prune-epoch  30 |  1200/ 2983 batches | lr 0.08 | ms/batch 59.10 | loss  3.62 | ppl    37.31
| prune-epoch  30 |  1400/ 2983 batches | lr 0.08 | ms/batch 59.13 | loss  3.64 | ppl    38.15
| prune-epoch  30 |  1600/ 2983 batches | lr 0.08 | ms/batch 59.12 | loss  3.71 | ppl    40.92
| prune-epoch  30 |  1800/ 2983 batches | lr 0.08 | ms/batch 59.18 | loss  3.62 | ppl    37.18
| prune-epoch  30 |  2000/ 2983 batches | lr 0.08 | ms/batch 59.09 | loss  3.65 | ppl    38.63
| prune-epoch  30 |  2200/ 2983 batches | lr 0.08 | ms/batch 59.14 | loss  3.51 | ppl    33.56
| prune-epoch  30 |  2400/ 2983 batches | lr 0.08 | ms/batch 59.20 | loss  3.55 | ppl    34.68
| prune-epoch  30 |  2600/ 2983 batches | lr 0.08 | ms/batch 59.13 | loss  3.58 | ppl    35.75
| prune-epoch  30 |  2800/ 2983 batches | lr 0.08 | ms/batch 59.12 | loss  3.54 | ppl    34.54
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  30 | time: 183.51s | valid loss  4.65 | valid ppl   104.18
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  31 |   200/ 2983 batches | lr 0.08 | ms/batch 60.95 | loss  3.69 | ppl    39.90
| prune-epoch  31 |   400/ 2983 batches | lr 0.08 | ms/batch 59.03 | loss  3.71 | ppl    40.84
| prune-epoch  31 |   600/ 2983 batches | lr 0.08 | ms/batch 59.04 | loss  3.54 | ppl    34.42
| prune-epoch  31 |   800/ 2983 batches | lr 0.08 | ms/batch 59.11 | loss  3.60 | ppl    36.49
| prune-epoch  31 |  1000/ 2983 batches | lr 0.08 | ms/batch 59.06 | loss  3.61 | ppl    37.07
| prune-epoch  31 |  1200/ 2983 batches | lr 0.08 | ms/batch 59.06 | loss  3.61 | ppl    37.14
| prune-epoch  31 |  1400/ 2983 batches | lr 0.08 | ms/batch 59.08 | loss  3.65 | ppl    38.34
| prune-epoch  31 |  1600/ 2983 batches | lr 0.08 | ms/batch 59.06 | loss  3.72 | ppl    41.28
| prune-epoch  31 |  1800/ 2983 batches | lr 0.08 | ms/batch 59.05 | loss  3.62 | ppl    37.52
| prune-epoch  31 |  2000/ 2983 batches | lr 0.08 | ms/batch 59.05 | loss  3.64 | ppl    38.09
| prune-epoch  31 |  2200/ 2983 batches | lr 0.08 | ms/batch 59.07 | loss  3.52 | ppl    33.76
| prune-epoch  31 |  2400/ 2983 batches | lr 0.08 | ms/batch 59.03 | loss  3.53 | ppl    34.28
| prune-epoch  31 |  2600/ 2983 batches | lr 0.08 | ms/batch 59.05 | loss  3.57 | ppl    35.69
| prune-epoch  31 |  2800/ 2983 batches | lr 0.08 | ms/batch 59.05 | loss  3.55 | ppl    34.71
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  31 | time: 183.17s | valid loss  4.65 | valid ppl   104.14
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  32 |   200/ 2983 batches | lr 0.08 | ms/batch 60.53 | loss  3.69 | ppl    39.85
| prune-epoch  32 |   400/ 2983 batches | lr 0.08 | ms/batch 58.50 | loss  3.72 | ppl    41.08
| prune-epoch  32 |   600/ 2983 batches | lr 0.08 | ms/batch 58.55 | loss  3.53 | ppl    34.26
| prune-epoch  32 |   800/ 2983 batches | lr 0.08 | ms/batch 58.56 | loss  3.60 | ppl    36.63
| prune-epoch  32 |  1000/ 2983 batches | lr 0.08 | ms/batch 58.53 | loss  3.61 | ppl    36.91
| prune-epoch  32 |  1200/ 2983 batches | lr 0.08 | ms/batch 58.53 | loss  3.62 | ppl    37.45
| prune-epoch  32 |  1400/ 2983 batches | lr 0.08 | ms/batch 58.51 | loss  3.64 | ppl    38.19
| prune-epoch  32 |  1600/ 2983 batches | lr 0.08 | ms/batch 58.52 | loss  3.71 | ppl    40.97
| prune-epoch  32 |  1800/ 2983 batches | lr 0.08 | ms/batch 58.51 | loss  3.63 | ppl    37.66
| prune-epoch  32 |  2000/ 2983 batches | lr 0.08 | ms/batch 58.52 | loss  3.64 | ppl    37.98
| prune-epoch  32 |  2200/ 2983 batches | lr 0.08 | ms/batch 58.52 | loss  3.52 | ppl    33.83
| prune-epoch  32 |  2400/ 2983 batches | lr 0.08 | ms/batch 58.51 | loss  3.53 | ppl    34.02
| prune-epoch  32 |  2600/ 2983 batches | lr 0.08 | ms/batch 58.50 | loss  3.58 | ppl    36.00
| prune-epoch  32 |  2800/ 2983 batches | lr 0.08 | ms/batch 58.51 | loss  3.55 | ppl    34.77
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  32 | time: 181.60s | valid loss  4.65 | valid ppl   104.11
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  33 |   200/ 2983 batches | lr 0.08 | ms/batch 61.19 | loss  3.69 | ppl    39.94
| prune-epoch  33 |   400/ 2983 batches | lr 0.08 | ms/batch 59.15 | loss  3.71 | ppl    40.77
| prune-epoch  33 |   600/ 2983 batches | lr 0.08 | ms/batch 59.20 | loss  3.53 | ppl    34.18
| prune-epoch  33 |   800/ 2983 batches | lr 0.08 | ms/batch 59.21 | loss  3.59 | ppl    36.38
| prune-epoch  33 |  1000/ 2983 batches | lr 0.08 | ms/batch 59.18 | loss  3.61 | ppl    37.14
| prune-epoch  33 |  1200/ 2983 batches | lr 0.08 | ms/batch 59.17 | loss  3.62 | ppl    37.39
| prune-epoch  33 |  1400/ 2983 batches | lr 0.08 | ms/batch 59.15 | loss  3.65 | ppl    38.29
| prune-epoch  33 |  1600/ 2983 batches | lr 0.08 | ms/batch 59.17 | loss  3.72 | ppl    41.19
| prune-epoch  33 |  1800/ 2983 batches | lr 0.08 | ms/batch 59.18 | loss  3.61 | ppl    36.92
| prune-epoch  33 |  2000/ 2983 batches | lr 0.08 | ms/batch 59.15 | loss  3.64 | ppl    38.04
| prune-epoch  33 |  2200/ 2983 batches | lr 0.08 | ms/batch 59.19 | loss  3.52 | ppl    33.76
| prune-epoch  33 |  2400/ 2983 batches | lr 0.08 | ms/batch 59.16 | loss  3.53 | ppl    34.24
| prune-epoch  33 |  2600/ 2983 batches | lr 0.08 | ms/batch 59.15 | loss  3.57 | ppl    35.51
| prune-epoch  33 |  2800/ 2983 batches | lr 0.08 | ms/batch 59.15 | loss  3.55 | ppl    34.70
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  33 | time: 183.54s | valid loss  4.65 | valid ppl   104.08
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  34 |   200/ 2983 batches | lr 0.08 | ms/batch 60.98 | loss  3.69 | ppl    39.91
| prune-epoch  34 |   400/ 2983 batches | lr 0.08 | ms/batch 58.99 | loss  3.70 | ppl    40.42
| prune-epoch  34 |   600/ 2983 batches | lr 0.08 | ms/batch 59.00 | loss  3.54 | ppl    34.39
| prune-epoch  34 |   800/ 2983 batches | lr 0.08 | ms/batch 58.99 | loss  3.59 | ppl    36.38
| prune-epoch  34 |  1000/ 2983 batches | lr 0.08 | ms/batch 58.97 | loss  3.60 | ppl    36.52
| prune-epoch  34 |  1200/ 2983 batches | lr 0.08 | ms/batch 58.97 | loss  3.62 | ppl    37.44
| prune-epoch  34 |  1400/ 2983 batches | lr 0.08 | ms/batch 58.98 | loss  3.65 | ppl    38.55
| prune-epoch  34 |  1600/ 2983 batches | lr 0.08 | ms/batch 58.97 | loss  3.71 | ppl    40.84
| prune-epoch  34 |  1800/ 2983 batches | lr 0.08 | ms/batch 59.02 | loss  3.61 | ppl    37.04
| prune-epoch  34 |  2000/ 2983 batches | lr 0.08 | ms/batch 58.98 | loss  3.63 | ppl    37.80
| prune-epoch  34 |  2200/ 2983 batches | lr 0.08 | ms/batch 58.97 | loss  3.51 | ppl    33.48
| prune-epoch  34 |  2400/ 2983 batches | lr 0.08 | ms/batch 58.99 | loss  3.53 | ppl    34.25
| prune-epoch  34 |  2600/ 2983 batches | lr 0.08 | ms/batch 58.98 | loss  3.58 | ppl    35.78
| prune-epoch  34 |  2800/ 2983 batches | lr 0.08 | ms/batch 58.99 | loss  3.54 | ppl    34.40
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  34 | time: 182.98s | valid loss  4.65 | valid ppl   104.07
-----------------------------------------------------------------------------------------
required epochs  40 | actual epochs  60
pretrain epochs  12 | prune epochs  14 | retrain epochs  34
=========================================================================================
| End of training | test loss  4.60 | test ppl    99.62
=========================================================================================
python main.py --cuda --emsize 1500 --nhid 1500 --dropout 0.65 --epochs 40 --tied --save model/prune/model.pt --prune --retrain --sparsity 0.9
<class 'torch.Tensor'> torch.Size([33278, 1500])
<class 'torch.Tensor'> torch.Size([6000, 1500])
<class 'torch.Tensor'> torch.Size([6000, 1500])
<class 'torch.Tensor'> torch.Size([6000])
<class 'torch.Tensor'> torch.Size([6000])
<class 'torch.Tensor'> torch.Size([6000, 1500])
<class 'torch.Tensor'> torch.Size([6000, 1500])
<class 'torch.Tensor'> torch.Size([6000])
<class 'torch.Tensor'> torch.Size([6000])
<class 'torch.Tensor'> torch.Size([33278])
RNNModel(
  (drop): Dropout(p=0.65)
  (encoder): Embedding(33278, 1500)
  (rnn): LSTM(1500, 1500, num_layers=2, dropout=0.65)
  (decoder): Linear(in_features=1500, out_features=33278, bias=True)
)
Dropout(p=0.65)
Embedding(33278, 1500)
LSTM(1500, 1500, num_layers=2, dropout=0.65)
Linear(in_features=1500, out_features=33278, bias=True)
| train-epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 57.17 | loss  7.94 | ppl  2819.11
| train-epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 56.64 | loss  6.84 | ppl   932.80
| train-epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 56.86 | loss  6.45 | ppl   631.39
| train-epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 56.75 | loss  6.30 | ppl   545.28
| train-epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 56.82 | loss  6.18 | ppl   484.46
| train-epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 56.81 | loss  6.12 | ppl   456.78
| train-epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 56.75 | loss  6.02 | ppl   411.93
| train-epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 56.78 | loss  6.03 | ppl   415.18
| train-epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 56.79 | loss  5.89 | ppl   359.80
| train-epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 56.81 | loss  5.86 | ppl   350.21
| train-epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 56.79 | loss  5.75 | ppl   313.41
| train-epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 56.70 | loss  5.76 | ppl   315.83
| train-epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 56.90 | loss  5.74 | ppl   311.87
| train-epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 56.85 | loss  5.64 | ppl   280.54
-----------------------------------------------------------------------------------------
| end of train epoch   1 | time: 176.25s | valid loss  5.48 | valid ppl   239.88
-----------------------------------------------------------------------------------------
| train-epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch 56.64 | loss  5.63 | ppl   278.30
| train-epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch 56.34 | loss  5.61 | ppl   272.19
| train-epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch 56.47 | loss  5.44 | ppl   230.34
| train-epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch 56.45 | loss  5.46 | ppl   234.93
| train-epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch 56.32 | loss  5.43 | ppl   228.03
| train-epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 56.33 | loss  5.43 | ppl   227.51
| train-epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 56.32 | loss  5.42 | ppl   225.48
| train-epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 56.40 | loss  5.47 | ppl   237.33
| train-epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch 56.27 | loss  5.34 | ppl   209.24
| train-epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch 56.31 | loss  5.36 | ppl   213.39
| train-epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch 56.43 | loss  5.27 | ppl   193.91
| train-epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch 56.35 | loss  5.30 | ppl   200.47
| train-epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 56.36 | loss  5.31 | ppl   201.41
| train-epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 56.35 | loss  5.23 | ppl   186.55
-----------------------------------------------------------------------------------------
| end of train epoch   2 | time: 174.98s | valid loss  5.15 | valid ppl   172.05
-----------------------------------------------------------------------------------------
| train-epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 57.37 | loss  5.27 | ppl   194.85
| train-epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch 57.01 | loss  5.28 | ppl   196.78
| train-epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 56.92 | loss  5.10 | ppl   164.81
| train-epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 57.00 | loss  5.15 | ppl   172.29
| train-epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 56.95 | loss  5.14 | ppl   169.88
| train-epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.01 | loss  5.13 | ppl   169.72
| train-epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.07 | loss  5.15 | ppl   172.79
| train-epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 56.98 | loss  5.22 | ppl   184.48
| train-epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 56.78 | loss  5.09 | ppl   162.91
| train-epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 56.79 | loss  5.13 | ppl   168.49
| train-epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 56.81 | loss  5.03 | ppl   153.33
| train-epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 56.80 | loss  5.06 | ppl   158.08
| train-epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch 56.81 | loss  5.08 | ppl   160.48
| train-epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 56.81 | loss  5.01 | ppl   149.50
-----------------------------------------------------------------------------------------
| end of train epoch   3 | time: 176.58s | valid loss  5.00 | valid ppl   148.08
-----------------------------------------------------------------------------------------
| train-epoch   4 |   200/ 2983 batches | lr 20.00 | ms/batch 56.93 | loss  5.06 | ppl   157.43
| train-epoch   4 |   400/ 2983 batches | lr 20.00 | ms/batch 56.68 | loss  5.08 | ppl   160.41
| train-epoch   4 |   600/ 2983 batches | lr 20.00 | ms/batch 56.76 | loss  4.90 | ppl   134.39
| train-epoch   4 |   800/ 2983 batches | lr 20.00 | ms/batch 56.70 | loss  4.96 | ppl   142.06
| train-epoch   4 |  1000/ 2983 batches | lr 20.00 | ms/batch 56.67 | loss  4.95 | ppl   140.84
| train-epoch   4 |  1200/ 2983 batches | lr 20.00 | ms/batch 56.68 | loss  4.95 | ppl   141.43
| train-epoch   4 |  1400/ 2983 batches | lr 20.00 | ms/batch 56.66 | loss  4.98 | ppl   145.90
| train-epoch   4 |  1600/ 2983 batches | lr 20.00 | ms/batch 56.67 | loss  5.05 | ppl   155.91
| train-epoch   4 |  1800/ 2983 batches | lr 20.00 | ms/batch 56.66 | loss  4.92 | ppl   137.31
| train-epoch   4 |  2000/ 2983 batches | lr 20.00 | ms/batch 56.92 | loss  4.97 | ppl   143.83
| train-epoch   4 |  2200/ 2983 batches | lr 20.00 | ms/batch 56.96 | loss  4.86 | ppl   129.11
| train-epoch   4 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.06 | loss  4.90 | ppl   134.12
| train-epoch   4 |  2600/ 2983 batches | lr 20.00 | ms/batch 56.91 | loss  4.92 | ppl   137.00
| train-epoch   4 |  2800/ 2983 batches | lr 20.00 | ms/batch 56.92 | loss  4.86 | ppl   128.44
-----------------------------------------------------------------------------------------
| end of train epoch   4 | time: 176.26s | valid loss  4.90 | valid ppl   134.17
-----------------------------------------------------------------------------------------
| train-epoch   5 |   200/ 2983 batches | lr 20.00 | ms/batch 57.02 | loss  4.91 | ppl   135.21
| train-epoch   5 |   400/ 2983 batches | lr 20.00 | ms/batch 56.71 | loss  4.93 | ppl   138.26
| train-epoch   5 |   600/ 2983 batches | lr 20.00 | ms/batch 56.90 | loss  4.75 | ppl   115.60
| train-epoch   5 |   800/ 2983 batches | lr 20.00 | ms/batch 56.77 | loss  4.81 | ppl   123.24
| train-epoch   5 |  1000/ 2983 batches | lr 20.00 | ms/batch 56.83 | loss  4.81 | ppl   122.36
| train-epoch   5 |  1200/ 2983 batches | lr 20.00 | ms/batch 56.76 | loss  4.82 | ppl   124.10
| train-epoch   5 |  1400/ 2983 batches | lr 20.00 | ms/batch 56.77 | loss  4.85 | ppl   128.10
| train-epoch   5 |  1600/ 2983 batches | lr 20.00 | ms/batch 56.76 | loss  4.92 | ppl   136.80
| train-epoch   5 |  1800/ 2983 batches | lr 20.00 | ms/batch 56.71 | loss  4.80 | ppl   121.05
| train-epoch   5 |  2000/ 2983 batches | lr 20.00 | ms/batch 56.76 | loss  4.84 | ppl   126.95
| train-epoch   5 |  2200/ 2983 batches | lr 20.00 | ms/batch 56.77 | loss  4.73 | ppl   113.85
| train-epoch   5 |  2400/ 2983 batches | lr 20.00 | ms/batch 56.98 | loss  4.77 | ppl   118.28
| train-epoch   5 |  2600/ 2983 batches | lr 20.00 | ms/batch 56.94 | loss  4.80 | ppl   121.23
| train-epoch   5 |  2800/ 2983 batches | lr 20.00 | ms/batch 56.80 | loss  4.73 | ppl   113.85
-----------------------------------------------------------------------------------------
| end of train epoch   5 | time: 176.28s | valid loss  4.83 | valid ppl   124.83
-----------------------------------------------------------------------------------------
| train-epoch   6 |   200/ 2983 batches | lr 20.00 | ms/batch 57.28 | loss  4.79 | ppl   120.22
| train-epoch   6 |   400/ 2983 batches | lr 20.00 | ms/batch 56.92 | loss  4.82 | ppl   123.36
| train-epoch   6 |   600/ 2983 batches | lr 20.00 | ms/batch 56.91 | loss  4.63 | ppl   102.79
| train-epoch   6 |   800/ 2983 batches | lr 20.00 | ms/batch 56.82 | loss  4.69 | ppl   109.12
| train-epoch   6 |  1000/ 2983 batches | lr 20.00 | ms/batch 56.68 | loss  4.70 | ppl   109.52
| train-epoch   6 |  1200/ 2983 batches | lr 20.00 | ms/batch 56.69 | loss  4.70 | ppl   110.40
| train-epoch   6 |  1400/ 2983 batches | lr 20.00 | ms/batch 56.89 | loss  4.75 | ppl   115.13
| train-epoch   6 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.08 | loss  4.82 | ppl   123.53
| train-epoch   6 |  1800/ 2983 batches | lr 20.00 | ms/batch 56.93 | loss  4.70 | ppl   109.55
| train-epoch   6 |  2000/ 2983 batches | lr 20.00 | ms/batch 56.95 | loss  4.74 | ppl   114.40
| train-epoch   6 |  2200/ 2983 batches | lr 20.00 | ms/batch 56.92 | loss  4.63 | ppl   102.59
| train-epoch   6 |  2400/ 2983 batches | lr 20.00 | ms/batch 56.84 | loss  4.67 | ppl   106.96
| train-epoch   6 |  2600/ 2983 batches | lr 20.00 | ms/batch 56.97 | loss  4.70 | ppl   109.44
| train-epoch   6 |  2800/ 2983 batches | lr 20.00 | ms/batch 56.89 | loss  4.64 | ppl   103.44
-----------------------------------------------------------------------------------------
| end of train epoch   6 | time: 176.57s | valid loss  4.77 | valid ppl   118.48
-----------------------------------------------------------------------------------------
| train-epoch   7 |   200/ 2983 batches | lr 20.00 | ms/batch 57.18 | loss  4.69 | ppl   109.02
| train-epoch   7 |   400/ 2983 batches | lr 20.00 | ms/batch 56.83 | loss  4.72 | ppl   112.02
| train-epoch   7 |   600/ 2983 batches | lr 20.00 | ms/batch 56.76 | loss  4.53 | ppl    93.17
| train-epoch   7 |   800/ 2983 batches | lr 20.00 | ms/batch 56.62 | loss  4.60 | ppl    99.25
| train-epoch   7 |  1000/ 2983 batches | lr 20.00 | ms/batch 56.61 | loss  4.60 | ppl    99.61
| train-epoch   7 |  1200/ 2983 batches | lr 20.00 | ms/batch 56.73 | loss  4.62 | ppl   101.09
| train-epoch   7 |  1400/ 2983 batches | lr 20.00 | ms/batch 56.73 | loss  4.66 | ppl   105.46
| train-epoch   7 |  1600/ 2983 batches | lr 20.00 | ms/batch 56.61 | loss  4.73 | ppl   113.13
| train-epoch   7 |  1800/ 2983 batches | lr 20.00 | ms/batch 56.60 | loss  4.61 | ppl   100.93
| train-epoch   7 |  2000/ 2983 batches | lr 20.00 | ms/batch 56.61 | loss  4.66 | ppl   105.46
| train-epoch   7 |  2200/ 2983 batches | lr 20.00 | ms/batch 56.61 | loss  4.54 | ppl    93.76
| train-epoch   7 |  2400/ 2983 batches | lr 20.00 | ms/batch 56.61 | loss  4.58 | ppl    97.64
| train-epoch   7 |  2600/ 2983 batches | lr 20.00 | ms/batch 56.62 | loss  4.61 | ppl   100.75
| train-epoch   7 |  2800/ 2983 batches | lr 20.00 | ms/batch 56.61 | loss  4.56 | ppl    95.22
-----------------------------------------------------------------------------------------
| end of train epoch   7 | time: 175.87s | valid loss  4.74 | valid ppl   114.55
-----------------------------------------------------------------------------------------
| train-epoch   8 |   200/ 2983 batches | lr 20.00 | ms/batch 57.08 | loss  4.61 | ppl   100.50
| train-epoch   8 |   400/ 2983 batches | lr 20.00 | ms/batch 56.82 | loss  4.63 | ppl   103.02
| train-epoch   8 |   600/ 2983 batches | lr 20.00 | ms/batch 56.77 | loss  4.45 | ppl    85.57
| train-epoch   8 |   800/ 2983 batches | lr 20.00 | ms/batch 56.83 | loss  4.51 | ppl    91.28
| train-epoch   8 |  1000/ 2983 batches | lr 20.00 | ms/batch 56.99 | loss  4.53 | ppl    92.62
| train-epoch   8 |  1200/ 2983 batches | lr 20.00 | ms/batch 56.98 | loss  4.54 | ppl    93.30
| train-epoch   8 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.00 | loss  4.58 | ppl    97.92
| train-epoch   8 |  1600/ 2983 batches | lr 20.00 | ms/batch 56.90 | loss  4.65 | ppl   105.00
| train-epoch   8 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.01 | loss  4.55 | ppl    94.19
| train-epoch   8 |  2000/ 2983 batches | lr 20.00 | ms/batch 56.94 | loss  4.58 | ppl    97.38
| train-epoch   8 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.02 | loss  4.47 | ppl    87.04
| train-epoch   8 |  2400/ 2983 batches | lr 20.00 | ms/batch 56.99 | loss  4.51 | ppl    90.86
| train-epoch   8 |  2600/ 2983 batches | lr 20.00 | ms/batch 56.97 | loss  4.54 | ppl    93.70
| train-epoch   8 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.02 | loss  4.48 | ppl    88.17
-----------------------------------------------------------------------------------------
| end of train epoch   8 | time: 176.69s | valid loss  4.73 | valid ppl   112.73
-----------------------------------------------------------------------------------------
| train-epoch   9 |   200/ 2983 batches | lr 20.00 | ms/batch 56.77 | loss  4.54 | ppl    93.53
| train-epoch   9 |   400/ 2983 batches | lr 20.00 | ms/batch 56.42 | loss  4.56 | ppl    95.57
| train-epoch   9 |   600/ 2983 batches | lr 20.00 | ms/batch 56.46 | loss  4.38 | ppl    79.91
| train-epoch   9 |   800/ 2983 batches | lr 20.00 | ms/batch 56.42 | loss  4.44 | ppl    84.43
| train-epoch   9 |  1000/ 2983 batches | lr 20.00 | ms/batch 56.44 | loss  4.46 | ppl    86.79
| train-epoch   9 |  1200/ 2983 batches | lr 20.00 | ms/batch 56.57 | loss  4.47 | ppl    87.59
| train-epoch   9 |  1400/ 2983 batches | lr 20.00 | ms/batch 56.50 | loss  4.51 | ppl    91.29
| train-epoch   9 |  1600/ 2983 batches | lr 20.00 | ms/batch 56.50 | loss  4.59 | ppl    98.53
| train-epoch   9 |  1800/ 2983 batches | lr 20.00 | ms/batch 56.39 | loss  4.48 | ppl    88.15
| train-epoch   9 |  2000/ 2983 batches | lr 20.00 | ms/batch 56.44 | loss  4.51 | ppl    91.25
| train-epoch   9 |  2200/ 2983 batches | lr 20.00 | ms/batch 56.52 | loss  4.40 | ppl    81.26
| train-epoch   9 |  2400/ 2983 batches | lr 20.00 | ms/batch 56.45 | loss  4.44 | ppl    85.16
| train-epoch   9 |  2600/ 2983 batches | lr 20.00 | ms/batch 56.47 | loss  4.48 | ppl    87.96
| train-epoch   9 |  2800/ 2983 batches | lr 20.00 | ms/batch 56.61 | loss  4.42 | ppl    83.38
-----------------------------------------------------------------------------------------
| end of train epoch   9 | time: 175.33s | valid loss  4.69 | valid ppl   108.87
-----------------------------------------------------------------------------------------
| train-epoch  10 |   200/ 2983 batches | lr 20.00 | ms/batch 57.46 | loss  4.47 | ppl    87.60
| train-epoch  10 |   400/ 2983 batches | lr 20.00 | ms/batch 57.06 | loss  4.49 | ppl    89.52
| train-epoch  10 |   600/ 2983 batches | lr 20.00 | ms/batch 57.12 | loss  4.32 | ppl    74.99
| train-epoch  10 |   800/ 2983 batches | lr 20.00 | ms/batch 57.07 | loss  4.37 | ppl    79.30
| train-epoch  10 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.21 | loss  4.40 | ppl    81.38
| train-epoch  10 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.17 | loss  4.41 | ppl    82.56
| train-epoch  10 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.14 | loss  4.45 | ppl    85.60
| train-epoch  10 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.09 | loss  4.53 | ppl    92.63
| train-epoch  10 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.01 | loss  4.42 | ppl    82.98
| train-epoch  10 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.12 | loss  4.46 | ppl    86.47
| train-epoch  10 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.04 | loss  4.34 | ppl    76.48
| train-epoch  10 |  2400/ 2983 batches | lr 20.00 | ms/batch 56.97 | loss  4.38 | ppl    79.67
| train-epoch  10 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.04 | loss  4.42 | ppl    82.86
| train-epoch  10 |  2800/ 2983 batches | lr 20.00 | ms/batch 56.89 | loss  4.36 | ppl    78.64
-----------------------------------------------------------------------------------------
| end of train epoch  10 | time: 177.06s | valid loss  4.68 | valid ppl   107.53
-----------------------------------------------------------------------------------------
| train-epoch  11 |   200/ 2983 batches | lr 20.00 | ms/batch 57.05 | loss  4.41 | ppl    82.50
| train-epoch  11 |   400/ 2983 batches | lr 20.00 | ms/batch 56.74 | loss  4.44 | ppl    84.97
| train-epoch  11 |   600/ 2983 batches | lr 20.00 | ms/batch 56.74 | loss  4.26 | ppl    70.97
| train-epoch  11 |   800/ 2983 batches | lr 20.00 | ms/batch 56.74 | loss  4.32 | ppl    75.17
| train-epoch  11 |  1000/ 2983 batches | lr 20.00 | ms/batch 56.73 | loss  4.35 | ppl    77.33
| train-epoch  11 |  1200/ 2983 batches | lr 20.00 | ms/batch 56.73 | loss  4.36 | ppl    78.28
| train-epoch  11 |  1400/ 2983 batches | lr 20.00 | ms/batch 56.74 | loss  4.39 | ppl    80.75
| train-epoch  11 |  1600/ 2983 batches | lr 20.00 | ms/batch 56.72 | loss  4.48 | ppl    88.12
| train-epoch  11 |  1800/ 2983 batches | lr 20.00 | ms/batch 56.78 | loss  4.37 | ppl    78.73
| train-epoch  11 |  2000/ 2983 batches | lr 20.00 | ms/batch 56.92 | loss  4.41 | ppl    82.13
| train-epoch  11 |  2200/ 2983 batches | lr 20.00 | ms/batch 56.92 | loss  4.29 | ppl    72.83
| train-epoch  11 |  2400/ 2983 batches | lr 20.00 | ms/batch 56.93 | loss  4.33 | ppl    76.05
| train-epoch  11 |  2600/ 2983 batches | lr 20.00 | ms/batch 56.93 | loss  4.36 | ppl    78.47
| train-epoch  11 |  2800/ 2983 batches | lr 20.00 | ms/batch 56.92 | loss  4.31 | ppl    74.61
-----------------------------------------------------------------------------------------
| end of train epoch  11 | time: 176.31s | valid loss  4.65 | valid ppl   104.75
-----------------------------------------------------------------------------------------
| train-epoch  12 |   200/ 2983 batches | lr 20.00 | ms/batch 56.95 | loss  4.37 | ppl    78.72
| train-epoch  12 |   400/ 2983 batches | lr 20.00 | ms/batch 56.62 | loss  4.39 | ppl    80.28
| train-epoch  12 |   600/ 2983 batches | lr 20.00 | ms/batch 56.65 | loss  4.21 | ppl    67.09
| train-epoch  12 |   800/ 2983 batches | lr 20.00 | ms/batch 56.63 | loss  4.26 | ppl    71.09
| train-epoch  12 |  1000/ 2983 batches | lr 20.00 | ms/batch 56.63 | loss  4.30 | ppl    73.52
| train-epoch  12 |  1200/ 2983 batches | lr 20.00 | ms/batch 56.63 | loss  4.31 | ppl    74.47
| train-epoch  12 |  1400/ 2983 batches | lr 20.00 | ms/batch 56.63 | loss  4.35 | ppl    77.47
| train-epoch  12 |  1600/ 2983 batches | lr 20.00 | ms/batch 56.61 | loss  4.43 | ppl    83.84
| train-epoch  12 |  1800/ 2983 batches | lr 20.00 | ms/batch 56.61 | loss  4.32 | ppl    75.18
| train-epoch  12 |  2000/ 2983 batches | lr 20.00 | ms/batch 56.63 | loss  4.36 | ppl    78.16
| train-epoch  12 |  2200/ 2983 batches | lr 20.00 | ms/batch 56.63 | loss  4.24 | ppl    69.24
| train-epoch  12 |  2400/ 2983 batches | lr 20.00 | ms/batch 56.62 | loss  4.28 | ppl    71.93
| train-epoch  12 |  2600/ 2983 batches | lr 20.00 | ms/batch 56.63 | loss  4.32 | ppl    74.94
| train-epoch  12 |  2800/ 2983 batches | lr 20.00 | ms/batch 56.62 | loss  4.27 | ppl    71.37
-----------------------------------------------------------------------------------------
| end of train epoch  12 | time: 175.75s | valid loss  4.65 | valid ppl   104.81
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 60.10 | loss  4.32 | ppl    75.05
| prune-epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 57.33 | loss  4.34 | ppl    76.77
| prune-epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 57.30 | loss  4.16 | ppl    63.92
| prune-epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 57.28 | loss  4.21 | ppl    67.67
| prune-epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.34 | loss  4.25 | ppl    69.97
| prune-epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.31 | loss  4.26 | ppl    70.53
| prune-epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.28 | loss  4.29 | ppl    72.61
| prune-epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.43 | loss  4.37 | ppl    79.11
| prune-epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.27 | loss  4.26 | ppl    70.61
| prune-epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.37 | loss  4.30 | ppl    73.61
| prune-epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.28 | loss  4.17 | ppl    64.86
| prune-epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.33 | loss  4.21 | ppl    67.43
| prune-epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.45 | loss  4.25 | ppl    69.86
| prune-epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.38 | loss  4.20 | ppl    66.62
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.39933322222222223
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.3993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.3993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.39933322222222223
-----------------------------------------------------------------------------------------
| end of prune epoch   1 | time: 178.36s | valid loss  4.63 | valid ppl   102.37
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch 60.01 | loss  4.26 | ppl    70.66
| prune-epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch 57.26 | loss  4.28 | ppl    72.52
| prune-epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch 57.32 | loss  4.10 | ppl    60.21
| prune-epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch 57.27 | loss  4.16 | ppl    64.10
| prune-epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.32 | loss  4.19 | ppl    66.15
| prune-epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.40 | loss  4.21 | ppl    67.40
| prune-epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.25 | loss  4.24 | ppl    69.17
| prune-epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.36 | loss  4.32 | ppl    75.34
| prune-epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.23 | loss  4.21 | ppl    67.39
| prune-epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.38 | loss  4.25 | ppl    70.41
| prune-epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.27 | loss  4.12 | ppl    61.82
| prune-epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.24 | loss  4.16 | ppl    64.22
| prune-epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.32 | loss  4.20 | ppl    66.56
| prune-epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.24 | loss  4.16 | ppl    64.05
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.3993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.3993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.3993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.3993333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch   2 | time: 178.23s | valid loss  4.62 | valid ppl   101.37
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 60.12 | loss  4.21 | ppl    67.35
| prune-epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch 57.35 | loss  4.24 | ppl    69.34
| prune-epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 57.40 | loss  4.06 | ppl    57.94
| prune-epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 57.42 | loss  4.11 | ppl    60.88
| prune-epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.38 | loss  4.15 | ppl    63.32
| prune-epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.37 | loss  4.16 | ppl    64.35
| prune-epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.27 | loss  4.20 | ppl    66.59
| prune-epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.21 | loss  4.28 | ppl    72.05
| prune-epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.23 | loss  4.17 | ppl    64.91
| prune-epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.21 | loss  4.21 | ppl    67.41
| prune-epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.23 | loss  4.09 | ppl    59.45
| prune-epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.23 | loss  4.12 | ppl    61.42
| prune-epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.23 | loss  4.16 | ppl    63.96
| prune-epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.22 | loss  4.12 | ppl    61.44
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.3993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.3993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.3993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.3993333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch   3 | time: 178.19s | valid loss  4.62 | valid ppl   101.41
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   4 |   200/ 2983 batches | lr 20.00 | ms/batch 59.61 | loss  4.18 | ppl    65.10
| prune-epoch   4 |   400/ 2983 batches | lr 20.00 | ms/batch 56.83 | loss  4.20 | ppl    66.82
| prune-epoch   4 |   600/ 2983 batches | lr 20.00 | ms/batch 56.94 | loss  4.02 | ppl    55.88
| prune-epoch   4 |   800/ 2983 batches | lr 20.00 | ms/batch 56.94 | loss  4.07 | ppl    58.47
| prune-epoch   4 |  1000/ 2983 batches | lr 20.00 | ms/batch 56.85 | loss  4.11 | ppl    60.96
| prune-epoch   4 |  1200/ 2983 batches | lr 20.00 | ms/batch 56.94 | loss  4.12 | ppl    61.72
| prune-epoch   4 |  1400/ 2983 batches | lr 20.00 | ms/batch 56.77 | loss  4.15 | ppl    63.61
| prune-epoch   4 |  1600/ 2983 batches | lr 20.00 | ms/batch 56.93 | loss  4.23 | ppl    69.06
| prune-epoch   4 |  1800/ 2983 batches | lr 20.00 | ms/batch 56.81 | loss  4.12 | ppl    61.67
| prune-epoch   4 |  2000/ 2983 batches | lr 20.00 | ms/batch 56.83 | loss  4.17 | ppl    64.65
| prune-epoch   4 |  2200/ 2983 batches | lr 20.00 | ms/batch 56.93 | loss  4.04 | ppl    57.04
| prune-epoch   4 |  2400/ 2983 batches | lr 20.00 | ms/batch 56.88 | loss  4.07 | ppl    58.83
| prune-epoch   4 |  2600/ 2983 batches | lr 20.00 | ms/batch 56.88 | loss  4.11 | ppl    61.04
| prune-epoch   4 |  2800/ 2983 batches | lr 20.00 | ms/batch 56.94 | loss  4.07 | ppl    58.76
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch   4 | time: 177.02s | valid loss  4.62 | valid ppl   101.46
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   5 |   200/ 2983 batches | lr 20.00 | ms/batch 60.01 | loss  4.13 | ppl    61.98
| prune-epoch   5 |   400/ 2983 batches | lr 20.00 | ms/batch 57.53 | loss  4.16 | ppl    64.01
| prune-epoch   5 |   600/ 2983 batches | lr 20.00 | ms/batch 57.44 | loss  3.98 | ppl    53.38
| prune-epoch   5 |   800/ 2983 batches | lr 20.00 | ms/batch 57.53 | loss  4.03 | ppl    56.27
| prune-epoch   5 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.41 | loss  4.07 | ppl    58.59
| prune-epoch   5 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.43 | loss  4.08 | ppl    59.40
| prune-epoch   5 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.49 | loss  4.11 | ppl    61.11
| prune-epoch   5 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.42 | loss  4.20 | ppl    66.51
| prune-epoch   5 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.52 | loss  4.09 | ppl    59.67
| prune-epoch   5 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.42 | loss  4.13 | ppl    61.91
| prune-epoch   5 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.49 | loss  4.01 | ppl    55.09
| prune-epoch   5 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.40 | loss  4.04 | ppl    56.97
| prune-epoch   5 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.39 | loss  4.08 | ppl    59.09
| prune-epoch   5 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.48 | loss  4.04 | ppl    57.08
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch   5 | time: 178.68s | valid loss  4.61 | valid ppl   100.53
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   6 |   200/ 2983 batches | lr 20.00 | ms/batch 60.00 | loss  4.09 | ppl    59.96
| prune-epoch   6 |   400/ 2983 batches | lr 20.00 | ms/batch 57.35 | loss  4.12 | ppl    61.68
| prune-epoch   6 |   600/ 2983 batches | lr 20.00 | ms/batch 57.39 | loss  3.95 | ppl    51.83
| prune-epoch   6 |   800/ 2983 batches | lr 20.00 | ms/batch 57.33 | loss  4.00 | ppl    54.35
| prune-epoch   6 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.45 | loss  4.04 | ppl    56.72
| prune-epoch   6 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.35 | loss  4.05 | ppl    57.20
| prune-epoch   6 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.34 | loss  4.08 | ppl    59.00
| prune-epoch   6 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.14 | loss  4.16 | ppl    64.03
| prune-epoch   6 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.14 | loss  4.06 | ppl    58.10
| prune-epoch   6 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.18 | loss  4.10 | ppl    60.30
| prune-epoch   6 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.13 | loss  3.97 | ppl    53.04
| prune-epoch   6 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.14 | loss  4.00 | ppl    54.81
| prune-epoch   6 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.15 | loss  4.04 | ppl    56.92
| prune-epoch   6 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.14 | loss  4.01 | ppl    54.96
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch   6 | time: 178.03s | valid loss  4.62 | valid ppl   101.81
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   7 |   200/ 2983 batches | lr 20.00 | ms/batch 59.86 | loss  4.06 | ppl    58.26
| prune-epoch   7 |   400/ 2983 batches | lr 20.00 | ms/batch 57.01 | loss  4.09 | ppl    59.98
| prune-epoch   7 |   600/ 2983 batches | lr 20.00 | ms/batch 57.18 | loss  3.92 | ppl    50.28
| prune-epoch   7 |   800/ 2983 batches | lr 20.00 | ms/batch 57.24 | loss  3.97 | ppl    53.17
| prune-epoch   7 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.17 | loss  4.00 | ppl    54.72
| prune-epoch   7 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.32 | loss  4.02 | ppl    55.71
| prune-epoch   7 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.17 | loss  4.04 | ppl    56.99
| prune-epoch   7 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.19 | loss  4.13 | ppl    62.12
| prune-epoch   7 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.19 | loss  4.02 | ppl    55.90
| prune-epoch   7 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.19 | loss  4.07 | ppl    58.42
| prune-epoch   7 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.33 | loss  3.94 | ppl    51.53
| prune-epoch   7 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.21 | loss  3.97 | ppl    52.83
| prune-epoch   7 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.22 | loss  4.01 | ppl    55.07
| prune-epoch   7 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.05 | loss  3.97 | ppl    53.02
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.6  actual sp:  0.5993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.6  actual sp:  0.5993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.6  actual sp:  0.5993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.6  actual sp:  0.5993333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch   7 | time: 177.87s | valid loss  4.61 | valid ppl   100.53
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   8 |   200/ 2983 batches | lr 20.00 | ms/batch 59.81 | loss  4.03 | ppl    56.16
| prune-epoch   8 |   400/ 2983 batches | lr 20.00 | ms/batch 57.29 | loss  4.05 | ppl    57.65
| prune-epoch   8 |   600/ 2983 batches | lr 20.00 | ms/batch 57.25 | loss  3.88 | ppl    48.37
| prune-epoch   8 |   800/ 2983 batches | lr 20.00 | ms/batch 57.25 | loss  3.92 | ppl    50.61
| prune-epoch   8 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.29 | loss  3.97 | ppl    53.10
| prune-epoch   8 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.25 | loss  3.99 | ppl    53.90
| prune-epoch   8 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.30 | loss  4.02 | ppl    55.45
| prune-epoch   8 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.29 | loss  4.09 | ppl    59.84
| prune-epoch   8 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.32 | loss  3.99 | ppl    54.32
| prune-epoch   8 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.33 | loss  4.03 | ppl    56.32
| prune-epoch   8 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.37 | loss  3.91 | ppl    49.68
| prune-epoch   8 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.38 | loss  3.94 | ppl    51.37
| prune-epoch   8 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.29 | loss  3.97 | ppl    52.93
| prune-epoch   8 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.41 | loss  3.94 | ppl    51.63
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.6  actual sp:  0.5993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.6  actual sp:  0.5993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.6  actual sp:  0.5993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.6  actual sp:  0.5993333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch   8 | time: 178.21s | valid loss  4.62 | valid ppl   101.35
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   9 |   200/ 2983 batches | lr 20.00 | ms/batch 59.84 | loss  4.03 | ppl    56.28
| prune-epoch   9 |   400/ 2983 batches | lr 20.00 | ms/batch 57.35 | loss  4.05 | ppl    57.25
| prune-epoch   9 |   600/ 2983 batches | lr 20.00 | ms/batch 57.25 | loss  3.87 | ppl    48.11
| prune-epoch   9 |   800/ 2983 batches | lr 20.00 | ms/batch 57.23 | loss  3.92 | ppl    50.59
| prune-epoch   9 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.35 | loss  3.97 | ppl    52.94
| prune-epoch   9 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.32 | loss  3.98 | ppl    53.36
| prune-epoch   9 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.35 | loss  4.00 | ppl    54.56
| prune-epoch   9 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.26 | loss  4.08 | ppl    59.18
| prune-epoch   9 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.27 | loss  3.99 | ppl    53.82
| prune-epoch   9 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.13 | loss  4.01 | ppl    55.25
| prune-epoch   9 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.10 | loss  3.89 | ppl    49.03
| prune-epoch   9 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.10 | loss  3.92 | ppl    50.27
| prune-epoch   9 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.13 | loss  3.97 | ppl    52.75
| prune-epoch   9 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.36 | loss  3.92 | ppl    50.61
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7  actual sp:  0.6993333333333334
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7  actual sp:  0.6993332222222222
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7  actual sp:  0.6993333333333334
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7  actual sp:  0.6993333333333334
-----------------------------------------------------------------------------------------
| end of prune epoch   9 | time: 177.94s | valid loss  4.62 | valid ppl   101.91
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  10 |   200/ 2983 batches | lr 20.00 | ms/batch 59.80 | loss  3.98 | ppl    53.58
| prune-epoch  10 |   400/ 2983 batches | lr 20.00 | ms/batch 57.23 | loss  4.01 | ppl    55.13
| prune-epoch  10 |   600/ 2983 batches | lr 20.00 | ms/batch 57.19 | loss  3.84 | ppl    46.47
| prune-epoch  10 |   800/ 2983 batches | lr 20.00 | ms/batch 57.15 | loss  3.88 | ppl    48.63
| prune-epoch  10 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.16 | loss  3.94 | ppl    51.18
| prune-epoch  10 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.15 | loss  3.94 | ppl    51.23
| prune-epoch  10 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.14 | loss  3.96 | ppl    52.43
| prune-epoch  10 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.23 | loss  4.04 | ppl    56.81
| prune-epoch  10 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.24 | loss  3.94 | ppl    51.54
| prune-epoch  10 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.22 | loss  3.99 | ppl    53.79
| prune-epoch  10 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.20 | loss  3.86 | ppl    47.36
| prune-epoch  10 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.16 | loss  3.89 | ppl    48.86
| prune-epoch  10 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.18 | loss  3.93 | ppl    50.78
| prune-epoch  10 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.21 | loss  3.90 | ppl    49.31
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7  actual sp:  0.6993333333333334
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7  actual sp:  0.6993333333333334
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7  actual sp:  0.6993333333333334
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7  actual sp:  0.6993333333333334
-----------------------------------------------------------------------------------------
| end of prune epoch  10 | time: 177.82s | valid loss  4.62 | valid ppl   101.93
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  11 |   200/ 2983 batches | lr 20.00 | ms/batch 59.24 | loss  4.03 | ppl    56.44
| prune-epoch  11 |   400/ 2983 batches | lr 20.00 | ms/batch 56.64 | loss  4.04 | ppl    57.11
| prune-epoch  11 |   600/ 2983 batches | lr 20.00 | ms/batch 56.95 | loss  3.87 | ppl    47.96
| prune-epoch  11 |   800/ 2983 batches | lr 20.00 | ms/batch 56.65 | loss  3.91 | ppl    49.93
| prune-epoch  11 |  1000/ 2983 batches | lr 20.00 | ms/batch 56.64 | loss  3.96 | ppl    52.25
| prune-epoch  11 |  1200/ 2983 batches | lr 20.00 | ms/batch 56.66 | loss  3.97 | ppl    53.02
| prune-epoch  11 |  1400/ 2983 batches | lr 20.00 | ms/batch 56.64 | loss  3.99 | ppl    54.07
| prune-epoch  11 |  1600/ 2983 batches | lr 20.00 | ms/batch 56.65 | loss  4.07 | ppl    58.40
| prune-epoch  11 |  1800/ 2983 batches | lr 20.00 | ms/batch 56.65 | loss  3.97 | ppl    53.12
| prune-epoch  11 |  2000/ 2983 batches | lr 20.00 | ms/batch 56.65 | loss  4.01 | ppl    55.17
| prune-epoch  11 |  2200/ 2983 batches | lr 20.00 | ms/batch 56.65 | loss  3.88 | ppl    48.48
| prune-epoch  11 |  2400/ 2983 batches | lr 20.00 | ms/batch 56.65 | loss  3.91 | ppl    49.73
| prune-epoch  11 |  2600/ 2983 batches | lr 20.00 | ms/batch 56.69 | loss  3.95 | ppl    51.92
| prune-epoch  11 |  2800/ 2983 batches | lr 20.00 | ms/batch 56.64 | loss  3.92 | ppl    50.17
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993332222222223
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch  11 | time: 176.24s | valid loss  4.63 | valid ppl   102.80
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  12 |   200/ 2983 batches | lr 20.00 | ms/batch 59.62 | loss  3.96 | ppl    52.71
| prune-epoch  12 |   400/ 2983 batches | lr 20.00 | ms/batch 57.30 | loss  4.00 | ppl    54.33
| prune-epoch  12 |   600/ 2983 batches | lr 20.00 | ms/batch 57.29 | loss  3.82 | ppl    45.50
| prune-epoch  12 |   800/ 2983 batches | lr 20.00 | ms/batch 57.31 | loss  3.87 | ppl    48.01
| prune-epoch  12 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.30 | loss  3.92 | ppl    50.32
| prune-epoch  12 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.29 | loss  3.92 | ppl    50.32
| prune-epoch  12 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.36 | loss  3.94 | ppl    51.55
| prune-epoch  12 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.50 | loss  4.02 | ppl    55.96
| prune-epoch  12 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.54 | loss  3.93 | ppl    51.12
| prune-epoch  12 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.79 | loss  3.97 | ppl    52.86
| prune-epoch  12 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.47 | loss  3.84 | ppl    46.69
| prune-epoch  12 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.59 | loss  3.87 | ppl    47.91
| prune-epoch  12 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.47 | loss  3.91 | ppl    50.00
| prune-epoch  12 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.69 | loss  3.88 | ppl    48.33
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch  12 | time: 178.68s | valid loss  4.63 | valid ppl   102.11
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  13 |   200/ 2983 batches | lr 20.00 | ms/batch 59.84 | loss  3.93 | ppl    50.72
| prune-epoch  13 |   400/ 2983 batches | lr 20.00 | ms/batch 57.49 | loss  3.96 | ppl    52.38
| prune-epoch  13 |   600/ 2983 batches | lr 20.00 | ms/batch 57.18 | loss  3.79 | ppl    44.27
| prune-epoch  13 |   800/ 2983 batches | lr 20.00 | ms/batch 57.35 | loss  3.84 | ppl    46.49
| prune-epoch  13 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.55 | loss  3.88 | ppl    48.58
| prune-epoch  13 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.51 | loss  3.90 | ppl    49.24
| prune-epoch  13 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.51 | loss  3.92 | ppl    50.27
| prune-epoch  13 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.21 | loss  4.00 | ppl    54.56
| prune-epoch  13 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.14 | loss  3.90 | ppl    49.61
| prune-epoch  13 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.14 | loss  3.94 | ppl    51.35
| prune-epoch  13 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.17 | loss  3.82 | ppl    45.46
| prune-epoch  13 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.15 | loss  3.85 | ppl    46.79
| prune-epoch  13 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.16 | loss  3.88 | ppl    48.34
| prune-epoch  13 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.16 | loss  3.85 | ppl    47.13
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch  13 | time: 178.05s | valid loss  4.62 | valid ppl   101.59
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  14 |   200/ 2983 batches | lr 20.00 | ms/batch 59.36 | loss  3.91 | ppl    49.73
| prune-epoch  14 |   400/ 2983 batches | lr 20.00 | ms/batch 57.04 | loss  3.93 | ppl    50.98
| prune-epoch  14 |   600/ 2983 batches | lr 20.00 | ms/batch 57.02 | loss  3.76 | ppl    42.95
| prune-epoch  14 |   800/ 2983 batches | lr 20.00 | ms/batch 57.02 | loss  3.81 | ppl    45.38
| prune-epoch  14 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.01 | loss  3.86 | ppl    47.55
| prune-epoch  14 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.01 | loss  3.87 | ppl    47.75
| prune-epoch  14 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.01 | loss  3.88 | ppl    48.67
| prune-epoch  14 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.01 | loss  3.97 | ppl    53.16
| prune-epoch  14 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.02 | loss  3.87 | ppl    48.13
| prune-epoch  14 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.00 | loss  3.92 | ppl    50.48
| prune-epoch  14 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.08 | loss  3.79 | ppl    44.31
| prune-epoch  14 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.30 | loss  3.82 | ppl    45.64
| prune-epoch  14 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.28 | loss  3.86 | ppl    47.44
| prune-epoch  14 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.27 | loss  3.82 | ppl    45.81
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch  14 | time: 177.47s | valid loss  4.61 | valid ppl   100.79
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  15 |   200/ 2983 batches | lr 20.00 | ms/batch 59.83 | loss  3.88 | ppl    48.57
| prune-epoch  15 |   400/ 2983 batches | lr 20.00 | ms/batch 57.51 | loss  3.90 | ppl    49.63
| prune-epoch  15 |   600/ 2983 batches | lr 20.00 | ms/batch 57.52 | loss  3.73 | ppl    41.74
| prune-epoch  15 |   800/ 2983 batches | lr 20.00 | ms/batch 57.53 | loss  3.79 | ppl    44.09
| prune-epoch  15 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.57 | loss  3.84 | ppl    46.48
| prune-epoch  15 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.64 | loss  3.85 | ppl    46.79
| prune-epoch  15 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.65 | loss  3.87 | ppl    47.87
| prune-epoch  15 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.66 | loss  3.95 | ppl    51.93
| prune-epoch  15 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.67 | loss  3.85 | ppl    47.14
| prune-epoch  15 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.65 | loss  3.89 | ppl    48.88
| prune-epoch  15 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.57 | loss  3.76 | ppl    43.04
| prune-epoch  15 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.51 | loss  3.80 | ppl    44.86
| prune-epoch  15 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.52 | loss  3.83 | ppl    46.29
| prune-epoch  15 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.53 | loss  3.81 | ppl    45.14
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch  15 | time: 179.04s | valid loss  4.62 | valid ppl   101.35
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  16 |   200/ 2983 batches | lr 20.00 | ms/batch 59.76 | loss  3.91 | ppl    50.11
| prune-epoch  16 |   400/ 2983 batches | lr 20.00 | ms/batch 57.38 | loss  3.94 | ppl    51.35
| prune-epoch  16 |   600/ 2983 batches | lr 20.00 | ms/batch 57.39 | loss  3.76 | ppl    42.88
| prune-epoch  16 |   800/ 2983 batches | lr 20.00 | ms/batch 57.36 | loss  3.81 | ppl    45.29
| prune-epoch  16 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.36 | loss  3.85 | ppl    47.10
| prune-epoch  16 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.35 | loss  3.87 | ppl    47.98
| prune-epoch  16 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.35 | loss  3.89 | ppl    48.88
| prune-epoch  16 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.36 | loss  3.97 | ppl    52.87
| prune-epoch  16 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.36 | loss  3.87 | ppl    48.14
| prune-epoch  16 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.37 | loss  3.91 | ppl    50.03
| prune-epoch  16 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.36 | loss  3.79 | ppl    44.29
| prune-epoch  16 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.35 | loss  3.81 | ppl    45.19
| prune-epoch  16 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.36 | loss  3.85 | ppl    47.20
| prune-epoch  16 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.36 | loss  3.82 | ppl    45.65
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch  16 | time: 178.41s | valid loss  4.63 | valid ppl   102.57
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  17 |   200/ 2983 batches | lr 20.00 | ms/batch 59.71 | loss  3.88 | ppl    48.24
| prune-epoch  17 |   400/ 2983 batches | lr 20.00 | ms/batch 57.51 | loss  3.90 | ppl    49.30
| prune-epoch  17 |   600/ 2983 batches | lr 20.00 | ms/batch 57.52 | loss  3.72 | ppl    41.31
| prune-epoch  17 |   800/ 2983 batches | lr 20.00 | ms/batch 57.51 | loss  3.77 | ppl    43.58
| prune-epoch  17 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.51 | loss  3.83 | ppl    45.86
| prune-epoch  17 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.51 | loss  3.83 | ppl    46.09
| prune-epoch  17 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.51 | loss  3.85 | ppl    47.20
| prune-epoch  17 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.51 | loss  3.93 | ppl    51.15
| prune-epoch  17 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.50 | loss  3.85 | ppl    46.84
| prune-epoch  17 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.59 | loss  3.88 | ppl    48.32
| prune-epoch  17 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.57 | loss  3.76 | ppl    43.04
| prune-epoch  17 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.49 | loss  3.78 | ppl    43.94
| prune-epoch  17 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.49 | loss  3.83 | ppl    46.04
| prune-epoch  17 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.50 | loss  3.80 | ppl    44.52
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch  17 | time: 178.84s | valid loss  4.62 | valid ppl   101.94
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  18 |   200/ 2983 batches | lr 20.00 | ms/batch 59.13 | loss  3.85 | ppl    47.21
| prune-epoch  18 |   400/ 2983 batches | lr 20.00 | ms/batch 56.89 | loss  3.87 | ppl    48.13
| prune-epoch  18 |   600/ 2983 batches | lr 20.00 | ms/batch 56.89 | loss  3.71 | ppl    40.67
| prune-epoch  18 |   800/ 2983 batches | lr 20.00 | ms/batch 56.90 | loss  3.76 | ppl    42.90
| prune-epoch  18 |  1000/ 2983 batches | lr 20.00 | ms/batch 56.90 | loss  3.81 | ppl    45.03
| prune-epoch  18 |  1200/ 2983 batches | lr 20.00 | ms/batch 56.90 | loss  3.81 | ppl    44.97
| prune-epoch  18 |  1400/ 2983 batches | lr 20.00 | ms/batch 56.89 | loss  3.84 | ppl    46.30
| prune-epoch  18 |  1600/ 2983 batches | lr 20.00 | ms/batch 56.90 | loss  3.91 | ppl    49.72
| prune-epoch  18 |  1800/ 2983 batches | lr 20.00 | ms/batch 56.93 | loss  3.82 | ppl    45.59
| prune-epoch  18 |  2000/ 2983 batches | lr 20.00 | ms/batch 56.91 | loss  3.87 | ppl    47.76
| prune-epoch  18 |  2200/ 2983 batches | lr 20.00 | ms/batch 56.92 | loss  3.73 | ppl    41.64
| prune-epoch  18 |  2400/ 2983 batches | lr 20.00 | ms/batch 56.91 | loss  3.76 | ppl    43.10
| prune-epoch  18 |  2600/ 2983 batches | lr 20.00 | ms/batch 56.91 | loss  3.80 | ppl    44.61
| prune-epoch  18 |  2800/ 2983 batches | lr 20.00 | ms/batch 56.91 | loss  3.77 | ppl    43.50
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch  18 | time: 177.03s | valid loss  4.63 | valid ppl   102.64
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  19 |   200/ 2983 batches | lr 20.00 | ms/batch 59.85 | loss  3.96 | ppl    52.53
| prune-epoch  19 |   400/ 2983 batches | lr 20.00 | ms/batch 57.60 | loss  3.96 | ppl    52.67
| prune-epoch  19 |   600/ 2983 batches | lr 20.00 | ms/batch 57.60 | loss  3.80 | ppl    44.67
| prune-epoch  19 |   800/ 2983 batches | lr 20.00 | ms/batch 57.59 | loss  3.85 | ppl    46.84
| prune-epoch  19 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.58 | loss  3.89 | ppl    49.09
| prune-epoch  19 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.57 | loss  3.90 | ppl    49.55
| prune-epoch  19 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.59 | loss  3.92 | ppl    50.53
| prune-epoch  19 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.60 | loss  3.99 | ppl    54.19
| prune-epoch  19 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.61 | loss  3.90 | ppl    49.30
| prune-epoch  19 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.59 | loss  3.94 | ppl    51.22
| prune-epoch  19 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.60 | loss  3.80 | ppl    44.92
| prune-epoch  19 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.58 | loss  3.84 | ppl    46.59
| prune-epoch  19 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.57 | loss  3.87 | ppl    48.01
| prune-epoch  19 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.56 | loss  3.85 | ppl    46.92
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch  19 | time: 179.07s | valid loss  4.64 | valid ppl   103.57
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 59.56 | loss  3.89 | ppl    49.03
| prune-epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 57.52 | loss  3.92 | ppl    50.32
| prune-epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 57.51 | loss  3.75 | ppl    42.43
| prune-epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 57.52 | loss  3.80 | ppl    44.70
| prune-epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.50 | loss  3.85 | ppl    46.78
| prune-epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.52 | loss  3.86 | ppl    47.36
| prune-epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.49 | loss  3.88 | ppl    48.35
| prune-epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.50 | loss  3.95 | ppl    52.01
| prune-epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.50 | loss  3.86 | ppl    47.65
| prune-epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.52 | loss  3.90 | ppl    49.52
| prune-epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.52 | loss  3.77 | ppl    43.51
| prune-epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.50 | loss  3.81 | ppl    44.99
| prune-epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.50 | loss  3.85 | ppl    46.83
| prune-epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.51 | loss  3.81 | ppl    45.23
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch   1 | time: 178.78s | valid loss  4.64 | valid ppl   103.39
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch 59.34 | loss  3.86 | ppl    47.51
| prune-epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch 57.33 | loss  3.89 | ppl    48.98
| prune-epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch 57.30 | loss  3.72 | ppl    41.20
| prune-epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch 57.31 | loss  3.77 | ppl    43.46
| prune-epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.30 | loss  3.82 | ppl    45.76
| prune-epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.30 | loss  3.83 | ppl    45.98
| prune-epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.30 | loss  3.85 | ppl    47.23
| prune-epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.32 | loss  3.92 | ppl    50.59
| prune-epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.31 | loss  3.84 | ppl    46.30
| prune-epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.33 | loss  3.88 | ppl    48.30
| prune-epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.37 | loss  3.75 | ppl    42.66
| prune-epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.33 | loss  3.78 | ppl    43.75
| prune-epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.30 | loss  3.82 | ppl    45.74
| prune-epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.30 | loss  3.79 | ppl    44.28
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch   2 | time: 178.20s | valid loss  4.62 | valid ppl   101.88
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 59.43 | loss  3.84 | ppl    46.52
| prune-epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch 57.41 | loss  3.86 | ppl    47.70
| prune-epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 57.47 | loss  3.70 | ppl    40.52
| prune-epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 57.43 | loss  3.75 | ppl    42.60
| prune-epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.38 | loss  3.80 | ppl    44.69
| prune-epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.38 | loss  3.81 | ppl    45.26
| prune-epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.40 | loss  3.83 | ppl    45.96
| prune-epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.38 | loss  3.90 | ppl    49.49
| prune-epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.38 | loss  3.81 | ppl    45.34
| prune-epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.39 | loss  3.86 | ppl    47.26
| prune-epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.39 | loss  3.74 | ppl    41.99
| prune-epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.47 | loss  3.76 | ppl    43.14
| prune-epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.48 | loss  3.80 | ppl    44.83
| prune-epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.48 | loss  3.77 | ppl    43.43
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch   3 | time: 178.50s | valid loss  4.65 | valid ppl   105.10
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   4 |   200/ 2983 batches | lr 20.00 | ms/batch 59.37 | loss  3.82 | ppl    45.81
| prune-epoch   4 |   400/ 2983 batches | lr 20.00 | ms/batch 57.32 | loss  3.85 | ppl    46.80
| prune-epoch   4 |   600/ 2983 batches | lr 20.00 | ms/batch 57.30 | loss  3.68 | ppl    39.52
| prune-epoch   4 |   800/ 2983 batches | lr 20.00 | ms/batch 57.31 | loss  3.73 | ppl    41.78
| prune-epoch   4 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.30 | loss  3.78 | ppl    43.85
| prune-epoch   4 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.28 | loss  3.79 | ppl    44.25
| prune-epoch   4 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.29 | loss  3.81 | ppl    45.20
| prune-epoch   4 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.30 | loss  3.89 | ppl    48.80
| prune-epoch   4 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.29 | loss  3.80 | ppl    44.72
| prune-epoch   4 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.26 | loss  3.84 | ppl    46.71
| prune-epoch   4 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.16 | loss  3.72 | ppl    41.08
| prune-epoch   4 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.25 | loss  3.74 | ppl    41.93
| prune-epoch   4 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.06 | loss  3.78 | ppl    43.82
| prune-epoch   4 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.03 | loss  3.75 | ppl    42.70
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch   4 | time: 177.77s | valid loss  4.65 | valid ppl   104.79
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   5 |   200/ 2983 batches | lr 20.00 | ms/batch 59.19 | loss  3.80 | ppl    44.85
| prune-epoch   5 |   400/ 2983 batches | lr 20.00 | ms/batch 57.18 | loss  3.84 | ppl    46.32
| prune-epoch   5 |   600/ 2983 batches | lr 20.00 | ms/batch 57.23 | loss  3.66 | ppl    39.01
| prune-epoch   5 |   800/ 2983 batches | lr 20.00 | ms/batch 57.20 | loss  3.72 | ppl    41.32
| prune-epoch   5 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.24 | loss  3.77 | ppl    43.29
| prune-epoch   5 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.33 | loss  3.77 | ppl    43.59
| prune-epoch   5 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.38 | loss  3.79 | ppl    44.37
| prune-epoch   5 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.43 | loss  3.87 | ppl    47.87
| prune-epoch   5 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.39 | loss  3.79 | ppl    44.07
| prune-epoch   5 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.41 | loss  3.82 | ppl    45.63
| prune-epoch   5 |  2200/ 2983 batches | lr 20.00 | ms/batch 57.41 | loss  3.70 | ppl    40.54
| prune-epoch   5 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.39 | loss  3.72 | ppl    41.23
| prune-epoch   5 |  2600/ 2983 batches | lr 20.00 | ms/batch 57.33 | loss  3.77 | ppl    43.21
| prune-epoch   5 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.27 | loss  3.74 | ppl    41.91
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch   5 | time: 178.02s | valid loss  4.64 | valid ppl   103.32
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   6 |   200/ 2983 batches | lr 20.00 | ms/batch 58.81 | loss  3.79 | ppl    44.28
| prune-epoch   6 |   400/ 2983 batches | lr 20.00 | ms/batch 56.77 | loss  3.82 | ppl    45.47
| prune-epoch   6 |   600/ 2983 batches | lr 20.00 | ms/batch 56.73 | loss  3.65 | ppl    38.40
| prune-epoch   6 |   800/ 2983 batches | lr 20.00 | ms/batch 56.69 | loss  3.70 | ppl    40.50
| prune-epoch   6 |  1000/ 2983 batches | lr 20.00 | ms/batch 56.72 | loss  3.75 | ppl    42.37
| prune-epoch   6 |  1200/ 2983 batches | lr 20.00 | ms/batch 56.85 | loss  3.76 | ppl    42.86
| prune-epoch   6 |  1400/ 2983 batches | lr 20.00 | ms/batch 56.81 | loss  3.78 | ppl    43.69
| prune-epoch   6 |  1600/ 2983 batches | lr 20.00 | ms/batch 56.84 | loss  3.86 | ppl    47.32
| prune-epoch   6 |  1800/ 2983 batches | lr 20.00 | ms/batch 56.86 | loss  3.77 | ppl    43.51
| prune-epoch   6 |  2000/ 2983 batches | lr 20.00 | ms/batch 56.82 | loss  3.82 | ppl    45.38
| prune-epoch   6 |  2200/ 2983 batches | lr 20.00 | ms/batch 56.84 | loss  3.67 | ppl    39.42
| prune-epoch   6 |  2400/ 2983 batches | lr 20.00 | ms/batch 56.84 | loss  3.71 | ppl    40.79
| prune-epoch   6 |  2600/ 2983 batches | lr 20.00 | ms/batch 56.84 | loss  3.75 | ppl    42.37
| prune-epoch   6 |  2800/ 2983 batches | lr 20.00 | ms/batch 56.80 | loss  3.72 | ppl    41.22
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch   6 | time: 176.49s | valid loss  4.66 | valid ppl   105.45
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   7 |   200/ 2983 batches | lr 5.00 | ms/batch 59.46 | loss  3.78 | ppl    44.00
| prune-epoch   7 |   400/ 2983 batches | lr 5.00 | ms/batch 57.43 | loss  3.79 | ppl    44.13
| prune-epoch   7 |   600/ 2983 batches | lr 5.00 | ms/batch 57.30 | loss  3.61 | ppl    36.91
| prune-epoch   7 |   800/ 2983 batches | lr 5.00 | ms/batch 57.36 | loss  3.64 | ppl    38.28
| prune-epoch   7 |  1000/ 2983 batches | lr 5.00 | ms/batch 57.35 | loss  3.68 | ppl    39.81
| prune-epoch   7 |  1200/ 2983 batches | lr 5.00 | ms/batch 57.41 | loss  3.69 | ppl    40.10
| prune-epoch   7 |  1400/ 2983 batches | lr 5.00 | ms/batch 57.44 | loss  3.70 | ppl    40.38
| prune-epoch   7 |  1600/ 2983 batches | lr 5.00 | ms/batch 57.46 | loss  3.76 | ppl    43.14
| prune-epoch   7 |  1800/ 2983 batches | lr 5.00 | ms/batch 57.38 | loss  3.67 | ppl    39.39
| prune-epoch   7 |  2000/ 2983 batches | lr 5.00 | ms/batch 57.38 | loss  3.71 | ppl    41.02
| prune-epoch   7 |  2200/ 2983 batches | lr 5.00 | ms/batch 57.30 | loss  3.57 | ppl    35.66
| prune-epoch   7 |  2400/ 2983 batches | lr 5.00 | ms/batch 57.41 | loss  3.59 | ppl    36.15
| prune-epoch   7 |  2600/ 2983 batches | lr 5.00 | ms/batch 57.43 | loss  3.62 | ppl    37.21
| prune-epoch   7 |  2800/ 2983 batches | lr 5.00 | ms/batch 57.41 | loss  3.58 | ppl    35.93
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch   7 | time: 178.25s | valid loss  4.62 | valid ppl   101.42
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   8 |   200/ 2983 batches | lr 5.00 | ms/batch 59.30 | loss  3.71 | ppl    40.90
| prune-epoch   8 |   400/ 2983 batches | lr 5.00 | ms/batch 57.38 | loss  3.73 | ppl    41.58
| prune-epoch   8 |   600/ 2983 batches | lr 5.00 | ms/batch 57.25 | loss  3.55 | ppl    34.99
| prune-epoch   8 |   800/ 2983 batches | lr 5.00 | ms/batch 57.34 | loss  3.60 | ppl    36.72
| prune-epoch   8 |  1000/ 2983 batches | lr 5.00 | ms/batch 57.30 | loss  3.65 | ppl    38.62
| prune-epoch   8 |  1200/ 2983 batches | lr 5.00 | ms/batch 57.35 | loss  3.65 | ppl    38.44
| prune-epoch   8 |  1400/ 2983 batches | lr 5.00 | ms/batch 57.31 | loss  3.67 | ppl    39.08
| prune-epoch   8 |  1600/ 2983 batches | lr 5.00 | ms/batch 57.39 | loss  3.73 | ppl    41.57
| prune-epoch   8 |  1800/ 2983 batches | lr 5.00 | ms/batch 57.33 | loss  3.65 | ppl    38.40
| prune-epoch   8 |  2000/ 2983 batches | lr 5.00 | ms/batch 57.33 | loss  3.69 | ppl    39.98
| prune-epoch   8 |  2200/ 2983 batches | lr 5.00 | ms/batch 57.37 | loss  3.55 | ppl    34.91
| prune-epoch   8 |  2400/ 2983 batches | lr 5.00 | ms/batch 57.30 | loss  3.57 | ppl    35.62
| prune-epoch   8 |  2600/ 2983 batches | lr 5.00 | ms/batch 57.33 | loss  3.60 | ppl    36.61
| prune-epoch   8 |  2800/ 2983 batches | lr 5.00 | ms/batch 57.34 | loss  3.58 | ppl    35.83
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch   8 | time: 178.08s | valid loss  4.62 | valid ppl   101.96
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   9 |   200/ 2983 batches | lr 5.00 | ms/batch 59.03 | loss  3.69 | ppl    39.89
| prune-epoch   9 |   400/ 2983 batches | lr 5.00 | ms/batch 57.05 | loss  3.71 | ppl    40.68
| prune-epoch   9 |   600/ 2983 batches | lr 5.00 | ms/batch 57.04 | loss  3.53 | ppl    34.24
| prune-epoch   9 |   800/ 2983 batches | lr 5.00 | ms/batch 57.17 | loss  3.58 | ppl    36.05
| prune-epoch   9 |  1000/ 2983 batches | lr 5.00 | ms/batch 57.14 | loss  3.64 | ppl    37.99
| prune-epoch   9 |  1200/ 2983 batches | lr 5.00 | ms/batch 57.11 | loss  3.64 | ppl    37.95
| prune-epoch   9 |  1400/ 2983 batches | lr 5.00 | ms/batch 57.12 | loss  3.65 | ppl    38.35
| prune-epoch   9 |  1600/ 2983 batches | lr 5.00 | ms/batch 57.16 | loss  3.72 | ppl    41.11
| prune-epoch   9 |  1800/ 2983 batches | lr 5.00 | ms/batch 57.17 | loss  3.63 | ppl    37.67
| prune-epoch   9 |  2000/ 2983 batches | lr 5.00 | ms/batch 57.12 | loss  3.68 | ppl    39.52
| prune-epoch   9 |  2200/ 2983 batches | lr 5.00 | ms/batch 57.14 | loss  3.53 | ppl    34.20
| prune-epoch   9 |  2400/ 2983 batches | lr 5.00 | ms/batch 57.07 | loss  3.56 | ppl    35.04
| prune-epoch   9 |  2600/ 2983 batches | lr 5.00 | ms/batch 57.12 | loss  3.60 | ppl    36.43
| prune-epoch   9 |  2800/ 2983 batches | lr 5.00 | ms/batch 57.15 | loss  3.56 | ppl    35.22
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch   9 | time: 177.45s | valid loss  4.63 | valid ppl   102.86
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  10 |   200/ 2983 batches | lr 1.25 | ms/batch 59.27 | loss  3.72 | ppl    41.38
| prune-epoch  10 |   400/ 2983 batches | lr 1.25 | ms/batch 57.30 | loss  3.74 | ppl    42.04
| prune-epoch  10 |   600/ 2983 batches | lr 1.25 | ms/batch 57.32 | loss  3.57 | ppl    35.37
| prune-epoch  10 |   800/ 2983 batches | lr 1.25 | ms/batch 57.32 | loss  3.62 | ppl    37.50
| prune-epoch  10 |  1000/ 2983 batches | lr 1.25 | ms/batch 57.25 | loss  3.65 | ppl    38.55
| prune-epoch  10 |  1200/ 2983 batches | lr 1.25 | ms/batch 57.31 | loss  3.67 | ppl    39.23
| prune-epoch  10 |  1400/ 2983 batches | lr 1.25 | ms/batch 57.40 | loss  3.67 | ppl    39.12
| prune-epoch  10 |  1600/ 2983 batches | lr 1.25 | ms/batch 57.37 | loss  3.74 | ppl    41.91
| prune-epoch  10 |  1800/ 2983 batches | lr 1.25 | ms/batch 57.36 | loss  3.66 | ppl    38.86
| prune-epoch  10 |  2000/ 2983 batches | lr 1.25 | ms/batch 57.33 | loss  3.69 | ppl    40.09
| prune-epoch  10 |  2200/ 2983 batches | lr 1.25 | ms/batch 57.39 | loss  3.57 | ppl    35.62
| prune-epoch  10 |  2400/ 2983 batches | lr 1.25 | ms/batch 57.39 | loss  3.57 | ppl    35.67
| prune-epoch  10 |  2600/ 2983 batches | lr 1.25 | ms/batch 57.33 | loss  3.61 | ppl    36.82
| prune-epoch  10 |  2800/ 2983 batches | lr 1.25 | ms/batch 57.21 | loss  3.56 | ppl    35.15
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  10 | time: 178.05s | valid loss  4.58 | valid ppl    97.86
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  11 |   200/ 2983 batches | lr 1.25 | ms/batch 59.24 | loss  3.71 | ppl    40.71
| prune-epoch  11 |   400/ 2983 batches | lr 1.25 | ms/batch 57.23 | loss  3.71 | ppl    40.97
| prune-epoch  11 |   600/ 2983 batches | lr 1.25 | ms/batch 57.27 | loss  3.55 | ppl    34.86
| prune-epoch  11 |   800/ 2983 batches | lr 1.25 | ms/batch 57.23 | loss  3.60 | ppl    36.56
| prune-epoch  11 |  1000/ 2983 batches | lr 1.25 | ms/batch 57.22 | loss  3.64 | ppl    38.05
| prune-epoch  11 |  1200/ 2983 batches | lr 1.25 | ms/batch 57.21 | loss  3.66 | ppl    38.72
| prune-epoch  11 |  1400/ 2983 batches | lr 1.25 | ms/batch 57.16 | loss  3.65 | ppl    38.52
| prune-epoch  11 |  1600/ 2983 batches | lr 1.25 | ms/batch 57.20 | loss  3.72 | ppl    41.39
| prune-epoch  11 |  1800/ 2983 batches | lr 1.25 | ms/batch 57.21 | loss  3.64 | ppl    38.26
| prune-epoch  11 |  2000/ 2983 batches | lr 1.25 | ms/batch 57.23 | loss  3.69 | ppl    39.85
| prune-epoch  11 |  2200/ 2983 batches | lr 1.25 | ms/batch 57.18 | loss  3.57 | ppl    35.56
| prune-epoch  11 |  2400/ 2983 batches | lr 1.25 | ms/batch 57.23 | loss  3.56 | ppl    35.07
| prune-epoch  11 |  2600/ 2983 batches | lr 1.25 | ms/batch 57.20 | loss  3.60 | ppl    36.71
| prune-epoch  11 |  2800/ 2983 batches | lr 1.25 | ms/batch 57.19 | loss  3.55 | ppl    34.84
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  11 | time: 177.71s | valid loss  4.58 | valid ppl    97.50
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  12 |   200/ 2983 batches | lr 1.25 | ms/batch 59.37 | loss  3.69 | ppl    40.16
| prune-epoch  12 |   400/ 2983 batches | lr 1.25 | ms/batch 57.30 | loss  3.70 | ppl    40.53
| prune-epoch  12 |   600/ 2983 batches | lr 1.25 | ms/batch 57.32 | loss  3.55 | ppl    34.80
| prune-epoch  12 |   800/ 2983 batches | lr 1.25 | ms/batch 57.35 | loss  3.60 | ppl    36.50
| prune-epoch  12 |  1000/ 2983 batches | lr 1.25 | ms/batch 57.38 | loss  3.63 | ppl    37.81
| prune-epoch  12 |  1200/ 2983 batches | lr 1.25 | ms/batch 57.35 | loss  3.65 | ppl    38.28
| prune-epoch  12 |  1400/ 2983 batches | lr 1.25 | ms/batch 57.31 | loss  3.65 | ppl    38.30
| prune-epoch  12 |  1600/ 2983 batches | lr 1.25 | ms/batch 57.35 | loss  3.71 | ppl    41.05
| prune-epoch  12 |  1800/ 2983 batches | lr 1.25 | ms/batch 57.39 | loss  3.64 | ppl    38.06
| prune-epoch  12 |  2000/ 2983 batches | lr 1.25 | ms/batch 57.42 | loss  3.68 | ppl    39.66
| prune-epoch  12 |  2200/ 2983 batches | lr 1.25 | ms/batch 57.36 | loss  3.57 | ppl    35.43
| prune-epoch  12 |  2400/ 2983 batches | lr 1.25 | ms/batch 57.43 | loss  3.56 | ppl    35.15
| prune-epoch  12 |  2600/ 2983 batches | lr 1.25 | ms/batch 57.40 | loss  3.59 | ppl    36.39
| prune-epoch  12 |  2800/ 2983 batches | lr 1.25 | ms/batch 57.31 | loss  3.55 | ppl    34.90
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  12 | time: 178.16s | valid loss  4.58 | valid ppl    97.26
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  13 |   200/ 2983 batches | lr 1.25 | ms/batch 58.80 | loss  3.69 | ppl    40.08
| prune-epoch  13 |   400/ 2983 batches | lr 1.25 | ms/batch 56.84 | loss  3.70 | ppl    40.44
| prune-epoch  13 |   600/ 2983 batches | lr 1.25 | ms/batch 56.77 | loss  3.54 | ppl    34.54
| prune-epoch  13 |   800/ 2983 batches | lr 1.25 | ms/batch 56.72 | loss  3.59 | ppl    36.19
| prune-epoch  13 |  1000/ 2983 batches | lr 1.25 | ms/batch 56.79 | loss  3.62 | ppl    37.52
| prune-epoch  13 |  1200/ 2983 batches | lr 1.25 | ms/batch 56.80 | loss  3.65 | ppl    38.29
| prune-epoch  13 |  1400/ 2983 batches | lr 1.25 | ms/batch 56.76 | loss  3.64 | ppl    38.03
| prune-epoch  13 |  1600/ 2983 batches | lr 1.25 | ms/batch 56.79 | loss  3.72 | ppl    41.17
| prune-epoch  13 |  1800/ 2983 batches | lr 1.25 | ms/batch 56.75 | loss  3.63 | ppl    37.89
| prune-epoch  13 |  2000/ 2983 batches | lr 1.25 | ms/batch 56.82 | loss  3.67 | ppl    39.20
| prune-epoch  13 |  2200/ 2983 batches | lr 1.25 | ms/batch 56.79 | loss  3.56 | ppl    35.13
| prune-epoch  13 |  2400/ 2983 batches | lr 1.25 | ms/batch 56.79 | loss  3.55 | ppl    34.73
| prune-epoch  13 |  2600/ 2983 batches | lr 1.25 | ms/batch 56.82 | loss  3.59 | ppl    36.25
| prune-epoch  13 |  2800/ 2983 batches | lr 1.25 | ms/batch 56.81 | loss  3.54 | ppl    34.52
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  13 | time: 176.46s | valid loss  4.58 | valid ppl    97.24
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  14 |   200/ 2983 batches | lr 1.25 | ms/batch 59.73 | loss  3.68 | ppl    39.63
| prune-epoch  14 |   400/ 2983 batches | lr 1.25 | ms/batch 57.39 | loss  3.69 | ppl    40.21
| prune-epoch  14 |   600/ 2983 batches | lr 1.25 | ms/batch 57.46 | loss  3.54 | ppl    34.36
| prune-epoch  14 |   800/ 2983 batches | lr 1.25 | ms/batch 57.51 | loss  3.58 | ppl    35.83
| prune-epoch  14 |  1000/ 2983 batches | lr 1.25 | ms/batch 57.45 | loss  3.62 | ppl    37.32
| prune-epoch  14 |  1200/ 2983 batches | lr 1.25 | ms/batch 57.38 | loss  3.64 | ppl    38.11
| prune-epoch  14 |  1400/ 2983 batches | lr 1.25 | ms/batch 57.41 | loss  3.63 | ppl    37.81
| prune-epoch  14 |  1600/ 2983 batches | lr 1.25 | ms/batch 57.44 | loss  3.71 | ppl    40.72
| prune-epoch  14 |  1800/ 2983 batches | lr 1.25 | ms/batch 57.42 | loss  3.63 | ppl    37.71
| prune-epoch  14 |  2000/ 2983 batches | lr 1.25 | ms/batch 57.44 | loss  3.67 | ppl    39.15
| prune-epoch  14 |  2200/ 2983 batches | lr 1.25 | ms/batch 57.43 | loss  3.56 | ppl    35.05
| prune-epoch  14 |  2400/ 2983 batches | lr 1.25 | ms/batch 57.40 | loss  3.55 | ppl    34.76
| prune-epoch  14 |  2600/ 2983 batches | lr 1.25 | ms/batch 57.41 | loss  3.59 | ppl    36.12
| prune-epoch  14 |  2800/ 2983 batches | lr 1.25 | ms/batch 57.51 | loss  3.54 | ppl    34.40
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  14 | time: 178.44s | valid loss  4.58 | valid ppl    97.19
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  15 |   200/ 2983 batches | lr 1.25 | ms/batch 59.40 | loss  3.67 | ppl    39.35
| prune-epoch  15 |   400/ 2983 batches | lr 1.25 | ms/batch 57.43 | loss  3.69 | ppl    40.10
| prune-epoch  15 |   600/ 2983 batches | lr 1.25 | ms/batch 57.26 | loss  3.53 | ppl    34.07
| prune-epoch  15 |   800/ 2983 batches | lr 1.25 | ms/batch 57.40 | loss  3.57 | ppl    35.43
| prune-epoch  15 |  1000/ 2983 batches | lr 1.25 | ms/batch 57.38 | loss  3.61 | ppl    37.09
| prune-epoch  15 |  1200/ 2983 batches | lr 1.25 | ms/batch 57.29 | loss  3.63 | ppl    37.71
| prune-epoch  15 |  1400/ 2983 batches | lr 1.25 | ms/batch 57.39 | loss  3.63 | ppl    37.80
| prune-epoch  15 |  1600/ 2983 batches | lr 1.25 | ms/batch 57.33 | loss  3.70 | ppl    40.32
| prune-epoch  15 |  1800/ 2983 batches | lr 1.25 | ms/batch 57.23 | loss  3.63 | ppl    37.75
| prune-epoch  15 |  2000/ 2983 batches | lr 1.25 | ms/batch 57.34 | loss  3.66 | ppl    38.73
| prune-epoch  15 |  2200/ 2983 batches | lr 1.25 | ms/batch 57.29 | loss  3.55 | ppl    34.81
| prune-epoch  15 |  2400/ 2983 batches | lr 1.25 | ms/batch 57.43 | loss  3.55 | ppl    34.68
| prune-epoch  15 |  2600/ 2983 batches | lr 1.25 | ms/batch 57.40 | loss  3.58 | ppl    35.87
| prune-epoch  15 |  2800/ 2983 batches | lr 1.25 | ms/batch 57.29 | loss  3.54 | ppl    34.61
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  15 | time: 178.11s | valid loss  4.58 | valid ppl    97.34
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  16 |   200/ 2983 batches | lr 1.25 | ms/batch 59.10 | loss  3.67 | ppl    39.14
| prune-epoch  16 |   400/ 2983 batches | lr 1.25 | ms/batch 57.04 | loss  3.69 | ppl    39.99
| prune-epoch  16 |   600/ 2983 batches | lr 1.25 | ms/batch 57.08 | loss  3.52 | ppl    33.82
| prune-epoch  16 |   800/ 2983 batches | lr 1.25 | ms/batch 57.20 | loss  3.57 | ppl    35.46
| prune-epoch  16 |  1000/ 2983 batches | lr 1.25 | ms/batch 57.21 | loss  3.61 | ppl    36.99
| prune-epoch  16 |  1200/ 2983 batches | lr 1.25 | ms/batch 57.26 | loss  3.63 | ppl    37.66
| prune-epoch  16 |  1400/ 2983 batches | lr 1.25 | ms/batch 57.19 | loss  3.63 | ppl    37.60
| prune-epoch  16 |  1600/ 2983 batches | lr 1.25 | ms/batch 57.01 | loss  3.70 | ppl    40.56
| prune-epoch  16 |  1800/ 2983 batches | lr 1.25 | ms/batch 57.09 | loss  3.62 | ppl    37.43
| prune-epoch  16 |  2000/ 2983 batches | lr 1.25 | ms/batch 57.10 | loss  3.66 | ppl    38.97
| prune-epoch  16 |  2200/ 2983 batches | lr 1.25 | ms/batch 57.19 | loss  3.55 | ppl    34.75
| prune-epoch  16 |  2400/ 2983 batches | lr 1.25 | ms/batch 57.23 | loss  3.55 | ppl    34.65
| prune-epoch  16 |  2600/ 2983 batches | lr 1.25 | ms/batch 57.13 | loss  3.58 | ppl    35.74
| prune-epoch  16 |  2800/ 2983 batches | lr 1.25 | ms/batch 57.22 | loss  3.54 | ppl    34.38
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  16 | time: 177.54s | valid loss  4.58 | valid ppl    97.34
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  17 |   200/ 2983 batches | lr 1.25 | ms/batch 59.34 | loss  3.66 | ppl    39.00
| prune-epoch  17 |   400/ 2983 batches | lr 1.25 | ms/batch 57.33 | loss  3.68 | ppl    39.81
| prune-epoch  17 |   600/ 2983 batches | lr 1.25 | ms/batch 57.34 | loss  3.51 | ppl    33.54
| prune-epoch  17 |   800/ 2983 batches | lr 1.25 | ms/batch 57.29 | loss  3.56 | ppl    35.29
| prune-epoch  17 |  1000/ 2983 batches | lr 1.25 | ms/batch 57.28 | loss  3.61 | ppl    36.83
| prune-epoch  17 |  1200/ 2983 batches | lr 1.25 | ms/batch 57.23 | loss  3.62 | ppl    37.41
| prune-epoch  17 |  1400/ 2983 batches | lr 1.25 | ms/batch 57.37 | loss  3.62 | ppl    37.30
| prune-epoch  17 |  1600/ 2983 batches | lr 1.25 | ms/batch 57.34 | loss  3.70 | ppl    40.34
| prune-epoch  17 |  1800/ 2983 batches | lr 1.25 | ms/batch 57.29 | loss  3.62 | ppl    37.37
| prune-epoch  17 |  2000/ 2983 batches | lr 1.25 | ms/batch 57.37 | loss  3.66 | ppl    38.72
| prune-epoch  17 |  2200/ 2983 batches | lr 1.25 | ms/batch 57.35 | loss  3.54 | ppl    34.63
| prune-epoch  17 |  2400/ 2983 batches | lr 1.25 | ms/batch 57.28 | loss  3.54 | ppl    34.31
| prune-epoch  17 |  2600/ 2983 batches | lr 1.25 | ms/batch 57.34 | loss  3.58 | ppl    36.01
| prune-epoch  17 |  2800/ 2983 batches | lr 1.25 | ms/batch 57.35 | loss  3.53 | ppl    34.26
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  17 | time: 178.03s | valid loss  4.58 | valid ppl    97.25
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  18 |   200/ 2983 batches | lr 1.25 | ms/batch 59.26 | loss  3.66 | ppl    38.94
| prune-epoch  18 |   400/ 2983 batches | lr 1.25 | ms/batch 57.20 | loss  3.67 | ppl    39.43
| prune-epoch  18 |   600/ 2983 batches | lr 1.25 | ms/batch 57.27 | loss  3.52 | ppl    33.71
| prune-epoch  18 |   800/ 2983 batches | lr 1.25 | ms/batch 57.18 | loss  3.56 | ppl    35.15
| prune-epoch  18 |  1000/ 2983 batches | lr 1.25 | ms/batch 57.21 | loss  3.60 | ppl    36.66
| prune-epoch  18 |  1200/ 2983 batches | lr 1.25 | ms/batch 57.25 | loss  3.62 | ppl    37.30
| prune-epoch  18 |  1400/ 2983 batches | lr 1.25 | ms/batch 57.20 | loss  3.62 | ppl    37.23
| prune-epoch  18 |  1600/ 2983 batches | lr 1.25 | ms/batch 57.33 | loss  3.70 | ppl    40.34
| prune-epoch  18 |  1800/ 2983 batches | lr 1.25 | ms/batch 57.25 | loss  3.61 | ppl    37.05
| prune-epoch  18 |  2000/ 2983 batches | lr 1.25 | ms/batch 57.19 | loss  3.66 | ppl    38.71
| prune-epoch  18 |  2200/ 2983 batches | lr 1.25 | ms/batch 57.26 | loss  3.53 | ppl    34.16
| prune-epoch  18 |  2400/ 2983 batches | lr 1.25 | ms/batch 57.28 | loss  3.54 | ppl    34.39
| prune-epoch  18 |  2600/ 2983 batches | lr 1.25 | ms/batch 57.24 | loss  3.57 | ppl    35.61
| prune-epoch  18 |  2800/ 2983 batches | lr 1.25 | ms/batch 57.24 | loss  3.53 | ppl    34.19
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  18 | time: 177.81s | valid loss  4.58 | valid ppl    97.11
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  19 |   200/ 2983 batches | lr 1.25 | ms/batch 59.31 | loss  3.65 | ppl    38.66
| prune-epoch  19 |   400/ 2983 batches | lr 1.25 | ms/batch 57.41 | loss  3.68 | ppl    39.49
| prune-epoch  19 |   600/ 2983 batches | lr 1.25 | ms/batch 57.43 | loss  3.51 | ppl    33.49
| prune-epoch  19 |   800/ 2983 batches | lr 1.25 | ms/batch 57.49 | loss  3.55 | ppl    34.93
| prune-epoch  19 |  1000/ 2983 batches | lr 1.25 | ms/batch 57.41 | loss  3.61 | ppl    36.81
| prune-epoch  19 |  1200/ 2983 batches | lr 1.25 | ms/batch 57.34 | loss  3.61 | ppl    36.86
| prune-epoch  19 |  1400/ 2983 batches | lr 1.25 | ms/batch 57.43 | loss  3.61 | ppl    37.04
| prune-epoch  19 |  1600/ 2983 batches | lr 1.25 | ms/batch 57.41 | loss  3.69 | ppl    39.87
| prune-epoch  19 |  1800/ 2983 batches | lr 1.25 | ms/batch 57.37 | loss  3.60 | ppl    36.77
| prune-epoch  19 |  2000/ 2983 batches | lr 1.25 | ms/batch 57.42 | loss  3.65 | ppl    38.63
| prune-epoch  19 |  2200/ 2983 batches | lr 1.25 | ms/batch 57.32 | loss  3.53 | ppl    33.98
| prune-epoch  19 |  2400/ 2983 batches | lr 1.25 | ms/batch 57.39 | loss  3.53 | ppl    34.20
| prune-epoch  19 |  2600/ 2983 batches | lr 1.25 | ms/batch 57.40 | loss  3.57 | ppl    35.66
| prune-epoch  19 |  2800/ 2983 batches | lr 1.25 | ms/batch 57.45 | loss  3.53 | ppl    34.16
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  19 | time: 178.29s | valid loss  4.58 | valid ppl    97.25
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  20 |   200/ 2983 batches | lr 0.31 | ms/batch 58.79 | loss  3.68 | ppl    39.69
| prune-epoch  20 |   400/ 2983 batches | lr 0.31 | ms/batch 56.79 | loss  3.73 | ppl    41.85
| prune-epoch  20 |   600/ 2983 batches | lr 0.31 | ms/batch 56.81 | loss  3.59 | ppl    36.18
| prune-epoch  20 |   800/ 2983 batches | lr 0.31 | ms/batch 56.85 | loss  3.66 | ppl    38.67
| prune-epoch  20 |  1000/ 2983 batches | lr 0.31 | ms/batch 56.81 | loss  3.67 | ppl    39.35
| prune-epoch  20 |  1200/ 2983 batches | lr 0.31 | ms/batch 56.85 | loss  3.68 | ppl    39.54
| prune-epoch  20 |  1400/ 2983 batches | lr 0.31 | ms/batch 56.83 | loss  3.68 | ppl    39.73
| prune-epoch  20 |  1600/ 2983 batches | lr 0.31 | ms/batch 56.84 | loss  3.74 | ppl    42.14
| prune-epoch  20 |  1800/ 2983 batches | lr 0.31 | ms/batch 56.80 | loss  3.69 | ppl    39.88
| prune-epoch  20 |  2000/ 2983 batches | lr 0.31 | ms/batch 56.88 | loss  3.66 | ppl    38.96
| prune-epoch  20 |  2200/ 2983 batches | lr 0.31 | ms/batch 56.79 | loss  3.58 | ppl    35.91
| prune-epoch  20 |  2400/ 2983 batches | lr 0.31 | ms/batch 56.89 | loss  3.61 | ppl    36.92
| prune-epoch  20 |  2600/ 2983 batches | lr 0.31 | ms/batch 56.85 | loss  3.62 | ppl    37.48
| prune-epoch  20 |  2800/ 2983 batches | lr 0.31 | ms/batch 56.75 | loss  3.56 | ppl    35.31
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  20 | time: 176.56s | valid loss  4.56 | valid ppl    95.54
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  21 |   200/ 2983 batches | lr 0.31 | ms/batch 59.45 | loss  3.74 | ppl    41.96
| prune-epoch  21 |   400/ 2983 batches | lr 0.31 | ms/batch 57.44 | loss  3.73 | ppl    41.75
| prune-epoch  21 |   600/ 2983 batches | lr 0.31 | ms/batch 57.50 | loss  3.55 | ppl    34.68
| prune-epoch  21 |   800/ 2983 batches | lr 0.31 | ms/batch 57.43 | loss  3.61 | ppl    37.08
| prune-epoch  21 |  1000/ 2983 batches | lr 0.31 | ms/batch 57.49 | loss  3.66 | ppl    38.68
| prune-epoch  21 |  1200/ 2983 batches | lr 0.31 | ms/batch 57.39 | loss  3.67 | ppl    39.11
| prune-epoch  21 |  1400/ 2983 batches | lr 0.31 | ms/batch 57.43 | loss  3.66 | ppl    39.01
| prune-epoch  21 |  1600/ 2983 batches | lr 0.31 | ms/batch 57.45 | loss  3.72 | ppl    41.47
| prune-epoch  21 |  1800/ 2983 batches | lr 0.31 | ms/batch 57.54 | loss  3.68 | ppl    39.63
| prune-epoch  21 |  2000/ 2983 batches | lr 0.31 | ms/batch 57.51 | loss  3.67 | ppl    39.29
| prune-epoch  21 |  2200/ 2983 batches | lr 0.31 | ms/batch 57.39 | loss  3.57 | ppl    35.64
| prune-epoch  21 |  2400/ 2983 batches | lr 0.31 | ms/batch 57.47 | loss  3.60 | ppl    36.74
| prune-epoch  21 |  2600/ 2983 batches | lr 0.31 | ms/batch 57.44 | loss  3.62 | ppl    37.49
| prune-epoch  21 |  2800/ 2983 batches | lr 0.31 | ms/batch 57.49 | loss  3.56 | ppl    35.22
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  21 | time: 178.45s | valid loss  4.56 | valid ppl    95.57
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  22 |   200/ 2983 batches | lr 0.31 | ms/batch 59.34 | loss  3.73 | ppl    41.53
| prune-epoch  22 |   400/ 2983 batches | lr 0.31 | ms/batch 57.34 | loss  3.73 | ppl    41.50
| prune-epoch  22 |   600/ 2983 batches | lr 0.31 | ms/batch 57.22 | loss  3.55 | ppl    34.93
| prune-epoch  22 |   800/ 2983 batches | lr 0.31 | ms/batch 57.37 | loss  3.62 | ppl    37.38
| prune-epoch  22 |  1000/ 2983 batches | lr 0.31 | ms/batch 57.32 | loss  3.66 | ppl    38.71
| prune-epoch  22 |  1200/ 2983 batches | lr 0.31 | ms/batch 57.38 | loss  3.67 | ppl    39.19
| prune-epoch  22 |  1400/ 2983 batches | lr 0.31 | ms/batch 57.34 | loss  3.68 | ppl    39.52
| prune-epoch  22 |  1600/ 2983 batches | lr 0.31 | ms/batch 57.35 | loss  3.72 | ppl    41.38
| prune-epoch  22 |  1800/ 2983 batches | lr 0.31 | ms/batch 57.32 | loss  3.68 | ppl    39.68
| prune-epoch  22 |  2000/ 2983 batches | lr 0.31 | ms/batch 57.32 | loss  3.68 | ppl    39.56
| prune-epoch  22 |  2200/ 2983 batches | lr 0.31 | ms/batch 57.27 | loss  3.57 | ppl    35.41
| prune-epoch  22 |  2400/ 2983 batches | lr 0.31 | ms/batch 57.27 | loss  3.59 | ppl    36.31
| prune-epoch  22 |  2600/ 2983 batches | lr 0.31 | ms/batch 57.32 | loss  3.62 | ppl    37.49
| prune-epoch  22 |  2800/ 2983 batches | lr 0.31 | ms/batch 57.37 | loss  3.56 | ppl    35.23
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  22 | time: 178.06s | valid loss  4.56 | valid ppl    95.49
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  23 |   200/ 2983 batches | lr 0.31 | ms/batch 59.11 | loss  3.72 | ppl    41.34
| prune-epoch  23 |   400/ 2983 batches | lr 0.31 | ms/batch 57.20 | loss  3.72 | ppl    41.45
| prune-epoch  23 |   600/ 2983 batches | lr 0.31 | ms/batch 57.12 | loss  3.54 | ppl    34.63
| prune-epoch  23 |   800/ 2983 batches | lr 0.31 | ms/batch 57.08 | loss  3.62 | ppl    37.19
| prune-epoch  23 |  1000/ 2983 batches | lr 0.31 | ms/batch 57.15 | loss  3.66 | ppl    38.70
| prune-epoch  23 |  1200/ 2983 batches | lr 0.31 | ms/batch 57.17 | loss  3.67 | ppl    39.26
| prune-epoch  23 |  1400/ 2983 batches | lr 0.31 | ms/batch 57.13 | loss  3.66 | ppl    38.96
| prune-epoch  23 |  1600/ 2983 batches | lr 0.31 | ms/batch 57.10 | loss  3.72 | ppl    41.36
| prune-epoch  23 |  1800/ 2983 batches | lr 0.31 | ms/batch 57.10 | loss  3.68 | ppl    39.78
| prune-epoch  23 |  2000/ 2983 batches | lr 0.31 | ms/batch 57.02 | loss  3.67 | ppl    39.39
| prune-epoch  23 |  2200/ 2983 batches | lr 0.31 | ms/batch 57.05 | loss  3.57 | ppl    35.46
| prune-epoch  23 |  2400/ 2983 batches | lr 0.31 | ms/batch 57.17 | loss  3.60 | ppl    36.45
| prune-epoch  23 |  2600/ 2983 batches | lr 0.31 | ms/batch 57.12 | loss  3.62 | ppl    37.33
| prune-epoch  23 |  2800/ 2983 batches | lr 0.31 | ms/batch 57.30 | loss  3.57 | ppl    35.46
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  23 | time: 177.49s | valid loss  4.56 | valid ppl    95.34
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  24 |   200/ 2983 batches | lr 0.31 | ms/batch 59.30 | loss  3.71 | ppl    41.03
| prune-epoch  24 |   400/ 2983 batches | lr 0.31 | ms/batch 57.46 | loss  3.72 | ppl    41.38
| prune-epoch  24 |   600/ 2983 batches | lr 0.31 | ms/batch 57.42 | loss  3.55 | ppl    34.91
| prune-epoch  24 |   800/ 2983 batches | lr 0.31 | ms/batch 57.34 | loss  3.61 | ppl    36.99
| prune-epoch  24 |  1000/ 2983 batches | lr 0.31 | ms/batch 57.37 | loss  3.65 | ppl    38.52
| prune-epoch  24 |  1200/ 2983 batches | lr 0.31 | ms/batch 57.54 | loss  3.67 | ppl    39.11
| prune-epoch  24 |  1400/ 2983 batches | lr 0.31 | ms/batch 57.40 | loss  3.66 | ppl    38.77
| prune-epoch  24 |  1600/ 2983 batches | lr 0.31 | ms/batch 57.53 | loss  3.72 | ppl    41.22
| prune-epoch  24 |  1800/ 2983 batches | lr 0.31 | ms/batch 57.40 | loss  3.68 | ppl    39.51
| prune-epoch  24 |  2000/ 2983 batches | lr 0.31 | ms/batch 57.47 | loss  3.68 | ppl    39.51
| prune-epoch  24 |  2200/ 2983 batches | lr 0.31 | ms/batch 57.32 | loss  3.57 | ppl    35.58
| prune-epoch  24 |  2400/ 2983 batches | lr 0.31 | ms/batch 57.24 | loss  3.59 | ppl    36.37
| prune-epoch  24 |  2600/ 2983 batches | lr 0.31 | ms/batch 57.39 | loss  3.62 | ppl    37.32
| prune-epoch  24 |  2800/ 2983 batches | lr 0.31 | ms/batch 57.28 | loss  3.56 | ppl    35.26
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  24 | time: 178.22s | valid loss  4.56 | valid ppl    95.26
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  25 |   200/ 2983 batches | lr 0.31 | ms/batch 59.22 | loss  3.72 | ppl    41.08
| prune-epoch  25 |   400/ 2983 batches | lr 0.31 | ms/batch 57.23 | loss  3.72 | ppl    41.16
| prune-epoch  25 |   600/ 2983 batches | lr 0.31 | ms/batch 57.20 | loss  3.55 | ppl    34.73
| prune-epoch  25 |   800/ 2983 batches | lr 0.31 | ms/batch 57.23 | loss  3.60 | ppl    36.75
| prune-epoch  25 |  1000/ 2983 batches | lr 0.31 | ms/batch 57.04 | loss  3.65 | ppl    38.48
| prune-epoch  25 |  1200/ 2983 batches | lr 0.31 | ms/batch 57.05 | loss  3.67 | ppl    39.08
| prune-epoch  25 |  1400/ 2983 batches | lr 0.31 | ms/batch 57.05 | loss  3.65 | ppl    38.53
| prune-epoch  25 |  1600/ 2983 batches | lr 0.31 | ms/batch 57.05 | loss  3.72 | ppl    41.15
| prune-epoch  25 |  1800/ 2983 batches | lr 0.31 | ms/batch 57.04 | loss  3.67 | ppl    39.44
| prune-epoch  25 |  2000/ 2983 batches | lr 0.31 | ms/batch 57.03 | loss  3.68 | ppl    39.65
| prune-epoch  25 |  2200/ 2983 batches | lr 0.31 | ms/batch 57.04 | loss  3.57 | ppl    35.42
| prune-epoch  25 |  2400/ 2983 batches | lr 0.31 | ms/batch 57.04 | loss  3.59 | ppl    36.22
| prune-epoch  25 |  2600/ 2983 batches | lr 0.31 | ms/batch 57.05 | loss  3.62 | ppl    37.16
| prune-epoch  25 |  2800/ 2983 batches | lr 0.31 | ms/batch 57.04 | loss  3.56 | ppl    35.19
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  25 | time: 177.34s | valid loss  4.56 | valid ppl    95.45
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  26 |   200/ 2983 batches | lr 0.08 | ms/batch 59.08 | loss  3.75 | ppl    42.31
| prune-epoch  26 |   400/ 2983 batches | lr 0.08 | ms/batch 57.26 | loss  3.78 | ppl    43.88
| prune-epoch  26 |   600/ 2983 batches | lr 0.08 | ms/batch 57.26 | loss  3.63 | ppl    37.61
| prune-epoch  26 |   800/ 2983 batches | lr 0.08 | ms/batch 57.26 | loss  3.70 | ppl    40.50
| prune-epoch  26 |  1000/ 2983 batches | lr 0.08 | ms/batch 57.27 | loss  3.75 | ppl    42.31
| prune-epoch  26 |  1200/ 2983 batches | lr 0.08 | ms/batch 57.25 | loss  3.74 | ppl    42.02
| prune-epoch  26 |  1400/ 2983 batches | lr 0.08 | ms/batch 57.28 | loss  3.74 | ppl    42.04
| prune-epoch  26 |  1600/ 2983 batches | lr 0.08 | ms/batch 57.23 | loss  3.82 | ppl    45.46
| prune-epoch  26 |  1800/ 2983 batches | lr 0.08 | ms/batch 57.19 | loss  3.75 | ppl    42.33
| prune-epoch  26 |  2000/ 2983 batches | lr 0.08 | ms/batch 57.20 | loss  3.73 | ppl    41.64
| prune-epoch  26 |  2200/ 2983 batches | lr 0.08 | ms/batch 57.20 | loss  3.59 | ppl    36.36
| prune-epoch  26 |  2400/ 2983 batches | lr 0.08 | ms/batch 57.20 | loss  3.61 | ppl    36.93
| prune-epoch  26 |  2600/ 2983 batches | lr 0.08 | ms/batch 57.19 | loss  3.64 | ppl    38.24
| prune-epoch  26 |  2800/ 2983 batches | lr 0.08 | ms/batch 57.17 | loss  3.61 | ppl    37.12
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  26 | time: 177.71s | valid loss  4.55 | valid ppl    94.29
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  27 |   200/ 2983 batches | lr 0.08 | ms/batch 58.55 | loss  3.77 | ppl    43.39
| prune-epoch  27 |   400/ 2983 batches | lr 0.08 | ms/batch 56.60 | loss  3.81 | ppl    45.24
| prune-epoch  27 |   600/ 2983 batches | lr 0.08 | ms/batch 56.59 | loss  3.63 | ppl    37.87
| prune-epoch  27 |   800/ 2983 batches | lr 0.08 | ms/batch 56.61 | loss  3.70 | ppl    40.38
| prune-epoch  27 |  1000/ 2983 batches | lr 0.08 | ms/batch 56.60 | loss  3.71 | ppl    41.04
| prune-epoch  27 |  1200/ 2983 batches | lr 0.08 | ms/batch 56.62 | loss  3.71 | ppl    40.76
| prune-epoch  27 |  1400/ 2983 batches | lr 0.08 | ms/batch 56.59 | loss  3.73 | ppl    41.59
| prune-epoch  27 |  1600/ 2983 batches | lr 0.08 | ms/batch 56.61 | loss  3.80 | ppl    44.73
| prune-epoch  27 |  1800/ 2983 batches | lr 0.08 | ms/batch 56.58 | loss  3.72 | ppl    41.23
| prune-epoch  27 |  2000/ 2983 batches | lr 0.08 | ms/batch 56.59 | loss  3.70 | ppl    40.63
| prune-epoch  27 |  2200/ 2983 batches | lr 0.08 | ms/batch 56.60 | loss  3.58 | ppl    35.93
| prune-epoch  27 |  2400/ 2983 batches | lr 0.08 | ms/batch 56.61 | loss  3.62 | ppl    37.23
| prune-epoch  27 |  2600/ 2983 batches | lr 0.08 | ms/batch 56.60 | loss  3.67 | ppl    39.09
| prune-epoch  27 |  2800/ 2983 batches | lr 0.08 | ms/batch 56.59 | loss  3.64 | ppl    37.99
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  27 | time: 175.85s | valid loss  4.54 | valid ppl    93.97
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  28 |   200/ 2983 batches | lr 0.08 | ms/batch 59.20 | loss  3.76 | ppl    43.13
| prune-epoch  28 |   400/ 2983 batches | lr 0.08 | ms/batch 57.47 | loss  3.79 | ppl    44.25
| prune-epoch  28 |   600/ 2983 batches | lr 0.08 | ms/batch 57.33 | loss  3.61 | ppl    36.98
| prune-epoch  28 |   800/ 2983 batches | lr 0.08 | ms/batch 57.26 | loss  3.67 | ppl    39.33
| prune-epoch  28 |  1000/ 2983 batches | lr 0.08 | ms/batch 57.27 | loss  3.70 | ppl    40.49
| prune-epoch  28 |  1200/ 2983 batches | lr 0.08 | ms/batch 57.28 | loss  3.70 | ppl    40.46
| prune-epoch  28 |  1400/ 2983 batches | lr 0.08 | ms/batch 57.24 | loss  3.71 | ppl    41.06
| prune-epoch  28 |  1600/ 2983 batches | lr 0.08 | ms/batch 57.23 | loss  3.79 | ppl    44.20
| prune-epoch  28 |  1800/ 2983 batches | lr 0.08 | ms/batch 57.24 | loss  3.71 | ppl    40.97
| prune-epoch  28 |  2000/ 2983 batches | lr 0.08 | ms/batch 57.26 | loss  3.71 | ppl    40.80
| prune-epoch  28 |  2200/ 2983 batches | lr 0.08 | ms/batch 57.24 | loss  3.59 | ppl    36.41
| prune-epoch  28 |  2400/ 2983 batches | lr 0.08 | ms/batch 57.24 | loss  3.62 | ppl    37.41
| prune-epoch  28 |  2600/ 2983 batches | lr 0.08 | ms/batch 57.23 | loss  3.67 | ppl    39.24
| prune-epoch  28 |  2800/ 2983 batches | lr 0.08 | ms/batch 57.24 | loss  3.64 | ppl    38.11
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  28 | time: 177.86s | valid loss  4.54 | valid ppl    93.90
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  29 |   200/ 2983 batches | lr 0.08 | ms/batch 59.08 | loss  3.75 | ppl    42.66
| prune-epoch  29 |   400/ 2983 batches | lr 0.08 | ms/batch 57.09 | loss  3.78 | ppl    43.69
| prune-epoch  29 |   600/ 2983 batches | lr 0.08 | ms/batch 57.21 | loss  3.60 | ppl    36.59
| prune-epoch  29 |   800/ 2983 batches | lr 0.08 | ms/batch 57.31 | loss  3.68 | ppl    39.56
| prune-epoch  29 |  1000/ 2983 batches | lr 0.08 | ms/batch 57.41 | loss  3.70 | ppl    40.39
| prune-epoch  29 |  1200/ 2983 batches | lr 0.08 | ms/batch 57.44 | loss  3.69 | ppl    40.22
| prune-epoch  29 |  1400/ 2983 batches | lr 0.08 | ms/batch 57.48 | loss  3.72 | ppl    41.06
| prune-epoch  29 |  1600/ 2983 batches | lr 0.08 | ms/batch 57.46 | loss  3.78 | ppl    43.91
| prune-epoch  29 |  1800/ 2983 batches | lr 0.08 | ms/batch 57.45 | loss  3.71 | ppl    40.84
| prune-epoch  29 |  2000/ 2983 batches | lr 0.08 | ms/batch 57.31 | loss  3.71 | ppl    40.83
| prune-epoch  29 |  2200/ 2983 batches | lr 0.08 | ms/batch 57.30 | loss  3.60 | ppl    36.46
| prune-epoch  29 |  2400/ 2983 batches | lr 0.08 | ms/batch 57.23 | loss  3.62 | ppl    37.35
| prune-epoch  29 |  2600/ 2983 batches | lr 0.08 | ms/batch 57.19 | loss  3.67 | ppl    39.10
| prune-epoch  29 |  2800/ 2983 batches | lr 0.08 | ms/batch 57.16 | loss  3.63 | ppl    37.86
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  29 | time: 177.93s | valid loss  4.54 | valid ppl    93.89
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  30 |   200/ 2983 batches | lr 0.08 | ms/batch 59.04 | loss  3.75 | ppl    42.35
| prune-epoch  30 |   400/ 2983 batches | lr 0.08 | ms/batch 56.86 | loss  3.78 | ppl    43.61
| prune-epoch  30 |   600/ 2983 batches | lr 0.08 | ms/batch 56.87 | loss  3.60 | ppl    36.62
| prune-epoch  30 |   800/ 2983 batches | lr 0.08 | ms/batch 56.84 | loss  3.66 | ppl    38.84
| prune-epoch  30 |  1000/ 2983 batches | lr 0.08 | ms/batch 56.84 | loss  3.69 | ppl    40.20
| prune-epoch  30 |  1200/ 2983 batches | lr 0.08 | ms/batch 56.84 | loss  3.69 | ppl    40.14
| prune-epoch  30 |  1400/ 2983 batches | lr 0.08 | ms/batch 56.81 | loss  3.71 | ppl    40.89
| prune-epoch  30 |  1600/ 2983 batches | lr 0.08 | ms/batch 56.81 | loss  3.79 | ppl    44.05
| prune-epoch  30 |  1800/ 2983 batches | lr 0.08 | ms/batch 56.82 | loss  3.71 | ppl    40.78
| prune-epoch  30 |  2000/ 2983 batches | lr 0.08 | ms/batch 56.82 | loss  3.71 | ppl    40.80
| prune-epoch  30 |  2200/ 2983 batches | lr 0.08 | ms/batch 56.83 | loss  3.59 | ppl    36.15
| prune-epoch  30 |  2400/ 2983 batches | lr 0.08 | ms/batch 56.82 | loss  3.62 | ppl    37.47
| prune-epoch  30 |  2600/ 2983 batches | lr 0.08 | ms/batch 56.82 | loss  3.67 | ppl    39.21
| prune-epoch  30 |  2800/ 2983 batches | lr 0.08 | ms/batch 56.83 | loss  3.62 | ppl    37.50
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  30 | time: 176.62s | valid loss  4.54 | valid ppl    93.85
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  31 |   200/ 2983 batches | lr 0.08 | ms/batch 59.02 | loss  3.75 | ppl    42.55
| prune-epoch  31 |   400/ 2983 batches | lr 0.08 | ms/batch 57.06 | loss  3.77 | ppl    43.41
| prune-epoch  31 |   600/ 2983 batches | lr 0.08 | ms/batch 57.06 | loss  3.59 | ppl    36.38
| prune-epoch  31 |   800/ 2983 batches | lr 0.08 | ms/batch 57.06 | loss  3.66 | ppl    38.87
| prune-epoch  31 |  1000/ 2983 batches | lr 0.08 | ms/batch 57.06 | loss  3.70 | ppl    40.40
| prune-epoch  31 |  1200/ 2983 batches | lr 0.08 | ms/batch 57.07 | loss  3.69 | ppl    40.12
| prune-epoch  31 |  1400/ 2983 batches | lr 0.08 | ms/batch 57.06 | loss  3.71 | ppl    41.01
| prune-epoch  31 |  1600/ 2983 batches | lr 0.08 | ms/batch 57.05 | loss  3.78 | ppl    43.82
| prune-epoch  31 |  1800/ 2983 batches | lr 0.08 | ms/batch 57.05 | loss  3.70 | ppl    40.61
| prune-epoch  31 |  2000/ 2983 batches | lr 0.08 | ms/batch 57.06 | loss  3.70 | ppl    40.43
| prune-epoch  31 |  2200/ 2983 batches | lr 0.08 | ms/batch 57.06 | loss  3.59 | ppl    36.40
| prune-epoch  31 |  2400/ 2983 batches | lr 0.08 | ms/batch 57.07 | loss  3.62 | ppl    37.42
| prune-epoch  31 |  2600/ 2983 batches | lr 0.08 | ms/batch 57.06 | loss  3.67 | ppl    39.17
| prune-epoch  31 |  2800/ 2983 batches | lr 0.08 | ms/batch 57.06 | loss  3.63 | ppl    37.83
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  31 | time: 177.24s | valid loss  4.54 | valid ppl    93.73
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  32 |   200/ 2983 batches | lr 0.08 | ms/batch 58.98 | loss  3.75 | ppl    42.49
| prune-epoch  32 |   400/ 2983 batches | lr 0.08 | ms/batch 57.01 | loss  3.77 | ppl    43.47
| prune-epoch  32 |   600/ 2983 batches | lr 0.08 | ms/batch 57.02 | loss  3.60 | ppl    36.49
| prune-epoch  32 |   800/ 2983 batches | lr 0.08 | ms/batch 57.01 | loss  3.67 | ppl    39.15
| prune-epoch  32 |  1000/ 2983 batches | lr 0.08 | ms/batch 57.02 | loss  3.70 | ppl    40.34
| prune-epoch  32 |  1200/ 2983 batches | lr 0.08 | ms/batch 57.02 | loss  3.69 | ppl    40.20
| prune-epoch  32 |  1400/ 2983 batches | lr 0.08 | ms/batch 57.03 | loss  3.71 | ppl    40.90
| prune-epoch  32 |  1600/ 2983 batches | lr 0.08 | ms/batch 57.04 | loss  3.78 | ppl    43.75
| prune-epoch  32 |  1800/ 2983 batches | lr 0.08 | ms/batch 57.04 | loss  3.71 | ppl    40.69
| prune-epoch  32 |  2000/ 2983 batches | lr 0.08 | ms/batch 57.02 | loss  3.70 | ppl    40.40
| prune-epoch  32 |  2200/ 2983 batches | lr 0.08 | ms/batch 57.03 | loss  3.59 | ppl    36.20
| prune-epoch  32 |  2400/ 2983 batches | lr 0.08 | ms/batch 57.04 | loss  3.62 | ppl    37.31
| prune-epoch  32 |  2600/ 2983 batches | lr 0.08 | ms/batch 57.03 | loss  3.66 | ppl    38.90
| prune-epoch  32 |  2800/ 2983 batches | lr 0.08 | ms/batch 57.03 | loss  3.63 | ppl    37.85
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  32 | time: 177.14s | valid loss  4.54 | valid ppl    93.80
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  33 |   200/ 2983 batches | lr 0.08 | ms/batch 59.11 | loss  3.75 | ppl    42.58
| prune-epoch  33 |   400/ 2983 batches | lr 0.08 | ms/batch 57.20 | loss  3.77 | ppl    43.50
| prune-epoch  33 |   600/ 2983 batches | lr 0.08 | ms/batch 57.21 | loss  3.60 | ppl    36.62
| prune-epoch  33 |   800/ 2983 batches | lr 0.08 | ms/batch 57.21 | loss  3.67 | ppl    39.45
| prune-epoch  33 |  1000/ 2983 batches | lr 0.08 | ms/batch 57.21 | loss  3.70 | ppl    40.39
| prune-epoch  33 |  1200/ 2983 batches | lr 0.08 | ms/batch 57.20 | loss  3.69 | ppl    40.12
| prune-epoch  33 |  1400/ 2983 batches | lr 0.08 | ms/batch 57.20 | loss  3.70 | ppl    40.59
| prune-epoch  33 |  1600/ 2983 batches | lr 0.08 | ms/batch 57.19 | loss  3.78 | ppl    43.96
| prune-epoch  33 |  1800/ 2983 batches | lr 0.08 | ms/batch 57.19 | loss  3.70 | ppl    40.48
| prune-epoch  33 |  2000/ 2983 batches | lr 0.08 | ms/batch 57.21 | loss  3.70 | ppl    40.53
| prune-epoch  33 |  2200/ 2983 batches | lr 0.08 | ms/batch 57.15 | loss  3.59 | ppl    36.40
| prune-epoch  33 |  2400/ 2983 batches | lr 0.08 | ms/batch 57.19 | loss  3.62 | ppl    37.17
| prune-epoch  33 |  2600/ 2983 batches | lr 0.08 | ms/batch 57.21 | loss  3.66 | ppl    38.93
| prune-epoch  33 |  2800/ 2983 batches | lr 0.08 | ms/batch 57.17 | loss  3.63 | ppl    37.62
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  33 | time: 177.64s | valid loss  4.54 | valid ppl    93.77
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  34 |   200/ 2983 batches | lr 0.08 | ms/batch 58.59 | loss  3.74 | ppl    42.26
| prune-epoch  34 |   400/ 2983 batches | lr 0.08 | ms/batch 56.63 | loss  3.77 | ppl    43.53
| prune-epoch  34 |   600/ 2983 batches | lr 0.08 | ms/batch 56.70 | loss  3.60 | ppl    36.50
| prune-epoch  34 |   800/ 2983 batches | lr 0.08 | ms/batch 56.66 | loss  3.65 | ppl    38.58
| prune-epoch  34 |  1000/ 2983 batches | lr 0.08 | ms/batch 56.61 | loss  3.69 | ppl    40.18
| prune-epoch  34 |  1200/ 2983 batches | lr 0.08 | ms/batch 56.61 | loss  3.69 | ppl    40.00
| prune-epoch  34 |  1400/ 2983 batches | lr 0.08 | ms/batch 56.61 | loss  3.71 | ppl    40.78
| prune-epoch  34 |  1600/ 2983 batches | lr 0.08 | ms/batch 56.59 | loss  3.77 | ppl    43.26
| prune-epoch  34 |  1800/ 2983 batches | lr 0.08 | ms/batch 56.59 | loss  3.70 | ppl    40.34
| prune-epoch  34 |  2000/ 2983 batches | lr 0.08 | ms/batch 56.59 | loss  3.70 | ppl    40.63
| prune-epoch  34 |  2200/ 2983 batches | lr 0.08 | ms/batch 56.59 | loss  3.59 | ppl    36.21
| prune-epoch  34 |  2400/ 2983 batches | lr 0.08 | ms/batch 56.60 | loss  3.62 | ppl    37.18
| prune-epoch  34 |  2600/ 2983 batches | lr 0.08 | ms/batch 56.59 | loss  3.66 | ppl    38.90
| prune-epoch  34 |  2800/ 2983 batches | lr 0.08 | ms/batch 56.59 | loss  3.64 | ppl    37.91
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  34 | time: 175.91s | valid loss  4.54 | valid ppl    93.73
-----------------------------------------------------------------------------------------
required epochs  40 | actual epochs  65
pretrain epochs  12 | prune epochs  19 | retrain epochs  34
=========================================================================================
| End of training | test loss  4.50 | test ppl    89.71
=========================================================================================
