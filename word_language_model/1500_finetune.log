<class 'torch.Tensor'> torch.Size([33278, 1500])
<class 'torch.Tensor'> torch.Size([6000, 1500])
<class 'torch.Tensor'> torch.Size([6000, 1500])
<class 'torch.Tensor'> torch.Size([6000])
<class 'torch.Tensor'> torch.Size([6000])
<class 'torch.Tensor'> torch.Size([6000, 1500])
<class 'torch.Tensor'> torch.Size([6000, 1500])
<class 'torch.Tensor'> torch.Size([6000])
<class 'torch.Tensor'> torch.Size([6000])
<class 'torch.Tensor'> torch.Size([33278])
RNNModel(
  (drop): Dropout(p=0.65)
  (encoder): Embedding(33278, 1500)
  (rnn): LSTM(1500, 1500, num_layers=2, dropout=0.65)
  (decoder): Linear(in_features=1500, out_features=33278, bias=True)
)
Dropout(p=0.65)
Embedding(33278, 1500)
LSTM(1500, 1500, num_layers=2, dropout=0.65)
Linear(in_features=1500, out_features=33278, bias=True)
begin prun train
| prune-epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 60.22 | loss  4.01 | ppl    54.92
| prune-epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 57.34 | loss  4.07 | ppl    58.42
| prune-epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 57.44 | loss  3.88 | ppl    48.54
| prune-epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 57.66 | loss  3.94 | ppl    51.48
| prune-epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.67 | loss  3.99 | ppl    54.08
| prune-epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.63 | loss  4.01 | ppl    55.04
| prune-epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.68 | loss  4.04 | ppl    56.56
| prune-epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.79 | loss  4.12 | ppl    61.60
| prune-epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.84 | loss  4.03 | ppl    55.98
| prune-epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 57.95 | loss  4.06 | ppl    58.06
| prune-epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.01 | loss  3.94 | ppl    51.41
| prune-epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.10 | loss  3.98 | ppl    53.26
| prune-epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.13 | loss  4.01 | ppl    55.33
| prune-epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.14 | loss  3.98 | ppl    53.40
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.3993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.3993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.3993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.3993333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch   1 | time: 179.97s | valid loss  4.61 | valid ppl   100.72
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch 60.66 | loss  3.99 | ppl    53.97
| prune-epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch 58.14 | loss  4.02 | ppl    55.62
| prune-epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch 58.12 | loss  3.85 | ppl    46.89
| prune-epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch 58.01 | loss  3.89 | ppl    48.95
| prune-epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.04 | loss  3.95 | ppl    51.86
| prune-epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.09 | loss  3.96 | ppl    52.51
| prune-epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.11 | loss  3.98 | ppl    53.54
| prune-epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.18 | loss  4.06 | ppl    57.96
| prune-epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.21 | loss  3.96 | ppl    52.55
| prune-epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.13 | loss  4.00 | ppl    54.75
| prune-epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.21 | loss  3.88 | ppl    48.44
| prune-epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.38 | loss  3.91 | ppl    49.96
| prune-epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.57 | loss  3.95 | ppl    52.13
| prune-epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.56 | loss  3.92 | ppl    50.22
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.3993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.3993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.3993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.4  actual sp:  0.3993333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch   2 | time: 181.85s | valid loss  4.61 | valid ppl   100.72
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 61.74 | loss  3.95 | ppl    52.14
| prune-epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch 58.81 | loss  3.98 | ppl    53.54
| prune-epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 58.89 | loss  3.80 | ppl    44.78
| prune-epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 58.97 | loss  3.86 | ppl    47.33
| prune-epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.73 | loss  3.90 | ppl    49.36
| prune-epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.85 | loss  3.91 | ppl    49.95
| prune-epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.93 | loss  3.93 | ppl    51.10
| prune-epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.92 | loss  4.02 | ppl    55.54
| prune-epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.89 | loss  3.92 | ppl    50.23
| prune-epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 59.08 | loss  3.96 | ppl    52.26
| prune-epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.91 | loss  3.83 | ppl    46.02
| prune-epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.91 | loss  3.86 | ppl    47.31
| prune-epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.86 | loss  3.90 | ppl    49.21
| prune-epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.82 | loss  3.86 | ppl    47.57
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch   3 | time: 184.21s | valid loss  4.61 | valid ppl   100.94
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   4 |   200/ 2983 batches | lr 20.00 | ms/batch 61.62 | loss  3.90 | ppl    49.20
| prune-epoch   4 |   400/ 2983 batches | lr 20.00 | ms/batch 58.66 | loss  3.92 | ppl    50.64
| prune-epoch   4 |   600/ 2983 batches | lr 20.00 | ms/batch 58.73 | loss  3.75 | ppl    42.55
| prune-epoch   4 |   800/ 2983 batches | lr 20.00 | ms/batch 58.71 | loss  3.80 | ppl    44.91
| prune-epoch   4 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.72 | loss  3.85 | ppl    46.86
| prune-epoch   4 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.70 | loss  3.86 | ppl    47.57
| prune-epoch   4 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.78 | loss  3.88 | ppl    48.27
| prune-epoch   4 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.67 | loss  3.96 | ppl    52.50
| prune-epoch   4 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.68 | loss  3.87 | ppl    47.81
| prune-epoch   4 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.75 | loss  3.91 | ppl    49.81
| prune-epoch   4 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.77 | loss  3.78 | ppl    43.71
| prune-epoch   4 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.73 | loss  3.81 | ppl    45.21
| prune-epoch   4 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.82 | loss  3.85 | ppl    46.86
| prune-epoch   4 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.74 | loss  3.82 | ppl    45.41
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.5  actual sp:  0.4993333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch   4 | time: 183.93s | valid loss  4.65 | valid ppl   104.35
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   5 |   200/ 2983 batches | lr 20.00 | ms/batch 61.44 | loss  3.87 | ppl    48.18
| prune-epoch   5 |   400/ 2983 batches | lr 20.00 | ms/batch 58.47 | loss  3.90 | ppl    49.37
| prune-epoch   5 |   600/ 2983 batches | lr 20.00 | ms/batch 58.65 | loss  3.72 | ppl    41.44
| prune-epoch   5 |   800/ 2983 batches | lr 20.00 | ms/batch 58.43 | loss  3.78 | ppl    43.82
| prune-epoch   5 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.50 | loss  3.82 | ppl    45.56
| prune-epoch   5 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.67 | loss  3.83 | ppl    45.98
| prune-epoch   5 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.47 | loss  3.85 | ppl    46.94
| prune-epoch   5 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.53 | loss  3.92 | ppl    50.56
| prune-epoch   5 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.50 | loss  3.83 | ppl    45.96
| prune-epoch   5 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.57 | loss  3.87 | ppl    48.07
| prune-epoch   5 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.47 | loss  3.74 | ppl    42.31
| prune-epoch   5 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.54 | loss  3.76 | ppl    43.13
| prune-epoch   5 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.75 | loss  3.81 | ppl    45.03
| prune-epoch   5 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.52 | loss  3.77 | ppl    43.45
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.6  actual sp:  0.5993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.6  actual sp:  0.5993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.6  actual sp:  0.5993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.6  actual sp:  0.5993333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch   5 | time: 183.07s | valid loss  4.65 | valid ppl   104.62
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   6 |   200/ 2983 batches | lr 20.00 | ms/batch 61.42 | loss  3.82 | ppl    45.58
| prune-epoch   6 |   400/ 2983 batches | lr 20.00 | ms/batch 58.71 | loss  3.85 | ppl    46.95
| prune-epoch   6 |   600/ 2983 batches | lr 20.00 | ms/batch 58.71 | loss  3.67 | ppl    39.26
| prune-epoch   6 |   800/ 2983 batches | lr 20.00 | ms/batch 58.80 | loss  3.72 | ppl    41.38
| prune-epoch   6 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.79 | loss  3.77 | ppl    43.33
| prune-epoch   6 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.76 | loss  3.78 | ppl    43.82
| prune-epoch   6 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.75 | loss  3.80 | ppl    44.54
| prune-epoch   6 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.91 | loss  3.88 | ppl    48.52
| prune-epoch   6 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.83 | loss  3.79 | ppl    44.34
| prune-epoch   6 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.75 | loss  3.82 | ppl    45.67
| prune-epoch   6 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.78 | loss  3.70 | ppl    40.53
| prune-epoch   6 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.81 | loss  3.73 | ppl    41.73
| prune-epoch   6 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.95 | loss  3.77 | ppl    43.28
| prune-epoch   6 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.70 | loss  3.73 | ppl    41.89
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.6  actual sp:  0.5993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.6  actual sp:  0.5993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.6  actual sp:  0.5993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.6  actual sp:  0.5993333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch   6 | time: 183.63s | valid loss  4.66 | valid ppl   105.46
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   7 |   200/ 2983 batches | lr 20.00 | ms/batch 61.43 | loss  3.83 | ppl    46.09
| prune-epoch   7 |   400/ 2983 batches | lr 20.00 | ms/batch 58.91 | loss  3.86 | ppl    47.30
| prune-epoch   7 |   600/ 2983 batches | lr 20.00 | ms/batch 58.62 | loss  3.68 | ppl    39.64
| prune-epoch   7 |   800/ 2983 batches | lr 20.00 | ms/batch 58.63 | loss  3.73 | ppl    41.66
| prune-epoch   7 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.64 | loss  3.77 | ppl    43.21
| prune-epoch   7 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.66 | loss  3.78 | ppl    43.70
| prune-epoch   7 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.61 | loss  3.80 | ppl    44.76
| prune-epoch   7 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.63 | loss  3.88 | ppl    48.28
| prune-epoch   7 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.69 | loss  3.78 | ppl    43.86
| prune-epoch   7 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.69 | loss  3.82 | ppl    45.62
| prune-epoch   7 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.68 | loss  3.70 | ppl    40.34
| prune-epoch   7 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.78 | loss  3.72 | ppl    41.41
| prune-epoch   7 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.72 | loss  3.76 | ppl    43.11
| prune-epoch   7 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.64 | loss  3.74 | ppl    41.99
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7  actual sp:  0.6993333333333334
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7  actual sp:  0.6993333333333334
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7  actual sp:  0.6993333333333334
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7  actual sp:  0.6993333333333334
-----------------------------------------------------------------------------------------
| end of prune epoch   7 | time: 182.88s | valid loss  4.65 | valid ppl   104.33
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   8 |   200/ 2983 batches | lr 20.00 | ms/batch 61.23 | loss  3.77 | ppl    43.28
| prune-epoch   8 |   400/ 2983 batches | lr 20.00 | ms/batch 58.69 | loss  3.80 | ppl    44.66
| prune-epoch   8 |   600/ 2983 batches | lr 20.00 | ms/batch 58.76 | loss  3.63 | ppl    37.69
| prune-epoch   8 |   800/ 2983 batches | lr 20.00 | ms/batch 58.71 | loss  3.68 | ppl    39.58
| prune-epoch   8 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.63 | loss  3.73 | ppl    41.53
| prune-epoch   8 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.76 | loss  3.73 | ppl    41.88
| prune-epoch   8 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.77 | loss  3.76 | ppl    42.86
| prune-epoch   8 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.75 | loss  3.83 | ppl    46.08
| prune-epoch   8 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.78 | loss  3.75 | ppl    42.52
| prune-epoch   8 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.68 | loss  3.78 | ppl    43.71
| prune-epoch   8 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.76 | loss  3.66 | ppl    38.75
| prune-epoch   8 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.74 | loss  3.68 | ppl    39.70
| prune-epoch   8 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.70 | loss  3.72 | ppl    41.08
| prune-epoch   8 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.80 | loss  3.68 | ppl    39.78
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7  actual sp:  0.6993333333333334
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7  actual sp:  0.6993333333333334
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7  actual sp:  0.6993333333333334
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7  actual sp:  0.6993333333333334
-----------------------------------------------------------------------------------------
| end of prune epoch   8 | time: 182.87s | valid loss  4.66 | valid ppl   105.19
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   9 |   200/ 2983 batches | lr 20.00 | ms/batch 60.69 | loss  3.86 | ppl    47.61
| prune-epoch   9 |   400/ 2983 batches | lr 20.00 | ms/batch 58.14 | loss  3.87 | ppl    48.11
| prune-epoch   9 |   600/ 2983 batches | lr 20.00 | ms/batch 58.15 | loss  3.70 | ppl    40.57
| prune-epoch   9 |   800/ 2983 batches | lr 20.00 | ms/batch 58.10 | loss  3.74 | ppl    42.10
| prune-epoch   9 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.12 | loss  3.79 | ppl    44.35
| prune-epoch   9 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.10 | loss  3.80 | ppl    44.55
| prune-epoch   9 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.28 | loss  3.82 | ppl    45.40
| prune-epoch   9 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.38 | loss  3.89 | ppl    49.07
| prune-epoch   9 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.13 | loss  3.80 | ppl    44.72
| prune-epoch   9 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.08 | loss  3.83 | ppl    46.11
| prune-epoch   9 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.09 | loss  3.71 | ppl    40.76
| prune-epoch   9 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.11 | loss  3.73 | ppl    41.61
| prune-epoch   9 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.12 | loss  3.77 | ppl    43.33
| prune-epoch   9 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.14 | loss  3.74 | ppl    42.10
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch   9 | time: 181.05s | valid loss  4.66 | valid ppl   105.16
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  10 |   200/ 2983 batches | lr 20.00 | ms/batch 60.95 | loss  3.78 | ppl    44.03
| prune-epoch  10 |   400/ 2983 batches | lr 20.00 | ms/batch 58.69 | loss  3.81 | ppl    45.01
| prune-epoch  10 |   600/ 2983 batches | lr 20.00 | ms/batch 58.75 | loss  3.64 | ppl    38.08
| prune-epoch  10 |   800/ 2983 batches | lr 20.00 | ms/batch 58.64 | loss  3.69 | ppl    40.02
| prune-epoch  10 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.98 | loss  3.74 | ppl    42.25
| prune-epoch  10 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.73 | loss  3.75 | ppl    42.43
| prune-epoch  10 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.63 | loss  3.76 | ppl    43.02
| prune-epoch  10 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.75 | loss  3.85 | ppl    46.77
| prune-epoch  10 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.78 | loss  3.76 | ppl    42.81
| prune-epoch  10 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.60 | loss  3.79 | ppl    44.14
| prune-epoch  10 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.67 | loss  3.67 | ppl    39.15
| prune-epoch  10 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.69 | loss  3.69 | ppl    40.08
| prune-epoch  10 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.64 | loss  3.73 | ppl    41.63
| prune-epoch  10 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.60 | loss  3.70 | ppl    40.53
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.7999999999999999  actual sp:  0.7993333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch  10 | time: 182.58s | valid loss  4.66 | valid ppl   105.88
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  11 |   200/ 2983 batches | lr 20.00 | ms/batch 60.80 | loss  3.85 | ppl    46.99
| prune-epoch  11 |   400/ 2983 batches | lr 20.00 | ms/batch 58.57 | loss  3.87 | ppl    47.97
| prune-epoch  11 |   600/ 2983 batches | lr 20.00 | ms/batch 58.49 | loss  3.70 | ppl    40.48
| prune-epoch  11 |   800/ 2983 batches | lr 20.00 | ms/batch 58.49 | loss  3.75 | ppl    42.33
| prune-epoch  11 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.56 | loss  3.79 | ppl    44.34
| prune-epoch  11 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.46 | loss  3.80 | ppl    44.63
| prune-epoch  11 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.48 | loss  3.81 | ppl    45.29
| prune-epoch  11 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.47 | loss  3.89 | ppl    48.84
| prune-epoch  11 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.47 | loss  3.80 | ppl    44.80
| prune-epoch  11 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.47 | loss  3.84 | ppl    46.46
| prune-epoch  11 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.54 | loss  3.71 | ppl    40.97
| prune-epoch  11 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.55 | loss  3.74 | ppl    42.13
| prune-epoch  11 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.48 | loss  3.77 | ppl    43.42
| prune-epoch  11 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.45 | loss  3.74 | ppl    42.22
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch  11 | time: 181.87s | valid loss  4.67 | valid ppl   106.94
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  12 |   200/ 2983 batches | lr 20.00 | ms/batch 60.67 | loss  3.79 | ppl    44.14
| prune-epoch  12 |   400/ 2983 batches | lr 20.00 | ms/batch 58.26 | loss  3.81 | ppl    45.13
| prune-epoch  12 |   600/ 2983 batches | lr 20.00 | ms/batch 58.28 | loss  3.64 | ppl    38.10
| prune-epoch  12 |   800/ 2983 batches | lr 20.00 | ms/batch 58.29 | loss  3.70 | ppl    40.30
| prune-epoch  12 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.48 | loss  3.75 | ppl    42.45
| prune-epoch  12 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.38 | loss  3.75 | ppl    42.69
| prune-epoch  12 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.27 | loss  3.77 | ppl    43.56
| prune-epoch  12 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.26 | loss  3.86 | ppl    47.36
| prune-epoch  12 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.28 | loss  3.77 | ppl    43.24
| prune-epoch  12 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.29 | loss  3.80 | ppl    44.70
| prune-epoch  12 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.23 | loss  3.67 | ppl    39.29
| prune-epoch  12 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.22 | loss  3.69 | ppl    40.19
| prune-epoch  12 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.26 | loss  3.74 | ppl    42.12
| prune-epoch  12 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.19 | loss  3.71 | ppl    40.99
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.85  actual sp:  0.8493333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch  12 | time: 181.31s | valid loss  4.68 | valid ppl   107.49
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  13 |   200/ 2983 batches | lr 20.00 | ms/batch 61.24 | loss  4.07 | ppl    58.62
| prune-epoch  13 |   400/ 2983 batches | lr 20.00 | ms/batch 58.41 | loss  4.07 | ppl    58.57
| prune-epoch  13 |   600/ 2983 batches | lr 20.00 | ms/batch 58.37 | loss  3.90 | ppl    49.48
| prune-epoch  13 |   800/ 2983 batches | lr 20.00 | ms/batch 58.40 | loss  3.94 | ppl    51.49
| prune-epoch  13 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.30 | loss  3.99 | ppl    54.01
| prune-epoch  13 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.42 | loss  4.00 | ppl    54.35
| prune-epoch  13 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.37 | loss  4.01 | ppl    55.27
| prune-epoch  13 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.33 | loss  4.09 | ppl    59.48
| prune-epoch  13 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.36 | loss  3.99 | ppl    54.18
| prune-epoch  13 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.40 | loss  4.03 | ppl    56.39
| prune-epoch  13 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.55 | loss  3.91 | ppl    49.71
| prune-epoch  13 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.39 | loss  3.93 | ppl    51.07
| prune-epoch  13 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.43 | loss  3.96 | ppl    52.64
| prune-epoch  13 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.46 | loss  3.94 | ppl    51.18
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of prune epoch  13 | time: 181.62s | valid loss  4.65 | valid ppl   104.87
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 60.39 | loss  3.98 | ppl    53.74
| prune-epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 58.38 | loss  4.00 | ppl    54.79
| prune-epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 58.34 | loss  3.83 | ppl    46.29
| prune-epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 58.39 | loss  3.89 | ppl    48.82
| prune-epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.37 | loss  3.93 | ppl    50.96
| prune-epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.34 | loss  3.94 | ppl    51.67
| prune-epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.43 | loss  3.96 | ppl    52.52
| prune-epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.46 | loss  4.04 | ppl    56.66
| prune-epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.52 | loss  3.95 | ppl    51.77
| prune-epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.30 | loss  3.99 | ppl    53.82
| prune-epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.37 | loss  3.86 | ppl    47.63
| prune-epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.35 | loss  3.89 | ppl    48.70
| prune-epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.30 | loss  3.93 | ppl    50.73
| prune-epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.32 | loss  3.90 | ppl    49.59
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch   1 | time: 181.39s | valid loss  4.66 | valid ppl   105.95
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch 60.47 | loss  3.94 | ppl    51.57
| prune-epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch 58.57 | loss  3.97 | ppl    52.83
| prune-epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch 58.41 | loss  3.80 | ppl    44.79
| prune-epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch 58.45 | loss  3.85 | ppl    47.03
| prune-epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.43 | loss  3.90 | ppl    49.37
| prune-epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.48 | loss  3.91 | ppl    49.98
| prune-epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.51 | loss  3.93 | ppl    50.83
| prune-epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.38 | loss  4.00 | ppl    54.73
| prune-epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.44 | loss  3.92 | ppl    50.22
| prune-epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.45 | loss  3.96 | ppl    52.26
| prune-epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.45 | loss  3.83 | ppl    46.17
| prune-epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.44 | loss  3.86 | ppl    47.29
| prune-epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.47 | loss  3.90 | ppl    49.36
| prune-epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.53 | loss  3.87 | ppl    48.04
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch   2 | time: 181.65s | valid loss  4.66 | valid ppl   105.58
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 59.88 | loss  3.92 | ppl    50.25
| prune-epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch 58.00 | loss  3.94 | ppl    51.61
| prune-epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 57.98 | loss  3.78 | ppl    43.69
| prune-epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 58.29 | loss  3.82 | ppl    45.64
| prune-epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 57.98 | loss  3.87 | ppl    48.13
| prune-epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 57.90 | loss  3.88 | ppl    48.42
| prune-epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 57.99 | loss  3.91 | ppl    49.68
| prune-epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 57.96 | loss  3.98 | ppl    53.27
| prune-epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 57.96 | loss  3.88 | ppl    48.65
| prune-epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.00 | loss  3.93 | ppl    51.16
| prune-epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.02 | loss  3.81 | ppl    45.28
| prune-epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 57.95 | loss  3.83 | ppl    45.97
| prune-epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.00 | loss  3.87 | ppl    48.00
| prune-epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 57.99 | loss  3.85 | ppl    46.93
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch   3 | time: 180.26s | valid loss  4.68 | valid ppl   107.25
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   4 |   200/ 2983 batches | lr 20.00 | ms/batch 60.61 | loss  3.93 | ppl    50.77
| prune-epoch   4 |   400/ 2983 batches | lr 20.00 | ms/batch 58.53 | loss  3.95 | ppl    51.97
| prune-epoch   4 |   600/ 2983 batches | lr 20.00 | ms/batch 58.56 | loss  3.78 | ppl    43.90
| prune-epoch   4 |   800/ 2983 batches | lr 20.00 | ms/batch 58.48 | loss  3.84 | ppl    46.43
| prune-epoch   4 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.57 | loss  3.88 | ppl    48.45
| prune-epoch   4 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.56 | loss  3.89 | ppl    49.03
| prune-epoch   4 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.56 | loss  3.92 | ppl    50.16
| prune-epoch   4 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.55 | loss  3.99 | ppl    54.02
| prune-epoch   4 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.56 | loss  3.90 | ppl    49.33
| prune-epoch   4 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.50 | loss  3.94 | ppl    51.19
| prune-epoch   4 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.59 | loss  3.82 | ppl    45.67
| prune-epoch   4 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.47 | loss  3.84 | ppl    46.68
| prune-epoch   4 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.61 | loss  3.88 | ppl    48.58
| prune-epoch   4 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.51 | loss  3.86 | ppl    47.34
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch   4 | time: 181.91s | valid loss  4.67 | valid ppl   106.24
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   5 |   200/ 2983 batches | lr 20.00 | ms/batch 60.30 | loss  3.90 | ppl    49.45
| prune-epoch   5 |   400/ 2983 batches | lr 20.00 | ms/batch 58.41 | loss  3.93 | ppl    50.88
| prune-epoch   5 |   600/ 2983 batches | lr 20.00 | ms/batch 58.40 | loss  3.76 | ppl    43.14
| prune-epoch   5 |   800/ 2983 batches | lr 20.00 | ms/batch 58.39 | loss  3.81 | ppl    45.24
| prune-epoch   5 |  1000/ 2983 batches | lr 20.00 | ms/batch 58.36 | loss  3.86 | ppl    47.62
| prune-epoch   5 |  1200/ 2983 batches | lr 20.00 | ms/batch 58.35 | loss  3.87 | ppl    47.90
| prune-epoch   5 |  1400/ 2983 batches | lr 20.00 | ms/batch 58.43 | loss  3.89 | ppl    48.99
| prune-epoch   5 |  1600/ 2983 batches | lr 20.00 | ms/batch 58.35 | loss  3.97 | ppl    52.73
| prune-epoch   5 |  1800/ 2983 batches | lr 20.00 | ms/batch 58.30 | loss  3.88 | ppl    48.59
| prune-epoch   5 |  2000/ 2983 batches | lr 20.00 | ms/batch 58.35 | loss  3.93 | ppl    50.71
| prune-epoch   5 |  2200/ 2983 batches | lr 20.00 | ms/batch 58.42 | loss  3.80 | ppl    44.56
| prune-epoch   5 |  2400/ 2983 batches | lr 20.00 | ms/batch 58.37 | loss  3.82 | ppl    45.59
| prune-epoch   5 |  2600/ 2983 batches | lr 20.00 | ms/batch 58.49 | loss  3.86 | ppl    47.38
| prune-epoch   5 |  2800/ 2983 batches | lr 20.00 | ms/batch 58.63 | loss  3.84 | ppl    46.53
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch   5 | time: 181.47s | valid loss  4.68 | valid ppl   107.48
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   6 |   200/ 2983 batches | lr 5.00 | ms/batch 60.19 | loss  3.89 | ppl    48.87
| prune-epoch   6 |   400/ 2983 batches | lr 5.00 | ms/batch 58.33 | loss  3.89 | ppl    48.76
| prune-epoch   6 |   600/ 2983 batches | lr 5.00 | ms/batch 58.27 | loss  3.71 | ppl    41.01
| prune-epoch   6 |   800/ 2983 batches | lr 5.00 | ms/batch 58.15 | loss  3.76 | ppl    42.82
| prune-epoch   6 |  1000/ 2983 batches | lr 5.00 | ms/batch 58.21 | loss  3.79 | ppl    44.16
| prune-epoch   6 |  1200/ 2983 batches | lr 5.00 | ms/batch 58.32 | loss  3.78 | ppl    44.00
| prune-epoch   6 |  1400/ 2983 batches | lr 5.00 | ms/batch 58.33 | loss  3.80 | ppl    44.61
| prune-epoch   6 |  1600/ 2983 batches | lr 5.00 | ms/batch 58.19 | loss  3.86 | ppl    47.43
| prune-epoch   6 |  1800/ 2983 batches | lr 5.00 | ms/batch 58.21 | loss  3.77 | ppl    43.44
| prune-epoch   6 |  2000/ 2983 batches | lr 5.00 | ms/batch 58.18 | loss  3.82 | ppl    45.42
| prune-epoch   6 |  2200/ 2983 batches | lr 5.00 | ms/batch 58.20 | loss  3.68 | ppl    39.59
| prune-epoch   6 |  2400/ 2983 batches | lr 5.00 | ms/batch 58.18 | loss  3.69 | ppl    39.99
| prune-epoch   6 |  2600/ 2983 batches | lr 5.00 | ms/batch 58.41 | loss  3.71 | ppl    41.03
| prune-epoch   6 |  2800/ 2983 batches | lr 5.00 | ms/batch 58.33 | loss  3.69 | ppl    40.11
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch   6 | time: 181.04s | valid loss  4.62 | valid ppl   101.88
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   7 |   200/ 2983 batches | lr 5.00 | ms/batch 60.63 | loss  3.81 | ppl    45.00
| prune-epoch   7 |   400/ 2983 batches | lr 5.00 | ms/batch 58.40 | loss  3.83 | ppl    45.89
| prune-epoch   7 |   600/ 2983 batches | lr 5.00 | ms/batch 58.44 | loss  3.66 | ppl    38.83
| prune-epoch   7 |   800/ 2983 batches | lr 5.00 | ms/batch 58.47 | loss  3.70 | ppl    40.29
| prune-epoch   7 |  1000/ 2983 batches | lr 5.00 | ms/batch 58.44 | loss  3.75 | ppl    42.60
| prune-epoch   7 |  1200/ 2983 batches | lr 5.00 | ms/batch 58.40 | loss  3.75 | ppl    42.57
| prune-epoch   7 |  1400/ 2983 batches | lr 5.00 | ms/batch 58.38 | loss  3.76 | ppl    43.07
| prune-epoch   7 |  1600/ 2983 batches | lr 5.00 | ms/batch 58.40 | loss  3.83 | ppl    45.94
| prune-epoch   7 |  1800/ 2983 batches | lr 5.00 | ms/batch 58.41 | loss  3.75 | ppl    42.38
| prune-epoch   7 |  2000/ 2983 batches | lr 5.00 | ms/batch 58.43 | loss  3.78 | ppl    44.03
| prune-epoch   7 |  2200/ 2983 batches | lr 5.00 | ms/batch 58.43 | loss  3.65 | ppl    38.36
| prune-epoch   7 |  2400/ 2983 batches | lr 5.00 | ms/batch 58.44 | loss  3.67 | ppl    39.12
| prune-epoch   7 |  2600/ 2983 batches | lr 5.00 | ms/batch 58.40 | loss  3.69 | ppl    39.99
| prune-epoch   7 |  2800/ 2983 batches | lr 5.00 | ms/batch 58.37 | loss  3.67 | ppl    39.42
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch   7 | time: 181.56s | valid loss  4.62 | valid ppl   101.89
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   8 |   200/ 2983 batches | lr 5.00 | ms/batch 60.51 | loss  3.78 | ppl    43.94
| prune-epoch   8 |   400/ 2983 batches | lr 5.00 | ms/batch 58.45 | loss  3.80 | ppl    44.78
| prune-epoch   8 |   600/ 2983 batches | lr 5.00 | ms/batch 58.42 | loss  3.64 | ppl    37.96
| prune-epoch   8 |   800/ 2983 batches | lr 5.00 | ms/batch 58.46 | loss  3.68 | ppl    39.60
| prune-epoch   8 |  1000/ 2983 batches | lr 5.00 | ms/batch 58.38 | loss  3.73 | ppl    41.82
| prune-epoch   8 |  1200/ 2983 batches | lr 5.00 | ms/batch 58.36 | loss  3.73 | ppl    41.72
| prune-epoch   8 |  1400/ 2983 batches | lr 5.00 | ms/batch 58.40 | loss  3.74 | ppl    42.14
| prune-epoch   8 |  1600/ 2983 batches | lr 5.00 | ms/batch 58.48 | loss  3.81 | ppl    45.09
| prune-epoch   8 |  1800/ 2983 batches | lr 5.00 | ms/batch 58.70 | loss  3.73 | ppl    41.62
| prune-epoch   8 |  2000/ 2983 batches | lr 5.00 | ms/batch 58.44 | loss  3.77 | ppl    43.22
| prune-epoch   8 |  2200/ 2983 batches | lr 5.00 | ms/batch 58.39 | loss  3.63 | ppl    37.77
| prune-epoch   8 |  2400/ 2983 batches | lr 5.00 | ms/batch 58.46 | loss  3.64 | ppl    38.27
| prune-epoch   8 |  2600/ 2983 batches | lr 5.00 | ms/batch 58.48 | loss  3.68 | ppl    39.79
| prune-epoch   8 |  2800/ 2983 batches | lr 5.00 | ms/batch 58.59 | loss  3.66 | ppl    39.02
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch   8 | time: 181.65s | valid loss  4.63 | valid ppl   102.44
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch   9 |   200/ 2983 batches | lr 1.25 | ms/batch 60.42 | loss  3.80 | ppl    44.74
| prune-epoch   9 |   400/ 2983 batches | lr 1.25 | ms/batch 58.43 | loss  3.83 | ppl    46.10
| prune-epoch   9 |   600/ 2983 batches | lr 1.25 | ms/batch 58.51 | loss  3.67 | ppl    39.34
| prune-epoch   9 |   800/ 2983 batches | lr 1.25 | ms/batch 58.53 | loss  3.70 | ppl    40.29
| prune-epoch   9 |  1000/ 2983 batches | lr 1.25 | ms/batch 58.53 | loss  3.74 | ppl    42.08
| prune-epoch   9 |  1200/ 2983 batches | lr 1.25 | ms/batch 58.52 | loss  3.75 | ppl    42.60
| prune-epoch   9 |  1400/ 2983 batches | lr 1.25 | ms/batch 58.62 | loss  3.74 | ppl    41.99
| prune-epoch   9 |  1600/ 2983 batches | lr 1.25 | ms/batch 58.55 | loss  3.81 | ppl    45.27
| prune-epoch   9 |  1800/ 2983 batches | lr 1.25 | ms/batch 58.49 | loss  3.73 | ppl    41.48
| prune-epoch   9 |  2000/ 2983 batches | lr 1.25 | ms/batch 58.49 | loss  3.80 | ppl    44.73
| prune-epoch   9 |  2200/ 2983 batches | lr 1.25 | ms/batch 58.51 | loss  3.64 | ppl    38.13
| prune-epoch   9 |  2400/ 2983 batches | lr 1.25 | ms/batch 58.43 | loss  3.66 | ppl    38.87
| prune-epoch   9 |  2600/ 2983 batches | lr 1.25 | ms/batch 58.52 | loss  3.67 | ppl    39.31
| prune-epoch   9 |  2800/ 2983 batches | lr 1.25 | ms/batch 58.47 | loss  3.65 | ppl    38.28
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch   9 | time: 181.76s | valid loss  4.58 | valid ppl    97.89
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  10 |   200/ 2983 batches | lr 1.25 | ms/batch 59.95 | loss  3.78 | ppl    43.91
| prune-epoch  10 |   400/ 2983 batches | lr 1.25 | ms/batch 58.07 | loss  3.80 | ppl    44.89
| prune-epoch  10 |   600/ 2983 batches | lr 1.25 | ms/batch 58.01 | loss  3.65 | ppl    38.28
| prune-epoch  10 |   800/ 2983 batches | lr 1.25 | ms/batch 57.99 | loss  3.67 | ppl    39.30
| prune-epoch  10 |  1000/ 2983 batches | lr 1.25 | ms/batch 57.97 | loss  3.72 | ppl    41.27
| prune-epoch  10 |  1200/ 2983 batches | lr 1.25 | ms/batch 58.31 | loss  3.74 | ppl    42.15
| prune-epoch  10 |  1400/ 2983 batches | lr 1.25 | ms/batch 58.15 | loss  3.72 | ppl    41.39
| prune-epoch  10 |  1600/ 2983 batches | lr 1.25 | ms/batch 58.30 | loss  3.81 | ppl    44.95
| prune-epoch  10 |  1800/ 2983 batches | lr 1.25 | ms/batch 58.29 | loss  3.71 | ppl    40.98
| prune-epoch  10 |  2000/ 2983 batches | lr 1.25 | ms/batch 58.20 | loss  3.79 | ppl    44.45
| prune-epoch  10 |  2200/ 2983 batches | lr 1.25 | ms/batch 57.97 | loss  3.63 | ppl    37.55
| prune-epoch  10 |  2400/ 2983 batches | lr 1.25 | ms/batch 57.97 | loss  3.65 | ppl    38.59
| prune-epoch  10 |  2600/ 2983 batches | lr 1.25 | ms/batch 58.00 | loss  3.67 | ppl    39.10
| prune-epoch  10 |  2800/ 2983 batches | lr 1.25 | ms/batch 58.14 | loss  3.64 | ppl    38.21
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  10 | time: 180.56s | valid loss  4.58 | valid ppl    97.34
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  11 |   200/ 2983 batches | lr 1.25 | ms/batch 61.17 | loss  3.76 | ppl    43.14
| prune-epoch  11 |   400/ 2983 batches | lr 1.25 | ms/batch 58.62 | loss  3.80 | ppl    44.59
| prune-epoch  11 |   600/ 2983 batches | lr 1.25 | ms/batch 58.51 | loss  3.64 | ppl    38.23
| prune-epoch  11 |   800/ 2983 batches | lr 1.25 | ms/batch 58.69 | loss  3.67 | ppl    39.20
| prune-epoch  11 |  1000/ 2983 batches | lr 1.25 | ms/batch 58.57 | loss  3.72 | ppl    41.09
| prune-epoch  11 |  1200/ 2983 batches | lr 1.25 | ms/batch 58.62 | loss  3.72 | ppl    41.45
| prune-epoch  11 |  1400/ 2983 batches | lr 1.25 | ms/batch 58.69 | loss  3.72 | ppl    41.25
| prune-epoch  11 |  1600/ 2983 batches | lr 1.25 | ms/batch 58.53 | loss  3.80 | ppl    44.68
| prune-epoch  11 |  1800/ 2983 batches | lr 1.25 | ms/batch 58.48 | loss  3.70 | ppl    40.62
| prune-epoch  11 |  2000/ 2983 batches | lr 1.25 | ms/batch 58.57 | loss  3.78 | ppl    43.96
| prune-epoch  11 |  2200/ 2983 batches | lr 1.25 | ms/batch 58.59 | loss  3.63 | ppl    37.59
| prune-epoch  11 |  2400/ 2983 batches | lr 1.25 | ms/batch 58.53 | loss  3.65 | ppl    38.36
| prune-epoch  11 |  2600/ 2983 batches | lr 1.25 | ms/batch 58.53 | loss  3.66 | ppl    39.00
| prune-epoch  11 |  2800/ 2983 batches | lr 1.25 | ms/batch 58.57 | loss  3.64 | ppl    38.03
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  11 | time: 182.11s | valid loss  4.58 | valid ppl    97.26
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  12 |   200/ 2983 batches | lr 1.25 | ms/batch 60.45 | loss  3.76 | ppl    43.16
| prune-epoch  12 |   400/ 2983 batches | lr 1.25 | ms/batch 58.41 | loss  3.80 | ppl    44.59
| prune-epoch  12 |   600/ 2983 batches | lr 1.25 | ms/batch 58.43 | loss  3.64 | ppl    38.27
| prune-epoch  12 |   800/ 2983 batches | lr 1.25 | ms/batch 58.57 | loss  3.67 | ppl    39.32
| prune-epoch  12 |  1000/ 2983 batches | lr 1.25 | ms/batch 58.52 | loss  3.72 | ppl    41.18
| prune-epoch  12 |  1200/ 2983 batches | lr 1.25 | ms/batch 58.41 | loss  3.73 | ppl    41.68
| prune-epoch  12 |  1400/ 2983 batches | lr 1.25 | ms/batch 58.39 | loss  3.72 | ppl    41.25
| prune-epoch  12 |  1600/ 2983 batches | lr 1.25 | ms/batch 58.34 | loss  3.80 | ppl    44.69
| prune-epoch  12 |  1800/ 2983 batches | lr 1.25 | ms/batch 58.40 | loss  3.70 | ppl    40.65
| prune-epoch  12 |  2000/ 2983 batches | lr 1.25 | ms/batch 58.38 | loss  3.79 | ppl    44.16
| prune-epoch  12 |  2200/ 2983 batches | lr 1.25 | ms/batch 58.37 | loss  3.63 | ppl    37.59
| prune-epoch  12 |  2400/ 2983 batches | lr 1.25 | ms/batch 58.43 | loss  3.65 | ppl    38.55
| prune-epoch  12 |  2600/ 2983 batches | lr 1.25 | ms/batch 58.40 | loss  3.67 | ppl    39.08
| prune-epoch  12 |  2800/ 2983 batches | lr 1.25 | ms/batch 58.42 | loss  3.64 | ppl    38.25
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  12 | time: 181.54s | valid loss  4.58 | valid ppl    97.36
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  13 |   200/ 2983 batches | lr 1.25 | ms/batch 60.36 | loss  3.77 | ppl    43.20
| prune-epoch  13 |   400/ 2983 batches | lr 1.25 | ms/batch 58.48 | loss  3.79 | ppl    44.13
| prune-epoch  13 |   600/ 2983 batches | lr 1.25 | ms/batch 58.38 | loss  3.64 | ppl    38.00
| prune-epoch  13 |   800/ 2983 batches | lr 1.25 | ms/batch 60.10 | loss  3.66 | ppl    39.02
| prune-epoch  13 |  1000/ 2983 batches | lr 1.25 | ms/batch 81.03 | loss  3.71 | ppl    40.90
| prune-epoch  13 |  1200/ 2983 batches | lr 1.25 | ms/batch 135.86 | loss  3.73 | ppl    41.54
| prune-epoch  13 |  1400/ 2983 batches | lr 1.25 | ms/batch 134.34 | loss  3.71 | ppl    40.86
| prune-epoch  13 |  1600/ 2983 batches | lr 1.25 | ms/batch 92.82 | loss  3.79 | ppl    44.45
| prune-epoch  13 |  1800/ 2983 batches | lr 1.25 | ms/batch 58.10 | loss  3.70 | ppl    40.47
| prune-epoch  13 |  2000/ 2983 batches | lr 1.25 | ms/batch 58.28 | loss  3.79 | ppl    44.26
| prune-epoch  13 |  2200/ 2983 batches | lr 1.25 | ms/batch 58.20 | loss  3.61 | ppl    37.15
| prune-epoch  13 |  2400/ 2983 batches | lr 1.25 | ms/batch 58.30 | loss  3.65 | ppl    38.32
| prune-epoch  13 |  2600/ 2983 batches | lr 1.25 | ms/batch 58.42 | loss  3.67 | ppl    39.16
| prune-epoch  13 |  2800/ 2983 batches | lr 1.25 | ms/batch 58.65 | loss  3.63 | ppl    37.88
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  13 | time: 223.91s | valid loss  4.57 | valid ppl    96.85
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  14 |   200/ 2983 batches | lr 1.25 | ms/batch 60.72 | loss  3.76 | ppl    43.01
| prune-epoch  14 |   400/ 2983 batches | lr 1.25 | ms/batch 58.34 | loss  3.79 | ppl    44.06
| prune-epoch  14 |   600/ 2983 batches | lr 1.25 | ms/batch 58.29 | loss  3.63 | ppl    37.56
| prune-epoch  14 |   800/ 2983 batches | lr 1.25 | ms/batch 58.20 | loss  3.66 | ppl    38.68
| prune-epoch  14 |  1000/ 2983 batches | lr 1.25 | ms/batch 58.25 | loss  3.70 | ppl    40.65
| prune-epoch  14 |  1200/ 2983 batches | lr 1.25 | ms/batch 58.26 | loss  3.72 | ppl    41.37
| prune-epoch  14 |  1400/ 2983 batches | lr 1.25 | ms/batch 58.30 | loss  3.72 | ppl    41.13
| prune-epoch  14 |  1600/ 2983 batches | lr 1.25 | ms/batch 58.44 | loss  3.79 | ppl    44.27
| prune-epoch  14 |  1800/ 2983 batches | lr 1.25 | ms/batch 58.74 | loss  3.70 | ppl    40.47
| prune-epoch  14 |  2000/ 2983 batches | lr 1.25 | ms/batch 58.64 | loss  3.78 | ppl    43.95
| prune-epoch  14 |  2200/ 2983 batches | lr 1.25 | ms/batch 58.69 | loss  3.61 | ppl    37.12
| prune-epoch  14 |  2400/ 2983 batches | lr 1.25 | ms/batch 58.73 | loss  3.65 | ppl    38.36
| prune-epoch  14 |  2600/ 2983 batches | lr 1.25 | ms/batch 58.75 | loss  3.66 | ppl    38.87
| prune-epoch  14 |  2800/ 2983 batches | lr 1.25 | ms/batch 58.67 | loss  3.64 | ppl    38.02
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  14 | time: 181.85s | valid loss  4.57 | valid ppl    96.88
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  15 |   200/ 2983 batches | lr 0.31 | ms/batch 60.69 | loss  3.79 | ppl    44.28
| prune-epoch  15 |   400/ 2983 batches | lr 0.31 | ms/batch 58.76 | loss  3.85 | ppl    46.78
| prune-epoch  15 |   600/ 2983 batches | lr 0.31 | ms/batch 58.85 | loss  3.71 | ppl    40.65
| prune-epoch  15 |   800/ 2983 batches | lr 0.31 | ms/batch 58.70 | loss  3.77 | ppl    43.48
| prune-epoch  15 |  1000/ 2983 batches | lr 0.31 | ms/batch 58.79 | loss  3.74 | ppl    42.10
| prune-epoch  15 |  1200/ 2983 batches | lr 0.31 | ms/batch 58.85 | loss  3.76 | ppl    43.15
| prune-epoch  15 |  1400/ 2983 batches | lr 0.31 | ms/batch 58.68 | loss  3.77 | ppl    43.54
| prune-epoch  15 |  1600/ 2983 batches | lr 0.31 | ms/batch 58.86 | loss  3.81 | ppl    45.14
| prune-epoch  15 |  1800/ 2983 batches | lr 0.31 | ms/batch 58.72 | loss  3.73 | ppl    41.86
| prune-epoch  15 |  2000/ 2983 batches | lr 0.31 | ms/batch 58.40 | loss  3.80 | ppl    44.55
| prune-epoch  15 |  2200/ 2983 batches | lr 0.31 | ms/batch 58.38 | loss  3.70 | ppl    40.61
| prune-epoch  15 |  2400/ 2983 batches | lr 0.31 | ms/batch 58.37 | loss  3.69 | ppl    39.87
| prune-epoch  15 |  2600/ 2983 batches | lr 0.31 | ms/batch 58.32 | loss  3.71 | ppl    41.03
| prune-epoch  15 |  2800/ 2983 batches | lr 0.31 | ms/batch 58.25 | loss  3.65 | ppl    38.63
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  15 | time: 182.06s | valid loss  4.56 | valid ppl    95.89
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  16 |   200/ 2983 batches | lr 0.31 | ms/batch 60.45 | loss  3.84 | ppl    46.73
| prune-epoch  16 |   400/ 2983 batches | lr 0.31 | ms/batch 58.47 | loss  3.85 | ppl    46.95
| prune-epoch  16 |   600/ 2983 batches | lr 0.31 | ms/batch 58.47 | loss  3.68 | ppl    39.48
| prune-epoch  16 |   800/ 2983 batches | lr 0.31 | ms/batch 58.44 | loss  3.75 | ppl    42.45
| prune-epoch  16 |  1000/ 2983 batches | lr 0.31 | ms/batch 58.50 | loss  3.74 | ppl    42.06
| prune-epoch  16 |  1200/ 2983 batches | lr 0.31 | ms/batch 58.31 | loss  3.74 | ppl    42.29
| prune-epoch  16 |  1400/ 2983 batches | lr 0.31 | ms/batch 58.31 | loss  3.75 | ppl    42.47
| prune-epoch  16 |  1600/ 2983 batches | lr 0.31 | ms/batch 58.45 | loss  3.80 | ppl    44.77
| prune-epoch  16 |  1800/ 2983 batches | lr 0.31 | ms/batch 58.18 | loss  3.75 | ppl    42.41
| prune-epoch  16 |  2000/ 2983 batches | lr 0.31 | ms/batch 58.28 | loss  3.80 | ppl    44.90
| prune-epoch  16 |  2200/ 2983 batches | lr 0.31 | ms/batch 58.47 | loss  3.69 | ppl    40.04
| prune-epoch  16 |  2400/ 2983 batches | lr 0.31 | ms/batch 58.34 | loss  3.68 | ppl    39.53
| prune-epoch  16 |  2600/ 2983 batches | lr 0.31 | ms/batch 58.28 | loss  3.72 | ppl    41.10
| prune-epoch  16 |  2800/ 2983 batches | lr 0.31 | ms/batch 58.38 | loss  3.65 | ppl    38.53
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  16 | time: 181.40s | valid loss  4.56 | valid ppl    95.88
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  17 |   200/ 2983 batches | lr 0.31 | ms/batch 59.85 | loss  3.84 | ppl    46.35
| prune-epoch  17 |   400/ 2983 batches | lr 0.31 | ms/batch 57.81 | loss  3.85 | ppl    46.79
| prune-epoch  17 |   600/ 2983 batches | lr 0.31 | ms/batch 57.86 | loss  3.68 | ppl    39.67
| prune-epoch  17 |   800/ 2983 batches | lr 0.31 | ms/batch 57.86 | loss  3.75 | ppl    42.70
| prune-epoch  17 |  1000/ 2983 batches | lr 0.31 | ms/batch 57.86 | loss  3.74 | ppl    42.01
| prune-epoch  17 |  1200/ 2983 batches | lr 0.31 | ms/batch 57.90 | loss  3.74 | ppl    42.13
| prune-epoch  17 |  1400/ 2983 batches | lr 0.31 | ms/batch 58.03 | loss  3.75 | ppl    42.61
| prune-epoch  17 |  1600/ 2983 batches | lr 0.31 | ms/batch 57.90 | loss  3.80 | ppl    44.62
| prune-epoch  17 |  1800/ 2983 batches | lr 0.31 | ms/batch 57.83 | loss  3.75 | ppl    42.31
| prune-epoch  17 |  2000/ 2983 batches | lr 0.31 | ms/batch 57.88 | loss  3.82 | ppl    45.66
| prune-epoch  17 |  2200/ 2983 batches | lr 0.31 | ms/batch 57.88 | loss  3.68 | ppl    39.54
| prune-epoch  17 |  2400/ 2983 batches | lr 0.31 | ms/batch 57.89 | loss  3.68 | ppl    39.59
| prune-epoch  17 |  2600/ 2983 batches | lr 0.31 | ms/batch 57.92 | loss  3.71 | ppl    41.03
| prune-epoch  17 |  2800/ 2983 batches | lr 0.31 | ms/batch 57.88 | loss  3.65 | ppl    38.60
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  17 | time: 179.92s | valid loss  4.56 | valid ppl    95.92
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  18 |   200/ 2983 batches | lr 0.31 | ms/batch 60.53 | loss  3.83 | ppl    46.25
| prune-epoch  18 |   400/ 2983 batches | lr 0.31 | ms/batch 58.49 | loss  3.84 | ppl    46.63
| prune-epoch  18 |   600/ 2983 batches | lr 0.31 | ms/batch 58.46 | loss  3.67 | ppl    39.42
| prune-epoch  18 |   800/ 2983 batches | lr 0.31 | ms/batch 58.54 | loss  3.75 | ppl    42.49
| prune-epoch  18 |  1000/ 2983 batches | lr 0.31 | ms/batch 58.37 | loss  3.74 | ppl    42.11
| prune-epoch  18 |  1200/ 2983 batches | lr 0.31 | ms/batch 58.48 | loss  3.75 | ppl    42.55
| prune-epoch  18 |  1400/ 2983 batches | lr 0.31 | ms/batch 58.48 | loss  3.75 | ppl    42.36
| prune-epoch  18 |  1600/ 2983 batches | lr 0.31 | ms/batch 58.39 | loss  3.80 | ppl    44.65
| prune-epoch  18 |  1800/ 2983 batches | lr 0.31 | ms/batch 58.36 | loss  3.75 | ppl    42.73
| prune-epoch  18 |  2000/ 2983 batches | lr 0.31 | ms/batch 58.42 | loss  3.81 | ppl    45.37
| prune-epoch  18 |  2200/ 2983 batches | lr 0.31 | ms/batch 58.34 | loss  3.66 | ppl    38.93
| prune-epoch  18 |  2400/ 2983 batches | lr 0.31 | ms/batch 58.43 | loss  3.69 | ppl    39.86
| prune-epoch  18 |  2600/ 2983 batches | lr 0.31 | ms/batch 58.34 | loss  3.71 | ppl    40.66
| prune-epoch  18 |  2800/ 2983 batches | lr 0.31 | ms/batch 58.40 | loss  3.66 | ppl    38.87
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  18 | time: 181.55s | valid loss  4.56 | valid ppl    95.93
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  19 |   200/ 2983 batches | lr 0.08 | ms/batch 60.17 | loss  3.85 | ppl    47.23
| prune-epoch  19 |   400/ 2983 batches | lr 0.08 | ms/batch 58.30 | loss  3.91 | ppl    49.94
| prune-epoch  19 |   600/ 2983 batches | lr 0.08 | ms/batch 58.32 | loss  3.75 | ppl    42.58
| prune-epoch  19 |   800/ 2983 batches | lr 0.08 | ms/batch 58.29 | loss  3.85 | ppl    47.02
| prune-epoch  19 |  1000/ 2983 batches | lr 0.08 | ms/batch 58.22 | loss  3.87 | ppl    48.01
| prune-epoch  19 |  1200/ 2983 batches | lr 0.08 | ms/batch 58.28 | loss  3.85 | ppl    46.88
| prune-epoch  19 |  1400/ 2983 batches | lr 0.08 | ms/batch 58.21 | loss  3.88 | ppl    48.27
| prune-epoch  19 |  1600/ 2983 batches | lr 0.08 | ms/batch 58.22 | loss  3.91 | ppl    49.71
| prune-epoch  19 |  1800/ 2983 batches | lr 0.08 | ms/batch 58.32 | loss  3.80 | ppl    44.90
| prune-epoch  19 |  2000/ 2983 batches | lr 0.08 | ms/batch 58.27 | loss  3.80 | ppl    44.62
| prune-epoch  19 |  2200/ 2983 batches | lr 0.08 | ms/batch 58.37 | loss  3.66 | ppl    38.82
| prune-epoch  19 |  2400/ 2983 batches | lr 0.08 | ms/batch 58.31 | loss  3.69 | ppl    40.21
| prune-epoch  19 |  2600/ 2983 batches | lr 0.08 | ms/batch 58.27 | loss  3.77 | ppl    43.22
| prune-epoch  19 |  2800/ 2983 batches | lr 0.08 | ms/batch 58.26 | loss  3.73 | ppl    41.52
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  19 | time: 181.08s | valid loss  4.55 | valid ppl    94.22
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  20 |   200/ 2983 batches | lr 0.08 | ms/batch 59.99 | loss  3.88 | ppl    48.51
| prune-epoch  20 |   400/ 2983 batches | lr 0.08 | ms/batch 58.05 | loss  3.92 | ppl    50.31
| prune-epoch  20 |   600/ 2983 batches | lr 0.08 | ms/batch 58.04 | loss  3.74 | ppl    42.22
| prune-epoch  20 |   800/ 2983 batches | lr 0.08 | ms/batch 58.06 | loss  3.80 | ppl    44.55
| prune-epoch  20 |  1000/ 2983 batches | lr 0.08 | ms/batch 58.08 | loss  3.81 | ppl    45.17
| prune-epoch  20 |  1200/ 2983 batches | lr 0.08 | ms/batch 58.07 | loss  3.79 | ppl    44.30
| prune-epoch  20 |  1400/ 2983 batches | lr 0.08 | ms/batch 58.08 | loss  3.82 | ppl    45.69
| prune-epoch  20 |  1600/ 2983 batches | lr 0.08 | ms/batch 58.04 | loss  3.86 | ppl    47.28
| prune-epoch  20 |  1800/ 2983 batches | lr 0.08 | ms/batch 58.12 | loss  3.78 | ppl    43.68
| prune-epoch  20 |  2000/ 2983 batches | lr 0.08 | ms/batch 58.08 | loss  3.81 | ppl    44.95
| prune-epoch  20 |  2200/ 2983 batches | lr 0.08 | ms/batch 58.06 | loss  3.69 | ppl    39.91
| prune-epoch  20 |  2400/ 2983 batches | lr 0.08 | ms/batch 58.05 | loss  3.73 | ppl    41.54
| prune-epoch  20 |  2600/ 2983 batches | lr 0.08 | ms/batch 58.07 | loss  3.78 | ppl    44.01
| prune-epoch  20 |  2800/ 2983 batches | lr 0.08 | ms/batch 58.04 | loss  3.74 | ppl    41.94
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  20 | time: 180.49s | valid loss  4.54 | valid ppl    93.82
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  21 |   200/ 2983 batches | lr 0.08 | ms/batch 60.35 | loss  3.87 | ppl    48.15
| prune-epoch  21 |   400/ 2983 batches | lr 0.08 | ms/batch 58.37 | loss  3.89 | ppl    48.99
| prune-epoch  21 |   600/ 2983 batches | lr 0.08 | ms/batch 58.38 | loss  3.71 | ppl    40.99
| prune-epoch  21 |   800/ 2983 batches | lr 0.08 | ms/batch 58.35 | loss  3.78 | ppl    43.92
| prune-epoch  21 |  1000/ 2983 batches | lr 0.08 | ms/batch 58.34 | loss  3.79 | ppl    44.19
| prune-epoch  21 |  1200/ 2983 batches | lr 0.08 | ms/batch 58.45 | loss  3.78 | ppl    44.02
| prune-epoch  21 |  1400/ 2983 batches | lr 0.08 | ms/batch 58.29 | loss  3.80 | ppl    44.77
| prune-epoch  21 |  1600/ 2983 batches | lr 0.08 | ms/batch 58.33 | loss  3.85 | ppl    47.11
| prune-epoch  21 |  1800/ 2983 batches | lr 0.08 | ms/batch 58.29 | loss  3.79 | ppl    44.32
| prune-epoch  21 |  2000/ 2983 batches | lr 0.08 | ms/batch 58.35 | loss  3.82 | ppl    45.44
| prune-epoch  21 |  2200/ 2983 batches | lr 0.08 | ms/batch 58.26 | loss  3.70 | ppl    40.42
| prune-epoch  21 |  2400/ 2983 batches | lr 0.08 | ms/batch 58.30 | loss  3.73 | ppl    41.51
| prune-epoch  21 |  2600/ 2983 batches | lr 0.08 | ms/batch 58.37 | loss  3.78 | ppl    43.78
| prune-epoch  21 |  2800/ 2983 batches | lr 0.08 | ms/batch 58.26 | loss  3.72 | ppl    41.45
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  21 | time: 181.28s | valid loss  4.54 | valid ppl    93.87
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  22 |   200/ 2983 batches | lr 0.08 | ms/batch 60.23 | loss  3.86 | ppl    47.34
| prune-epoch  22 |   400/ 2983 batches | lr 0.08 | ms/batch 58.35 | loss  3.87 | ppl    47.86
| prune-epoch  22 |   600/ 2983 batches | lr 0.08 | ms/batch 58.27 | loss  3.70 | ppl    40.38
| prune-epoch  22 |   800/ 2983 batches | lr 0.08 | ms/batch 58.38 | loss  3.77 | ppl    43.59
| prune-epoch  22 |  1000/ 2983 batches | lr 0.08 | ms/batch 58.30 | loss  3.80 | ppl    44.71
| prune-epoch  22 |  1200/ 2983 batches | lr 0.08 | ms/batch 58.36 | loss  3.78 | ppl    43.99
| prune-epoch  22 |  1400/ 2983 batches | lr 0.08 | ms/batch 58.30 | loss  3.81 | ppl    45.09
| prune-epoch  22 |  1600/ 2983 batches | lr 0.08 | ms/batch 58.35 | loss  3.86 | ppl    47.38
| prune-epoch  22 |  1800/ 2983 batches | lr 0.08 | ms/batch 58.29 | loss  3.80 | ppl    44.64
| prune-epoch  22 |  2000/ 2983 batches | lr 0.08 | ms/batch 58.31 | loss  3.83 | ppl    45.93
| prune-epoch  22 |  2200/ 2983 batches | lr 0.08 | ms/batch 58.29 | loss  3.70 | ppl    40.30
| prune-epoch  22 |  2400/ 2983 batches | lr 0.08 | ms/batch 58.40 | loss  3.71 | ppl    40.74
| prune-epoch  22 |  2600/ 2983 batches | lr 0.08 | ms/batch 58.54 | loss  3.76 | ppl    43.04
| prune-epoch  22 |  2800/ 2983 batches | lr 0.08 | ms/batch 58.45 | loss  3.72 | ppl    41.17
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  22 | time: 181.33s | valid loss  4.54 | valid ppl    93.87
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  23 |   200/ 2983 batches | lr 0.02 | ms/batch 60.59 | loss  3.87 | ppl    47.99
| prune-epoch  23 |   400/ 2983 batches | lr 0.02 | ms/batch 58.62 | loss  3.89 | ppl    48.89
| prune-epoch  23 |   600/ 2983 batches | lr 0.02 | ms/batch 58.56 | loss  3.73 | ppl    41.50
| prune-epoch  23 |   800/ 2983 batches | lr 0.02 | ms/batch 58.58 | loss  3.81 | ppl    45.27
| prune-epoch  23 |  1000/ 2983 batches | lr 0.02 | ms/batch 58.57 | loss  3.84 | ppl    46.75
| prune-epoch  23 |  1200/ 2983 batches | lr 0.02 | ms/batch 58.44 | loss  3.82 | ppl    45.82
| prune-epoch  23 |  1400/ 2983 batches | lr 0.02 | ms/batch 58.44 | loss  3.85 | ppl    47.12
| prune-epoch  23 |  1600/ 2983 batches | lr 0.02 | ms/batch 58.37 | loss  3.90 | ppl    49.47
| prune-epoch  23 |  1800/ 2983 batches | lr 0.02 | ms/batch 58.63 | loss  3.84 | ppl    46.52
| prune-epoch  23 |  2000/ 2983 batches | lr 0.02 | ms/batch 58.57 | loss  3.86 | ppl    47.64
| prune-epoch  23 |  2200/ 2983 batches | lr 0.02 | ms/batch 58.50 | loss  3.71 | ppl    41.05
| prune-epoch  23 |  2400/ 2983 batches | lr 0.02 | ms/batch 58.47 | loss  3.71 | ppl    41.03
| prune-epoch  23 |  2600/ 2983 batches | lr 0.02 | ms/batch 58.60 | loss  3.77 | ppl    43.53
| prune-epoch  23 |  2800/ 2983 batches | lr 0.02 | ms/batch 58.42 | loss  3.72 | ppl    41.17
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  23 | time: 181.82s | valid loss  4.54 | valid ppl    93.63
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  24 |   200/ 2983 batches | lr 0.02 | ms/batch 59.92 | loss  3.87 | ppl    47.83
| prune-epoch  24 |   400/ 2983 batches | lr 0.02 | ms/batch 57.91 | loss  3.90 | ppl    49.18
| prune-epoch  24 |   600/ 2983 batches | lr 0.02 | ms/batch 57.94 | loss  3.73 | ppl    41.56
| prune-epoch  24 |   800/ 2983 batches | lr 0.02 | ms/batch 57.90 | loss  3.81 | ppl    45.09
| prune-epoch  24 |  1000/ 2983 batches | lr 0.02 | ms/batch 57.94 | loss  3.83 | ppl    46.11
| prune-epoch  24 |  1200/ 2983 batches | lr 0.02 | ms/batch 58.02 | loss  3.82 | ppl    45.55
| prune-epoch  24 |  1400/ 2983 batches | lr 0.02 | ms/batch 58.09 | loss  3.84 | ppl    46.59
| prune-epoch  24 |  1600/ 2983 batches | lr 0.02 | ms/batch 58.04 | loss  3.90 | ppl    49.45
| prune-epoch  24 |  1800/ 2983 batches | lr 0.02 | ms/batch 58.17 | loss  3.84 | ppl    46.32
| prune-epoch  24 |  2000/ 2983 batches | lr 0.02 | ms/batch 58.14 | loss  3.85 | ppl    46.98
| prune-epoch  24 |  2200/ 2983 batches | lr 0.02 | ms/batch 58.05 | loss  3.70 | ppl    40.41
| prune-epoch  24 |  2400/ 2983 batches | lr 0.02 | ms/batch 57.94 | loss  3.72 | ppl    41.19
| prune-epoch  24 |  2600/ 2983 batches | lr 0.02 | ms/batch 57.93 | loss  3.77 | ppl    43.26
| prune-epoch  24 |  2800/ 2983 batches | lr 0.02 | ms/batch 57.91 | loss  3.72 | ppl    41.33
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  24 | time: 180.27s | valid loss  4.54 | valid ppl    93.49
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  25 |   200/ 2983 batches | lr 0.02 | ms/batch 60.90 | loss  3.87 | ppl    47.80
| prune-epoch  25 |   400/ 2983 batches | lr 0.02 | ms/batch 58.76 | loss  3.90 | ppl    49.60
| prune-epoch  25 |   600/ 2983 batches | lr 0.02 | ms/batch 58.68 | loss  3.73 | ppl    41.50
| prune-epoch  25 |   800/ 2983 batches | lr 0.02 | ms/batch 58.57 | loss  3.80 | ppl    44.88
| prune-epoch  25 |  1000/ 2983 batches | lr 0.02 | ms/batch 58.67 | loss  3.83 | ppl    46.06
| prune-epoch  25 |  1200/ 2983 batches | lr 0.02 | ms/batch 58.57 | loss  3.82 | ppl    45.54
| prune-epoch  25 |  1400/ 2983 batches | lr 0.02 | ms/batch 58.55 | loss  3.84 | ppl    46.60
| prune-epoch  25 |  1600/ 2983 batches | lr 0.02 | ms/batch 58.52 | loss  3.90 | ppl    49.28
| prune-epoch  25 |  1800/ 2983 batches | lr 0.02 | ms/batch 58.49 | loss  3.83 | ppl    46.02
| prune-epoch  25 |  2000/ 2983 batches | lr 0.02 | ms/batch 58.55 | loss  3.84 | ppl    46.71
| prune-epoch  25 |  2200/ 2983 batches | lr 0.02 | ms/batch 58.47 | loss  3.70 | ppl    40.39
| prune-epoch  25 |  2400/ 2983 batches | lr 0.02 | ms/batch 58.55 | loss  3.72 | ppl    41.25
| prune-epoch  25 |  2600/ 2983 batches | lr 0.02 | ms/batch 58.49 | loss  3.77 | ppl    43.22
| prune-epoch  25 |  2800/ 2983 batches | lr 0.02 | ms/batch 58.54 | loss  3.74 | ppl    41.97
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  25 | time: 182.02s | valid loss  4.54 | valid ppl    93.39
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  26 |   200/ 2983 batches | lr 0.02 | ms/batch 60.38 | loss  3.87 | ppl    47.96
| prune-epoch  26 |   400/ 2983 batches | lr 0.02 | ms/batch 58.33 | loss  3.90 | ppl    49.53
| prune-epoch  26 |   600/ 2983 batches | lr 0.02 | ms/batch 58.31 | loss  3.72 | ppl    41.46
| prune-epoch  26 |   800/ 2983 batches | lr 0.02 | ms/batch 58.34 | loss  3.80 | ppl    44.83
| prune-epoch  26 |  1000/ 2983 batches | lr 0.02 | ms/batch 58.40 | loss  3.82 | ppl    45.76
| prune-epoch  26 |  1200/ 2983 batches | lr 0.02 | ms/batch 58.39 | loss  3.81 | ppl    44.98
| prune-epoch  26 |  1400/ 2983 batches | lr 0.02 | ms/batch 58.33 | loss  3.84 | ppl    46.38
| prune-epoch  26 |  1600/ 2983 batches | lr 0.02 | ms/batch 58.35 | loss  3.88 | ppl    48.56
| prune-epoch  26 |  1800/ 2983 batches | lr 0.02 | ms/batch 58.38 | loss  3.82 | ppl    45.83
| prune-epoch  26 |  2000/ 2983 batches | lr 0.02 | ms/batch 58.37 | loss  3.84 | ppl    46.32
| prune-epoch  26 |  2200/ 2983 batches | lr 0.02 | ms/batch 58.46 | loss  3.70 | ppl    40.33
| prune-epoch  26 |  2400/ 2983 batches | lr 0.02 | ms/batch 58.36 | loss  3.71 | ppl    41.00
| prune-epoch  26 |  2600/ 2983 batches | lr 0.02 | ms/batch 58.29 | loss  3.77 | ppl    43.54
| prune-epoch  26 |  2800/ 2983 batches | lr 0.02 | ms/batch 58.33 | loss  3.73 | ppl    41.87
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  26 | time: 181.35s | valid loss  4.54 | valid ppl    93.34
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  27 |   200/ 2983 batches | lr 0.02 | ms/batch 60.14 | loss  3.87 | ppl    48.15
| prune-epoch  27 |   400/ 2983 batches | lr 0.02 | ms/batch 58.20 | loss  3.90 | ppl    49.52
| prune-epoch  27 |   600/ 2983 batches | lr 0.02 | ms/batch 58.16 | loss  3.72 | ppl    41.31
| prune-epoch  27 |   800/ 2983 batches | lr 0.02 | ms/batch 58.11 | loss  3.80 | ppl    44.70
| prune-epoch  27 |  1000/ 2983 batches | lr 0.02 | ms/batch 58.15 | loss  3.82 | ppl    45.64
| prune-epoch  27 |  1200/ 2983 batches | lr 0.02 | ms/batch 58.16 | loss  3.81 | ppl    45.26
| prune-epoch  27 |  1400/ 2983 batches | lr 0.02 | ms/batch 58.15 | loss  3.84 | ppl    46.36
| prune-epoch  27 |  1600/ 2983 batches | lr 0.02 | ms/batch 58.19 | loss  3.89 | ppl    48.96
| prune-epoch  27 |  1800/ 2983 batches | lr 0.02 | ms/batch 58.12 | loss  3.82 | ppl    45.46
| prune-epoch  27 |  2000/ 2983 batches | lr 0.02 | ms/batch 58.18 | loss  3.83 | ppl    46.09
| prune-epoch  27 |  2200/ 2983 batches | lr 0.02 | ms/batch 58.08 | loss  3.70 | ppl    40.28
| prune-epoch  27 |  2400/ 2983 batches | lr 0.02 | ms/batch 58.21 | loss  3.71 | ppl    41.06
| prune-epoch  27 |  2600/ 2983 batches | lr 0.02 | ms/batch 58.13 | loss  3.77 | ppl    43.48
| prune-epoch  27 |  2800/ 2983 batches | lr 0.02 | ms/batch 58.15 | loss  3.73 | ppl    41.85
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  27 | time: 180.73s | valid loss  4.54 | valid ppl    93.29
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  28 |   200/ 2983 batches | lr 0.02 | ms/batch 60.37 | loss  3.88 | ppl    48.39
| prune-epoch  28 |   400/ 2983 batches | lr 0.02 | ms/batch 58.42 | loss  3.90 | ppl    49.45
| prune-epoch  28 |   600/ 2983 batches | lr 0.02 | ms/batch 58.39 | loss  3.72 | ppl    41.45
| prune-epoch  28 |   800/ 2983 batches | lr 0.02 | ms/batch 58.47 | loss  3.79 | ppl    44.31
| prune-epoch  28 |  1000/ 2983 batches | lr 0.02 | ms/batch 58.41 | loss  3.82 | ppl    45.59
| prune-epoch  28 |  1200/ 2983 batches | lr 0.02 | ms/batch 58.40 | loss  3.80 | ppl    44.88
| prune-epoch  28 |  1400/ 2983 batches | lr 0.02 | ms/batch 58.43 | loss  3.84 | ppl    46.37
| prune-epoch  28 |  1600/ 2983 batches | lr 0.02 | ms/batch 58.40 | loss  3.89 | ppl    48.73
| prune-epoch  28 |  1800/ 2983 batches | lr 0.02 | ms/batch 58.42 | loss  3.82 | ppl    45.49
| prune-epoch  28 |  2000/ 2983 batches | lr 0.02 | ms/batch 58.46 | loss  3.83 | ppl    46.14
| prune-epoch  28 |  2200/ 2983 batches | lr 0.02 | ms/batch 58.37 | loss  3.69 | ppl    40.07
| prune-epoch  28 |  2400/ 2983 batches | lr 0.02 | ms/batch 58.36 | loss  3.72 | ppl    41.20
| prune-epoch  28 |  2600/ 2983 batches | lr 0.02 | ms/batch 58.42 | loss  3.78 | ppl    43.63
| prune-epoch  28 |  2800/ 2983 batches | lr 0.02 | ms/batch 58.43 | loss  3.74 | ppl    42.04
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  28 | time: 181.50s | valid loss  4.54 | valid ppl    93.26
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  29 |   200/ 2983 batches | lr 0.02 | ms/batch 60.36 | loss  3.88 | ppl    48.46
| prune-epoch  29 |   400/ 2983 batches | lr 0.02 | ms/batch 58.35 | loss  3.90 | ppl    49.52
| prune-epoch  29 |   600/ 2983 batches | lr 0.02 | ms/batch 58.36 | loss  3.72 | ppl    41.47
| prune-epoch  29 |   800/ 2983 batches | lr 0.02 | ms/batch 58.43 | loss  3.78 | ppl    44.02
| prune-epoch  29 |  1000/ 2983 batches | lr 0.02 | ms/batch 58.37 | loss  3.82 | ppl    45.45
| prune-epoch  29 |  1200/ 2983 batches | lr 0.02 | ms/batch 58.38 | loss  3.81 | ppl    45.19
| prune-epoch  29 |  1400/ 2983 batches | lr 0.02 | ms/batch 58.34 | loss  3.83 | ppl    46.26
| prune-epoch  29 |  1600/ 2983 batches | lr 0.02 | ms/batch 58.38 | loss  3.89 | ppl    48.86
| prune-epoch  29 |  1800/ 2983 batches | lr 0.02 | ms/batch 58.33 | loss  3.81 | ppl    45.33
| prune-epoch  29 |  2000/ 2983 batches | lr 0.02 | ms/batch 58.36 | loss  3.83 | ppl    46.06
| prune-epoch  29 |  2200/ 2983 batches | lr 0.02 | ms/batch 58.38 | loss  3.69 | ppl    40.06
| prune-epoch  29 |  2400/ 2983 batches | lr 0.02 | ms/batch 58.40 | loss  3.72 | ppl    41.26
| prune-epoch  29 |  2600/ 2983 batches | lr 0.02 | ms/batch 58.35 | loss  3.78 | ppl    43.90
| prune-epoch  29 |  2800/ 2983 batches | lr 0.02 | ms/batch 58.36 | loss  3.74 | ppl    42.04
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  29 | time: 181.37s | valid loss  4.53 | valid ppl    93.22
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  30 |   200/ 2983 batches | lr 0.02 | ms/batch 60.45 | loss  3.87 | ppl    48.06
| prune-epoch  30 |   400/ 2983 batches | lr 0.02 | ms/batch 58.46 | loss  3.90 | ppl    49.20
| prune-epoch  30 |   600/ 2983 batches | lr 0.02 | ms/batch 58.47 | loss  3.72 | ppl    41.41
| prune-epoch  30 |   800/ 2983 batches | lr 0.02 | ms/batch 58.49 | loss  3.78 | ppl    43.90
| prune-epoch  30 |  1000/ 2983 batches | lr 0.02 | ms/batch 58.53 | loss  3.82 | ppl    45.58
| prune-epoch  30 |  1200/ 2983 batches | lr 0.02 | ms/batch 58.54 | loss  3.81 | ppl    44.93
| prune-epoch  30 |  1400/ 2983 batches | lr 0.02 | ms/batch 58.46 | loss  3.83 | ppl    46.14
| prune-epoch  30 |  1600/ 2983 batches | lr 0.02 | ms/batch 58.45 | loss  3.88 | ppl    48.49
| prune-epoch  30 |  1800/ 2983 batches | lr 0.02 | ms/batch 58.44 | loss  3.82 | ppl    45.40
| prune-epoch  30 |  2000/ 2983 batches | lr 0.02 | ms/batch 58.53 | loss  3.83 | ppl    46.00
| prune-epoch  30 |  2200/ 2983 batches | lr 0.02 | ms/batch 58.48 | loss  3.69 | ppl    40.19
| prune-epoch  30 |  2400/ 2983 batches | lr 0.02 | ms/batch 58.52 | loss  3.72 | ppl    41.42
| prune-epoch  30 |  2600/ 2983 batches | lr 0.02 | ms/batch 58.41 | loss  3.78 | ppl    43.79
| prune-epoch  30 |  2800/ 2983 batches | lr 0.02 | ms/batch 58.46 | loss  3.74 | ppl    42.04
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  30 | time: 181.71s | valid loss  4.53 | valid ppl    93.19
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  31 |   200/ 2983 batches | lr 0.02 | ms/batch 60.01 | loss  3.88 | ppl    48.28
| prune-epoch  31 |   400/ 2983 batches | lr 0.02 | ms/batch 57.93 | loss  3.90 | ppl    49.24
| prune-epoch  31 |   600/ 2983 batches | lr 0.02 | ms/batch 57.98 | loss  3.71 | ppl    40.88
| prune-epoch  31 |   800/ 2983 batches | lr 0.02 | ms/batch 57.95 | loss  3.79 | ppl    44.06
| prune-epoch  31 |  1000/ 2983 batches | lr 0.02 | ms/batch 57.98 | loss  3.82 | ppl    45.40
| prune-epoch  31 |  1200/ 2983 batches | lr 0.02 | ms/batch 57.96 | loss  3.80 | ppl    44.90
| prune-epoch  31 |  1400/ 2983 batches | lr 0.02 | ms/batch 58.00 | loss  3.83 | ppl    46.03
| prune-epoch  31 |  1600/ 2983 batches | lr 0.02 | ms/batch 57.96 | loss  3.88 | ppl    48.64
| prune-epoch  31 |  1800/ 2983 batches | lr 0.02 | ms/batch 58.02 | loss  3.82 | ppl    45.51
| prune-epoch  31 |  2000/ 2983 batches | lr 0.02 | ms/batch 57.97 | loss  3.83 | ppl    45.90
| prune-epoch  31 |  2200/ 2983 batches | lr 0.02 | ms/batch 57.98 | loss  3.69 | ppl    40.22
| prune-epoch  31 |  2400/ 2983 batches | lr 0.02 | ms/batch 57.94 | loss  3.71 | ppl    41.03
| prune-epoch  31 |  2600/ 2983 batches | lr 0.02 | ms/batch 57.98 | loss  3.78 | ppl    43.68
| prune-epoch  31 |  2800/ 2983 batches | lr 0.02 | ms/batch 57.94 | loss  3.74 | ppl    41.91
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  31 | time: 180.20s | valid loss  4.53 | valid ppl    93.18
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  32 |   200/ 2983 batches | lr 0.02 | ms/batch 60.51 | loss  3.87 | ppl    48.10
| prune-epoch  32 |   400/ 2983 batches | lr 0.02 | ms/batch 58.59 | loss  3.90 | ppl    49.21
| prune-epoch  32 |   600/ 2983 batches | lr 0.02 | ms/batch 58.58 | loss  3.71 | ppl    41.03
| prune-epoch  32 |   800/ 2983 batches | lr 0.02 | ms/batch 58.54 | loss  3.78 | ppl    43.92
| prune-epoch  32 |  1000/ 2983 batches | lr 0.02 | ms/batch 58.58 | loss  3.81 | ppl    45.17
| prune-epoch  32 |  1200/ 2983 batches | lr 0.02 | ms/batch 58.46 | loss  3.81 | ppl    45.08
| prune-epoch  32 |  1400/ 2983 batches | lr 0.02 | ms/batch 58.56 | loss  3.84 | ppl    46.33
| prune-epoch  32 |  1600/ 2983 batches | lr 0.02 | ms/batch 58.46 | loss  3.88 | ppl    48.43
| prune-epoch  32 |  1800/ 2983 batches | lr 0.02 | ms/batch 58.55 | loss  3.82 | ppl    45.49
| prune-epoch  32 |  2000/ 2983 batches | lr 0.02 | ms/batch 58.50 | loss  3.83 | ppl    45.97
| prune-epoch  32 |  2200/ 2983 batches | lr 0.02 | ms/batch 58.49 | loss  3.69 | ppl    40.20
| prune-epoch  32 |  2400/ 2983 batches | lr 0.02 | ms/batch 58.50 | loss  3.72 | ppl    41.18
| prune-epoch  32 |  2600/ 2983 batches | lr 0.02 | ms/batch 58.56 | loss  3.78 | ppl    43.88
| prune-epoch  32 |  2800/ 2983 batches | lr 0.02 | ms/batch 58.55 | loss  3.73 | ppl    41.85
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  32 | time: 181.86s | valid loss  4.53 | valid ppl    93.16
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  33 |   200/ 2983 batches | lr 0.02 | ms/batch 60.44 | loss  3.87 | ppl    47.90
| prune-epoch  33 |   400/ 2983 batches | lr 0.02 | ms/batch 58.41 | loss  3.89 | ppl    49.02
| prune-epoch  33 |   600/ 2983 batches | lr 0.02 | ms/batch 58.36 | loss  3.72 | ppl    41.23
| prune-epoch  33 |   800/ 2983 batches | lr 0.02 | ms/batch 58.41 | loss  3.78 | ppl    43.98
| prune-epoch  33 |  1000/ 2983 batches | lr 0.02 | ms/batch 58.37 | loss  3.81 | ppl    44.96
| prune-epoch  33 |  1200/ 2983 batches | lr 0.02 | ms/batch 58.40 | loss  3.80 | ppl    44.92
| prune-epoch  33 |  1400/ 2983 batches | lr 0.02 | ms/batch 58.35 | loss  3.83 | ppl    46.08
| prune-epoch  33 |  1600/ 2983 batches | lr 0.02 | ms/batch 58.33 | loss  3.88 | ppl    48.54
| prune-epoch  33 |  1800/ 2983 batches | lr 0.02 | ms/batch 58.42 | loss  3.82 | ppl    45.56
| prune-epoch  33 |  2000/ 2983 batches | lr 0.02 | ms/batch 58.28 | loss  3.82 | ppl    45.78
| prune-epoch  33 |  2200/ 2983 batches | lr 0.02 | ms/batch 58.36 | loss  3.69 | ppl    40.16
| prune-epoch  33 |  2400/ 2983 batches | lr 0.02 | ms/batch 58.34 | loss  3.72 | ppl    41.26
| prune-epoch  33 |  2600/ 2983 batches | lr 0.02 | ms/batch 58.33 | loss  3.78 | ppl    43.77
| prune-epoch  33 |  2800/ 2983 batches | lr 0.02 | ms/batch 58.41 | loss  3.74 | ppl    42.07
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  33 | time: 181.37s | valid loss  4.53 | valid ppl    93.14
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  34 |   200/ 2983 batches | lr 0.02 | ms/batch 60.15 | loss  3.87 | ppl    47.83
| prune-epoch  34 |   400/ 2983 batches | lr 0.02 | ms/batch 58.17 | loss  3.90 | ppl    49.49
| prune-epoch  34 |   600/ 2983 batches | lr 0.02 | ms/batch 58.07 | loss  3.72 | ppl    41.14
| prune-epoch  34 |   800/ 2983 batches | lr 0.02 | ms/batch 58.11 | loss  3.78 | ppl    43.61
| prune-epoch  34 |  1000/ 2983 batches | lr 0.02 | ms/batch 58.15 | loss  3.81 | ppl    45.00
| prune-epoch  34 |  1200/ 2983 batches | lr 0.02 | ms/batch 58.16 | loss  3.81 | ppl    45.14
| prune-epoch  34 |  1400/ 2983 batches | lr 0.02 | ms/batch 58.17 | loss  3.83 | ppl    46.03
| prune-epoch  34 |  1600/ 2983 batches | lr 0.02 | ms/batch 58.13 | loss  3.88 | ppl    48.50
| prune-epoch  34 |  1800/ 2983 batches | lr 0.02 | ms/batch 58.17 | loss  3.81 | ppl    45.33
| prune-epoch  34 |  2000/ 2983 batches | lr 0.02 | ms/batch 58.19 | loss  3.83 | ppl    45.88
| prune-epoch  34 |  2200/ 2983 batches | lr 0.02 | ms/batch 58.15 | loss  3.70 | ppl    40.34
| prune-epoch  34 |  2400/ 2983 batches | lr 0.02 | ms/batch 58.21 | loss  3.72 | ppl    41.45
| prune-epoch  34 |  2600/ 2983 batches | lr 0.02 | ms/batch 58.17 | loss  3.78 | ppl    43.77
| prune-epoch  34 |  2800/ 2983 batches | lr 0.02 | ms/batch 58.11 | loss  3.74 | ppl    42.16
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  34 | time: 180.72s | valid loss  4.53 | valid ppl    93.14
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  35 |   200/ 2983 batches | lr 0.02 | ms/batch 60.32 | loss  3.86 | ppl    47.65
| prune-epoch  35 |   400/ 2983 batches | lr 0.02 | ms/batch 58.48 | loss  3.89 | ppl    48.89
| prune-epoch  35 |   600/ 2983 batches | lr 0.02 | ms/batch 58.45 | loss  3.71 | ppl    40.95
| prune-epoch  35 |   800/ 2983 batches | lr 0.02 | ms/batch 58.44 | loss  3.78 | ppl    43.84
| prune-epoch  35 |  1000/ 2983 batches | lr 0.02 | ms/batch 58.38 | loss  3.81 | ppl    45.09
| prune-epoch  35 |  1200/ 2983 batches | lr 0.02 | ms/batch 58.39 | loss  3.81 | ppl    45.03
| prune-epoch  35 |  1400/ 2983 batches | lr 0.02 | ms/batch 58.42 | loss  3.83 | ppl    45.92
| prune-epoch  35 |  1600/ 2983 batches | lr 0.02 | ms/batch 58.41 | loss  3.88 | ppl    48.49
| prune-epoch  35 |  1800/ 2983 batches | lr 0.02 | ms/batch 58.42 | loss  3.82 | ppl    45.63
| prune-epoch  35 |  2000/ 2983 batches | lr 0.02 | ms/batch 58.49 | loss  3.83 | ppl    45.91
| prune-epoch  35 |  2200/ 2983 batches | lr 0.02 | ms/batch 58.34 | loss  3.70 | ppl    40.48
| prune-epoch  35 |  2400/ 2983 batches | lr 0.02 | ms/batch 58.35 | loss  3.72 | ppl    41.17
| prune-epoch  35 |  2600/ 2983 batches | lr 0.02 | ms/batch 58.44 | loss  3.78 | ppl    43.71
| prune-epoch  35 |  2800/ 2983 batches | lr 0.02 | ms/batch 58.41 | loss  3.74 | ppl    42.16
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  35 | time: 181.50s | valid loss  4.53 | valid ppl    93.13
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  36 |   200/ 2983 batches | lr 0.02 | ms/batch 60.30 | loss  3.87 | ppl    47.79
| prune-epoch  36 |   400/ 2983 batches | lr 0.02 | ms/batch 58.38 | loss  3.89 | ppl    48.90
| prune-epoch  36 |   600/ 2983 batches | lr 0.02 | ms/batch 58.39 | loss  3.71 | ppl    41.04
| prune-epoch  36 |   800/ 2983 batches | lr 0.02 | ms/batch 58.36 | loss  3.78 | ppl    44.01
| prune-epoch  36 |  1000/ 2983 batches | lr 0.02 | ms/batch 58.40 | loss  3.81 | ppl    45.16
| prune-epoch  36 |  1200/ 2983 batches | lr 0.02 | ms/batch 58.40 | loss  3.81 | ppl    44.95
| prune-epoch  36 |  1400/ 2983 batches | lr 0.02 | ms/batch 58.36 | loss  3.83 | ppl    46.01
| prune-epoch  36 |  1600/ 2983 batches | lr 0.02 | ms/batch 58.32 | loss  3.88 | ppl    48.64
| prune-epoch  36 |  1800/ 2983 batches | lr 0.02 | ms/batch 58.38 | loss  3.81 | ppl    45.29
| prune-epoch  36 |  2000/ 2983 batches | lr 0.02 | ms/batch 58.33 | loss  3.83 | ppl    46.25
| prune-epoch  36 |  2200/ 2983 batches | lr 0.02 | ms/batch 58.35 | loss  3.70 | ppl    40.38
| prune-epoch  36 |  2400/ 2983 batches | lr 0.02 | ms/batch 58.33 | loss  3.72 | ppl    41.35
| prune-epoch  36 |  2600/ 2983 batches | lr 0.02 | ms/batch 58.36 | loss  3.77 | ppl    43.57
| prune-epoch  36 |  2800/ 2983 batches | lr 0.02 | ms/batch 58.39 | loss  3.74 | ppl    41.91
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  36 | time: 181.34s | valid loss  4.53 | valid ppl    93.12
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  37 |   200/ 2983 batches | lr 0.02 | ms/batch 60.41 | loss  3.87 | ppl    47.73
| prune-epoch  37 |   400/ 2983 batches | lr 0.02 | ms/batch 58.48 | loss  3.89 | ppl    48.84
| prune-epoch  37 |   600/ 2983 batches | lr 0.02 | ms/batch 58.39 | loss  3.71 | ppl    41.02
| prune-epoch  37 |   800/ 2983 batches | lr 0.02 | ms/batch 58.46 | loss  3.78 | ppl    43.74
| prune-epoch  37 |  1000/ 2983 batches | lr 0.02 | ms/batch 58.43 | loss  3.81 | ppl    44.95
| prune-epoch  37 |  1200/ 2983 batches | lr 0.02 | ms/batch 58.50 | loss  3.80 | ppl    44.81
| prune-epoch  37 |  1400/ 2983 batches | lr 0.02 | ms/batch 58.44 | loss  3.83 | ppl    45.92
| prune-epoch  37 |  1600/ 2983 batches | lr 0.02 | ms/batch 58.43 | loss  3.88 | ppl    48.52
| prune-epoch  37 |  1800/ 2983 batches | lr 0.02 | ms/batch 58.42 | loss  3.82 | ppl    45.51
| prune-epoch  37 |  2000/ 2983 batches | lr 0.02 | ms/batch 58.44 | loss  3.83 | ppl    45.95
| prune-epoch  37 |  2200/ 2983 batches | lr 0.02 | ms/batch 58.43 | loss  3.69 | ppl    40.06
| prune-epoch  37 |  2400/ 2983 batches | lr 0.02 | ms/batch 58.45 | loss  3.72 | ppl    41.24
| prune-epoch  37 |  2600/ 2983 batches | lr 0.02 | ms/batch 58.43 | loss  3.78 | ppl    43.64
| prune-epoch  37 |  2800/ 2983 batches | lr 0.02 | ms/batch 58.41 | loss  3.74 | ppl    42.15
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  37 | time: 181.59s | valid loss  4.53 | valid ppl    93.11
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  38 |   200/ 2983 batches | lr 0.02 | ms/batch 59.93 | loss  3.87 | ppl    47.72
| prune-epoch  38 |   400/ 2983 batches | lr 0.02 | ms/batch 57.97 | loss  3.89 | ppl    48.73
| prune-epoch  38 |   600/ 2983 batches | lr 0.02 | ms/batch 57.98 | loss  3.71 | ppl    40.69
| prune-epoch  38 |   800/ 2983 batches | lr 0.02 | ms/batch 58.01 | loss  3.78 | ppl    43.64
| prune-epoch  38 |  1000/ 2983 batches | lr 0.02 | ms/batch 57.97 | loss  3.81 | ppl    45.09
| prune-epoch  38 |  1200/ 2983 batches | lr 0.02 | ms/batch 57.98 | loss  3.80 | ppl    44.78
| prune-epoch  38 |  1400/ 2983 batches | lr 0.02 | ms/batch 57.97 | loss  3.84 | ppl    46.32
| prune-epoch  38 |  1600/ 2983 batches | lr 0.02 | ms/batch 57.96 | loss  3.88 | ppl    48.19
| prune-epoch  38 |  1800/ 2983 batches | lr 0.02 | ms/batch 57.95 | loss  3.81 | ppl    44.98
| prune-epoch  38 |  2000/ 2983 batches | lr 0.02 | ms/batch 57.94 | loss  3.83 | ppl    45.91
| prune-epoch  38 |  2200/ 2983 batches | lr 0.02 | ms/batch 58.00 | loss  3.69 | ppl    40.18
| prune-epoch  38 |  2400/ 2983 batches | lr 0.02 | ms/batch 57.98 | loss  3.72 | ppl    41.40
| prune-epoch  38 |  2600/ 2983 batches | lr 0.02 | ms/batch 57.99 | loss  3.78 | ppl    43.90
| prune-epoch  38 |  2800/ 2983 batches | lr 0.02 | ms/batch 57.93 | loss  3.73 | ppl    41.80
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  38 | time: 180.18s | valid loss  4.53 | valid ppl    93.12
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  39 |   200/ 2983 batches | lr 0.02 | ms/batch 60.43 | loss  3.87 | ppl    47.94
| prune-epoch  39 |   400/ 2983 batches | lr 0.02 | ms/batch 58.63 | loss  3.89 | ppl    48.74
| prune-epoch  39 |   600/ 2983 batches | lr 0.02 | ms/batch 58.60 | loss  3.71 | ppl    40.78
| prune-epoch  39 |   800/ 2983 batches | lr 0.02 | ms/batch 58.60 | loss  3.78 | ppl    43.96
| prune-epoch  39 |  1000/ 2983 batches | lr 0.02 | ms/batch 58.50 | loss  3.80 | ppl    44.84
| prune-epoch  39 |  1200/ 2983 batches | lr 0.02 | ms/batch 58.48 | loss  3.80 | ppl    44.70
| prune-epoch  39 |  1400/ 2983 batches | lr 0.02 | ms/batch 58.54 | loss  3.83 | ppl    46.14
| prune-epoch  39 |  1600/ 2983 batches | lr 0.02 | ms/batch 58.52 | loss  3.88 | ppl    48.55
| prune-epoch  39 |  1800/ 2983 batches | lr 0.02 | ms/batch 58.55 | loss  3.82 | ppl    45.47
| prune-epoch  39 |  2000/ 2983 batches | lr 0.02 | ms/batch 58.56 | loss  3.83 | ppl    45.90
| prune-epoch  39 |  2200/ 2983 batches | lr 0.02 | ms/batch 58.51 | loss  3.70 | ppl    40.47
| prune-epoch  39 |  2400/ 2983 batches | lr 0.02 | ms/batch 58.51 | loss  3.72 | ppl    41.22
| prune-epoch  39 |  2600/ 2983 batches | lr 0.02 | ms/batch 58.51 | loss  3.77 | ppl    43.56
| prune-epoch  39 |  2800/ 2983 batches | lr 0.02 | ms/batch 58.52 | loss  3.73 | ppl    41.87
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  39 | time: 181.85s | valid loss  4.53 | valid ppl    93.12
-----------------------------------------------------------------------------------------
begin prun train
| prune-epoch  40 |   200/ 2983 batches | lr 0.00 | ms/batch 60.23 | loss  3.87 | ppl    47.88
| prune-epoch  40 |   400/ 2983 batches | lr 0.00 | ms/batch 58.31 | loss  3.89 | ppl    49.02
| prune-epoch  40 |   600/ 2983 batches | lr 0.00 | ms/batch 58.41 | loss  3.72 | ppl    41.07
| prune-epoch  40 |   800/ 2983 batches | lr 0.00 | ms/batch 58.40 | loss  3.79 | ppl    44.43
| prune-epoch  40 |  1000/ 2983 batches | lr 0.00 | ms/batch 58.40 | loss  3.82 | ppl    45.38
| prune-epoch  40 |  1200/ 2983 batches | lr 0.00 | ms/batch 58.40 | loss  3.81 | ppl    45.15
| prune-epoch  40 |  1400/ 2983 batches | lr 0.00 | ms/batch 58.34 | loss  3.84 | ppl    46.71
| prune-epoch  40 |  1600/ 2983 batches | lr 0.00 | ms/batch 58.38 | loss  3.88 | ppl    48.66
| prune-epoch  40 |  1800/ 2983 batches | lr 0.00 | ms/batch 58.35 | loss  3.82 | ppl    45.41
| prune-epoch  40 |  2000/ 2983 batches | lr 0.00 | ms/batch 58.37 | loss  3.83 | ppl    46.20
| prune-epoch  40 |  2200/ 2983 batches | lr 0.00 | ms/batch 58.36 | loss  3.70 | ppl    40.53
| prune-epoch  40 |  2400/ 2983 batches | lr 0.00 | ms/batch 58.41 | loss  3.73 | ppl    41.48
| prune-epoch  40 |  2600/ 2983 batches | lr 0.00 | ms/batch 58.30 | loss  3.78 | ppl    43.79
| prune-epoch  40 |  2800/ 2983 batches | lr 0.00 | ms/batch 58.39 | loss  3.73 | ppl    41.67
end prun train
weight_ih_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l0        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_ih_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
weight_hh_l1        shape torch.Size([6000, 1500])
       expected sp:  0.9  actual sp:  0.8993333333333333
-----------------------------------------------------------------------------------------
| end of retrain epoch  40 | time: 181.34s | valid loss  4.53 | valid ppl    93.11
-----------------------------------------------------------------------------------------
required epochs  40 | actual epochs  53
pretrain epochs   0 | prune epochs  13 | retrain epochs  40
=========================================================================================
| End of training | test loss  4.49 | test ppl    88.94
=========================================================================================
